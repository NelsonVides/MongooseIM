{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"MongooseIM platform Home: http://github.com/esl/MongooseIM Product page: https://www.erlang-solutions.com/products/mongooseim.html Documentation: https://mongooseim.readthedocs.org/ Get to know MongooseIM MongooseIM is a robust and efficient chat (or instant messaging) platform aimed at large installations. Designed for enterprise, it is fault-tolerant, can utilise the resources of multiple clustered machines, and easily scales for more capacity by simply adding a box or VM. MongooseIM can accept client sessions over vanilla XMPP, REST API and SSE, as well as Websockets, and BOSH (HTTP long-polling). As a platform, MongooseIM includes several server-side (backend) and client-side (frontend) components. We provide a test suite, metrics, a load testing platform, and a monitoring server. We recommend third-party, open source client libraries for XMPP and REST API. MongooseIM is brought to you by Erlang Solutions . MongooseIM platform components Server-side components We offer a set of server-side components: WombatOAM is a powerful monitoring platform that comes with a dedicated MongooseIM plugin Test suite - here are some useful tools to test and validate your XMPP servers: escalus : Erlang XMPP client amoc : a load testing tools MongooseICE : is a STUN and TURN server written for traversing NATs and relaying streams MongoosePush : is a flexible push notification server with APNS and FCM support Client-side components XMPP client libraries - we recommend the following client libraries: iOS, Objective-C: XMPPframework Android, Java: Smack Web, JavaScript: Stanza.io , Strophe.js REST API client libraries - we recommend following client libraries: iOS, Swift: Jayme Android, Java: Retrofit Download packages For a quick start just download: The pre-built packages that suit your platform (Ubuntu, Debian, CentOS, and macOS) The Docker image : https://hub.docker.com/r/mongooseim/mongooseim/ (source code repository: https://github.com/esl/mongooseim-docker ) Public testing Check out our test results: Continuous integration: https://travis-ci.org/esl/MongooseIM Code coverage: https://codecov.io/gh/esl/MongooseIM Continuous Load Testing: http://tide.erlang-solutions.com/ Load test history: Versions See the documentation for the latest releases: Master 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 2.2.2 2.1.1 2.1.0 2.0.1 2.0.0 1.6.2 1.6.1 1.6.0 When developing new features/modules, please make sure you add basic documentation to the doc/ directory, and add a link to your document in doc/README.md. Participate! Suggestions, questions, thoughts? Contact us directly: Raise a GitHub issue : https://github.com/esl/MongooseIM/issues Email us at mongoose-im@erlang-solutions.com Follow our Twitter account : https://twitter.com/MongooseIM Like our Facebook page : https://www.facebook.com/MongooseIM/ Subscribe to our mailing list at https://groups.google.com/d/forum/mongooseim-announce to receive no more than two montly emails as well as access to the free and open archives.","title":"Home"},{"location":"#mongooseim-platform","text":"Home: http://github.com/esl/MongooseIM Product page: https://www.erlang-solutions.com/products/mongooseim.html Documentation: https://mongooseim.readthedocs.org/","title":"MongooseIM platform"},{"location":"#get-to-know-mongooseim","text":"MongooseIM is a robust and efficient chat (or instant messaging) platform aimed at large installations. Designed for enterprise, it is fault-tolerant, can utilise the resources of multiple clustered machines, and easily scales for more capacity by simply adding a box or VM. MongooseIM can accept client sessions over vanilla XMPP, REST API and SSE, as well as Websockets, and BOSH (HTTP long-polling). As a platform, MongooseIM includes several server-side (backend) and client-side (frontend) components. We provide a test suite, metrics, a load testing platform, and a monitoring server. We recommend third-party, open source client libraries for XMPP and REST API. MongooseIM is brought to you by Erlang Solutions .","title":"Get to know MongooseIM"},{"location":"#mongooseim-platform-components","text":"","title":"MongooseIM platform components"},{"location":"#server-side-components","text":"We offer a set of server-side components: WombatOAM is a powerful monitoring platform that comes with a dedicated MongooseIM plugin Test suite - here are some useful tools to test and validate your XMPP servers: escalus : Erlang XMPP client amoc : a load testing tools MongooseICE : is a STUN and TURN server written for traversing NATs and relaying streams MongoosePush : is a flexible push notification server with APNS and FCM support","title":"Server-side components"},{"location":"#client-side-components","text":"XMPP client libraries - we recommend the following client libraries: iOS, Objective-C: XMPPframework Android, Java: Smack Web, JavaScript: Stanza.io , Strophe.js REST API client libraries - we recommend following client libraries: iOS, Swift: Jayme Android, Java: Retrofit","title":"Client-side components"},{"location":"#download-packages","text":"For a quick start just download: The pre-built packages that suit your platform (Ubuntu, Debian, CentOS, and macOS) The Docker image : https://hub.docker.com/r/mongooseim/mongooseim/ (source code repository: https://github.com/esl/mongooseim-docker )","title":"Download packages"},{"location":"#public-testing","text":"Check out our test results: Continuous integration: https://travis-ci.org/esl/MongooseIM Code coverage: https://codecov.io/gh/esl/MongooseIM Continuous Load Testing: http://tide.erlang-solutions.com/ Load test history:","title":"Public testing"},{"location":"#versions","text":"See the documentation for the latest releases: Master 3.5.0 3.4.0 3.3.0 3.2.0 3.1.0 3.0.0 2.2.2 2.1.1 2.1.0 2.0.1 2.0.0 1.6.2 1.6.1 1.6.0 When developing new features/modules, please make sure you add basic documentation to the doc/ directory, and add a link to your document in doc/README.md.","title":"Versions"},{"location":"#participate","text":"Suggestions, questions, thoughts? Contact us directly: Raise a GitHub issue : https://github.com/esl/MongooseIM/issues Email us at mongoose-im@erlang-solutions.com Follow our Twitter account : https://twitter.com/MongooseIM Like our Facebook page : https://www.facebook.com/MongooseIM/ Subscribe to our mailing list at https://groups.google.com/d/forum/mongooseim-announce to receive no more than two montly emails as well as access to the free and open archives.","title":"Participate!"},{"location":"Advanced-configuration/","text":"For advanced configuration use the following files: mongooseim.cfg for pure MongooseIM settings, vm.args to affect the Erlang VM behaviour (performance tuning, node name), app.config to change low-level logging parameters and settings of other Erlang applications. Since you've gotten this far, we assume you're already familiar with Erlang syntax. mongooseim.cfg This file consists of multiple erlang tuples terminated with a period. In order to configure it, go to [MongooseIM repo root]/rel/files/ (if you're building from source) or [MongooseIM install root]/etc/ if you're using a pre-built version. The tuple order is important, unless no host_config option is set. Retaining the default layout is recommended so that the experienced MongooseIM users can smoothly traverse the file. mongooseim.cfg is full of useful comments and in most cases they should be sufficient help in changing the configuration. Options All options except hosts , host , host_config , listen and outgoing_connections may be used in the host_config tuple. There are two kinds of local options - those that are kept separately for each domain in the config file (defined inside host_config ) and the options local for a node in the cluster. \"global\" options are shared by all cluster nodes and all domains. Options labeled as \"multi\" (in this page) can be declared multiple times in a row, e.g. one per domain. Section names below correspond with the ones in the file. Override stored options override_global, override_local, override_acls - optional Description: Will cause MongooseIM to erase all global/local/acl options in database respectively. This ensures that ALL settings of a specific type will be reloaded on startup. Debugging loglevel (local) Description: Log level configured with an integer: 0 (disabled), 1 (critical), 2 (error), 3 (warning), 4 (info), 5 (debug). Recommended values for production systems are 2 or 3 (5 is for development). Served hostnames hosts (global) Description: List of domains supported by this cluster. Warning: Extension modules and database backends will be started separately for every domain. When increasing the number of domains please make sure you have enough resources available (e.g. connection limit set in DBMS). Example: [\"localhost\", \"domain2\"] route_subdomain (local) Description: If a stanza is addressed to a subdomain of the served domain and this option is set to s2s , such a stanza will be transmitted over s2s. Without it, MongooseIM will try to route the stanza to one of the internal services. Note: s2s is the only valid value. Any other will simply disable the feature. Listening ports listen (local) Description: List of modules handling the incoming connections. By default, 3 are enabled: ejabberd_cowboy , ejabberd_c2s and ejabberd_s2s_in . They accept XMPP, BOSH, Websocket and S2S connections (plus queries to metrics API). Syntax: List of tuples: {Port, Module, ModuleSpecificOptions} See also: Listener modules s2s_use_starttls (global) Description: Controls StartTLS feature for S2S connections. Values: false optional required required_trusted - uses OpenSSL's function SSL_get_verify_result s2s_certfile (global) Description: Path to X509 PEM file with a certificate and a private key inside (not protected by any password). Required if s2s_use_starttls is enabled. s2s_ciphers (global) Description: Defines a list of accepted SSL ciphers in outgoing S2S connection. Please refer to the OpenSSL documentation for the cipher string format. Default: \"TLSv1.2:TLSv1.3\" domain_certfile (multi, global) Description: Overrides common certificates with new ones specific for chosen XMPP domains. Applies to S2S and C2S connections. Syntax: {domain_certfile, \"example.com\", \"/path/to/example.com.pem\"}. s2s_default_policy (local) Description: Default policy for a new S2S (server-to-server) both incoming and outgoing connection to/from an unknown remote server. s2s_host (multi, local) Description: Allows black/whitelisting S2S destinations. Syntax: { {s2s_host, \"somehost.com\"}, allow|deny }. outgoing_s2s_port (local) Description: Defines a port to be used for outgoing S2S connections. Cannot be random. Default: 5269 s2s_addr (multi, global) Description: Override DNS lookup for a specific non-local XMPP domain and use a predefined server IP and port for S2S connection. Syntax: \"{ {s2s_addr, \\\"some-domain\\\"}, { {10,20,30,40}, 7890 } }.\" outgoing_s2s_options (global) Description: Specifies the order of address families to try when establishing S2S connection and the connection timeout (in milliseconds or atom infinity ). Default: {outgoing_s2s_options, [ipv4, ipv6], 10000}. Family values: inet4 / ipv4 , inet6 / ipv6 s2s_shared (global) Description: S2S shared secret used in Server Dialback extension. Syntax: {s2s_shared, <<\"shared secret\">>} . Default: 10 strong random bytes, hex-encoded. s2s_dns_options (local) Description: Parameters used in DNS lookups for outgoing S2S connections. Syntax: {s2s_dns_options, [{Opt, Val}, ...]}. Supported options timeout (integer, seconds, default: 10) - A timeout for DNS lookup. retries (integer, default: 2) - How many DNS lookups will be attempted. Example: {s2s_dns_options, [{timeout, 30}, {retries, 1}]}. s2s_max_retry_delay (local) Description: How many seconds MIM node should wait until next attempt to connect to remote XMPP cluster. Syntax: {s2s_max_retry_delay, Delay}. Default: 300 Example: {s2s_max_retry_delay, 30}. Session backend sm_backend (global) Description: Backend for storing user session data. Currently all nodes in a cluster must have access to a complete session database. Valid backends are mnesia and redis . Mnesia is sufficient in most cases, use Redis only in large deployments when you notice issues with the mnesia backend. Mnesia: {sm_backend, {mnesia, []}} Redis: {sm_backend, {redis, []}} Requires redis pool defined in outgoing_pools : {redis, global, default, ..., ...} . See redis section in outgoing connections doc Authentication auth_method (local) Description: Chooses an authentication module or a list of modules. Modules from the list are queried one after another until one of them replies positively. Valid values: internal (Mnesia), rdbms , external , anonymous , ldap , jwt , riak , http , pki Warning: Authentication backends support only specific SASL mechanisms, see auth backends capabilities . Examples: rdbms , [internal, anonymous] auth_opts (local) Description: Provides different parameters that will be applied to a choosen authentication method. auth_password_format and auth_scram_iterations are common to http , rdbms , internal and riak . auth_password_format Description: Decide whether user passwords will be kept plain or hashed in the database. Currently the popular XMPP clients support the SCRAM method, so it is strongly recommended to use the hashed version. The older ones can still use PLAIN mechiansm. DIGEST-MD5 is not available with scram . Values: plain , scram Default: plain (for compatibility reasons, might change soon) auth_scram_iterations Description: Hash function round count. The higher the value, the more difficult breaking the hashes is. We advise against setting it too low. Default: 4096 external backend options http backend options jwt backend options ldap backend options sasl_mechanisms (local) Description: Specifies a list of allowed SASL mechanisms. It affects the methods announced during stream negotiation and is enforced eventually (user can't pick mechanism not listed here but available in the source code). Warning: This list is still filtered by auth backends capabilities Valid values: cyrsasl_plain, cyrsasl_digest, cyrsasl_scram, cyrsasl_anonymous, cyrsasl_oauth, cyrsasl_external Default: [cyrsasl_plain, cyrsasl_digest, cyrsasl_scram, cyrsasl_anonymous, cyrsasl_oauth, cyrsasl_external] Examples: [cyrsasl_plain] , [cyrsasl_anonymous, cyrsasl_scram] extauth_instances (local) Description: Specifies a number of workers serving external authentication requests. Syntax: {extauth_instances, Count}. Default: 1 Authentication backend capabilities The table below shows the supported SASL mechanisms for each authentication backend module. cyrsasl plain cyrsasl digest cyrsasl scram cyrsasl anonymous cyrsasl external internal x x x rdbms x x x external x anonymous x x x x ldap x x jwt x riak x x x http x x x pki x cyrsasl_oauth does not use the auth backends at all and requires the mod_auth_token module enabled instead. Outgoing connections setup outgoing_pools (local) Description Declares pools for outgoing connections. See more in outgoing connections configuration Syntax [{Type, Host, Tag, PoolOptions, ConnectionOptions}] Example : [{riak, global, default, [], [{address, \"127.0.0.1\"}]}, {http, host, auth, [], [{server, \"127.0.0.1\"}]} RDBMS connection setup RDBMS connection pools are set using outgoing connections configuration . There are some additional options that influence all database connections in the server: pgsql_users_number_estimate (local) Description: PostgreSQL's internal structure can make the row counting slow. Enabling this option uses alternative query to SELECT COUNT , that might be not as accurate but is always fast. Syntax: {pgsql_users_number_estimate, false | true} Default: false rdbms_server_type (local) Description: Specifies RDBMS type. Some modules may optimise queries for certain DBs (e.g. mod_mam_rdbms_user uses different query for mssql ). Syntax: {rdbms_server_type, Type} Supported values: mssql , pgsql or undefined Default: undefined Traffic shapers shaper (mutli, global) Description: Define a class of a shaper which is a mechanism for limiting traffic to prevent DoS attack or calming down too noisy clients. Syntax: {shaper, AtomName, {maxrate, BytesPerSecond}} max_fsm_queue (local) Description: When enabled, will terminate certain processes (e.g. client handlers) that exceed message limit, to prevent resource exhaustion. This option is set for C2S, outgoing S2S and component connections and can be overridden for particular ejabberd_s2s or ejabberd_service listeners in their configurations. Use with caution! Syntax: {max_fsm_queue, MaxFsmQueueLength} Access control lists acl (multi) Description: Define access control list class. Syntax: {acl, AtomName, Definition} Regexp format: Syntax for _regexp can be found in Erlang documentation - it's based on AWK syntax. For _glob use sh regexp syntax. Valid definitions: all {user, U} - check if the username equals U and the domain either equals the one specified by the module executing the check or (if the module does a global check) is on the served domains list ( hosts option) {user, U, S} - check if the username equals U and the domain equals S {server, S} - check if the domain equals S {resource, R} - check if the resource equals R {user_regexp, UR} - perform a regular expression UR check on the username and check the server name like in user {user_regexp, UR, S} - perform a regular expression UR check on the username and check if the domain equals S {server_regexp, SR} - perform a regular expression SR check on a domain {resource_regexp, RR} - perform a regular expression SR check on a resource {node_regexp, UR, SR} - username must match UR and domain must match SR {user_glob, UR} - like _regexp variant but with sh syntax {server_glob, UR} - like _regexp variant but with sh syntax {resource_glob, UR} - like _regexp variant but with sh syntax {node_glob, UR} - like _regexp variant but with sh syntax Access rules access (multi, global) Description: Define an access rule for internal checks. The configuration file contains all built-in ones with proper comments. Syntax: {access, AtomName, [{Value, AclName}]} registration_timeout (local) Description: Limits the registration frequency from a single IP. Valid values are infinity or a number of seconds. mongooseimctl_access_commands (local) Description: Defines access rules to chosen mongooseimctl commands. Syntax: {mongooseimctl_access_commands, [Rule1, Rule2, ...]}. Rule syntax: {AccessRule, Commands, ArgumentRestrictions} AccessRule - A name of a rule defined with acl config key. Commands - A list of command names (e.g. [\"restart\", \"stop\"] ) or all . ArgumentRestrictions - A list of permitted argument values (e.g. [{domain, \"localhost\"}] ). Example: {mongooseimctl_access_commands, [{local, [\"join_cluster\"], [{node, \"mongooseim@prime\"}]}]}. Default language language (global) Description: Default language for messages sent by the server to users. You can get a full list of supported codes by executing cd [MongooseIM root] ; ls priv/*.msg | awk '{split($0,a,\"/\"); split(a[4],b,\".\"); print b[1]}' ( en is not listed there) Default: en Miscellaneous all_metrics_are_global (local) Description: When enabled, all per-host metrics are merged into global equivalents. It means it is no longer possible to view individual host1, host2, host3, ... metrics, only sums are available. This option significantly reduces CPU and (especially) memory footprint in setups with exceptionally many domains (thousands, tens of thousands). Default: false routing_modules (local) Description: Provides an ordered list of modules used for routing messages. If one of the modules accepts packet for processing, the remaining ones are not called. Syntax: {routing_modules, ModulesList}. Valid modules: mongoose_router_global - Calls filter_packet hook. mongoose_router_localdomain - Routes packets addressed to a domain supported by the local cluster. mongoose_router_external_localnode - Delivers packet to an XMPP component connected to the node, which processes the request. mongoose_router_external - Delivers packet to an XMPP component connected to the local cluster. ejabberd_s2s - Forwards a packet to another XMPP cluster over XMPP Federation. Default: [mongoose_router_global, mongoose_router_localdomain, mongoose_router_external_localnode, mongoose_router_external, ejabberd_s2s] Example: {routing_modules, [mongoose_router_global, mongoose_router_localdomain]}. replaced_wait_timeout (local) Description: When a user session is replaced (due to a full JID conflict) by a new one, this parameter specifies the time MongooseIM waits for the old sessions to close. The default value is sufficient in most cases. If you observe replaced_wait_timeout warning in logs, then most probably the old sessions are frozen for some reason and it should be investigated. Syntax: {replaced_wait_timeout, TimeInMilliseconds} Default: 2000 cowboy_server_name (local) Description: If configured, replaces Cowboy's default name returned in the server HTTP response header. It may be used for extra security, as it makes it harder for the malicious user to learn what HTTP software is running under a specific port. This option applies to all listeners started by the ejabberd_cowboy module. Syntax: {cowboy_server_name, NewName} Default: no value, i.e. Cowboy is used as a header value Example: {cowboy_server_name, \"Apache\"} Modules For a specific configuration, please refer to Modules page. modules (local) Description: List of enabled modules with their options. Services For a specific configuration, please refer to Services page. services (local) Description: List of enabled services with their options. Per-domain configuration The host_config allows configuring most options separately for specific domains served by the cluster. It is best to put host_config tuple right after the global section it overrides/complements or even at the end of mongooseim.cfg . host_config (multi, local) Syntax: {host_config, Domain, [ {{add, modules}, [{mod_some, Opts}]}, {access, c2s, [{deny, local}]}, ... ]}. vm.args This file contains parameters passed directly to the Erlang VM. To configure it, go to [MongooseIM root]/rel/files/ . Let's explore the default options. Options -sname - Erlang node name. Can be changed to name , if necessary -setcookie - Erlang cookie. All nodes in a cluster must use the same cookie value. +K - Enables kernel polling. It improves the stability when a large number of sockets is opened, but some systems might benefit from disabling it. Might be a subject of individual load testing. +A 5 - Sets the asynchronous threads number. Async threads improve I/O operations efficiency by relieving scheduler threads of IO waits. +P 10000000 - Process count limit. This is a maximum allowed number of processes running per node. In general, it should exceed the tripled estimated online user count. -env ERL_MAX_PORTS 250000 - Open port count. This is a maximum allowed number of ports opened per node. In general, it should exceed the tripled estimated online user count. Keep in mind that increasing this number also increases the memory usage by a constant amount, so finding the right balance for it is important for every project. -env ERL_FULLSWEEP_AFTER 2 - affects garbage collection. Reduces memory consumption (forces often full g.c.) at the expense of CPU usage. -sasl sasl_error_logger false - MongooseIM's solution for logging is Lager, so SASL error logger is disabled. app.config A file with Erlang application configuration. To configure it, go to [MongooseIM root]/rel/files/ . By default only the following applications can be found there: lager - check Lager's documentation for more information. Here you can change the logs location and the file names ( file ), as well as the rotation strategy ( size and count ) and date formatting ( date ). Ignore the log level parameters - by default they are overridden with the value set in mongooseim.cfg . ejabberd keep_lager_intact (default: false ) - set it to true when you want to keep lager log level parameters from app.config . false means overriding the log levels with the value set in mongooseim.cfg . config (default: \"etc/mongooseim.cfg\" ) - path to MongooseIM config file. ssl session_lifetime (default specified in the file: 600 seconds) - This parameter says for how long should the ssl session remain in the cache for further re-use, should ssl session resumption happen. Configuring TLS: Certificates & Keys TLS is configured in one of two ways: some modules need a private key and certificate (chain) in separate files, while others need both in a single file. This is because recent additions use OTP's ssl library, while older modules use p1_tls , respectively. Client-to-server connections need both in the same .pem file Server-to-server connections need both in the same .pem file BOSH, WebSockets and REST APIs need them in separate files In order to create private key & certificate bundle, you may simply concatenate them. More information about configuring TLS for these endpoints is available in Listener modules page.","title":"Advanced Configuration"},{"location":"Advanced-configuration/#mongooseimcfg","text":"This file consists of multiple erlang tuples terminated with a period. In order to configure it, go to [MongooseIM repo root]/rel/files/ (if you're building from source) or [MongooseIM install root]/etc/ if you're using a pre-built version. The tuple order is important, unless no host_config option is set. Retaining the default layout is recommended so that the experienced MongooseIM users can smoothly traverse the file. mongooseim.cfg is full of useful comments and in most cases they should be sufficient help in changing the configuration.","title":"mongooseim.cfg"},{"location":"Advanced-configuration/#options","text":"All options except hosts , host , host_config , listen and outgoing_connections may be used in the host_config tuple. There are two kinds of local options - those that are kept separately for each domain in the config file (defined inside host_config ) and the options local for a node in the cluster. \"global\" options are shared by all cluster nodes and all domains. Options labeled as \"multi\" (in this page) can be declared multiple times in a row, e.g. one per domain. Section names below correspond with the ones in the file.","title":"Options"},{"location":"Advanced-configuration/#override-stored-options","text":"override_global, override_local, override_acls - optional Description: Will cause MongooseIM to erase all global/local/acl options in database respectively. This ensures that ALL settings of a specific type will be reloaded on startup.","title":"Override stored options"},{"location":"Advanced-configuration/#debugging","text":"loglevel (local) Description: Log level configured with an integer: 0 (disabled), 1 (critical), 2 (error), 3 (warning), 4 (info), 5 (debug). Recommended values for production systems are 2 or 3 (5 is for development).","title":"Debugging"},{"location":"Advanced-configuration/#served-hostnames","text":"hosts (global) Description: List of domains supported by this cluster. Warning: Extension modules and database backends will be started separately for every domain. When increasing the number of domains please make sure you have enough resources available (e.g. connection limit set in DBMS). Example: [\"localhost\", \"domain2\"] route_subdomain (local) Description: If a stanza is addressed to a subdomain of the served domain and this option is set to s2s , such a stanza will be transmitted over s2s. Without it, MongooseIM will try to route the stanza to one of the internal services. Note: s2s is the only valid value. Any other will simply disable the feature.","title":"Served hostnames"},{"location":"Advanced-configuration/#listening-ports","text":"listen (local) Description: List of modules handling the incoming connections. By default, 3 are enabled: ejabberd_cowboy , ejabberd_c2s and ejabberd_s2s_in . They accept XMPP, BOSH, Websocket and S2S connections (plus queries to metrics API). Syntax: List of tuples: {Port, Module, ModuleSpecificOptions} See also: Listener modules s2s_use_starttls (global) Description: Controls StartTLS feature for S2S connections. Values: false optional required required_trusted - uses OpenSSL's function SSL_get_verify_result s2s_certfile (global) Description: Path to X509 PEM file with a certificate and a private key inside (not protected by any password). Required if s2s_use_starttls is enabled. s2s_ciphers (global) Description: Defines a list of accepted SSL ciphers in outgoing S2S connection. Please refer to the OpenSSL documentation for the cipher string format. Default: \"TLSv1.2:TLSv1.3\" domain_certfile (multi, global) Description: Overrides common certificates with new ones specific for chosen XMPP domains. Applies to S2S and C2S connections. Syntax: {domain_certfile, \"example.com\", \"/path/to/example.com.pem\"}. s2s_default_policy (local) Description: Default policy for a new S2S (server-to-server) both incoming and outgoing connection to/from an unknown remote server. s2s_host (multi, local) Description: Allows black/whitelisting S2S destinations. Syntax: { {s2s_host, \"somehost.com\"}, allow|deny }. outgoing_s2s_port (local) Description: Defines a port to be used for outgoing S2S connections. Cannot be random. Default: 5269 s2s_addr (multi, global) Description: Override DNS lookup for a specific non-local XMPP domain and use a predefined server IP and port for S2S connection. Syntax: \"{ {s2s_addr, \\\"some-domain\\\"}, { {10,20,30,40}, 7890 } }.\" outgoing_s2s_options (global) Description: Specifies the order of address families to try when establishing S2S connection and the connection timeout (in milliseconds or atom infinity ). Default: {outgoing_s2s_options, [ipv4, ipv6], 10000}. Family values: inet4 / ipv4 , inet6 / ipv6 s2s_shared (global) Description: S2S shared secret used in Server Dialback extension. Syntax: {s2s_shared, <<\"shared secret\">>} . Default: 10 strong random bytes, hex-encoded. s2s_dns_options (local) Description: Parameters used in DNS lookups for outgoing S2S connections. Syntax: {s2s_dns_options, [{Opt, Val}, ...]}. Supported options timeout (integer, seconds, default: 10) - A timeout for DNS lookup. retries (integer, default: 2) - How many DNS lookups will be attempted. Example: {s2s_dns_options, [{timeout, 30}, {retries, 1}]}. s2s_max_retry_delay (local) Description: How many seconds MIM node should wait until next attempt to connect to remote XMPP cluster. Syntax: {s2s_max_retry_delay, Delay}. Default: 300 Example: {s2s_max_retry_delay, 30}.","title":"Listening ports"},{"location":"Advanced-configuration/#session-backend","text":"sm_backend (global) Description: Backend for storing user session data. Currently all nodes in a cluster must have access to a complete session database. Valid backends are mnesia and redis . Mnesia is sufficient in most cases, use Redis only in large deployments when you notice issues with the mnesia backend. Mnesia: {sm_backend, {mnesia, []}} Redis: {sm_backend, {redis, []}} Requires redis pool defined in outgoing_pools : {redis, global, default, ..., ...} . See redis section in outgoing connections doc","title":"Session backend"},{"location":"Advanced-configuration/#authentication","text":"auth_method (local) Description: Chooses an authentication module or a list of modules. Modules from the list are queried one after another until one of them replies positively. Valid values: internal (Mnesia), rdbms , external , anonymous , ldap , jwt , riak , http , pki Warning: Authentication backends support only specific SASL mechanisms, see auth backends capabilities . Examples: rdbms , [internal, anonymous] auth_opts (local) Description: Provides different parameters that will be applied to a choosen authentication method. auth_password_format and auth_scram_iterations are common to http , rdbms , internal and riak . auth_password_format Description: Decide whether user passwords will be kept plain or hashed in the database. Currently the popular XMPP clients support the SCRAM method, so it is strongly recommended to use the hashed version. The older ones can still use PLAIN mechiansm. DIGEST-MD5 is not available with scram . Values: plain , scram Default: plain (for compatibility reasons, might change soon) auth_scram_iterations Description: Hash function round count. The higher the value, the more difficult breaking the hashes is. We advise against setting it too low. Default: 4096 external backend options http backend options jwt backend options ldap backend options sasl_mechanisms (local) Description: Specifies a list of allowed SASL mechanisms. It affects the methods announced during stream negotiation and is enforced eventually (user can't pick mechanism not listed here but available in the source code). Warning: This list is still filtered by auth backends capabilities Valid values: cyrsasl_plain, cyrsasl_digest, cyrsasl_scram, cyrsasl_anonymous, cyrsasl_oauth, cyrsasl_external Default: [cyrsasl_plain, cyrsasl_digest, cyrsasl_scram, cyrsasl_anonymous, cyrsasl_oauth, cyrsasl_external] Examples: [cyrsasl_plain] , [cyrsasl_anonymous, cyrsasl_scram] extauth_instances (local) Description: Specifies a number of workers serving external authentication requests. Syntax: {extauth_instances, Count}. Default: 1","title":"Authentication"},{"location":"Advanced-configuration/#authentication-backend-capabilities","text":"The table below shows the supported SASL mechanisms for each authentication backend module. cyrsasl plain cyrsasl digest cyrsasl scram cyrsasl anonymous cyrsasl external internal x x x rdbms x x x external x anonymous x x x x ldap x x jwt x riak x x x http x x x pki x cyrsasl_oauth does not use the auth backends at all and requires the mod_auth_token module enabled instead.","title":"Authentication backend capabilities"},{"location":"Advanced-configuration/#outgoing-connections-setup","text":"outgoing_pools (local) Description Declares pools for outgoing connections. See more in outgoing connections configuration Syntax [{Type, Host, Tag, PoolOptions, ConnectionOptions}] Example : [{riak, global, default, [], [{address, \"127.0.0.1\"}]}, {http, host, auth, [], [{server, \"127.0.0.1\"}]}","title":"Outgoing connections setup"},{"location":"Advanced-configuration/#rdbms-connection-setup","text":"RDBMS connection pools are set using outgoing connections configuration . There are some additional options that influence all database connections in the server: pgsql_users_number_estimate (local) Description: PostgreSQL's internal structure can make the row counting slow. Enabling this option uses alternative query to SELECT COUNT , that might be not as accurate but is always fast. Syntax: {pgsql_users_number_estimate, false | true} Default: false rdbms_server_type (local) Description: Specifies RDBMS type. Some modules may optimise queries for certain DBs (e.g. mod_mam_rdbms_user uses different query for mssql ). Syntax: {rdbms_server_type, Type} Supported values: mssql , pgsql or undefined Default: undefined","title":"RDBMS connection setup"},{"location":"Advanced-configuration/#traffic-shapers","text":"shaper (mutli, global) Description: Define a class of a shaper which is a mechanism for limiting traffic to prevent DoS attack or calming down too noisy clients. Syntax: {shaper, AtomName, {maxrate, BytesPerSecond}} max_fsm_queue (local) Description: When enabled, will terminate certain processes (e.g. client handlers) that exceed message limit, to prevent resource exhaustion. This option is set for C2S, outgoing S2S and component connections and can be overridden for particular ejabberd_s2s or ejabberd_service listeners in their configurations. Use with caution! Syntax: {max_fsm_queue, MaxFsmQueueLength}","title":"Traffic shapers"},{"location":"Advanced-configuration/#access-control-lists","text":"acl (multi) Description: Define access control list class. Syntax: {acl, AtomName, Definition} Regexp format: Syntax for _regexp can be found in Erlang documentation - it's based on AWK syntax. For _glob use sh regexp syntax. Valid definitions: all {user, U} - check if the username equals U and the domain either equals the one specified by the module executing the check or (if the module does a global check) is on the served domains list ( hosts option) {user, U, S} - check if the username equals U and the domain equals S {server, S} - check if the domain equals S {resource, R} - check if the resource equals R {user_regexp, UR} - perform a regular expression UR check on the username and check the server name like in user {user_regexp, UR, S} - perform a regular expression UR check on the username and check if the domain equals S {server_regexp, SR} - perform a regular expression SR check on a domain {resource_regexp, RR} - perform a regular expression SR check on a resource {node_regexp, UR, SR} - username must match UR and domain must match SR {user_glob, UR} - like _regexp variant but with sh syntax {server_glob, UR} - like _regexp variant but with sh syntax {resource_glob, UR} - like _regexp variant but with sh syntax {node_glob, UR} - like _regexp variant but with sh syntax","title":"Access control lists"},{"location":"Advanced-configuration/#access-rules","text":"access (multi, global) Description: Define an access rule for internal checks. The configuration file contains all built-in ones with proper comments. Syntax: {access, AtomName, [{Value, AclName}]} registration_timeout (local) Description: Limits the registration frequency from a single IP. Valid values are infinity or a number of seconds. mongooseimctl_access_commands (local) Description: Defines access rules to chosen mongooseimctl commands. Syntax: {mongooseimctl_access_commands, [Rule1, Rule2, ...]}. Rule syntax: {AccessRule, Commands, ArgumentRestrictions} AccessRule - A name of a rule defined with acl config key. Commands - A list of command names (e.g. [\"restart\", \"stop\"] ) or all . ArgumentRestrictions - A list of permitted argument values (e.g. [{domain, \"localhost\"}] ). Example: {mongooseimctl_access_commands, [{local, [\"join_cluster\"], [{node, \"mongooseim@prime\"}]}]}.","title":"Access rules"},{"location":"Advanced-configuration/#default-language","text":"language (global) Description: Default language for messages sent by the server to users. You can get a full list of supported codes by executing cd [MongooseIM root] ; ls priv/*.msg | awk '{split($0,a,\"/\"); split(a[4],b,\".\"); print b[1]}' ( en is not listed there) Default: en","title":"Default language"},{"location":"Advanced-configuration/#miscellaneous","text":"all_metrics_are_global (local) Description: When enabled, all per-host metrics are merged into global equivalents. It means it is no longer possible to view individual host1, host2, host3, ... metrics, only sums are available. This option significantly reduces CPU and (especially) memory footprint in setups with exceptionally many domains (thousands, tens of thousands). Default: false routing_modules (local) Description: Provides an ordered list of modules used for routing messages. If one of the modules accepts packet for processing, the remaining ones are not called. Syntax: {routing_modules, ModulesList}. Valid modules: mongoose_router_global - Calls filter_packet hook. mongoose_router_localdomain - Routes packets addressed to a domain supported by the local cluster. mongoose_router_external_localnode - Delivers packet to an XMPP component connected to the node, which processes the request. mongoose_router_external - Delivers packet to an XMPP component connected to the local cluster. ejabberd_s2s - Forwards a packet to another XMPP cluster over XMPP Federation. Default: [mongoose_router_global, mongoose_router_localdomain, mongoose_router_external_localnode, mongoose_router_external, ejabberd_s2s] Example: {routing_modules, [mongoose_router_global, mongoose_router_localdomain]}. replaced_wait_timeout (local) Description: When a user session is replaced (due to a full JID conflict) by a new one, this parameter specifies the time MongooseIM waits for the old sessions to close. The default value is sufficient in most cases. If you observe replaced_wait_timeout warning in logs, then most probably the old sessions are frozen for some reason and it should be investigated. Syntax: {replaced_wait_timeout, TimeInMilliseconds} Default: 2000 cowboy_server_name (local) Description: If configured, replaces Cowboy's default name returned in the server HTTP response header. It may be used for extra security, as it makes it harder for the malicious user to learn what HTTP software is running under a specific port. This option applies to all listeners started by the ejabberd_cowboy module. Syntax: {cowboy_server_name, NewName} Default: no value, i.e. Cowboy is used as a header value Example: {cowboy_server_name, \"Apache\"}","title":"Miscellaneous"},{"location":"Advanced-configuration/#modules","text":"For a specific configuration, please refer to Modules page. modules (local) Description: List of enabled modules with their options.","title":"Modules"},{"location":"Advanced-configuration/#services","text":"For a specific configuration, please refer to Services page. services (local) Description: List of enabled services with their options.","title":"Services"},{"location":"Advanced-configuration/#per-domain-configuration","text":"The host_config allows configuring most options separately for specific domains served by the cluster. It is best to put host_config tuple right after the global section it overrides/complements or even at the end of mongooseim.cfg . host_config (multi, local) Syntax: {host_config, Domain, [ {{add, modules}, [{mod_some, Opts}]}, {access, c2s, [{deny, local}]}, ... ]}.","title":"Per-domain configuration"},{"location":"Advanced-configuration/#vmargs","text":"This file contains parameters passed directly to the Erlang VM. To configure it, go to [MongooseIM root]/rel/files/ . Let's explore the default options.","title":"vm.args"},{"location":"Advanced-configuration/#options_1","text":"-sname - Erlang node name. Can be changed to name , if necessary -setcookie - Erlang cookie. All nodes in a cluster must use the same cookie value. +K - Enables kernel polling. It improves the stability when a large number of sockets is opened, but some systems might benefit from disabling it. Might be a subject of individual load testing. +A 5 - Sets the asynchronous threads number. Async threads improve I/O operations efficiency by relieving scheduler threads of IO waits. +P 10000000 - Process count limit. This is a maximum allowed number of processes running per node. In general, it should exceed the tripled estimated online user count. -env ERL_MAX_PORTS 250000 - Open port count. This is a maximum allowed number of ports opened per node. In general, it should exceed the tripled estimated online user count. Keep in mind that increasing this number also increases the memory usage by a constant amount, so finding the right balance for it is important for every project. -env ERL_FULLSWEEP_AFTER 2 - affects garbage collection. Reduces memory consumption (forces often full g.c.) at the expense of CPU usage. -sasl sasl_error_logger false - MongooseIM's solution for logging is Lager, so SASL error logger is disabled.","title":"Options"},{"location":"Advanced-configuration/#appconfig","text":"A file with Erlang application configuration. To configure it, go to [MongooseIM root]/rel/files/ . By default only the following applications can be found there: lager - check Lager's documentation for more information. Here you can change the logs location and the file names ( file ), as well as the rotation strategy ( size and count ) and date formatting ( date ). Ignore the log level parameters - by default they are overridden with the value set in mongooseim.cfg . ejabberd keep_lager_intact (default: false ) - set it to true when you want to keep lager log level parameters from app.config . false means overriding the log levels with the value set in mongooseim.cfg . config (default: \"etc/mongooseim.cfg\" ) - path to MongooseIM config file. ssl session_lifetime (default specified in the file: 600 seconds) - This parameter says for how long should the ssl session remain in the cache for further re-use, should ssl session resumption happen.","title":"app.config"},{"location":"Advanced-configuration/#configuring-tls-certificates-keys","text":"TLS is configured in one of two ways: some modules need a private key and certificate (chain) in separate files, while others need both in a single file. This is because recent additions use OTP's ssl library, while older modules use p1_tls , respectively. Client-to-server connections need both in the same .pem file Server-to-server connections need both in the same .pem file BOSH, WebSockets and REST APIs need them in separate files In order to create private key & certificate bundle, you may simply concatenate them. More information about configuring TLS for these endpoints is available in Listener modules page.","title":"Configuring TLS: Certificates &amp; Keys"},{"location":"Basic-configuration/","text":"vars.config The vars.config file can be found under the [MongooseIM root]/rel/ directory. Change the most important settings quickly and without touching mongooseim.cfg or vm.args files directly. Recommended for basic usage. The file contains erlang tuples terminated with period ('.'). For users not familiar with Erlang syntax, here is a quick cheat sheet: Each config option (key and value) is a tuple. Tuples are (Erlangers, forgive us the simplification) other Erlang terms separated with commas and enclosed in curly brackets ({}). Tuples (at least the top-level ones) in vars.config are always 2-element. The first element of each tuple is the name (Erlang atom). The file contains all possible keys so you will never have to change the first element or add new tuple. The second element is a string (in quotes: \"\"). Remeber to escape quote with backslash ('\\') if you ever use one inside a string. A value can be a list. Erlang lists are other Erlang terms separated with commas and enclosed in square brackets ([]). If a value is terminated with a period (e.g. acl ) or a comma (e.g. mod_privacy ), don't change it. Config options that are \"features\", can be disabled by using empty string as the value or prepending the actual value with '%' ('%' starts one-line comment in Erlang, like '//' in C or Java). Options There are 2 types of options: params and features. Unlike params, features can be disabled. hosts - param Description: List of supported XMPP domains. Usually it's best to stick with just one or two domains. Warning: extension modules and database backends will be started separately for every domain, so when increasing the number of domains please make sure you have enough resources available (e.g. connection limit set in DBMS). Example: \"[\\\"localhost\\\", \\\"domain2\\\"]\" host_config - feature Description: List of specific options for chosen XMPP domains. They will override the global ones. Allowed keys are marked on the Advanced configuration page Syntax: \"{host_config, \\\"overridden-domain\\\", [{key, value}]}.\" Example: \"{host_config, \\\"localhost2\\\", [{auth_method, anonymous}, {allow_multiple_connections, false}]}.\" auth_ldap - feature Description: Put [[LDAP configuration]] here. all_metrics_are_global - param Description: When set to 'true', per-host metrics are replaced with global equivalents. For more info consult Advanced configuration s2s_addr - feature Description: Override DNS lookup for specific non-local XMPP domain and use predefined server IP and port for S2S connection (server-to-server). Syntax: \"{ {s2s_addr, \\\"some-domain\\\"}, { {10,20,30,40}, 7890 } }.\" s2s_default_policy - param Description: Default policy for new S2S (server-to-server) both incoming and outgoing connection to/from unknown remote server. outgoing_s2s_port - param Description: Port to be used locally when establishing outgoing S2S (server-to-server) connection. Default is 5269. node_name - param Description: Erlang node name. Should be changed when deploying MongooseIM cluster, otherwise not relevant. c2s_port - param Description: Port to listen on for standard incoming XMPP connections. Default is 5222. s2s_port - param Description: Port to listen on for incoming S2S (server-to-server) connections. Default is 5269. cowboy_port - param Description: Port for all HTTP-based MongooseIM services like BOSH or Websockets. Default is 5280. mod_last, mod_offline, mod_privacy, mod_private, mod_roster, mod_vcard, mod_snmp - feature Description: Allows enabling/disabling specific modules and configuring them. Read more on the Modules page. sm_backend - param Description: Defines the session management module (session storage backend). Valid values: mnesia , redis auth_method - param Description: Chooses authentication modules. Can be either a single module or a list of modules to be tried in sequence until one of them succeeds. Valid values: internal , rdbms , external , anonymous , ldap , riak internal means Mnesia-based Examples: \"rdbms\" , \"[internal, anonymous]\" ext_auth_script - feature Description: Path to the authentication script used by external auth module. Script API specification can be found in [[External authentication script]]. tls_config - feature Description: Allows enabling the StartTLS feature in client-to-server XMPP connections. Just remove '%%' prefix and set path to the PEM file containing certificate and (not protected by password) private key in X.509 format. zlib - feature Description: Controls the zlib compression feature for client-to-server XMPP connections. To enable it, remove '%%' prefix. You can define a limit for output data size to prevent killing the server with zlib bomb . Set it to unlimited to bypass the check ( not recommended ).","title":"Basic Configuration"},{"location":"Basic-configuration/#varsconfig","text":"The vars.config file can be found under the [MongooseIM root]/rel/ directory. Change the most important settings quickly and without touching mongooseim.cfg or vm.args files directly. Recommended for basic usage. The file contains erlang tuples terminated with period ('.'). For users not familiar with Erlang syntax, here is a quick cheat sheet: Each config option (key and value) is a tuple. Tuples are (Erlangers, forgive us the simplification) other Erlang terms separated with commas and enclosed in curly brackets ({}). Tuples (at least the top-level ones) in vars.config are always 2-element. The first element of each tuple is the name (Erlang atom). The file contains all possible keys so you will never have to change the first element or add new tuple. The second element is a string (in quotes: \"\"). Remeber to escape quote with backslash ('\\') if you ever use one inside a string. A value can be a list. Erlang lists are other Erlang terms separated with commas and enclosed in square brackets ([]). If a value is terminated with a period (e.g. acl ) or a comma (e.g. mod_privacy ), don't change it. Config options that are \"features\", can be disabled by using empty string as the value or prepending the actual value with '%' ('%' starts one-line comment in Erlang, like '//' in C or Java).","title":"vars.config"},{"location":"Basic-configuration/#options","text":"There are 2 types of options: params and features. Unlike params, features can be disabled. hosts - param Description: List of supported XMPP domains. Usually it's best to stick with just one or two domains. Warning: extension modules and database backends will be started separately for every domain, so when increasing the number of domains please make sure you have enough resources available (e.g. connection limit set in DBMS). Example: \"[\\\"localhost\\\", \\\"domain2\\\"]\" host_config - feature Description: List of specific options for chosen XMPP domains. They will override the global ones. Allowed keys are marked on the Advanced configuration page Syntax: \"{host_config, \\\"overridden-domain\\\", [{key, value}]}.\" Example: \"{host_config, \\\"localhost2\\\", [{auth_method, anonymous}, {allow_multiple_connections, false}]}.\" auth_ldap - feature Description: Put [[LDAP configuration]] here. all_metrics_are_global - param Description: When set to 'true', per-host metrics are replaced with global equivalents. For more info consult Advanced configuration s2s_addr - feature Description: Override DNS lookup for specific non-local XMPP domain and use predefined server IP and port for S2S connection (server-to-server). Syntax: \"{ {s2s_addr, \\\"some-domain\\\"}, { {10,20,30,40}, 7890 } }.\" s2s_default_policy - param Description: Default policy for new S2S (server-to-server) both incoming and outgoing connection to/from unknown remote server. outgoing_s2s_port - param Description: Port to be used locally when establishing outgoing S2S (server-to-server) connection. Default is 5269. node_name - param Description: Erlang node name. Should be changed when deploying MongooseIM cluster, otherwise not relevant. c2s_port - param Description: Port to listen on for standard incoming XMPP connections. Default is 5222. s2s_port - param Description: Port to listen on for incoming S2S (server-to-server) connections. Default is 5269. cowboy_port - param Description: Port for all HTTP-based MongooseIM services like BOSH or Websockets. Default is 5280. mod_last, mod_offline, mod_privacy, mod_private, mod_roster, mod_vcard, mod_snmp - feature Description: Allows enabling/disabling specific modules and configuring them. Read more on the Modules page. sm_backend - param Description: Defines the session management module (session storage backend). Valid values: mnesia , redis auth_method - param Description: Chooses authentication modules. Can be either a single module or a list of modules to be tried in sequence until one of them succeeds. Valid values: internal , rdbms , external , anonymous , ldap , riak internal means Mnesia-based Examples: \"rdbms\" , \"[internal, anonymous]\" ext_auth_script - feature Description: Path to the authentication script used by external auth module. Script API specification can be found in [[External authentication script]]. tls_config - feature Description: Allows enabling the StartTLS feature in client-to-server XMPP connections. Just remove '%%' prefix and set path to the PEM file containing certificate and (not protected by password) private key in X.509 format. zlib - feature Description: Controls the zlib compression feature for client-to-server XMPP connections. To enable it, remove '%%' prefix. You can define a limit for output data size to prevent killing the server with zlib bomb . Set it to unlimited to bypass the check ( not recommended ).","title":"Options"},{"location":"Contributions/","text":"Our contributions to the ecosystem. Third-party opensource projects XMPPframework for iOS Available on: robbiehanson/XMPPFramework XEP-0363: HTTP File Upload XEP-0313: Message Archive Management XEP-0030: Service Discovery MUC light Token-based reconnection Revamped README: making people feel like this is a well mantained and up to date framework Created a way to Mock a piece of the framework to improve the way we write tests Smack for Android Available on: igniterealtime/Smack XEP-0357: Push Notifications XEP-0191: Blocking Command XEP-0313: Message Archive Management XEP-0308: Last Message Correction MUC light Token-based reconnection Instant Stream Resumption XEP-0231: Bits of Binary XEP-0333: Chat Markers MAM documentation Movim See movim/movim on GitHub for more details. Docker image for Movim: https://github.com/esl/movim-docker Software by Erlang Solutions escalus See esl/escalus on GitHub for more details. An XMPP client library in Erlang for conveniently testing XMPP servers Apache license 2.0 amoc See esl/amoc on GitHub for more details. amoc is a simple tool for running massively parallel XMPP tests Apache license 2.0 Note: amoc stands for \"A Murder of Crows\" exml See esl/exml on GitHub for more details. XML parsing library in Erlang Apache license 2.0 MongooseICE: ICE (STUN/TURN) server See MongooseICE on GitHub for more details. MongoosePush: Push notifications server (APNS/FCM) See MongoosePush on GitHub for more details. Open standards MUC light MUC stands for Multi-User Chat. MUC light is a presenceless and subscription-based group chat, relying on a simplified version of MUC. Token-based reconnection Token-based reconnection (TBR) Reconnection mechanism, for temporary disconnections, using tokens instead of passwords","title":"Contributions to ecosystem"},{"location":"Contributions/#third-party-opensource-projects","text":"","title":"Third-party opensource projects"},{"location":"Contributions/#xmppframework-for-ios","text":"Available on: robbiehanson/XMPPFramework XEP-0363: HTTP File Upload XEP-0313: Message Archive Management XEP-0030: Service Discovery MUC light Token-based reconnection Revamped README: making people feel like this is a well mantained and up to date framework Created a way to Mock a piece of the framework to improve the way we write tests","title":"XMPPframework for iOS"},{"location":"Contributions/#smack-for-android","text":"Available on: igniterealtime/Smack XEP-0357: Push Notifications XEP-0191: Blocking Command XEP-0313: Message Archive Management XEP-0308: Last Message Correction MUC light Token-based reconnection Instant Stream Resumption XEP-0231: Bits of Binary XEP-0333: Chat Markers MAM documentation","title":"Smack for Android"},{"location":"Contributions/#movim","text":"See movim/movim on GitHub for more details. Docker image for Movim: https://github.com/esl/movim-docker","title":"Movim"},{"location":"Contributions/#software-by-erlang-solutions","text":"","title":"Software by Erlang Solutions"},{"location":"Contributions/#escalus","text":"See esl/escalus on GitHub for more details. An XMPP client library in Erlang for conveniently testing XMPP servers Apache license 2.0","title":"escalus"},{"location":"Contributions/#amoc","text":"See esl/amoc on GitHub for more details. amoc is a simple tool for running massively parallel XMPP tests Apache license 2.0 Note: amoc stands for \"A Murder of Crows\"","title":"amoc"},{"location":"Contributions/#exml","text":"See esl/exml on GitHub for more details. XML parsing library in Erlang Apache license 2.0","title":"exml"},{"location":"Contributions/#mongooseice-ice-stunturn-server","text":"See MongooseICE on GitHub for more details.","title":"MongooseICE: ICE (STUN/TURN) server"},{"location":"Contributions/#mongoosepush-push-notifications-server-apnsfcm","text":"See MongoosePush on GitHub for more details.","title":"MongoosePush: Push notifications server (APNS/FCM)"},{"location":"Contributions/#open-standards","text":"","title":"Open standards"},{"location":"Contributions/#muc-light","text":"MUC stands for Multi-User Chat. MUC light is a presenceless and subscription-based group chat, relying on a simplified version of MUC.","title":"MUC light"},{"location":"Contributions/#token-based-reconnection","text":"Token-based reconnection (TBR) Reconnection mechanism, for temporary disconnections, using tokens instead of passwords","title":"Token-based reconnection"},{"location":"Differentiators/","text":"Differentiators MongooseIM provides: Massive scalability: for greater and faster growth, costs-effectiveness as well as resource utilisation Platform approach: designed with consistency, end-to-end battle testing across the whole ecosystem (all server and client components, and tools) Code quality: extensive refactoring, substantial optimisations, continuous integration and deployment Extensive testing: automated continuous functional code coverage, integration testing, end-to-end testing with real clients Continuous load testing Unique version: no proprietary extensions, fully open source, fully open standards Contributions to ( XMPP Standards Foundation ): implementations of XEPs, innovations contributed Professional support, and flexible customer service Contributions to third party open source codebases: strenghthening the ecosystem Initial differences from the parent project This project began its life as a fork of ejabberd v.2.1.8 back in 2011, and later underwent major cleanup, refactoring and optimization. Major steps performed at the time: Bringing the project source tree to compliance with OTP project structure recommendations Swapping autotools for the Erlang community-standard build tool rebar Removal of obsolete and/or rarely used modules to reduce maintenance burden Reduction of runtime memory consumption by refactoring the code to use Erlang's binary data type for string manipulation and storage instead of operating on linked lists of characters Functional test coverage of the system according to corresponding RFCs and XEPs","title":"Differentiators"},{"location":"Differentiators/#differentiators","text":"MongooseIM provides: Massive scalability: for greater and faster growth, costs-effectiveness as well as resource utilisation Platform approach: designed with consistency, end-to-end battle testing across the whole ecosystem (all server and client components, and tools) Code quality: extensive refactoring, substantial optimisations, continuous integration and deployment Extensive testing: automated continuous functional code coverage, integration testing, end-to-end testing with real clients Continuous load testing Unique version: no proprietary extensions, fully open source, fully open standards Contributions to ( XMPP Standards Foundation ): implementations of XEPs, innovations contributed Professional support, and flexible customer service Contributions to third party open source codebases: strenghthening the ecosystem","title":"Differentiators"},{"location":"Differentiators/#initial-differences-from-the-parent-project","text":"This project began its life as a fork of ejabberd v.2.1.8 back in 2011, and later underwent major cleanup, refactoring and optimization. Major steps performed at the time: Bringing the project source tree to compliance with OTP project structure recommendations Swapping autotools for the Erlang community-standard build tool rebar Removal of obsolete and/or rarely used modules to reduce maintenance burden Reduction of runtime memory consumption by refactoring the code to use Erlang's binary data type for string manipulation and storage instead of operating on linked lists of characters Functional test coverage of the system according to corresponding RFCs and XEPs","title":"Initial differences from the parent project"},{"location":"Erlang-cookie-security/","text":"In order for MongooseIM nodes to communicate with each other, they have to share a common secret - i.e. a cookie - which is a feature of the underlying Erlang VM. The cookie itself is an UTF8 string that is up to 255 characters in size. Thanks to the cookie, MongooseIM nodes can determine if they are allowed to communicate with each other and with no cookie no communication would flow between the nodes - a feature especially useful when you are running more than one applications on a single machine. For ease of deployment and staging, each MongooseIM node is configured with a predefined erlang cookie. However, one should remember that for production environments this cookie should be reconfigured to a new secret cookie, as this will secure your system from intrusion. You can change the cookie by changing the parameters of the -setcookie parameter in the vm.args file. Nonetheless, one should remember that communication between Erlang nodes is unencrypted by default, hence, the cookie is vulnerable to sniffing. If one has access to a MongooseIM cookie and figures out the hostname of a node, one can execute shell commands remotely on that node. Therefore, one should either provide privacy at the network layer (strongly recommended) or disable port 4369 for ultimate security.","title":"Erlang Cookie Security"},{"location":"History/","text":"MongooseIM history 2011: Fork of ejabberd MongooseIM's birthplace is a private Erlang Solutions' branch of ProcessOne's ejabberd - an XMPP/Jabber server written in Erlang. What would later become a leading, highly customisable and scalable XMPP platform, originated in a strong idea - storing all internal strings in binaries instead of lists, among other significant improvements. The change was introduced in 0.1.0 proto-MongooseIM release and 3.0.0-alpha-X series of ejabberd. This opened the door for achieving higher performance, lower latency and introducing other subsequent improvements building up to a plaform we are truly proud of. 2012-2015: Fully independent project growing fast The next steps were achieving full OTP and rebar compliance, removal of obsolete and/or rarely used modules, reduction of the runtime memory consumption and functional test coverage. MongooseIM 1.0.0 was released on July 10th of 2012. MongooseIM XMPP server fully independently went through multiple versions, following its own path with its own resources: 1.1.x in 2012, 1.2.x in 2013, 1.3.x , 1.4.x , 1.5.x in 2014, and 1.6.x in 2015. 2016: Pivot to fullstack messaging platform MongooseIM Platform appeared in 2016, with the release of MongooseIM XMPP server 2.0.0 . The MongooseIM platform components were: MongooseIM XMPP server, featuring a unique REST API for client developers and MUC light WombatOAM, for monitoring and operations escalus, an Erlang XMPP client for test automation amoc, for load generation Smack for Android in Java (third party) XMPPFramework for iOS in Objective-C (third party) Retrofit by Square for Android in Java (third party) Jayme by Inaka for iOS in Swift 2017: Platform expansion and strengthening We also introduced some MongooseIM platform components that are independent of the XMPP server. So far the list includes: Mangosta iOS Mangosta Android MongoosePush MongooseICE 2018-2019: Planetary architecture, to welcome IoT-scale and chabots The next step on our journey with the MongooseIM platform is to enable building planetary scale architectures. This is necessary to welcome the massive influx of users that come with a full stack IoT and chatbot solution. The ability to connect robots and humans is the requirement of the next technological breakthrough. Erlang Solution's goal is to utilise XMPP features suited for chatbots, and build open standards for completeness of solution.","title":"History"},{"location":"History/#mongooseim-history","text":"","title":"MongooseIM history"},{"location":"History/#2011-fork-of-ejabberd","text":"MongooseIM's birthplace is a private Erlang Solutions' branch of ProcessOne's ejabberd - an XMPP/Jabber server written in Erlang. What would later become a leading, highly customisable and scalable XMPP platform, originated in a strong idea - storing all internal strings in binaries instead of lists, among other significant improvements. The change was introduced in 0.1.0 proto-MongooseIM release and 3.0.0-alpha-X series of ejabberd. This opened the door for achieving higher performance, lower latency and introducing other subsequent improvements building up to a plaform we are truly proud of.","title":"2011: Fork of ejabberd"},{"location":"History/#2012-2015-fully-independent-project-growing-fast","text":"The next steps were achieving full OTP and rebar compliance, removal of obsolete and/or rarely used modules, reduction of the runtime memory consumption and functional test coverage. MongooseIM 1.0.0 was released on July 10th of 2012. MongooseIM XMPP server fully independently went through multiple versions, following its own path with its own resources: 1.1.x in 2012, 1.2.x in 2013, 1.3.x , 1.4.x , 1.5.x in 2014, and 1.6.x in 2015.","title":"2012-2015: Fully independent project growing fast"},{"location":"History/#2016-pivot-to-fullstack-messaging-platform","text":"MongooseIM Platform appeared in 2016, with the release of MongooseIM XMPP server 2.0.0 . The MongooseIM platform components were: MongooseIM XMPP server, featuring a unique REST API for client developers and MUC light WombatOAM, for monitoring and operations escalus, an Erlang XMPP client for test automation amoc, for load generation Smack for Android in Java (third party) XMPPFramework for iOS in Objective-C (third party) Retrofit by Square for Android in Java (third party) Jayme by Inaka for iOS in Swift","title":"2016: Pivot to fullstack messaging platform"},{"location":"History/#2017-platform-expansion-and-strengthening","text":"We also introduced some MongooseIM platform components that are independent of the XMPP server. So far the list includes: Mangosta iOS Mangosta Android MongoosePush MongooseICE","title":"2017: Platform expansion and strengthening"},{"location":"History/#2018-2019-planetary-architecture-to-welcome-iot-scale-and-chabots","text":"The next step on our journey with the MongooseIM platform is to enable building planetary scale architectures. This is necessary to welcome the massive influx of users that come with a full stack IoT and chatbot solution. The ability to connect robots and humans is the requirement of the next technological breakthrough. Erlang Solution's goal is to utilise XMPP features suited for chatbots, and build open standards for completeness of solution.","title":"2018-2019: Planetary architecture, to welcome IoT-scale and chabots"},{"location":"advanced-configuration/Listener-modules/","text":"Some of the MongooseIM modules are specialised in handling user connections. They can be used in the listen clause in the mongooseim.cfg file. See this section for their description and configuration options. Options described with a value type (e.g. string, integer) are key-value tuples. Other options are enabled by being added as atoms. E.g. a tuple option might be: {access, c2s} while other options are added as: starttls . Client-to-server (C2S): ejabberd_c2s Handles pure XMPP client-to-server (C2S) connections, relies on ejabberd_listener for listening. It processes the incoming data from the user client, while the data reception and parsing is executed with ejabberd_receiver 's help. You only need to declare running ejabberd_c2s , to have the other 2 modules started and used. Default port: 5222 Configuration General access (atom, default: c2s ) - Access Rule to use for C2S connections. c2s_shaper (atom, default: none ) - Connection shaper to use for incoming C2S stanzas. max_stanza_size (positive integer, default: infinity) - Maximum allowed incoming stanza size. Warning: this limit is checked after the input data parsing, so it does not apply to the input data size itself. backlog (positive integer, default 100) - overrides the default TCP backlog value max_fsm_queue (positive integer, the value of this option set global) - message queue limit to prevent resource exhaustion; overrides the global value of this option hibernate_after (integer, default: 0) - Time in milliseconds after which a client process spawned by this listener will hibernate. Hibernation greatly reduces memory consumption of client processes, but may result in increased CPU consumption if a client is used very frequently. The default, recommended value of 0 means that the client processes will hibernate at every opportunity. acceptors_num (integer, default: 100) - For TCP-based listeners: the number of processes accepting new connections on the listening socket. zlib (atom or a positive integer, default: disabled) - Enables ZLIB support, the integer value is a limit for a decompressed output size (to prevent successful ZLIB bomb attack ); the limit can be disabled with an atom 'unlimited'. Common TLS options starttls (default: disabled) - Enables StartTLS support; requires certfile . starttls_required (default: disabled) - enforces StartTLS usage. tls (default: disabled) - When this option is set, clients must initiate a TLS session immediately after connecting, before beginning the normal XML stream. tls_module (atom, default: fast_tls ) - Provides a TLS library to use. fast_tls uses OpenSSL-based NIFs, while just_tls uses Erlang TLS implementation provided by OTP. They are fully interchangeable, with some exceptions ( ejabberd_c2s options supported by only one of them are explicitly described, e.g. crlfiles ). certfile (string, default: no certfile will be used) - Path to the X509 PEM file with a certificate and a private key (not protected by a password). If the certificate is signed by an intermediate CA, you should specify here the whole CA chain by concatenating all public keys together and appending the private key after that. cafile (string, default: no CA file will be used) - Path to the X509 PEM file with a CA chain that will be used to verify clients. Won't have any effect if verify_peer is not enabled. verify_peer (default: disabled) - Enforces verification of a client certificate. Requires a valid cafile . dhfile (string, default: no DH file will be used) - Path to the Diffie Hellman parameter file fast_tls - specific options ciphers (string, default: \"TLSv1.2:TLSv1.3\" ) - Cipher suites to use with StartTLS or TLS. Please refer to the OpenSSL documentation for the cipher string format. protocol_options List of OpenSSL options, the default value is [\"no_sslv2\", \"no_sslv3\", \"no_tlsv1, \"no_tlsv1_1\"] . You can find the mappings between supported options and actual OpenSSL flags in the fast_tls source code . just_tls - specific options crlfiles (list of strings, default: []) - A list of paths to Certificate Revocation Lists. HTTP-based services (BOSH, WebSocket, REST): ejabberd_cowboy Manages all HTTP-based services, such as BOSH (HTTP long-polling) and WebSocket. Unlike ejabberd_c2s , it doesn't use ejabberd_receiver or ejabberd_listener . Default port: 5280 Configuration ip (IP tuple, default: {0,0,0,0} ) - IP address to bind to. num_acceptors (positive integer, default: 100) - Number of acceptors. transport_options (proplist, default: []) - Ranch-specific transport options. See ranch:opt() . protocol_options (proplist, default: []) - Protocol configuration options for Cowboy. See Cowboy HTTP module docs . ssl (list of ssl options, required for https, no default value) - If specified, https will be used. Accepts all ranch_ssl options that don't take fun() parameters. Only certfile and keyfile are mandatory. See ranch_ssl documentation for details. A minimal usage would be as follows: {ssl, [ {certfile, \"priv/ssl/fake_cert.pem\"}, {keyfile, \"priv/ssl/fake_key.pem\"}, ]}, Here, certfile and keyfile specify the certificate and private key files respectively. If the keyfile is password-protected, one will need to specify the password with {password, \"secret\"} . If the certificate is signed by an intermediate CA, one will probably want to specify the CA chain with cacertfile option. Note that port , ip and max_connections are taken from the listener config above and will be ignored if specified under ssl . modules (list of tuples: {Host, Path, Modules} ) - List of enabled HTTP-based modules. \"_\" equals any host. mod_bosh - BOSH connections handler. Default declaration: `{\"_\", \"/http-bind\", mod_bosh}` mod_websockets - Websocket connections as defined in RFC 7395 . You can pass optional parameters: {timeout, Val} (positive integer, default: infinity) - the time after which an inactive user is disconnected. {ping_rate, Val} (positive integer, default: none) - the Ping rate points to the time between pings sent by server. By declaring this field you enable server-side pinging. {max_stanza_size, Val} (positive integer, default: infinity) - Maximum allowed incoming stanza size. Warning: this limit is checked after the input data parsing, so it does not apply to the input data size itself. {ejabberd_service, Params} (default: []) - this enables external component connections over WebSockets. See the ejabberd_service section for more details how to configure it. Default declaration: `{\"_\", \"/ws-xmpp\", mod_websockets, []}` (OBSOLETE) mongoose_api - REST API for accessing internal MongooseIM metrics. Please refer to the REST interface to metrics page for more information. Default declaration: `{\"localhost\", \"/api\", mongoose_api, [{handlers, [mongoose_api_metrics]}]}` mongoose_api_admin - REST API for admin commands. Exposes all mongoose_commands. It expects one optional argument: Credentials: {auth, {Username, Password}} . If they're not provided, authorization is disabled. Example: `{\"localhost\", \"/api\", mongoose_api_admin, [{auth, {<<\"ala\">>, <<\"makotaipsa\">>}}]}` mongoose_api_client - REST API for client side commands. Exposes all mongoose_commands marked as \"user\". Example: `{\"localhost\", \"/api/contacts/{:jid}\", mongoose_api_client_contacts, []}` HTTP module: mod_cowboy This module provides an additional routing layer on top of HTTP(s) or WS(S) protocols. It allows other HTTP/WS modules to coexist under the same URL on the single port. Packets are forwarded to them based on the protocol. This mechanism is transparent to actual handlers so the path sharing does not require any additional code. Example: If you wish, you can use BOSH and WS XMPP handlers (mod_bosh, mod_websockets) on a single port and a URL without any code modifications. Here's an example of its configuration (added to ejabberd_cowboy modules list described above): {\"_\", \"/[...]\", mod_cowboy, [{http, mod_revproxy, [{timeout, 5000}, % time limit for upstream to respond {body_length, 8000000}, % maximum body size (may be infinity) {custom_headers, [{<<\"header\">>,<<\"value\">>}]} % list of extra headers that are send to upstream ]}, {ws, xmpp, mod_websockets} ]}, According to this configuration, all HTTP requests will go through the mod_revproxy module (see mod_revproxy for more details). As for now, all WebSocket connections with the Sec-WebSocket-Protocol: xmpp header, will go through the mod_websockets connection. This is the MongooseIM's regular websocket connection handler. Server-to-server (S2S): ejabberd_s2s_in Handles incoming server-to-server (S2S) connections (federation). Relies on ejabberd_listener and ejabberd_receiver just like ejabberd_c2s . Note: Many S2S options are configured as top-level config options and they apply to both incoming and outgoing connections. Please refer to the Advanced configuration for more information. Default port: 5269 Configuration shaper (atom, default: none ) - Connection shaper to use for incoming S2S data. max_stanza_size (positive integer, default: infinity) - Maximum allowed incoming stanza size. Warning: this limit is checked after input data parsing, so it does not apply to the input data size itself. protocol_options List of supported SSL protocols, default \"no_sslv3\". It also accepts \"no_tlsv1\" and \"no_tlsv1_1\" dhfile (string, default: no DH file will be used) - Path to the Diffie Hellman parameter file ciphers (string, default: \"TLSv1.2:TLSv1.3\" ) - cipher suites to use with StartTLS. cafile (string, default: no CA file will be used) - Path to the X509 PEM file with a CA chain that will be used to verify clients (here server initiating S2S connection). XMPP components: ejabberd_service Interface for XMPP components ( XEP-0114: Jabber Component Protocol ), enabling communication between servers and \"external\" components over the XMPP network. Default port: 8888 Configuration access (atom, default: all ) - Access Rule to use for incoming component connections. password (string) - the service is protected with this password shaper_rule (atom, default: none ) - Connection shaper to use for incoming component traffic. service_check_from (boolean, default: true ) - Checks whether the server should verify the \"from\" field in stanzas from the component max_fsm_queue (positive integer, the value of this option set global) - message queue limit to prevent resource exhaustion; overrides the global value of this option hidden_components (boolean, default: false ) - All components connected to an endpoint with this option enabled will be considered \"hidden\" (see explanation below). conflict_behaviour ( disconnect , kick_old , default: disconnect ) - If set to kick_old , in case of a routing conflict it stops the previous connection (see the explanation below). According to ( XEP-0114: Jabber Component Protocol ) component's hostname should be given in the element. Custom extension to the protocol In order to register a component for all virtual hosts served by the server (listed in global variable hosts), the component must add the attribute is_subdomain=\"true\" to the opening stream element. This maybe helpful if someone wants to have a single instance of a component serving multiple virtual hosts. The is_subdomain attribute is optional and the default behaviour is as described in the XEP. Hidden components Hidden components have a special flag enabled in the internal component table. Alone, it doesn't change the server behaviour in any way, but it may be used by other modules and extensions to execute special logic. An example would be mod_disco , which may be configured to filter out hidden components from disco results, so they won't be discoverable by clients. A reason to do so could be reduced traffic - systems with many components could return very long disco responses. Also, some deployments would like to avoid revealing some services; not because it is a security threat (this method does not prevent clients from communicating with hidden components), but rather because they are not meant to interact with clients directly (e.g. helper components for other components). Conflict behaviour By default, when a component tries to connect and a registration conflict occures, we drop such connection by sending: <stream:error> <conflict xmlns='urn:ietf:params:xml:ns:xmpp-streams'/> </stream:error> </stream:stream> It makes implementing the reconnection logic difficult, because the old connection would not allow any other connections. By setting {conflict_behaviour, kick_old} , we drop any old connections registered at the same host, before accepting new ones.","title":"Listener Modules"},{"location":"advanced-configuration/Listener-modules/#client-to-server-c2s-ejabberd_c2s","text":"Handles pure XMPP client-to-server (C2S) connections, relies on ejabberd_listener for listening. It processes the incoming data from the user client, while the data reception and parsing is executed with ejabberd_receiver 's help. You only need to declare running ejabberd_c2s , to have the other 2 modules started and used. Default port: 5222","title":"Client-to-server (C2S): ejabberd_c2s"},{"location":"advanced-configuration/Listener-modules/#configuration","text":"","title":"Configuration"},{"location":"advanced-configuration/Listener-modules/#general","text":"access (atom, default: c2s ) - Access Rule to use for C2S connections. c2s_shaper (atom, default: none ) - Connection shaper to use for incoming C2S stanzas. max_stanza_size (positive integer, default: infinity) - Maximum allowed incoming stanza size. Warning: this limit is checked after the input data parsing, so it does not apply to the input data size itself. backlog (positive integer, default 100) - overrides the default TCP backlog value max_fsm_queue (positive integer, the value of this option set global) - message queue limit to prevent resource exhaustion; overrides the global value of this option hibernate_after (integer, default: 0) - Time in milliseconds after which a client process spawned by this listener will hibernate. Hibernation greatly reduces memory consumption of client processes, but may result in increased CPU consumption if a client is used very frequently. The default, recommended value of 0 means that the client processes will hibernate at every opportunity. acceptors_num (integer, default: 100) - For TCP-based listeners: the number of processes accepting new connections on the listening socket. zlib (atom or a positive integer, default: disabled) - Enables ZLIB support, the integer value is a limit for a decompressed output size (to prevent successful ZLIB bomb attack ); the limit can be disabled with an atom 'unlimited'.","title":"General"},{"location":"advanced-configuration/Listener-modules/#common-tls-options","text":"starttls (default: disabled) - Enables StartTLS support; requires certfile . starttls_required (default: disabled) - enforces StartTLS usage. tls (default: disabled) - When this option is set, clients must initiate a TLS session immediately after connecting, before beginning the normal XML stream. tls_module (atom, default: fast_tls ) - Provides a TLS library to use. fast_tls uses OpenSSL-based NIFs, while just_tls uses Erlang TLS implementation provided by OTP. They are fully interchangeable, with some exceptions ( ejabberd_c2s options supported by only one of them are explicitly described, e.g. crlfiles ). certfile (string, default: no certfile will be used) - Path to the X509 PEM file with a certificate and a private key (not protected by a password). If the certificate is signed by an intermediate CA, you should specify here the whole CA chain by concatenating all public keys together and appending the private key after that. cafile (string, default: no CA file will be used) - Path to the X509 PEM file with a CA chain that will be used to verify clients. Won't have any effect if verify_peer is not enabled. verify_peer (default: disabled) - Enforces verification of a client certificate. Requires a valid cafile . dhfile (string, default: no DH file will be used) - Path to the Diffie Hellman parameter file","title":"Common TLS options"},{"location":"advanced-configuration/Listener-modules/#fast_tls-specific-options","text":"ciphers (string, default: \"TLSv1.2:TLSv1.3\" ) - Cipher suites to use with StartTLS or TLS. Please refer to the OpenSSL documentation for the cipher string format. protocol_options List of OpenSSL options, the default value is [\"no_sslv2\", \"no_sslv3\", \"no_tlsv1, \"no_tlsv1_1\"] . You can find the mappings between supported options and actual OpenSSL flags in the fast_tls source code .","title":"fast_tls - specific options"},{"location":"advanced-configuration/Listener-modules/#just_tls-specific-options","text":"crlfiles (list of strings, default: []) - A list of paths to Certificate Revocation Lists.","title":"just_tls - specific options"},{"location":"advanced-configuration/Listener-modules/#http-based-services-bosh-websocket-rest-ejabberd_cowboy","text":"Manages all HTTP-based services, such as BOSH (HTTP long-polling) and WebSocket. Unlike ejabberd_c2s , it doesn't use ejabberd_receiver or ejabberd_listener . Default port: 5280","title":"HTTP-based services (BOSH, WebSocket, REST): ejabberd_cowboy"},{"location":"advanced-configuration/Listener-modules/#configuration_1","text":"ip (IP tuple, default: {0,0,0,0} ) - IP address to bind to. num_acceptors (positive integer, default: 100) - Number of acceptors. transport_options (proplist, default: []) - Ranch-specific transport options. See ranch:opt() . protocol_options (proplist, default: []) - Protocol configuration options for Cowboy. See Cowboy HTTP module docs . ssl (list of ssl options, required for https, no default value) - If specified, https will be used. Accepts all ranch_ssl options that don't take fun() parameters. Only certfile and keyfile are mandatory. See ranch_ssl documentation for details. A minimal usage would be as follows: {ssl, [ {certfile, \"priv/ssl/fake_cert.pem\"}, {keyfile, \"priv/ssl/fake_key.pem\"}, ]}, Here, certfile and keyfile specify the certificate and private key files respectively. If the keyfile is password-protected, one will need to specify the password with {password, \"secret\"} . If the certificate is signed by an intermediate CA, one will probably want to specify the CA chain with cacertfile option. Note that port , ip and max_connections are taken from the listener config above and will be ignored if specified under ssl . modules (list of tuples: {Host, Path, Modules} ) - List of enabled HTTP-based modules. \"_\" equals any host. mod_bosh - BOSH connections handler. Default declaration: `{\"_\", \"/http-bind\", mod_bosh}` mod_websockets - Websocket connections as defined in RFC 7395 . You can pass optional parameters: {timeout, Val} (positive integer, default: infinity) - the time after which an inactive user is disconnected. {ping_rate, Val} (positive integer, default: none) - the Ping rate points to the time between pings sent by server. By declaring this field you enable server-side pinging. {max_stanza_size, Val} (positive integer, default: infinity) - Maximum allowed incoming stanza size. Warning: this limit is checked after the input data parsing, so it does not apply to the input data size itself. {ejabberd_service, Params} (default: []) - this enables external component connections over WebSockets. See the ejabberd_service section for more details how to configure it. Default declaration: `{\"_\", \"/ws-xmpp\", mod_websockets, []}` (OBSOLETE) mongoose_api - REST API for accessing internal MongooseIM metrics. Please refer to the REST interface to metrics page for more information. Default declaration: `{\"localhost\", \"/api\", mongoose_api, [{handlers, [mongoose_api_metrics]}]}` mongoose_api_admin - REST API for admin commands. Exposes all mongoose_commands. It expects one optional argument: Credentials: {auth, {Username, Password}} . If they're not provided, authorization is disabled. Example: `{\"localhost\", \"/api\", mongoose_api_admin, [{auth, {<<\"ala\">>, <<\"makotaipsa\">>}}]}` mongoose_api_client - REST API for client side commands. Exposes all mongoose_commands marked as \"user\". Example: `{\"localhost\", \"/api/contacts/{:jid}\", mongoose_api_client_contacts, []}`","title":"Configuration"},{"location":"advanced-configuration/Listener-modules/#http-module-mod_cowboy","text":"This module provides an additional routing layer on top of HTTP(s) or WS(S) protocols. It allows other HTTP/WS modules to coexist under the same URL on the single port. Packets are forwarded to them based on the protocol. This mechanism is transparent to actual handlers so the path sharing does not require any additional code. Example: If you wish, you can use BOSH and WS XMPP handlers (mod_bosh, mod_websockets) on a single port and a URL without any code modifications. Here's an example of its configuration (added to ejabberd_cowboy modules list described above): {\"_\", \"/[...]\", mod_cowboy, [{http, mod_revproxy, [{timeout, 5000}, % time limit for upstream to respond {body_length, 8000000}, % maximum body size (may be infinity) {custom_headers, [{<<\"header\">>,<<\"value\">>}]} % list of extra headers that are send to upstream ]}, {ws, xmpp, mod_websockets} ]}, According to this configuration, all HTTP requests will go through the mod_revproxy module (see mod_revproxy for more details). As for now, all WebSocket connections with the Sec-WebSocket-Protocol: xmpp header, will go through the mod_websockets connection. This is the MongooseIM's regular websocket connection handler.","title":"HTTP module: mod_cowboy"},{"location":"advanced-configuration/Listener-modules/#server-to-server-s2s-ejabberd_s2s_in","text":"Handles incoming server-to-server (S2S) connections (federation). Relies on ejabberd_listener and ejabberd_receiver just like ejabberd_c2s . Note: Many S2S options are configured as top-level config options and they apply to both incoming and outgoing connections. Please refer to the Advanced configuration for more information. Default port: 5269","title":"Server-to-server (S2S): ejabberd_s2s_in"},{"location":"advanced-configuration/Listener-modules/#configuration_2","text":"shaper (atom, default: none ) - Connection shaper to use for incoming S2S data. max_stanza_size (positive integer, default: infinity) - Maximum allowed incoming stanza size. Warning: this limit is checked after input data parsing, so it does not apply to the input data size itself. protocol_options List of supported SSL protocols, default \"no_sslv3\". It also accepts \"no_tlsv1\" and \"no_tlsv1_1\" dhfile (string, default: no DH file will be used) - Path to the Diffie Hellman parameter file ciphers (string, default: \"TLSv1.2:TLSv1.3\" ) - cipher suites to use with StartTLS. cafile (string, default: no CA file will be used) - Path to the X509 PEM file with a CA chain that will be used to verify clients (here server initiating S2S connection).","title":"Configuration"},{"location":"advanced-configuration/Listener-modules/#xmpp-components-ejabberd_service","text":"Interface for XMPP components ( XEP-0114: Jabber Component Protocol ), enabling communication between servers and \"external\" components over the XMPP network. Default port: 8888","title":"XMPP components: ejabberd_service"},{"location":"advanced-configuration/Listener-modules/#configuration_3","text":"access (atom, default: all ) - Access Rule to use for incoming component connections. password (string) - the service is protected with this password shaper_rule (atom, default: none ) - Connection shaper to use for incoming component traffic. service_check_from (boolean, default: true ) - Checks whether the server should verify the \"from\" field in stanzas from the component max_fsm_queue (positive integer, the value of this option set global) - message queue limit to prevent resource exhaustion; overrides the global value of this option hidden_components (boolean, default: false ) - All components connected to an endpoint with this option enabled will be considered \"hidden\" (see explanation below). conflict_behaviour ( disconnect , kick_old , default: disconnect ) - If set to kick_old , in case of a routing conflict it stops the previous connection (see the explanation below). According to ( XEP-0114: Jabber Component Protocol ) component's hostname should be given in the element.","title":"Configuration"},{"location":"advanced-configuration/Listener-modules/#custom-extension-to-the-protocol","text":"In order to register a component for all virtual hosts served by the server (listed in global variable hosts), the component must add the attribute is_subdomain=\"true\" to the opening stream element. This maybe helpful if someone wants to have a single instance of a component serving multiple virtual hosts. The is_subdomain attribute is optional and the default behaviour is as described in the XEP.","title":"Custom extension to the protocol"},{"location":"advanced-configuration/Listener-modules/#hidden-components","text":"Hidden components have a special flag enabled in the internal component table. Alone, it doesn't change the server behaviour in any way, but it may be used by other modules and extensions to execute special logic. An example would be mod_disco , which may be configured to filter out hidden components from disco results, so they won't be discoverable by clients. A reason to do so could be reduced traffic - systems with many components could return very long disco responses. Also, some deployments would like to avoid revealing some services; not because it is a security threat (this method does not prevent clients from communicating with hidden components), but rather because they are not meant to interact with clients directly (e.g. helper components for other components).","title":"Hidden components"},{"location":"advanced-configuration/Listener-modules/#conflict-behaviour","text":"By default, when a component tries to connect and a registration conflict occures, we drop such connection by sending: <stream:error> <conflict xmlns='urn:ietf:params:xml:ns:xmpp-streams'/> </stream:error> </stream:stream> It makes implementing the reconnection logic difficult, because the old connection would not allow any other connections. By setting {conflict_behaviour, kick_old} , we drop any old connections registered at the same host, before accepting new ones.","title":"Conflict behaviour"},{"location":"advanced-configuration/Modules/","text":"MongooseIM provides a wide range of pluggable and configurable modules, that implement various features including XEPs. For instance mod_muc enables Multi-User Chat (group chat), mod_mam gives us Message Archive Management, and mod_stream_management is for stanza acknowledgement and stream resumption. This modular architecture provides great flexibility for everyday operations and feature development. A module configuration generally looks like this: {mod_muc, [ {host, \"muc.@HOST@\"}, {access, muc}, {access_create, muc_create} ]}, Module list Some of the modules feature an iqdisc parameter. It defines the method for handling incoming IQ stanzas. Please refer to [[IQ handlers]] for more information. Valid values: no_queue , one_queue , {queues, N} , parallel . Default: one_queue . mod_adhoc Implements XEP-0050: Ad-Hoc Commands for advertising and executing application-specific commands, such as those related to a configuration workflow, using XEP-0004: Data Forms in order to structure the information exchange. This is extremely useful for use cases such as remote administration, user engagement via polls, and ChatBots. mod_amp Implements a subset of XEP-0079: Advanced Message Processing functionality, that enables entities to request, and servers to perform advanced processing of XMPP message stanzas, including reliable data transport, time-sensitive delivery, and expiration of transient messages. mod_auth_token A module used by SASL X-OAUTH mechanism. It provides an API to manage custom OAuth tokens . It requires mod_keystore as an actual key database. mod_blocking Implements XEP-0191: Blocking Command , a simplified interface to privacy lists. mod_bosh Allows users to connect to MongooseIM using BOSH (Bidirectional-streams Over Synchronous HTTP), the HTTP long-polling technique described in XEP-0124: Bidirectional-streams Over Synchronous HTTP (BOSH) and XEP-0206: XMPP Over BOSH . mod_caps Implements XEP-0115 Entity Capabilities . It queries clients for their supported functionalities and caches them in Mnesia. This module tightly cooperates with mod_pubsub in order to deliver PEP events to user's subscribers. mod_carboncopy Implements XEP-0280: Message Carbons in order to keep all IM clients for a user engaged in a real-time conversation by carbon-copying all inbound and outbound messages to all interested resources (Full JIDs). mod_commands A central gateway providing access to a subset of MongooseIM functions by channels other than XMPP. Commands defined there are currently accessible via REST API. mod_csi Enables the XEP-0352: Client State Indication functionality. mod_disco Implements XEP-0030: Service Discovery for discovering information (capabilities, protocols, features) about other XMPP entities. mod_event_pusher A framework module to build other notification-based modules on. mod_event_pusher_sns Allows sending online/offline notifications, chat and groupchat messages as events to Amazon Simple Notification Service . mod_event_pusher_rabbit Allows sending presence changes (to available/unavailable), chat and groupchat messages as events to a RabbitMQ server. mod_event_pusher_push Implements XEP-0357 Push Notifiactions to provide push notifications to clients that are temporary unavailable. mod_event_pusher_http Forward events to an external HTTP service. This applies to situations such as sending messages or presences to mobile/SMS/email push service, big data, or an analytics service. mod_http_upload Implements XEP-0363: HTTP File Upload for coordinating with an XMPP server to upload files via HTTP and receive URLs that can be shared in messages. mod_inbox Implements custom inbox XEP mod_global_distrib Enables sharing a single XMPP domain between distinct datacenters ( experimental ). mod_jingle_sip Enables Jingle to SIP and SIP to Jingle translator. mod_keystore Serves as a storage for crypto keys for mod_auth_token . mod_last Implements XEP-0012: Last Activity) for communicating information about the last activity associated with an XMPP entity (most recent presence information from an offline contact). mod_mam Implements XEP-0313: Message Archive Management , that defines a protocol to query and control an archive of messages stored on a server. mod_muc Implements XEP-0045: Multi-User Chat) , for a featureful multi-user text chat (group chat), whereby multiple XMPP users can exchange messages in the context of a chat room. It is tightly coupled with user presence in chat rooms. mod_muc_commands Provides mod_muc related mongoose_commands , accessible via the client REST API. mod_muc_log Implements a logging subsystem for [mod_muc]. mod_muc_light Implements XEP Multi-User Chat Light . mod_muc_light_commands Provides mod_muc_light related mongoose_commands , accessible via client REST API. mod_offline Provides an offline messages storage that is compliant with XEP-0160: Best Practices for Handling Offline Messages) . mod_offline_stub Prevents <service-unavailable/> error when the message recipient is offline. mod_ping Implements XEP-0199 XMPP Ping , enabling periodic XMPP pings sent to clients and responds to those sent from clients. mod_privacy This module implements XEP-0016: Privacy Lists) , for enabling or disabling communication with other entities on a network. mod_private Implements XEP-0049 (Private XML Storage) to store and query private user data in XML format. mod_pubsub This extension implements XEP-0060 (Publish-Subscribe) . It is a pluggable implementation using behaviours provided by node_*.erl and nodetree_*.erl modules. mod_push_service_mongoosepush Handles push notifications generated by mod_pubsub 's node_push and passes them to MongoosePush service. mod_register Implements XEP-0077: In-Band Registration) , that enables creating an account and changing the password once connected. This does not provide a solution to the forgotten password use case via SMS or email. mod_revproxy With this extension, MongooseIM may serve as a reverse proxy. mod_roster Roster support, specified in RFC 6121 . Includes support for XEP-0237: Roster Versioning . mod_shared_roster_ldap This module, when enabled, will inject roster entries fetched from LDAP. mod_sic Implements XEP-0279: Server IP Check) that enables a client to discover its external IP address. mod_stream_management Enables XEP-0198: Stream Management functionality that defines the active management of an XML stream between two XMPP entities, including features for stanza acknowledgements and stream resumption. mod_time XEP-0202: Entity Time implementation. With this extensions, clients can get the current server time. mod_vcard Provides support for vCards, as specified in XEP-0054: vcard-temp and XEP-0055: Jabber Search . mod_version This module provides the functionality specified in XEP-0092: Software Version .","title":"Extension Modules"},{"location":"advanced-configuration/Modules/#module-list","text":"Some of the modules feature an iqdisc parameter. It defines the method for handling incoming IQ stanzas. Please refer to [[IQ handlers]] for more information. Valid values: no_queue , one_queue , {queues, N} , parallel . Default: one_queue .","title":"Module list"},{"location":"advanced-configuration/Modules/#mod_adhoc","text":"Implements XEP-0050: Ad-Hoc Commands for advertising and executing application-specific commands, such as those related to a configuration workflow, using XEP-0004: Data Forms in order to structure the information exchange. This is extremely useful for use cases such as remote administration, user engagement via polls, and ChatBots.","title":"mod_adhoc"},{"location":"advanced-configuration/Modules/#mod_amp","text":"Implements a subset of XEP-0079: Advanced Message Processing functionality, that enables entities to request, and servers to perform advanced processing of XMPP message stanzas, including reliable data transport, time-sensitive delivery, and expiration of transient messages.","title":"mod_amp"},{"location":"advanced-configuration/Modules/#mod_auth_token","text":"A module used by SASL X-OAUTH mechanism. It provides an API to manage custom OAuth tokens . It requires mod_keystore as an actual key database.","title":"mod_auth_token"},{"location":"advanced-configuration/Modules/#mod_blocking","text":"Implements XEP-0191: Blocking Command , a simplified interface to privacy lists.","title":"mod_blocking"},{"location":"advanced-configuration/Modules/#mod_bosh","text":"Allows users to connect to MongooseIM using BOSH (Bidirectional-streams Over Synchronous HTTP), the HTTP long-polling technique described in XEP-0124: Bidirectional-streams Over Synchronous HTTP (BOSH) and XEP-0206: XMPP Over BOSH .","title":"mod_bosh"},{"location":"advanced-configuration/Modules/#mod_caps","text":"Implements XEP-0115 Entity Capabilities . It queries clients for their supported functionalities and caches them in Mnesia. This module tightly cooperates with mod_pubsub in order to deliver PEP events to user's subscribers.","title":"mod_caps"},{"location":"advanced-configuration/Modules/#mod_carboncopy","text":"Implements XEP-0280: Message Carbons in order to keep all IM clients for a user engaged in a real-time conversation by carbon-copying all inbound and outbound messages to all interested resources (Full JIDs).","title":"mod_carboncopy"},{"location":"advanced-configuration/Modules/#mod_commands","text":"A central gateway providing access to a subset of MongooseIM functions by channels other than XMPP. Commands defined there are currently accessible via REST API.","title":"mod_commands"},{"location":"advanced-configuration/Modules/#mod_csi","text":"Enables the XEP-0352: Client State Indication functionality.","title":"mod_csi"},{"location":"advanced-configuration/Modules/#mod_disco","text":"Implements XEP-0030: Service Discovery for discovering information (capabilities, protocols, features) about other XMPP entities.","title":"mod_disco"},{"location":"advanced-configuration/Modules/#mod_event_pusher","text":"A framework module to build other notification-based modules on.","title":"mod_event_pusher"},{"location":"advanced-configuration/Modules/#mod_event_pusher_sns","text":"Allows sending online/offline notifications, chat and groupchat messages as events to Amazon Simple Notification Service .","title":"mod_event_pusher_sns"},{"location":"advanced-configuration/Modules/#mod_event_pusher_rabbit","text":"Allows sending presence changes (to available/unavailable), chat and groupchat messages as events to a RabbitMQ server.","title":"mod_event_pusher_rabbit"},{"location":"advanced-configuration/Modules/#mod_event_pusher_push","text":"Implements XEP-0357 Push Notifiactions to provide push notifications to clients that are temporary unavailable.","title":"mod_event_pusher_push"},{"location":"advanced-configuration/Modules/#mod_event_pusher_http","text":"Forward events to an external HTTP service. This applies to situations such as sending messages or presences to mobile/SMS/email push service, big data, or an analytics service.","title":"mod_event_pusher_http"},{"location":"advanced-configuration/Modules/#mod_http_upload","text":"Implements XEP-0363: HTTP File Upload for coordinating with an XMPP server to upload files via HTTP and receive URLs that can be shared in messages.","title":"mod_http_upload"},{"location":"advanced-configuration/Modules/#mod_inbox","text":"Implements custom inbox XEP","title":"mod_inbox"},{"location":"advanced-configuration/Modules/#mod_global_distrib","text":"Enables sharing a single XMPP domain between distinct datacenters ( experimental ).","title":"mod_global_distrib"},{"location":"advanced-configuration/Modules/#mod_jingle_sip","text":"Enables Jingle to SIP and SIP to Jingle translator.","title":"mod_jingle_sip"},{"location":"advanced-configuration/Modules/#mod_keystore","text":"Serves as a storage for crypto keys for mod_auth_token .","title":"mod_keystore"},{"location":"advanced-configuration/Modules/#mod_last","text":"Implements XEP-0012: Last Activity) for communicating information about the last activity associated with an XMPP entity (most recent presence information from an offline contact).","title":"mod_last"},{"location":"advanced-configuration/Modules/#mod_mam","text":"Implements XEP-0313: Message Archive Management , that defines a protocol to query and control an archive of messages stored on a server.","title":"mod_mam"},{"location":"advanced-configuration/Modules/#mod_muc","text":"Implements XEP-0045: Multi-User Chat) , for a featureful multi-user text chat (group chat), whereby multiple XMPP users can exchange messages in the context of a chat room. It is tightly coupled with user presence in chat rooms.","title":"mod_muc"},{"location":"advanced-configuration/Modules/#mod_muc_commands","text":"Provides mod_muc related mongoose_commands , accessible via the client REST API.","title":"mod_muc_commands"},{"location":"advanced-configuration/Modules/#mod_muc_log","text":"Implements a logging subsystem for [mod_muc].","title":"mod_muc_log"},{"location":"advanced-configuration/Modules/#mod_muc_light","text":"Implements XEP Multi-User Chat Light .","title":"mod_muc_light"},{"location":"advanced-configuration/Modules/#mod_muc_light_commands","text":"Provides mod_muc_light related mongoose_commands , accessible via client REST API.","title":"mod_muc_light_commands"},{"location":"advanced-configuration/Modules/#mod_offline","text":"Provides an offline messages storage that is compliant with XEP-0160: Best Practices for Handling Offline Messages) .","title":"mod_offline"},{"location":"advanced-configuration/Modules/#mod_offline_stub","text":"Prevents <service-unavailable/> error when the message recipient is offline.","title":"mod_offline_stub"},{"location":"advanced-configuration/Modules/#mod_ping","text":"Implements XEP-0199 XMPP Ping , enabling periodic XMPP pings sent to clients and responds to those sent from clients.","title":"mod_ping"},{"location":"advanced-configuration/Modules/#mod_privacy","text":"This module implements XEP-0016: Privacy Lists) , for enabling or disabling communication with other entities on a network.","title":"mod_privacy"},{"location":"advanced-configuration/Modules/#mod_private","text":"Implements XEP-0049 (Private XML Storage) to store and query private user data in XML format.","title":"mod_private"},{"location":"advanced-configuration/Modules/#mod_pubsub","text":"This extension implements XEP-0060 (Publish-Subscribe) . It is a pluggable implementation using behaviours provided by node_*.erl and nodetree_*.erl modules.","title":"mod_pubsub"},{"location":"advanced-configuration/Modules/#mod_push_service_mongoosepush","text":"Handles push notifications generated by mod_pubsub 's node_push and passes them to MongoosePush service.","title":"mod_push_service_mongoosepush"},{"location":"advanced-configuration/Modules/#mod_register","text":"Implements XEP-0077: In-Band Registration) , that enables creating an account and changing the password once connected. This does not provide a solution to the forgotten password use case via SMS or email.","title":"mod_register"},{"location":"advanced-configuration/Modules/#mod_revproxy","text":"With this extension, MongooseIM may serve as a reverse proxy.","title":"mod_revproxy"},{"location":"advanced-configuration/Modules/#mod_roster","text":"Roster support, specified in RFC 6121 . Includes support for XEP-0237: Roster Versioning .","title":"mod_roster"},{"location":"advanced-configuration/Modules/#mod_shared_roster_ldap","text":"This module, when enabled, will inject roster entries fetched from LDAP.","title":"mod_shared_roster_ldap"},{"location":"advanced-configuration/Modules/#mod_sic","text":"Implements XEP-0279: Server IP Check) that enables a client to discover its external IP address.","title":"mod_sic"},{"location":"advanced-configuration/Modules/#mod_stream_management","text":"Enables XEP-0198: Stream Management functionality that defines the active management of an XML stream between two XMPP entities, including features for stanza acknowledgements and stream resumption.","title":"mod_stream_management"},{"location":"advanced-configuration/Modules/#mod_time","text":"XEP-0202: Entity Time implementation. With this extensions, clients can get the current server time.","title":"mod_time"},{"location":"advanced-configuration/Modules/#mod_vcard","text":"Provides support for vCards, as specified in XEP-0054: vcard-temp and XEP-0055: Jabber Search .","title":"mod_vcard"},{"location":"advanced-configuration/Modules/#mod_version","text":"This module provides the functionality specified in XEP-0092: Software Version .","title":"mod_version"},{"location":"advanced-configuration/Services/","text":"Some functionalities in MongooseIM are provided by \"services\". A service is similar to a module, but while a module is started for every virtual host and may have global or host-specific configuration, a service is started only once with global configuration. Service configuration is similar to a module configuration, e.g.: {services, [ {service_admin_extra, [{submods, [node, accounts, sessions]}]} ] }. Service list As of version 2.2, only one module is a \"service provider\". Eventually the modules which are not host-specific will be refactored to be services. service_admin_extra Provides additional commands to mongooseimctl script. Options submods (default: all submodules): List of function groups added by service_admin_extra . Allowed elements: accounts : Adds change_password , check_password_hash , delete_old_users , delete_old_users_vhost , ban_account , num_active_users , check_account , check_password last : Adds set_last node : Adds load_config , get_cookie , remove_node private : Adds private_get , private_set roster : Adds add_rosteritem , delete_rosteritem , process_rosteritems , get_roster , push_roster , push_roster_all , push_roster_alltoall sessions : Adds num_resources , resource_num , kick_session , status_num_host , status_num , status_list_host , status_list , connected_users_info , connected_users_vhost , user_sessions_info , set_presence stanza : Adds send_message_chat , send_message_headline , send_stanza_c2s stats : Adds stats , stats_host vcard : Adds get_vcard , get_vcard2 , get_vcard2_multi , set_vcard , set_vcard2 , set_vcard2_multi gdpr : Adds retrieve_personal_data Example configuration {service_admin_extra, [{submods, [node, accounts, sessions]}]}","title":"Services"},{"location":"advanced-configuration/Services/#service-list","text":"As of version 2.2, only one module is a \"service provider\". Eventually the modules which are not host-specific will be refactored to be services.","title":"Service list"},{"location":"advanced-configuration/Services/#service_admin_extra","text":"Provides additional commands to mongooseimctl script.","title":"service_admin_extra"},{"location":"advanced-configuration/Services/#options","text":"submods (default: all submodules): List of function groups added by service_admin_extra . Allowed elements: accounts : Adds change_password , check_password_hash , delete_old_users , delete_old_users_vhost , ban_account , num_active_users , check_account , check_password last : Adds set_last node : Adds load_config , get_cookie , remove_node private : Adds private_get , private_set roster : Adds add_rosteritem , delete_rosteritem , process_rosteritems , get_roster , push_roster , push_roster_all , push_roster_alltoall sessions : Adds num_resources , resource_num , kick_session , status_num_host , status_num , status_list_host , status_list , connected_users_info , connected_users_vhost , user_sessions_info , set_presence stanza : Adds send_message_chat , send_message_headline , send_stanza_c2s stats : Adds stats , stats_host vcard : Adds get_vcard , get_vcard2 , get_vcard2_multi , set_vcard , set_vcard2 , set_vcard2_multi gdpr : Adds retrieve_personal_data","title":"Options"},{"location":"advanced-configuration/Services/#example-configuration","text":"{service_admin_extra, [{submods, [node, accounts, sessions]}]}","title":"Example configuration"},{"location":"advanced-configuration/TLS-hardening/","text":"OTP TLS vs. Fast TLS Before we explain the TLS hardening in MongooseIM, we need to describe the TLS libraries used in the project. These are \"OTP TLS\" and \"Fast TLS\". The former is provided by (as the name suggests) OTP as the ssl application. Large part of the logic is implemented in Erlang but it calls OpenSSL API for some operations anyway. The latter is a community-maintained driver, which is implemented as NIFs (native C code). It uses OpenSSL API for all operations. Most MongooseIM components use the TLS library provided by OTP. However, some of them choose to integrate with fast_tls library instead. The former one is used primarily by MIM dependencies, while the latter is used only by MIM modules. None of them is strictly better than the other. Below you may find a summary of the differences between them. fast_tls is faster. There are options that OTP TLS (a.k.a just_tls in the ejabberd_c2s configuration) supports exclusively: Immediate connection drop when the client certificate is invalid Certificate Revocation Lists More flexible certificate verification options Allowed protocol versions may be configured: Globally for OTP TLS via an environment variable Per socket in Fast TLS via OpenSSL cipher string Deprecations MongooseIM is configured to allow only TLS 1.2 or higher, due to known vulnerabilities in TLS 1.0 and 1.1. It is still possible to enable earlier versions, however it is strongly discouraged. OTP TLS hardening Protocol list for OTP TLS is set via the protocol_version environment variable. It's an Erlang runtime variable, so it is not configured in the OS but rather in the app.config file. It may be found in etc/ folder inside MongooseIM release and in [repository root]/rel/files/ . In order to change the list, please find the following lines: {protocol_version, ['tlsv1.2' %, 'tlsv1.3' % supported in OTP >= 22 ]} By default only TLS 1.2 is enabled, as 1.3 is not supported by OTPs older than 22.0. If you are using OTP 22.0 or newer, you may remove leading % before 'tlsv1.3' . The remaining valid values are: 'tlsv1.1' , tlsv1 , sslv3 . This setting affects the following MongooseIM components: Raw XMPP over TCP connections, if ejabberd_c2s listener is configured to use just_tls . All outgoing connections (databases, AMQP, SIP etc.) HTTP endpoints Fast TLS hardening Fast TLS expects an OpenSSL cipher string as one of optional connection parameters. This string is configured individually for every module that uses it. By default, MongooseIM sets this option to TLSv1.2:TLSv1.3 for each component. The list below enumerates all components that use Fast TLS and describes how to change this string. ejabberd_c2s - main user session abstraction + XMPP over TCP listener Please consult the respective section in Listener modules . ejabberd_s2s_in - incoming S2S connections (XMPP Federation) Please consult the respective section in Listener modules . ejabberd_s2s_out - outgoing S2S connections (XMPP Federation) Please check the documentation for s2s_ciphers option. mod_global_distrib - Global Distribution module Please add {ciphers, \"string\"} to tls_opts parameter of mod_global_distrib , as described in the documentation .","title":"TLS hardening"},{"location":"advanced-configuration/TLS-hardening/#otp-tls-vs-fast-tls","text":"Before we explain the TLS hardening in MongooseIM, we need to describe the TLS libraries used in the project. These are \"OTP TLS\" and \"Fast TLS\". The former is provided by (as the name suggests) OTP as the ssl application. Large part of the logic is implemented in Erlang but it calls OpenSSL API for some operations anyway. The latter is a community-maintained driver, which is implemented as NIFs (native C code). It uses OpenSSL API for all operations. Most MongooseIM components use the TLS library provided by OTP. However, some of them choose to integrate with fast_tls library instead. The former one is used primarily by MIM dependencies, while the latter is used only by MIM modules. None of them is strictly better than the other. Below you may find a summary of the differences between them. fast_tls is faster. There are options that OTP TLS (a.k.a just_tls in the ejabberd_c2s configuration) supports exclusively: Immediate connection drop when the client certificate is invalid Certificate Revocation Lists More flexible certificate verification options Allowed protocol versions may be configured: Globally for OTP TLS via an environment variable Per socket in Fast TLS via OpenSSL cipher string","title":"OTP TLS vs. Fast TLS"},{"location":"advanced-configuration/TLS-hardening/#deprecations","text":"MongooseIM is configured to allow only TLS 1.2 or higher, due to known vulnerabilities in TLS 1.0 and 1.1. It is still possible to enable earlier versions, however it is strongly discouraged.","title":"Deprecations"},{"location":"advanced-configuration/TLS-hardening/#otp-tls-hardening","text":"Protocol list for OTP TLS is set via the protocol_version environment variable. It's an Erlang runtime variable, so it is not configured in the OS but rather in the app.config file. It may be found in etc/ folder inside MongooseIM release and in [repository root]/rel/files/ . In order to change the list, please find the following lines: {protocol_version, ['tlsv1.2' %, 'tlsv1.3' % supported in OTP >= 22 ]} By default only TLS 1.2 is enabled, as 1.3 is not supported by OTPs older than 22.0. If you are using OTP 22.0 or newer, you may remove leading % before 'tlsv1.3' . The remaining valid values are: 'tlsv1.1' , tlsv1 , sslv3 . This setting affects the following MongooseIM components: Raw XMPP over TCP connections, if ejabberd_c2s listener is configured to use just_tls . All outgoing connections (databases, AMQP, SIP etc.) HTTP endpoints","title":"OTP TLS hardening"},{"location":"advanced-configuration/TLS-hardening/#fast-tls-hardening","text":"Fast TLS expects an OpenSSL cipher string as one of optional connection parameters. This string is configured individually for every module that uses it. By default, MongooseIM sets this option to TLSv1.2:TLSv1.3 for each component. The list below enumerates all components that use Fast TLS and describes how to change this string. ejabberd_c2s - main user session abstraction + XMPP over TCP listener Please consult the respective section in Listener modules . ejabberd_s2s_in - incoming S2S connections (XMPP Federation) Please consult the respective section in Listener modules . ejabberd_s2s_out - outgoing S2S connections (XMPP Federation) Please check the documentation for s2s_ciphers option. mod_global_distrib - Global Distribution module Please add {ciphers, \"string\"} to tls_opts parameter of mod_global_distrib , as described in the documentation .","title":"Fast TLS hardening"},{"location":"advanced-configuration/acl/","text":"In MongooseIM access control is performed via Access Control Lists (ACL). Initially, this functionality was supposed to answer the following question: \"Is a given user allowed to access a particular resource?\". The answer was either allow or deny , but this functionality was extended to return any value. For instance, we can ask how many concurrent session a given user can open, where the answer may vary depending on user affiliation - are they an admin or a normal user. The functionality is defined via two top-level options: {acl, Name, Pattern} : contrary to its name, it defines a user or the whole group. For instance we can define admin users or banned users. {access, Name, List} : an ACL that has a name and list of rules and values returned by them in the case of a successfull match. ACL tuple {acl, Name, Pattern} : the name could be any atom. This name will be used in the access definitions. Note that there might be many ACL entries with the same name, in this case the result will be the union of all patterns. Patterns This sections describes all possible ACL patterns. Some of them use the re syntax for regular expressions and some accept the glob syntax. re definitions glob definitions Patterns can be defined in one of the following formats: all All users/JIDs match. {user, username()} All users with a given user name: {user, \"admin\"} : includes admin@localhost , admin@xmpp.org , etc. {user, username(), server()} In this case the username and the domain have to match: {user, \"admin\", \"localhost\"} : admin@localhost matches, but admin@xmpp.org doesn't. {server, server()} All users from a given domain: {server, \"localhost\"} : admin@localhost and pawel@localhost match, but pawel@xmpp.org doesn't. {resource, resource()} All users with a matching resource: {resource, \"res1\"} : admin@localhost/res1 matches, but admin@localhost/res2 doesn't. {user_regexp, username_regexp()} Similar to user, but the match is done against a regular expression: {user_regexp, \"^ad.*\"} : admin@localhost and ads@localhost2 match, but pad@localhost doesn't. {user_regexp, username_regexp(), server()} Similar to user, the username is matched against regex, the server part has to be exactly the same: {user_regexp, \"^ad.*\", \"localhost\"} : admin@localhost matches, but admin@xmpp.org doesn't. {server_regexp, server_regexp()} Analogous to user_regexp , but regex matches on the server part of the JID: {server_regexp, \"^local.*\"} : admin@localhost matches, but admin@relocal doesn't. {resource_regexp, resource_regexp()} The same story as above, but for the resource part: {resource_regexp, \"res.*\"} : admin@localhost/resource matches, but admin@localhost/ios doesn't. {node_regexp, username_regexp(), server_regexp()} Regexp matching on both the username and the domain: {node_regexp, \"ad.*\", \"loc.*\"} : admin@localhost matches, but pawel@xmpp.org doesn't. {user_glob, username_glob()} Match on the username part using glob style patterns: {user_glob, \"paw*\"} : pawel@localhost matches, but admin@localhost doesn't. {user_glob, username_glob(), server()} Match on the username part using glob patterns and on the server using exact match: {user_glob, \"paw*\", \"localhost\"} : pawel@localhost matches, but pawel@xmpp.org doesn't. {server_glob, server_glob()} Match on the server part using glob patterns: {server_glob, \"local*\"} : pawel@localhost matches, but pawel@xmpp.org doesn't. {resource_glob, resource_glob()} Match on the resource part using glob patterns: {resource_glob, \"r*\"} : pawel@localhost/res matches, but pawel@xmpp.org doesn't. {node_glob, username_glob(), server_glob()} Match on the username and the server part using glob patterns: {node_glob, \"paw*\", \"loc*\"} : pawel@localhost/res matches, but pawel@xmpp.org doesn't. Access tuple Once we have our group of interest gathered in an ACL tuple, we can use them in an access control list. To do so, we need to specify a tuple like the following: {access, name_of_access_rule, [{value(), acl_name()}]} As an example we can discuss 2 rules which are present in the default config file: {access, register, [{allow, all}]} . This rule is used while registering a new user. The example above has no restrictions, but we might want to block certain JIDs, admin JID for instance. To do so we need to set: {acl, admin, {user, \"admin\"}}. , then {access, register, [{deny, admin}, {allow, all}]}. {access, max_user_offline_messages, [{5000, admin}, {100, all}]} . This rule is used in mod_offline , it determines mod_offline 's storage limit. For users defined in the admin ACL (for example {acl, admin, {user, \"pawel\", \"localhost\"}} ) the size is 5000 messages, while the size for a normal user is 10. Priority: global vs host access lists By default, both ACL and access elements are \"global\", so they apply to all domains available on the server. However, using the host_config option, we are able to override the rules for a particular domain. %% Define specific Access Rules in a virtual host. {host_config, \"localhost\", [ {access, c2s, [{allow, admin}, {deny, all}]}, {access, register, [{deny, all}]} ] }. The global rule has the highest priority, however if the global rule ends with {allow, all} the host specific rule is taken into account. For developers To access the ACL functionality, one has to use the acl:match_rule/3 function. Given the following ACL: {access, register, [{deny, all}]} One can call: acl:match_rule(<<\"localhost\">>, register, jid:make(<<\"p\">>, <<\"localhost\">>, <<>>)). Which in our case will return deny. If the rule is not host specific, one can use global instead of <<\"localhost\">> .","title":"ACL"},{"location":"advanced-configuration/acl/#acl-tuple","text":"{acl, Name, Pattern} : the name could be any atom. This name will be used in the access definitions. Note that there might be many ACL entries with the same name, in this case the result will be the union of all patterns.","title":"ACL tuple"},{"location":"advanced-configuration/acl/#patterns","text":"This sections describes all possible ACL patterns. Some of them use the re syntax for regular expressions and some accept the glob syntax. re definitions glob definitions Patterns can be defined in one of the following formats:","title":"Patterns"},{"location":"advanced-configuration/acl/#all","text":"All users/JIDs match.","title":"all"},{"location":"advanced-configuration/acl/#user-username","text":"All users with a given user name: {user, \"admin\"} : includes admin@localhost , admin@xmpp.org , etc.","title":"{user, username()}"},{"location":"advanced-configuration/acl/#user-username-server","text":"In this case the username and the domain have to match: {user, \"admin\", \"localhost\"} : admin@localhost matches, but admin@xmpp.org doesn't.","title":"{user, username(), server()}"},{"location":"advanced-configuration/acl/#server-server","text":"All users from a given domain: {server, \"localhost\"} : admin@localhost and pawel@localhost match, but pawel@xmpp.org doesn't.","title":"{server, server()}"},{"location":"advanced-configuration/acl/#resource-resource","text":"All users with a matching resource: {resource, \"res1\"} : admin@localhost/res1 matches, but admin@localhost/res2 doesn't.","title":"{resource, resource()}"},{"location":"advanced-configuration/acl/#user_regexp-username_regexp","text":"Similar to user, but the match is done against a regular expression: {user_regexp, \"^ad.*\"} : admin@localhost and ads@localhost2 match, but pad@localhost doesn't.","title":"{user_regexp, username_regexp()}"},{"location":"advanced-configuration/acl/#user_regexp-username_regexp-server","text":"Similar to user, the username is matched against regex, the server part has to be exactly the same: {user_regexp, \"^ad.*\", \"localhost\"} : admin@localhost matches, but admin@xmpp.org doesn't.","title":"{user_regexp, username_regexp(), server()}"},{"location":"advanced-configuration/acl/#server_regexp-server_regexp","text":"Analogous to user_regexp , but regex matches on the server part of the JID: {server_regexp, \"^local.*\"} : admin@localhost matches, but admin@relocal doesn't.","title":"{server_regexp, server_regexp()}"},{"location":"advanced-configuration/acl/#resource_regexp-resource_regexp","text":"The same story as above, but for the resource part: {resource_regexp, \"res.*\"} : admin@localhost/resource matches, but admin@localhost/ios doesn't.","title":"{resource_regexp, resource_regexp()}"},{"location":"advanced-configuration/acl/#node_regexp-username_regexp-server_regexp","text":"Regexp matching on both the username and the domain: {node_regexp, \"ad.*\", \"loc.*\"} : admin@localhost matches, but pawel@xmpp.org doesn't.","title":"{node_regexp, username_regexp(), server_regexp()}"},{"location":"advanced-configuration/acl/#user_glob-username_glob","text":"Match on the username part using glob style patterns: {user_glob, \"paw*\"} : pawel@localhost matches, but admin@localhost doesn't.","title":"{user_glob, username_glob()}"},{"location":"advanced-configuration/acl/#user_glob-username_glob-server","text":"Match on the username part using glob patterns and on the server using exact match: {user_glob, \"paw*\", \"localhost\"} : pawel@localhost matches, but pawel@xmpp.org doesn't.","title":"{user_glob, username_glob(), server()}"},{"location":"advanced-configuration/acl/#server_glob-server_glob","text":"Match on the server part using glob patterns: {server_glob, \"local*\"} : pawel@localhost matches, but pawel@xmpp.org doesn't.","title":"{server_glob, server_glob()}"},{"location":"advanced-configuration/acl/#resource_glob-resource_glob","text":"Match on the resource part using glob patterns: {resource_glob, \"r*\"} : pawel@localhost/res matches, but pawel@xmpp.org doesn't.","title":"{resource_glob, resource_glob()}"},{"location":"advanced-configuration/acl/#node_glob-username_glob-server_glob","text":"Match on the username and the server part using glob patterns: {node_glob, \"paw*\", \"loc*\"} : pawel@localhost/res matches, but pawel@xmpp.org doesn't.","title":"{node_glob, username_glob(), server_glob()}"},{"location":"advanced-configuration/acl/#access-tuple","text":"Once we have our group of interest gathered in an ACL tuple, we can use them in an access control list. To do so, we need to specify a tuple like the following: {access, name_of_access_rule, [{value(), acl_name()}]} As an example we can discuss 2 rules which are present in the default config file: {access, register, [{allow, all}]} . This rule is used while registering a new user. The example above has no restrictions, but we might want to block certain JIDs, admin JID for instance. To do so we need to set: {acl, admin, {user, \"admin\"}}. , then {access, register, [{deny, admin}, {allow, all}]}. {access, max_user_offline_messages, [{5000, admin}, {100, all}]} . This rule is used in mod_offline , it determines mod_offline 's storage limit. For users defined in the admin ACL (for example {acl, admin, {user, \"pawel\", \"localhost\"}} ) the size is 5000 messages, while the size for a normal user is 10.","title":"Access tuple"},{"location":"advanced-configuration/acl/#priority-global-vs-host-access-lists","text":"By default, both ACL and access elements are \"global\", so they apply to all domains available on the server. However, using the host_config option, we are able to override the rules for a particular domain. %% Define specific Access Rules in a virtual host. {host_config, \"localhost\", [ {access, c2s, [{allow, admin}, {deny, all}]}, {access, register, [{deny, all}]} ] }. The global rule has the highest priority, however if the global rule ends with {allow, all} the host specific rule is taken into account.","title":"Priority: global vs host access lists"},{"location":"advanced-configuration/acl/#for-developers","text":"To access the ACL functionality, one has to use the acl:match_rule/3 function. Given the following ACL: {access, register, [{deny, all}]} One can call: acl:match_rule(<<\"localhost\">>, register, jid:make(<<\"p\">>, <<\"localhost\">>, <<>>)). Which in our case will return deny. If the rule is not host specific, one can use global instead of <<\"localhost\">> .","title":"For developers"},{"location":"advanced-configuration/database-backends-configuration/","text":"Database Backends MongooseIM can work with several databases, both RDBMS (SQL) and NOSQL ones. Some of them require extra work before they can be used. For example the SQL databases require defining a schema. MongooseIM is tested with TravisCI, so the travis scripts can be used as a reference. A Brief Overview Data in MongooseIM is either transient or persistent: transient : volatile data changing often, such as session data, stream management data, and other in-memory data. These don't need any backup, since after a potential failure, they will naturally rebuild as clients reconnect. persistent : long-lived data, such as roster items, credentials, and chat archives. These absolutely need regular and tested backups. Choosing a database for MongooseIM Here is some general advice on the use of databases. Subsequent sections go into more depth on each database: what they are suitable for and how to set them up. Transient data: Mnesia - we highly recommend Mnesia (a highly available and distributed database) over Redis for storing transient data. Being an Erlang-based database, it's the default persistance option for most modules in MongooseIM. Warning : we strongly recommend keeping persistent data in an external DB (RDBMS or Riak) for production. Mnesia is not suitable for the volumes of persistent data which some modules may require. Sooner or later a migration will be needed which may be painful. It is possible to store all data in Mnesia, but only for testing purposes, not for any serious deployments. Redis - A fantastic choice for storing live data. It's highly scalable and it can be easily shared by multiple MongooseIM nodes. Additionally, Redis' great performance makes it an excellent choice for storing user session data. We recommend caution, since it has not yet been widely tested in production. Persistent Data: RDBMS - MongooseIM has a strong backend support for relational databases. Reliable and battle proven, they are a great choice for regular MongooseIM use cases and features like privacy lists , vcards , roster , private storage , last activity and message archive . Never loose your data. Use MySQL, MariaDB, PostgreSQL, or MS SQL Server. Riak KV - If you're planning to deploy a massive cluster, consider Riak KV as a potential storage backend solution. It offers high availability and fault tolerance which is excatly what you need for your distributed MongooseIM architecture. Use Riak KV with privacy lists , vcards , roster , private storage , last activity and message archive . Erlang Solutions commercially supports Riak KV. Cassandra - Only for MAM (Message Archive Management). ElasticSearch - Only for MAM (Message Archive Management). User Data: LDAP - Used for: users, shared rosters, vCards RDBMS MySQL Can be used for : users (credentials) vcards roster private storage privacy/block lists last activity mam (message archive management) muc_light rooms Setup Warning: MongooseIM cannot connect to MySQL over TLS with OTP 20.3 . The schema files can be found in the priv directory. The default schema is defined in the mysql.sql file. You can use the following command to apply it on localhost: mysql -h localhost -u user -p -e 'create database mongooseim' mysql -h localhost -u user -p mongooseim < mysql.sql You should also configure MySQL database in the mongooseim.cfg file. Please refer to the Advanced configuration/Database setup for more information. Version notice The required minimum version of MySQL is 5.5.14 . For versions 5.7.8 and older, add the following options to your MySQL configuration file: innodb_large_prefix=true innodb_file_format=BARRACUDA innodb_file_format_max=BARRACUDA innodb_file_per_table=true For versions 5.7.9 and newer, all of the above options are set correctly by default. PostgreSQL Can be used for: users (credentials) vcards roster private storage privacy/block lists last activity mam (message archive management) muc_light rooms Setup The schema files can be found in the priv directory. The default schema is defined in the pg.sql file. You can use the following command to apply it on localhost: psql -h localhost -U user -c \"CREATE DATABASE mongooseim;\" psql -h localhost -U user -q -d mongooseim -f pg.sql You should also configure Postgres database in mongooseim.cfg file. Please refer to the Advanced configuration/Database setup for more information. Microsoft SQL Server Microsoft SQL Server, sometimes called MSSQL, or Azure SQL Database. Warning: MongooseIM can only connect to MSSQL on Ubuntu Xenial x64 . This can be used for: users (credentials) vcards roster private storage privacy/block lists last activity mam (message archive management) muc_light rooms Setup MSSQL can be used from MongooseIM through the ODBC layer with FreeTDS driver, so you need them installed on your system. # Ubuntu $ sudo apt install freetds-dev tdsodbc # CentOS $ sudo yum install freetds # macOS $ brew install freetds Then you need to configure the connection. Add your database ( mongooseim here) to the /etc/odbc.ini or $HOME/.odbc.ini file: [mongoose-mssql] ; Ubuntu Driver = /usr/lib/x86_64-linux-gnu/odbc/libtdsodbc.so Setup = /usr/lib/x86_64-linux-gnu/odbc/libtdsS.so ; CentOS ; Driver = /usr/lib64/libtdsodbc.so.0 ; Setup = /usr/lib64/libtdsS.so ; macOS ; Driver = /usr/local/Cellar/freetds/[current version]/lib/libtdsodbc.so Server = 127.0.0.1 Port = 1433 Database = mongooseim Charset = UTF-8 TDS_Version = 7.2 client_charset = UTF-8 Please amend the paths above to match your current OS if necessary. For more details, please refer to the freetds.conf documentation and unixodbc documentation . MongooseIM is built with ODBC support by default. Deadlocks notice If muc_light's backend is set to ODBC and in your system there is many rooms created in parallel, there may be some deadlocks due to the READ_COMMITTED_SNAPSHOT set to OFF by default. In this case we recommend to set this database property to ON , this will enable row level locking which significantly reduces deadlock chances around muc_light operations. This property can be set by the following ALTER DATABASE query: ALTER DATABASE $name_of_your_db SET READ_COMMITTED_SNAPSHOT ON The command above may take some time. Then you need to import the SQL schema from either mssql2012.sql or azuresql.sql file depending on which database you are using. You can use a Microsoft's GUI tool (the provided .sql files should work with it) or isql, but after a slight modification of the dump file: cat azuresql.sql | tr -d '\\r' | tr '\\n' ' ' | sed 's/GO/\\n/g' | isql mongoose-mssql username password -b The final step is to configure mongooseim.cfg appropriately. Configure the database section as follows: {rdbms_server_type, mssql}. {outgoing_pools, [ {rdbms, global, default, [{workers, 5}], [{server, \"DSN=mongoose-mssql;UID=username;PWD=password\"}]} ]}. NOSQL Riak KV Riak KV, for Key-Value, is technically supported by MongooseIM for versions upper than Riak KV 2.0. Erlang Solutions commercially supports Riak KV. Can be used for: users (credentials) vcards roster private storage privacy/block lists last activity mam (message archive management) Setup We are using the Riak data types, so the minimal supported version is 2.0. To be able to store above persistent date one have to run the following command: RIAK_HOST=\"http://localhost:8098\" curl -XPUT $RIAK_HOST/search/schema/vcard \\ -H 'Content-Type:application/xml' \\ --data-binary @tools/vcard_search_schema.xml curl -XPUT $RIAK_HOST/search/index/vcard \\ -H 'Content-Type: application/json' \\ -d '{\"schema\":\"vcard\"}' #MAM curl -XPUT $RIAK_HOST/search/schema/mam \\ -H 'Content-Type:application/xml' \\ --data-binary @tools/mam_search_schema.xml curl -XPUT $RIAK_HOST/search/index/mam \\ -H 'Content-Type: application/json' \\ -d '{\"schema\":\"mam\"}' # user base riak-admin bucket-type create users '{\"props\":{\"datatype\":\"map\"}}' riak-admin bucket-type activate users # rosters riak-admin bucket-type create rosters '{\"props\":{\"datatype\":\"map\"}}' riak-admin bucket-type activate rosters riak-admin bucket-type create roster_versions '{\"props\":{\"last_write_wins\":true, \"dvv_enabled\":false}}' riak-admin bucket-type activate roster_versions # private storage riak-admin bucket-type create private '{\"props\":{\"last_write_wins\":true, \"dvv_enabled\":false}}' riak-admin bucket-type activate private # vCard riak-admin bucket-type create vcard '{\"props\":{\"last_write_wins\":true, \"search_index\":\"vcard\", \"dvv_enabled\":false}}' riak-admin bucket-type activate vcard riak-admin bucket-type create mam_yz '{\"props\":{\"datatype\":\"map\", \"search_index\":\"mam\"}}' riak-admin bucket-type activate mam_yz # Last activity riak-admin bucket-type create last '{\"props\":{\"last_write_wins\":true, \"dvv_enabled\":false}}' riak-admin bucket-type activate last # Offline messages riak-admin bucket-type create offline '{\"props\":{\"last_write_wins\":true, \"dvv_enabled\":false}}' riak-admin bucket-type activate offline # Privacy/blocking lists riak-admin bucket-type create privacy_defaults '{\"props\":{\"last_write_wins\":true, \"dvv_enabled\":false}}' riak-admin bucket-type activate privacy_defaults riak-admin bucket-type create privacy_lists_names '{\"props\":{\"datatype\":\"set\"}}' riak-admin bucket-type activate privacy_lists_names riak-admin bucket-type create privacy_lists '{\"props\":{\"last_write_wins\":true,\"dvv_enabled\":false}}' riak-admin bucket-type activate privacy_lists This will create bucket types, search schemas and indexes required for storing the above persitent data and it will activate them. You should also configure Riak in the mongooseim.cfg file. Please refer to Advanced configuration/Database setup for more information. Cassandra Setup This will prepare Cassandra for connection from MongooseIM. Make sure Cassandra is running, open a new terminal window and enter the following commands: $ cqlsh $ cqlsh> source '$REPO/priv/casssandra.cql'; ElasticSearch Can be used for: MAM (Message Archive Management) Setup Please note that MongooseIM has been tested to work properly with ElasticSearch version 5.6.9. In order to use ElasticSearch as a MAM backend, you'll need to create required indexes and mappings. From the root of MongooseIM's repository run: curl -X PUT $ELASTICSEARCH_URL/messages -d '@priv/elasticsearch/pm.json' curl -X PUT $ELASTICSEARCH_URL/muc_messages -d '@priv/elasticsearch/muc.json' where $ELASTICSEARCH_URL is a URL pointing to your ElasticSearch node's HTTP API endpoint. Please refer to advanced configuration page to check how to configure MongooseIM to connect to ElasticSearch node. Redis Can be used for: users sessions Setup No additional steps required. LDAP Can be used for: users (credentials) shared roster vcard Setup No additional steps required, the modules that are using LDAP are very customizable, so they can be configured to support existsing schemas.d","title":"Database backends configuration"},{"location":"advanced-configuration/database-backends-configuration/#database-backends","text":"MongooseIM can work with several databases, both RDBMS (SQL) and NOSQL ones. Some of them require extra work before they can be used. For example the SQL databases require defining a schema. MongooseIM is tested with TravisCI, so the travis scripts can be used as a reference.","title":"Database Backends"},{"location":"advanced-configuration/database-backends-configuration/#a-brief-overview","text":"Data in MongooseIM is either transient or persistent: transient : volatile data changing often, such as session data, stream management data, and other in-memory data. These don't need any backup, since after a potential failure, they will naturally rebuild as clients reconnect. persistent : long-lived data, such as roster items, credentials, and chat archives. These absolutely need regular and tested backups.","title":"A Brief Overview"},{"location":"advanced-configuration/database-backends-configuration/#choosing-a-database-for-mongooseim","text":"Here is some general advice on the use of databases. Subsequent sections go into more depth on each database: what they are suitable for and how to set them up. Transient data: Mnesia - we highly recommend Mnesia (a highly available and distributed database) over Redis for storing transient data. Being an Erlang-based database, it's the default persistance option for most modules in MongooseIM. Warning : we strongly recommend keeping persistent data in an external DB (RDBMS or Riak) for production. Mnesia is not suitable for the volumes of persistent data which some modules may require. Sooner or later a migration will be needed which may be painful. It is possible to store all data in Mnesia, but only for testing purposes, not for any serious deployments. Redis - A fantastic choice for storing live data. It's highly scalable and it can be easily shared by multiple MongooseIM nodes. Additionally, Redis' great performance makes it an excellent choice for storing user session data. We recommend caution, since it has not yet been widely tested in production. Persistent Data: RDBMS - MongooseIM has a strong backend support for relational databases. Reliable and battle proven, they are a great choice for regular MongooseIM use cases and features like privacy lists , vcards , roster , private storage , last activity and message archive . Never loose your data. Use MySQL, MariaDB, PostgreSQL, or MS SQL Server. Riak KV - If you're planning to deploy a massive cluster, consider Riak KV as a potential storage backend solution. It offers high availability and fault tolerance which is excatly what you need for your distributed MongooseIM architecture. Use Riak KV with privacy lists , vcards , roster , private storage , last activity and message archive . Erlang Solutions commercially supports Riak KV. Cassandra - Only for MAM (Message Archive Management). ElasticSearch - Only for MAM (Message Archive Management). User Data: LDAP - Used for: users, shared rosters, vCards","title":"Choosing a database for MongooseIM"},{"location":"advanced-configuration/database-backends-configuration/#rdbms","text":"","title":"RDBMS"},{"location":"advanced-configuration/database-backends-configuration/#mysql","text":"Can be used for : users (credentials) vcards roster private storage privacy/block lists last activity mam (message archive management) muc_light rooms Setup Warning: MongooseIM cannot connect to MySQL over TLS with OTP 20.3 . The schema files can be found in the priv directory. The default schema is defined in the mysql.sql file. You can use the following command to apply it on localhost: mysql -h localhost -u user -p -e 'create database mongooseim' mysql -h localhost -u user -p mongooseim < mysql.sql You should also configure MySQL database in the mongooseim.cfg file. Please refer to the Advanced configuration/Database setup for more information. Version notice The required minimum version of MySQL is 5.5.14 . For versions 5.7.8 and older, add the following options to your MySQL configuration file: innodb_large_prefix=true innodb_file_format=BARRACUDA innodb_file_format_max=BARRACUDA innodb_file_per_table=true For versions 5.7.9 and newer, all of the above options are set correctly by default.","title":"MySQL"},{"location":"advanced-configuration/database-backends-configuration/#postgresql","text":"Can be used for: users (credentials) vcards roster private storage privacy/block lists last activity mam (message archive management) muc_light rooms Setup The schema files can be found in the priv directory. The default schema is defined in the pg.sql file. You can use the following command to apply it on localhost: psql -h localhost -U user -c \"CREATE DATABASE mongooseim;\" psql -h localhost -U user -q -d mongooseim -f pg.sql You should also configure Postgres database in mongooseim.cfg file. Please refer to the Advanced configuration/Database setup for more information.","title":"PostgreSQL"},{"location":"advanced-configuration/database-backends-configuration/#microsoft-sql-server","text":"Microsoft SQL Server, sometimes called MSSQL, or Azure SQL Database. Warning: MongooseIM can only connect to MSSQL on Ubuntu Xenial x64 . This can be used for: users (credentials) vcards roster private storage privacy/block lists last activity mam (message archive management) muc_light rooms Setup MSSQL can be used from MongooseIM through the ODBC layer with FreeTDS driver, so you need them installed on your system. # Ubuntu $ sudo apt install freetds-dev tdsodbc # CentOS $ sudo yum install freetds # macOS $ brew install freetds Then you need to configure the connection. Add your database ( mongooseim here) to the /etc/odbc.ini or $HOME/.odbc.ini file: [mongoose-mssql] ; Ubuntu Driver = /usr/lib/x86_64-linux-gnu/odbc/libtdsodbc.so Setup = /usr/lib/x86_64-linux-gnu/odbc/libtdsS.so ; CentOS ; Driver = /usr/lib64/libtdsodbc.so.0 ; Setup = /usr/lib64/libtdsS.so ; macOS ; Driver = /usr/local/Cellar/freetds/[current version]/lib/libtdsodbc.so Server = 127.0.0.1 Port = 1433 Database = mongooseim Charset = UTF-8 TDS_Version = 7.2 client_charset = UTF-8 Please amend the paths above to match your current OS if necessary. For more details, please refer to the freetds.conf documentation and unixodbc documentation . MongooseIM is built with ODBC support by default. Deadlocks notice If muc_light's backend is set to ODBC and in your system there is many rooms created in parallel, there may be some deadlocks due to the READ_COMMITTED_SNAPSHOT set to OFF by default. In this case we recommend to set this database property to ON , this will enable row level locking which significantly reduces deadlock chances around muc_light operations. This property can be set by the following ALTER DATABASE query: ALTER DATABASE $name_of_your_db SET READ_COMMITTED_SNAPSHOT ON The command above may take some time. Then you need to import the SQL schema from either mssql2012.sql or azuresql.sql file depending on which database you are using. You can use a Microsoft's GUI tool (the provided .sql files should work with it) or isql, but after a slight modification of the dump file: cat azuresql.sql | tr -d '\\r' | tr '\\n' ' ' | sed 's/GO/\\n/g' | isql mongoose-mssql username password -b The final step is to configure mongooseim.cfg appropriately. Configure the database section as follows: {rdbms_server_type, mssql}. {outgoing_pools, [ {rdbms, global, default, [{workers, 5}], [{server, \"DSN=mongoose-mssql;UID=username;PWD=password\"}]} ]}.","title":"Microsoft SQL Server"},{"location":"advanced-configuration/database-backends-configuration/#nosql","text":"","title":"NOSQL"},{"location":"advanced-configuration/database-backends-configuration/#riak-kv","text":"Riak KV, for Key-Value, is technically supported by MongooseIM for versions upper than Riak KV 2.0. Erlang Solutions commercially supports Riak KV. Can be used for: users (credentials) vcards roster private storage privacy/block lists last activity mam (message archive management) Setup We are using the Riak data types, so the minimal supported version is 2.0. To be able to store above persistent date one have to run the following command: RIAK_HOST=\"http://localhost:8098\" curl -XPUT $RIAK_HOST/search/schema/vcard \\ -H 'Content-Type:application/xml' \\ --data-binary @tools/vcard_search_schema.xml curl -XPUT $RIAK_HOST/search/index/vcard \\ -H 'Content-Type: application/json' \\ -d '{\"schema\":\"vcard\"}' #MAM curl -XPUT $RIAK_HOST/search/schema/mam \\ -H 'Content-Type:application/xml' \\ --data-binary @tools/mam_search_schema.xml curl -XPUT $RIAK_HOST/search/index/mam \\ -H 'Content-Type: application/json' \\ -d '{\"schema\":\"mam\"}' # user base riak-admin bucket-type create users '{\"props\":{\"datatype\":\"map\"}}' riak-admin bucket-type activate users # rosters riak-admin bucket-type create rosters '{\"props\":{\"datatype\":\"map\"}}' riak-admin bucket-type activate rosters riak-admin bucket-type create roster_versions '{\"props\":{\"last_write_wins\":true, \"dvv_enabled\":false}}' riak-admin bucket-type activate roster_versions # private storage riak-admin bucket-type create private '{\"props\":{\"last_write_wins\":true, \"dvv_enabled\":false}}' riak-admin bucket-type activate private # vCard riak-admin bucket-type create vcard '{\"props\":{\"last_write_wins\":true, \"search_index\":\"vcard\", \"dvv_enabled\":false}}' riak-admin bucket-type activate vcard riak-admin bucket-type create mam_yz '{\"props\":{\"datatype\":\"map\", \"search_index\":\"mam\"}}' riak-admin bucket-type activate mam_yz # Last activity riak-admin bucket-type create last '{\"props\":{\"last_write_wins\":true, \"dvv_enabled\":false}}' riak-admin bucket-type activate last # Offline messages riak-admin bucket-type create offline '{\"props\":{\"last_write_wins\":true, \"dvv_enabled\":false}}' riak-admin bucket-type activate offline # Privacy/blocking lists riak-admin bucket-type create privacy_defaults '{\"props\":{\"last_write_wins\":true, \"dvv_enabled\":false}}' riak-admin bucket-type activate privacy_defaults riak-admin bucket-type create privacy_lists_names '{\"props\":{\"datatype\":\"set\"}}' riak-admin bucket-type activate privacy_lists_names riak-admin bucket-type create privacy_lists '{\"props\":{\"last_write_wins\":true,\"dvv_enabled\":false}}' riak-admin bucket-type activate privacy_lists This will create bucket types, search schemas and indexes required for storing the above persitent data and it will activate them. You should also configure Riak in the mongooseim.cfg file. Please refer to Advanced configuration/Database setup for more information.","title":"Riak KV"},{"location":"advanced-configuration/database-backends-configuration/#cassandra","text":"Setup This will prepare Cassandra for connection from MongooseIM. Make sure Cassandra is running, open a new terminal window and enter the following commands: $ cqlsh $ cqlsh> source '$REPO/priv/casssandra.cql';","title":"Cassandra"},{"location":"advanced-configuration/database-backends-configuration/#elasticsearch","text":"Can be used for: MAM (Message Archive Management) Setup Please note that MongooseIM has been tested to work properly with ElasticSearch version 5.6.9. In order to use ElasticSearch as a MAM backend, you'll need to create required indexes and mappings. From the root of MongooseIM's repository run: curl -X PUT $ELASTICSEARCH_URL/messages -d '@priv/elasticsearch/pm.json' curl -X PUT $ELASTICSEARCH_URL/muc_messages -d '@priv/elasticsearch/muc.json' where $ELASTICSEARCH_URL is a URL pointing to your ElasticSearch node's HTTP API endpoint. Please refer to advanced configuration page to check how to configure MongooseIM to connect to ElasticSearch node.","title":"ElasticSearch"},{"location":"advanced-configuration/database-backends-configuration/#redis","text":"Can be used for: users sessions Setup No additional steps required.","title":"Redis"},{"location":"advanced-configuration/database-backends-configuration/#ldap","text":"Can be used for: users (credentials) shared roster vcard Setup No additional steps required, the modules that are using LDAP are very customizable, so they can be configured to support existsing schemas.d","title":"LDAP"},{"location":"advanced-configuration/outgoing-connections/","text":"Outgoing connections MongooseIM can be configured to talk to external service like databases or HTTP servers in order to get or set the required data. The interface for outgoing connections management was unified and is now available via the outgoing_pools config option for the following type of connections: cassandra - pool of connections to Cassandra cluster riak - pool of connections to Riak cluster redis - pool of connections to Redis server http - pool of connections to various HTTP(S) servers MongooseIM can talk to, in example HTTP authentication backend or HTTP notifications elastic - pool of connections to ElasticSearch server rdbms - pool of connections to an RDBMS database rabbit - pool of connections to a RabbitMQ server ldap - pool of connections to an LDAP server generic - pool of generic workers not associated directly with a particular connection (SNS, PushNotifications) All the above pools are managed by inaka/worker_pool library. Every entry in the outgoing_pools is a 5-element tuple: {Type, Host, Tag, PoolOptions, ConnectionOptions} Where: Type is one of the types listed above Host can be set to: global - meaning the pool will started once no matter how many XMPP hosts served by MongooseIM host - the pool will be started for all the XMPP hosts served by MongooseIM a binary representing a specific XMPP host like <<\"domain1.chat.im\">> Tag is a name to distinguish pools with the same Type and Host parameter. PoolOptions is a list of {key, value} pairs as defined in worker_pool doc with the following exception: strategy - specifies the worker selection strategy for the given pool, default is best_worker , more details on this can be found in Choosing strategy in worker_pool doc call_timeout - specifies the timeout, in milliseconds, for a call operation to the pool ConnectionOptions - options list passed to the start function of the pool type Examples Provided MongooseIM serves domains <<\"a.com\">> , <<\"b.com\">> , <<\"c.eu\">> and <<\"d.eu\">> the following outgoing_pools configuration: {redis, <<\"a.com\">>, default, PoolOpts, ConnOptsForDomain1}, {redis, host, default, PoolOpts, ConnOpts}, {redis, <<\"c.eu\", default, PoolOpts, ConnOptsForDomain2} will be expanded to the following configuration: {redis, <<\"a.com\">>, default, PoolOpts, ConnOptsForDomain1}, {redis, <<\"b.com\">>, default, PoolOpts, ConnOpts}, {redis, <<\"c.eu\", default, PoolOpts, ConnOptsForDomain2}, {redis, <<\"d.eu\">>, default, PoolOpts, ConnOpts} RDBMS connection setup An example RDBMS configuration inside outgoing_pools may look like this: {outgoing_pools, [ {rdbms, global, default, [{workers, 5}], [{server, {mysql, \"localhost\", 3306, \"mydb\", \"user\", \"passwd\"}}]} ]}. This configuration will create a default, global pool of 5 connections to a mysql database. We might also want to add a dedicated pool for a specific host: {outgoing_pools, [ {rdbms, global, default, [{workers, 5}], [{server, {mysql, \"localhost\", 3306, \"mydb\", \"user\", \"passwd\"}}]}, {rdbms, \"myhost.com\", default, [{workers, 3}], [{server, {mysql, \"localhost\", 3306, \"mydb\", \"user\", \"passwd\"}}]} ]}. Please remember that SQL databases require creating a schema. See Database backends configuration for more information. Also see Advanced configuration for additional options that influence RDBMS connections. Currently all pools must use the same RDBMS type (e.g. mysql , pgsql ). Connection options server Description: SQL DB connection configuration. Currently supported DB types are mysql and pgsql . Syntax: {server, {Type, Host, Port, DBName, Username, Password}}. or {server, \"<ODBC connection string>\"} Default: undefined keepalive_interval Description: When enabled, will send SELECT 1 query through every DB connection at given interval to keep them open. This option should be used to ensure that database connections are restarted after they became broken (e.g. due to a database restart or a load balancer dropping connections). Currently, not every network related error returned from a database driver to a regular query will imply a connection restart. Syntax: {keepalive_interval, IntervalSeconds}. Example: {keepalive_interval, 30}. Default: undefined MySQL and PostgreSQL SSL connection setup In order to establish a secure connection with a database, additional options must be passed in the server tuple. Here is the proper syntax: {server, {Type, Host, Port, DBName, Username, Password, SSL}}. MySQL SSL configuration options for MySQL: SSL Description: Specifies SSL connection options. Syntax: [Opt] Supported values: The options are just a list of Erlang ssl:ssl_option() . More details can be found in official Erlang ssl documentation . Warning: MongooseIM cannot connect to MySQL over TLS with OTP 20.3 . Example configuration An example configuration can look as follows: {outgoing_pools, [ {rdbms, global, default, [{workers, 5}], [{server, {mysql, \"localhost\", 3306, \"mydb\", \"mim\", \"mimpass\", [{verify, verify_peer}, {cacertfile, \"path/to/cacert.pem\"}, {server_name_indication, disable}]}}]} ]}. PostgreSQL SSL configuration options for PGSQL: SSL Description: Specifies general options for SSL connection. Syntax: [SSLMode, SSLOpts] SSLMode Description: Specifies a mode of SSL connection. Mode expresses how much the PostgreSQL driver carries about security of the connections. For more information click here . Syntax: {ssl, Mode} Supported values: false , true , required SSLOpts Description: Specifies SSL connection options. Syntax: {ssl_opts, [Opt]} Supported values: The options are just a list of Erlang ssl:ssl_option() . More details can be found in official Erlang ssl documentation . Example configuration An example configuration can look as follows: {outgoing_pools, [ {rdbms, global, default, [{workers, 5}], [{server, {pgsql, \"localhost\", 5432, \"mydb\", \"mim\", \"mimpass\", [{ssl, required}, {ssl_opts, [{verify, verify_peer}, {cacertfile, \"path/to/cacert.pem\"}]}]}}]} ]}. ODBC SSL connection setup If you've configured MongooseIM to use an ODBC driver, i.e. you've provided an ODBC connection string in the server option, e.g. {server, \"DSN=mydb\"}. then the SSL options, along other connection options, should be present in the ~/.odbc.ini file. To enable SSL connection the sslmode option needs to be set to verify-full . Additionally, you can provide the path to the CA certificate using the sslrootcert option. Example ~/.odbc.ini configuration [mydb] Driver = ... ServerName = ... Port = ... ... sslmode = verify-full sslrootcert = /path/to/ca/cert HTTP connections setup Some MongooseIM modules need an HTTP connection to external service. These pools need to be configured and started before the module needs them. Below is a sample configuration: {outgoing_pools, [ {http, global, default, PoolOptions, ConnectionOptions} ]}. PoolOptions are described above, below there are the recommended PoolOptions for HTTP pools: strategy - the recommended value is available_worker call_timeout - it should be equal or longer than the value set in request_timeout below. ConnectionOptions can take the following {key, value} pairs: {server, HostName} - string, default: \"http://localhost\" - the URL of the destination HTTP server (including a port number if needed). {path_prefix, Prefix} - string, default: \"/\" - the part of the destination URL that is appended to the host name ( host option). {request_timeout, TimeoutValue} - non-negative integer, default: 2000 - maximum number of milliseconds to wait for the HTTP response. Example configuration {outgoing_pools, [ {http, global, http_auth, [{strategy, available_worker}], [{server, \"https://my_server:8080\"}]} ]}. Redis connection setup Session manager backend or mod_global_distrib requires a redis pool defined in the outgoing_pools option. They can be defined as follows: {ougtoing_pools, [ {redis, global, Tag, WorkersOptions, ConnectionOptions} ]}. The Tag parameter can only be set to default for a session backend. For mod_global_distrib module it can take any value (default is global_distrib ) but the name needs to be passed as: {redis, [{pool, Tag}]} in the mod_global_distrib options. See mod_global_distrib doc for details and examples. The ConnectionOptions list can take following parametrs as {key, value } pairs: host (default: \"localhost\" ) the hostname or IP address of the Redis server port (default: 6379 ) the port of the Redis server database (default: 0 ) number of the database to use by the pool password (default: \"\" ) the password to the database (if set). Example {ougtoing_pools, [ {redis, global, default, [{strategy, random_worker}], [{host, \"198.172.15.12\"}, {port, 9923}]} ]}. Riak connection setup Currently only one Riak connection pool can exist for each supported XMPP host. It is configured with the following tuple inside the outgoing_pools config option. {outgoing_pools, [ {riak, global, default, [{workers, 20}], [{address, \"127.0.0.1\"}, {port, 8087}]} ]}. Riak SSL connection setup Using SSL for Riak connection requires passing extra options in ConnectionOptions to the aforementioned riak tuple. Here is the proper syntax: Credentials Description: Specifies credentials to use to connect to the database. Syntax: {credentials, User, Password} Supported values User and Password are strings with a database username and password respectively. CACert Description: Specifies a path to the CA certificate that was used to sign the database certificates. Syntax: {cacertfile, Path} Supported values Path is a string with a path to the CA certificate file. SSL_Opts Description : list of SSL options as defined in Erlang SSL module doc They will be passed verbatim to the ssl:connect function. Syntax {ssl_opts, ListOfSSLOpts} Example : {ssl_opts, [{ciphers, [\"AES256-SHA\", \"DHE-RSA-AES128-SHA256\"]}, {server_name_indication, disable}]} Example configuration An example configuration can look as follows: {outgoing_pools, [ {riak, global, default, [{workers, 20}, {strategy, next_worker}], [{address, \"127.0.0.1\"}, {port, 8087}, {credentials, \"username\", \"pass\"}, {cacertfile, \"path/to/cacert.pem\"}]} ]}. Cassandra connection setup The minimum pool definition for cassandra workers looks as follows: {outgoing_pools, [ {cassandra, global, default, [], []} ]}. In this case MongooseIM will by default try to connect to Cassandra server on \"localhost\" and port 9042. The keyspace used in queries will be mongooseim . ConnectionOptions The ConnectionOptions list can take following parameters as {key, Value} pairs: servers - A list of servers in Cassandra cluster in {HostnameOrIP, Port} format. keyspace - A name of keyspace to use in queries executed in this pool. You can find a full list in cqerl documentation . Example {cassandra, global, default, [], [ {servers, [{\"cassandra_server1.example.com\", 9042}, {\"cassandra_server2.example.com\", 9042}] }, {keyspace, \"big_mongooseim\"} ] ]} SSL connection setup In order to establish a secure connection to Cassandra you must make some changes in the MongooseIM and Cassandra configuration files. Create server keystore Follow this guide if you need to create certificate files. Change the Cassandra configuration file Find client_encryption_options in cassandra.yaml and make these changes: client_encryption_options: \u2002\u2002\u2002\u2002enabled: true \u2002\u2002\u2002\u2002keystore: /your_certificate_directory/server.keystore \u2002\u2002\u2002\u2002keystore_password: your_password Save the changes and restart Cassandra. Enable MongooseIM to connect with SSL An SSL connection can be established with both self-signed and CA-signed certificates. Self-signed certificate Add the following to ConnectionOptions list: {ssl, [{verify, verify_none}]} Save the changes and restart MongooseIM. CA-signed certificate Add the following to ConnectionOptions list: {ssl, [{cacertfile, \"/path/to/rootCA.pem\"}, {verify, verify_peer}]} Save the changes and restart MongooseIM. Testing the connection Make sure Cassandra is running and then run MongooseIM in live mode: $ ./mongooseim live $ (mongooseim@localhost)1> cqerl:get_client(default). {ok,{<0.474.0>,#Ref<0.160699839.1270874114.234457>}} $ (mongooseim@localhost)2> sys:get_state(pid(0,474,0)). {live,{client_state,cqerl_auth_plain_handler,undefined, \u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002undefined, \u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002{\"localhost\",9042}, \u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002ssl, \u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002{sslsocket,{gen_tcp,#Port<0.8458>,tls_connection,undefined}, \u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002 <0.475.0>}, \u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002undefined,mongooseim,infinity,<<>>,undefined, \u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002[...], \u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002{[],[]}, \u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002[0,1,2,3,4,5,6,7,8,9,10,11|...], \u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002[],hash, \u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002{{\"localhost\",9042}, \u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002 [...]}}} If no errors occurred and your output is similar to the one above then your MongooseIM and Cassandra nodes can communicate over SSL. ElasticSearch connection setup A connection pool to ElasticSearch can be configured as follows: {outgoing_pools, [ {elastic, global, default, [], [{host, \"localhost\"}]} ]}. Currently only one pool with tag default can be used. MongooseIM uses inaka/tirerl library to communicate with ElasticSearch. This library uses worker_pool in a bit different way than MongooseIM does, so the following options are not configurable via WPoolOpts : call_timeout (inifinity) worker selection strategy ( available_worker or what's set as default_strategy of worker_pool application) overrun_warning (infinity) overrun_handler , ({error_logger, warning_report}) Other worker_pool options are possible to set. In ConnectionOpts you can add (as {key, value} pairs): host (default: \"localhost\" ) - hostname or IP address of ElasticSearch node port (default: 9200 ) - port the ElasticSearch node's HTTP API is listening on Run the following function in the MongooseIM shell to verify that the connection has been established: 1> mongoose_elasticsearch:health(). {ok,#{<<\"active_primary_shards\">> => 15,<<\"active_shards\">> => 15, <<\"active_shards_percent_as_number\">> => 50.0, <<\"cluster_name\">> => <<\"docker-cluster\">>, <<\"delayed_unassigned_shards\">> => 0, <<\"initializing_shards\">> => 0, <<\"number_of_data_nodes\">> => 1, <<\"number_of_in_flight_fetch\">> => 0, <<\"number_of_nodes\">> => 1, <<\"number_of_pending_tasks\">> => 0, <<\"relocating_shards\">> => 0, <<\"status\">> => <<\"yellow\">>, <<\"task_max_waiting_in_queue_millis\">> => 0, <<\"timed_out\">> => false, <<\"unassigned_shards\">> => 15}} Note that the output might differ based on your ElasticSearch cluster configuration. RabbitMQ connection setup RabbitMQ backend for mod_event_pusher requires a rabbit pool defined in the outgoing_pools option. They can be defined as follows: {ougtoing_pools, [ {rabbit, host, Tag, WorkersOptions, ConnectionOptions} ]}. Notice that Host parameter is set to atom host . This basically means that MongooseIM will start as many rabbit pools as XMPP hosts are served by the server. The Tag parameter must be set to event_pusher in order to be able to use the pool for mod_event_pusher_rabbit . Any other Tag can be used for any other RabbitMQ connection pool. The ConnectionOptions list can take following parameters as {key, value } pairs: amqp_host (default: \"localhost\" ) - Defines RabbitMQ server host (domain or IP address; both as a string); amqp_port (default: 5672 ) - Defines RabbitMQ server AMQP port; amqp_username (default: \"guest\" ) - Defines RabbitMQ server username; amqp_password (default: \"guest\" ) - Defines RabbitMQ server password; confirms_enabled (default: false ) - Enables/disables one-to-one publishers confirms; max_worker_queue_len (default: 1000 ; use infinity to disable it) - Sets a limit of messages in a worker's mailbox above which the worker starts dropping the messages. If a worker message queue length reaches the limit, messages from the head of the queue are dropped until the queue length is again below the limit. Example {ougtoing_pools, [ {rabbit, host, event_pusher, [{workers, 20}], [{amqp_host, \"localhost\"}, {amqp_port, 5672}, {amqp_username, \"guest\"}, {amqp_password, \"guest\"}, {confirms_enabled, true}, {max_worker_queue_len, 100}]} ]}. LDAP connection setup To configure a pool of connections to an LDAP server, use the following syntax: {ldap, Host, Tag, PoolOptions, ConnectionOptions} Connection options The following options can be specified in the ConnectionOptions list: servers Description: List of IP addresses or DNS names of your LDAP servers. They are tried sequentially until the connection succeeds. Value: A list of strings Default: [\"localhost\"] Example: [\"primary-ldap-server.example.com\", \"secondary-ldap-server.example.com\"] encrypt Description: Enable connection encryption with your LDAP server. The value tls enables encryption by using LDAP over SSL. Note that STARTTLS encryption is not supported. Values: none , tls Default: none tls_options Description: Specifies TLS connection options. Requires {encrypt, tls} (see above). Value: List of ssl:tls_client_option() . More details can be found in the official Erlang ssl documentation . Default: no options Example: [{verify, verify_peer}, {cacertfile, \"path/to/cacert.pem\"}] port Description: Port to connect to your LDAP server. Values: Integer Default: 389 if encryption is disabled. 636 if encryption is enabled. rootdn Description: Bind DN Values: String Default: empty string which is anonymous connection password Description: Bind password Values: String Default: empty string connect_interval Description: Interval between consecutive connection attempts in case of connection failure Value: Integer (milliseconds) Default: 10000 Example A pool started for each host with the default tag and 5 workers. The LDAP server is at ldap-server.example.com:389 . MongooseIM will authenticate as cn=admin,dc=example,dc=com with the provided password. {outgoing_pools, [ {ldap, host, default, [{workers, 5}], [{servers, [\"ldap-server.example.com\"]}, {rootdn, \"cn=admin,dc=example,dc=com\"}, {password, \"ldap-admin-password\"}] } ]}.","title":"Outgoing connections"},{"location":"advanced-configuration/outgoing-connections/#outgoing-connections","text":"MongooseIM can be configured to talk to external service like databases or HTTP servers in order to get or set the required data. The interface for outgoing connections management was unified and is now available via the outgoing_pools config option for the following type of connections: cassandra - pool of connections to Cassandra cluster riak - pool of connections to Riak cluster redis - pool of connections to Redis server http - pool of connections to various HTTP(S) servers MongooseIM can talk to, in example HTTP authentication backend or HTTP notifications elastic - pool of connections to ElasticSearch server rdbms - pool of connections to an RDBMS database rabbit - pool of connections to a RabbitMQ server ldap - pool of connections to an LDAP server generic - pool of generic workers not associated directly with a particular connection (SNS, PushNotifications) All the above pools are managed by inaka/worker_pool library. Every entry in the outgoing_pools is a 5-element tuple: {Type, Host, Tag, PoolOptions, ConnectionOptions} Where: Type is one of the types listed above Host can be set to: global - meaning the pool will started once no matter how many XMPP hosts served by MongooseIM host - the pool will be started for all the XMPP hosts served by MongooseIM a binary representing a specific XMPP host like <<\"domain1.chat.im\">> Tag is a name to distinguish pools with the same Type and Host parameter. PoolOptions is a list of {key, value} pairs as defined in worker_pool doc with the following exception: strategy - specifies the worker selection strategy for the given pool, default is best_worker , more details on this can be found in Choosing strategy in worker_pool doc call_timeout - specifies the timeout, in milliseconds, for a call operation to the pool ConnectionOptions - options list passed to the start function of the pool type","title":"Outgoing connections"},{"location":"advanced-configuration/outgoing-connections/#examples","text":"Provided MongooseIM serves domains <<\"a.com\">> , <<\"b.com\">> , <<\"c.eu\">> and <<\"d.eu\">> the following outgoing_pools configuration: {redis, <<\"a.com\">>, default, PoolOpts, ConnOptsForDomain1}, {redis, host, default, PoolOpts, ConnOpts}, {redis, <<\"c.eu\", default, PoolOpts, ConnOptsForDomain2} will be expanded to the following configuration: {redis, <<\"a.com\">>, default, PoolOpts, ConnOptsForDomain1}, {redis, <<\"b.com\">>, default, PoolOpts, ConnOpts}, {redis, <<\"c.eu\", default, PoolOpts, ConnOptsForDomain2}, {redis, <<\"d.eu\">>, default, PoolOpts, ConnOpts}","title":"Examples"},{"location":"advanced-configuration/outgoing-connections/#rdbms-connection-setup","text":"An example RDBMS configuration inside outgoing_pools may look like this: {outgoing_pools, [ {rdbms, global, default, [{workers, 5}], [{server, {mysql, \"localhost\", 3306, \"mydb\", \"user\", \"passwd\"}}]} ]}. This configuration will create a default, global pool of 5 connections to a mysql database. We might also want to add a dedicated pool for a specific host: {outgoing_pools, [ {rdbms, global, default, [{workers, 5}], [{server, {mysql, \"localhost\", 3306, \"mydb\", \"user\", \"passwd\"}}]}, {rdbms, \"myhost.com\", default, [{workers, 3}], [{server, {mysql, \"localhost\", 3306, \"mydb\", \"user\", \"passwd\"}}]} ]}. Please remember that SQL databases require creating a schema. See Database backends configuration for more information. Also see Advanced configuration for additional options that influence RDBMS connections. Currently all pools must use the same RDBMS type (e.g. mysql , pgsql ).","title":"RDBMS connection setup"},{"location":"advanced-configuration/outgoing-connections/#connection-options","text":"server Description: SQL DB connection configuration. Currently supported DB types are mysql and pgsql . Syntax: {server, {Type, Host, Port, DBName, Username, Password}}. or {server, \"<ODBC connection string>\"} Default: undefined keepalive_interval Description: When enabled, will send SELECT 1 query through every DB connection at given interval to keep them open. This option should be used to ensure that database connections are restarted after they became broken (e.g. due to a database restart or a load balancer dropping connections). Currently, not every network related error returned from a database driver to a regular query will imply a connection restart. Syntax: {keepalive_interval, IntervalSeconds}. Example: {keepalive_interval, 30}. Default: undefined","title":"Connection options"},{"location":"advanced-configuration/outgoing-connections/#mysql-and-postgresql-ssl-connection-setup","text":"In order to establish a secure connection with a database, additional options must be passed in the server tuple. Here is the proper syntax: {server, {Type, Host, Port, DBName, Username, Password, SSL}}.","title":"MySQL and PostgreSQL SSL connection setup"},{"location":"advanced-configuration/outgoing-connections/#mysql","text":"SSL configuration options for MySQL: SSL Description: Specifies SSL connection options. Syntax: [Opt] Supported values: The options are just a list of Erlang ssl:ssl_option() . More details can be found in official Erlang ssl documentation . Warning: MongooseIM cannot connect to MySQL over TLS with OTP 20.3 .","title":"MySQL"},{"location":"advanced-configuration/outgoing-connections/#example-configuration","text":"An example configuration can look as follows: {outgoing_pools, [ {rdbms, global, default, [{workers, 5}], [{server, {mysql, \"localhost\", 3306, \"mydb\", \"mim\", \"mimpass\", [{verify, verify_peer}, {cacertfile, \"path/to/cacert.pem\"}, {server_name_indication, disable}]}}]} ]}.","title":"Example configuration"},{"location":"advanced-configuration/outgoing-connections/#postgresql","text":"SSL configuration options for PGSQL: SSL Description: Specifies general options for SSL connection. Syntax: [SSLMode, SSLOpts] SSLMode Description: Specifies a mode of SSL connection. Mode expresses how much the PostgreSQL driver carries about security of the connections. For more information click here . Syntax: {ssl, Mode} Supported values: false , true , required SSLOpts Description: Specifies SSL connection options. Syntax: {ssl_opts, [Opt]} Supported values: The options are just a list of Erlang ssl:ssl_option() . More details can be found in official Erlang ssl documentation .","title":"PostgreSQL"},{"location":"advanced-configuration/outgoing-connections/#example-configuration_1","text":"An example configuration can look as follows: {outgoing_pools, [ {rdbms, global, default, [{workers, 5}], [{server, {pgsql, \"localhost\", 5432, \"mydb\", \"mim\", \"mimpass\", [{ssl, required}, {ssl_opts, [{verify, verify_peer}, {cacertfile, \"path/to/cacert.pem\"}]}]}}]} ]}.","title":"Example configuration"},{"location":"advanced-configuration/outgoing-connections/#odbc-ssl-connection-setup","text":"If you've configured MongooseIM to use an ODBC driver, i.e. you've provided an ODBC connection string in the server option, e.g. {server, \"DSN=mydb\"}. then the SSL options, along other connection options, should be present in the ~/.odbc.ini file. To enable SSL connection the sslmode option needs to be set to verify-full . Additionally, you can provide the path to the CA certificate using the sslrootcert option.","title":"ODBC SSL connection setup"},{"location":"advanced-configuration/outgoing-connections/#example-odbcini-configuration","text":"[mydb] Driver = ... ServerName = ... Port = ... ... sslmode = verify-full sslrootcert = /path/to/ca/cert","title":"Example ~/.odbc.ini configuration"},{"location":"advanced-configuration/outgoing-connections/#http-connections-setup","text":"Some MongooseIM modules need an HTTP connection to external service. These pools need to be configured and started before the module needs them. Below is a sample configuration: {outgoing_pools, [ {http, global, default, PoolOptions, ConnectionOptions} ]}. PoolOptions are described above, below there are the recommended PoolOptions for HTTP pools: strategy - the recommended value is available_worker call_timeout - it should be equal or longer than the value set in request_timeout below. ConnectionOptions can take the following {key, value} pairs: {server, HostName} - string, default: \"http://localhost\" - the URL of the destination HTTP server (including a port number if needed). {path_prefix, Prefix} - string, default: \"/\" - the part of the destination URL that is appended to the host name ( host option). {request_timeout, TimeoutValue} - non-negative integer, default: 2000 - maximum number of milliseconds to wait for the HTTP response.","title":"HTTP connections setup"},{"location":"advanced-configuration/outgoing-connections/#example-configuration_2","text":"{outgoing_pools, [ {http, global, http_auth, [{strategy, available_worker}], [{server, \"https://my_server:8080\"}]} ]}.","title":"Example configuration"},{"location":"advanced-configuration/outgoing-connections/#redis-connection-setup","text":"Session manager backend or mod_global_distrib requires a redis pool defined in the outgoing_pools option. They can be defined as follows: {ougtoing_pools, [ {redis, global, Tag, WorkersOptions, ConnectionOptions} ]}. The Tag parameter can only be set to default for a session backend. For mod_global_distrib module it can take any value (default is global_distrib ) but the name needs to be passed as: {redis, [{pool, Tag}]} in the mod_global_distrib options. See mod_global_distrib doc for details and examples. The ConnectionOptions list can take following parametrs as {key, value } pairs: host (default: \"localhost\" ) the hostname or IP address of the Redis server port (default: 6379 ) the port of the Redis server database (default: 0 ) number of the database to use by the pool password (default: \"\" ) the password to the database (if set).","title":"Redis connection setup"},{"location":"advanced-configuration/outgoing-connections/#example","text":"{ougtoing_pools, [ {redis, global, default, [{strategy, random_worker}], [{host, \"198.172.15.12\"}, {port, 9923}]} ]}.","title":"Example"},{"location":"advanced-configuration/outgoing-connections/#riak-connection-setup","text":"Currently only one Riak connection pool can exist for each supported XMPP host. It is configured with the following tuple inside the outgoing_pools config option. {outgoing_pools, [ {riak, global, default, [{workers, 20}], [{address, \"127.0.0.1\"}, {port, 8087}]} ]}.","title":"Riak connection setup"},{"location":"advanced-configuration/outgoing-connections/#riak-ssl-connection-setup","text":"Using SSL for Riak connection requires passing extra options in ConnectionOptions to the aforementioned riak tuple. Here is the proper syntax: Credentials Description: Specifies credentials to use to connect to the database. Syntax: {credentials, User, Password} Supported values User and Password are strings with a database username and password respectively. CACert Description: Specifies a path to the CA certificate that was used to sign the database certificates. Syntax: {cacertfile, Path} Supported values Path is a string with a path to the CA certificate file. SSL_Opts Description : list of SSL options as defined in Erlang SSL module doc They will be passed verbatim to the ssl:connect function. Syntax {ssl_opts, ListOfSSLOpts} Example : {ssl_opts, [{ciphers, [\"AES256-SHA\", \"DHE-RSA-AES128-SHA256\"]}, {server_name_indication, disable}]}","title":"Riak SSL connection setup"},{"location":"advanced-configuration/outgoing-connections/#example-configuration_3","text":"An example configuration can look as follows: {outgoing_pools, [ {riak, global, default, [{workers, 20}, {strategy, next_worker}], [{address, \"127.0.0.1\"}, {port, 8087}, {credentials, \"username\", \"pass\"}, {cacertfile, \"path/to/cacert.pem\"}]} ]}.","title":"Example configuration"},{"location":"advanced-configuration/outgoing-connections/#cassandra-connection-setup","text":"The minimum pool definition for cassandra workers looks as follows: {outgoing_pools, [ {cassandra, global, default, [], []} ]}. In this case MongooseIM will by default try to connect to Cassandra server on \"localhost\" and port 9042. The keyspace used in queries will be mongooseim .","title":"Cassandra connection setup"},{"location":"advanced-configuration/outgoing-connections/#connectionoptions","text":"The ConnectionOptions list can take following parameters as {key, Value} pairs: servers - A list of servers in Cassandra cluster in {HostnameOrIP, Port} format. keyspace - A name of keyspace to use in queries executed in this pool. You can find a full list in cqerl documentation .","title":"ConnectionOptions"},{"location":"advanced-configuration/outgoing-connections/#example_1","text":"{cassandra, global, default, [], [ {servers, [{\"cassandra_server1.example.com\", 9042}, {\"cassandra_server2.example.com\", 9042}] }, {keyspace, \"big_mongooseim\"} ] ]}","title":"Example"},{"location":"advanced-configuration/outgoing-connections/#ssl-connection-setup","text":"In order to establish a secure connection to Cassandra you must make some changes in the MongooseIM and Cassandra configuration files.","title":"SSL connection setup"},{"location":"advanced-configuration/outgoing-connections/#create-server-keystore","text":"Follow this guide if you need to create certificate files.","title":"Create server keystore"},{"location":"advanced-configuration/outgoing-connections/#change-the-cassandra-configuration-file","text":"Find client_encryption_options in cassandra.yaml and make these changes: client_encryption_options: \u2002\u2002\u2002\u2002enabled: true \u2002\u2002\u2002\u2002keystore: /your_certificate_directory/server.keystore \u2002\u2002\u2002\u2002keystore_password: your_password Save the changes and restart Cassandra.","title":"Change the Cassandra configuration file"},{"location":"advanced-configuration/outgoing-connections/#enable-mongooseim-to-connect-with-ssl","text":"An SSL connection can be established with both self-signed and CA-signed certificates.","title":"Enable MongooseIM to connect with SSL"},{"location":"advanced-configuration/outgoing-connections/#self-signed-certificate","text":"Add the following to ConnectionOptions list: {ssl, [{verify, verify_none}]} Save the changes and restart MongooseIM.","title":"Self-signed certificate"},{"location":"advanced-configuration/outgoing-connections/#ca-signed-certificate","text":"Add the following to ConnectionOptions list: {ssl, [{cacertfile, \"/path/to/rootCA.pem\"}, {verify, verify_peer}]} Save the changes and restart MongooseIM.","title":"CA-signed certificate"},{"location":"advanced-configuration/outgoing-connections/#testing-the-connection","text":"Make sure Cassandra is running and then run MongooseIM in live mode: $ ./mongooseim live $ (mongooseim@localhost)1> cqerl:get_client(default). {ok,{<0.474.0>,#Ref<0.160699839.1270874114.234457>}} $ (mongooseim@localhost)2> sys:get_state(pid(0,474,0)). {live,{client_state,cqerl_auth_plain_handler,undefined, \u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002undefined, \u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002{\"localhost\",9042}, \u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002ssl, \u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002{sslsocket,{gen_tcp,#Port<0.8458>,tls_connection,undefined}, \u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002 <0.475.0>}, \u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002undefined,mongooseim,infinity,<<>>,undefined, \u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002[...], \u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002{[],[]}, \u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002[0,1,2,3,4,5,6,7,8,9,10,11|...], \u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002[],hash, \u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002{{\"localhost\",9042}, \u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002 [...]}}} If no errors occurred and your output is similar to the one above then your MongooseIM and Cassandra nodes can communicate over SSL.","title":"Testing the connection"},{"location":"advanced-configuration/outgoing-connections/#elasticsearch-connection-setup","text":"A connection pool to ElasticSearch can be configured as follows: {outgoing_pools, [ {elastic, global, default, [], [{host, \"localhost\"}]} ]}. Currently only one pool with tag default can be used. MongooseIM uses inaka/tirerl library to communicate with ElasticSearch. This library uses worker_pool in a bit different way than MongooseIM does, so the following options are not configurable via WPoolOpts : call_timeout (inifinity) worker selection strategy ( available_worker or what's set as default_strategy of worker_pool application) overrun_warning (infinity) overrun_handler , ({error_logger, warning_report}) Other worker_pool options are possible to set. In ConnectionOpts you can add (as {key, value} pairs): host (default: \"localhost\" ) - hostname or IP address of ElasticSearch node port (default: 9200 ) - port the ElasticSearch node's HTTP API is listening on Run the following function in the MongooseIM shell to verify that the connection has been established: 1> mongoose_elasticsearch:health(). {ok,#{<<\"active_primary_shards\">> => 15,<<\"active_shards\">> => 15, <<\"active_shards_percent_as_number\">> => 50.0, <<\"cluster_name\">> => <<\"docker-cluster\">>, <<\"delayed_unassigned_shards\">> => 0, <<\"initializing_shards\">> => 0, <<\"number_of_data_nodes\">> => 1, <<\"number_of_in_flight_fetch\">> => 0, <<\"number_of_nodes\">> => 1, <<\"number_of_pending_tasks\">> => 0, <<\"relocating_shards\">> => 0, <<\"status\">> => <<\"yellow\">>, <<\"task_max_waiting_in_queue_millis\">> => 0, <<\"timed_out\">> => false, <<\"unassigned_shards\">> => 15}} Note that the output might differ based on your ElasticSearch cluster configuration.","title":"ElasticSearch connection setup"},{"location":"advanced-configuration/outgoing-connections/#rabbitmq-connection-setup","text":"RabbitMQ backend for mod_event_pusher requires a rabbit pool defined in the outgoing_pools option. They can be defined as follows: {ougtoing_pools, [ {rabbit, host, Tag, WorkersOptions, ConnectionOptions} ]}. Notice that Host parameter is set to atom host . This basically means that MongooseIM will start as many rabbit pools as XMPP hosts are served by the server. The Tag parameter must be set to event_pusher in order to be able to use the pool for mod_event_pusher_rabbit . Any other Tag can be used for any other RabbitMQ connection pool. The ConnectionOptions list can take following parameters as {key, value } pairs: amqp_host (default: \"localhost\" ) - Defines RabbitMQ server host (domain or IP address; both as a string); amqp_port (default: 5672 ) - Defines RabbitMQ server AMQP port; amqp_username (default: \"guest\" ) - Defines RabbitMQ server username; amqp_password (default: \"guest\" ) - Defines RabbitMQ server password; confirms_enabled (default: false ) - Enables/disables one-to-one publishers confirms; max_worker_queue_len (default: 1000 ; use infinity to disable it) - Sets a limit of messages in a worker's mailbox above which the worker starts dropping the messages. If a worker message queue length reaches the limit, messages from the head of the queue are dropped until the queue length is again below the limit.","title":"RabbitMQ connection setup"},{"location":"advanced-configuration/outgoing-connections/#example_2","text":"{ougtoing_pools, [ {rabbit, host, event_pusher, [{workers, 20}], [{amqp_host, \"localhost\"}, {amqp_port, 5672}, {amqp_username, \"guest\"}, {amqp_password, \"guest\"}, {confirms_enabled, true}, {max_worker_queue_len, 100}]} ]}.","title":"Example"},{"location":"advanced-configuration/outgoing-connections/#ldap-connection-setup","text":"To configure a pool of connections to an LDAP server, use the following syntax: {ldap, Host, Tag, PoolOptions, ConnectionOptions}","title":"LDAP connection setup"},{"location":"advanced-configuration/outgoing-connections/#connection-options_1","text":"The following options can be specified in the ConnectionOptions list: servers Description: List of IP addresses or DNS names of your LDAP servers. They are tried sequentially until the connection succeeds. Value: A list of strings Default: [\"localhost\"] Example: [\"primary-ldap-server.example.com\", \"secondary-ldap-server.example.com\"] encrypt Description: Enable connection encryption with your LDAP server. The value tls enables encryption by using LDAP over SSL. Note that STARTTLS encryption is not supported. Values: none , tls Default: none tls_options Description: Specifies TLS connection options. Requires {encrypt, tls} (see above). Value: List of ssl:tls_client_option() . More details can be found in the official Erlang ssl documentation . Default: no options Example: [{verify, verify_peer}, {cacertfile, \"path/to/cacert.pem\"}] port Description: Port to connect to your LDAP server. Values: Integer Default: 389 if encryption is disabled. 636 if encryption is enabled. rootdn Description: Bind DN Values: String Default: empty string which is anonymous connection password Description: Bind password Values: String Default: empty string connect_interval Description: Interval between consecutive connection attempts in case of connection failure Value: Integer (milliseconds) Default: 10000","title":"Connection options"},{"location":"advanced-configuration/outgoing-connections/#example_3","text":"A pool started for each host with the default tag and 5 workers. The LDAP server is at ldap-server.example.com:389 . MongooseIM will authenticate as cn=admin,dc=example,dc=com with the provided password. {outgoing_pools, [ {ldap, host, default, [{workers, 5}], [{servers, [\"ldap-server.example.com\"]}, {rootdn, \"cn=admin,dc=example,dc=com\"}, {password, \"ldap-admin-password\"}] } ]}.","title":"Example"},{"location":"authentication-backends/External-authentication-module/","text":"Overview This backend delegates the authentication to an external script. Requires the SASL PLAIN method. Script API specification All \"commands\" sent from Erlang VM to the script are prefixed with a 2-byte unsigned integer (command length), MSB first. The script is expected to return responses in the same format. Currently only 2 response packets are supported: 0x0000 = false (for failure). 0x0001 = true (for success). The following list describes packets that the script should support. auth:<username>:<domain>:<password> - Check password. setpass:<username>:<domain>:<password> - Set password. tryregister:<username>:<domain>:<password> - Register a user. removeuser:<username>:<domain> - Remove a user. removeuser3:<username>:<domain>:<password> - Remove a user if the password is correct. isuser:<username>:<domain> - Check if a user exists. Configuration options extauth_program Description: Path to the authentication script used by the external auth module.","title":"External Authentication Module"},{"location":"authentication-backends/External-authentication-module/#overview","text":"This backend delegates the authentication to an external script. Requires the SASL PLAIN method.","title":"Overview"},{"location":"authentication-backends/External-authentication-module/#script-api-specification","text":"All \"commands\" sent from Erlang VM to the script are prefixed with a 2-byte unsigned integer (command length), MSB first. The script is expected to return responses in the same format. Currently only 2 response packets are supported: 0x0000 = false (for failure). 0x0001 = true (for success). The following list describes packets that the script should support. auth:<username>:<domain>:<password> - Check password. setpass:<username>:<domain>:<password> - Set password. tryregister:<username>:<domain>:<password> - Register a user. removeuser:<username>:<domain> - Remove a user. removeuser3:<username>:<domain>:<password> - Remove a user if the password is correct. isuser:<username>:<domain> - Check if a user exists.","title":"Script API specification"},{"location":"authentication-backends/External-authentication-module/#configuration-options","text":"extauth_program Description: Path to the authentication script used by the external auth module.","title":"Configuration options"},{"location":"authentication-backends/HTTP-authentication-module/","text":"Overview The purpose of this module is to connect with an external REST API and delegate the authentication operations to it whenever possible. The component must implement the API described in one of the next sections for ejabberd_auth_http to work out of the box. The module can be especially useful for users maintaining their own central user database which is shared with other services. It fits perfectly when the client application uses a custom authentication token and MongooseIM has to validate it externally. Configuration How to enable For a full reference please check Advanced-configuration#authentication . The simplest way is to just replace the default auth_method option in rel/files/mongooseim.cfg with {auth_method, http} . Enabling the module is not enough! Please follow instructions below. Configuration options ejabberd_auth_http uses an outgoing http connection pool called auth . The pool has to be defined in outgoing_pools section (see Outgoing-connections#/http-connections ). The following options can be set in the auth_opts tuple in rel/files/mongooseim.cfg : basic_auth (default: \"\" ) - HTTP Basic Authentication in format \"username:password\" ; auth service doesn't have to require authentication for HTTP auth to work Example {auth_opts, [ {basic_auth, \"mongooseim:DzviNQw3qyGJDrJDu+ClyA\"}, ]}. SCRAM support ejabberd_auth_http can use the SCRAM method. When SCRAM is enabled, the passwords sent to the auth service are serialised and the same serialised format is expected when fetching a password from the component. It is transparent when MongooseIM is responsible for all DB operations such as password setting, account creation etc. The service CAN perform the (de)serialization of SCRAM-encoded passwords. You can find more details on the SCRAM serialization page. Authentication service API URL format All GET requests include the following URL-encoded query string: ?user=<username>&server=<domain>&pass=<password> . All POST requests have the following URL-encoded string in the request body: user=<username>&server=<domain>&pass=<password> . If a certain method does not need a password, the value of pass is undefined , so it shouldn't be used. Return codes For the best integration, the return code range should not exceed the list below: 500 - internal server error 409 - conflict 404 - not found 403 - not allowed 401 - not authorised 400 - other error, should be sent in response body 204 - success, no return data 201 - created 200 - success, return value in response body Whenever the specification says \"anything else\", service should use one of the codes from the list above. Some requests consider multiple return codes a \"success\". It is up to the server-side developer to pick one of the codes. HTTP header Content-Length IMPORTANT: The authentication server MUST include a Content-Length HTTP header in the response. A body can be missing in the first data chunk read from a socket, leading to strange authentication errors. Method register Description: Creates a user account. HTTP method: POST Type: mandatory when mod_register is enabled Return values: 201 - success 409 - user already exists anything else - will be treated as failure Method check_password Description: Must respond if the password is valid for the user. HTTP method: GET Type: mandatory when SCRAM is not used Return values: 200, true or false in the body anything else - will be treated as false Method get_password Description: Must return the user's password in plaintext or in the SCRAM serialised form. HTTP method: GET Type: mandatory when SCRAM or DIGEST SASL mechanism is used Return values: 200, password in the body anything else - get_password will fail Method user_exists Description: Must return the information whether the user exists in DB. HTTP method: GET Type: mandatory Return values: 200, true or false in body anything else - will be treated as false Method set_password Description: Must set user's password in the internal database to a provided value. The value should not be transformed (except for URL-decoding) before writing into the DB. HTTP method: POST Type: mandatory when mod_register is enabled Return values: 200 or 201 or 204 - success anything else - will be treated as false Method remove_user Description: Removes a user account. HTTP method: POST Type: mandatory when mod_register is enabled Return values: 200 or 201 or 204 - success 404 - user does not exist 403 - not allowed for some reason 40X - will be treated as bad request Method remove_user_validate Description: Removes a user account only if the provided password is valid. HTTP method: POST Type: mandatory when mod_register is enabled Return values: 200 or 201 or 204 - success 404 - user does not exist 403 - invalid user password or not allowed for other reason 40X - will be treated as bad request Authentication service API recipes Below you can find some examples of the auth service APIs and MongooseIM-side configuration along with use cases. System using a common, custom auth token An Auth token is provided as a password. Service implements: check_password , user_exists MongooseIM config: password_format : plain , mod_register disabled Client side: MUST NOT use DIGEST-MD5 mechanism; use PLAIN Central database of plaintext passwords Service implements: check_password , get_password , user_exists MongooseIM config: password_format : plain , mod_register disabled Client side: May use any available auth method Central database able to process SCRAM Service implements: get_password , user_exists MongooseIM config: password_format : scram , mod_register disabled Client side: May use any available auth method Godlike MongooseIM Service implements: all methods MongooseIM config: password_format : scram (recommended) or plain , mod_register enabled Client side: May use any available auth method","title":"HTTP Authentication Module"},{"location":"authentication-backends/HTTP-authentication-module/#overview","text":"The purpose of this module is to connect with an external REST API and delegate the authentication operations to it whenever possible. The component must implement the API described in one of the next sections for ejabberd_auth_http to work out of the box. The module can be especially useful for users maintaining their own central user database which is shared with other services. It fits perfectly when the client application uses a custom authentication token and MongooseIM has to validate it externally.","title":"Overview"},{"location":"authentication-backends/HTTP-authentication-module/#configuration","text":"","title":"Configuration"},{"location":"authentication-backends/HTTP-authentication-module/#how-to-enable","text":"For a full reference please check Advanced-configuration#authentication . The simplest way is to just replace the default auth_method option in rel/files/mongooseim.cfg with {auth_method, http} . Enabling the module is not enough! Please follow instructions below.","title":"How to enable"},{"location":"authentication-backends/HTTP-authentication-module/#configuration-options","text":"ejabberd_auth_http uses an outgoing http connection pool called auth . The pool has to be defined in outgoing_pools section (see Outgoing-connections#/http-connections ). The following options can be set in the auth_opts tuple in rel/files/mongooseim.cfg : basic_auth (default: \"\" ) - HTTP Basic Authentication in format \"username:password\" ; auth service doesn't have to require authentication for HTTP auth to work","title":"Configuration options"},{"location":"authentication-backends/HTTP-authentication-module/#example","text":"{auth_opts, [ {basic_auth, \"mongooseim:DzviNQw3qyGJDrJDu+ClyA\"}, ]}.","title":"Example"},{"location":"authentication-backends/HTTP-authentication-module/#scram-support","text":"ejabberd_auth_http can use the SCRAM method. When SCRAM is enabled, the passwords sent to the auth service are serialised and the same serialised format is expected when fetching a password from the component. It is transparent when MongooseIM is responsible for all DB operations such as password setting, account creation etc. The service CAN perform the (de)serialization of SCRAM-encoded passwords. You can find more details on the SCRAM serialization page.","title":"SCRAM support"},{"location":"authentication-backends/HTTP-authentication-module/#authentication-service-api","text":"","title":"Authentication service API"},{"location":"authentication-backends/HTTP-authentication-module/#url-format","text":"All GET requests include the following URL-encoded query string: ?user=<username>&server=<domain>&pass=<password> . All POST requests have the following URL-encoded string in the request body: user=<username>&server=<domain>&pass=<password> . If a certain method does not need a password, the value of pass is undefined , so it shouldn't be used.","title":"URL format"},{"location":"authentication-backends/HTTP-authentication-module/#return-codes","text":"For the best integration, the return code range should not exceed the list below: 500 - internal server error 409 - conflict 404 - not found 403 - not allowed 401 - not authorised 400 - other error, should be sent in response body 204 - success, no return data 201 - created 200 - success, return value in response body Whenever the specification says \"anything else\", service should use one of the codes from the list above. Some requests consider multiple return codes a \"success\". It is up to the server-side developer to pick one of the codes.","title":"Return codes"},{"location":"authentication-backends/HTTP-authentication-module/#http-header-content-length","text":"IMPORTANT: The authentication server MUST include a Content-Length HTTP header in the response. A body can be missing in the first data chunk read from a socket, leading to strange authentication errors.","title":"HTTP header Content-Length"},{"location":"authentication-backends/HTTP-authentication-module/#method-register","text":"Description: Creates a user account. HTTP method: POST Type: mandatory when mod_register is enabled Return values: 201 - success 409 - user already exists anything else - will be treated as failure","title":"Method register"},{"location":"authentication-backends/HTTP-authentication-module/#method-check_password","text":"Description: Must respond if the password is valid for the user. HTTP method: GET Type: mandatory when SCRAM is not used Return values: 200, true or false in the body anything else - will be treated as false","title":"Method check_password"},{"location":"authentication-backends/HTTP-authentication-module/#method-get_password","text":"Description: Must return the user's password in plaintext or in the SCRAM serialised form. HTTP method: GET Type: mandatory when SCRAM or DIGEST SASL mechanism is used Return values: 200, password in the body anything else - get_password will fail","title":"Method get_password"},{"location":"authentication-backends/HTTP-authentication-module/#method-user_exists","text":"Description: Must return the information whether the user exists in DB. HTTP method: GET Type: mandatory Return values: 200, true or false in body anything else - will be treated as false","title":"Method user_exists"},{"location":"authentication-backends/HTTP-authentication-module/#method-set_password","text":"Description: Must set user's password in the internal database to a provided value. The value should not be transformed (except for URL-decoding) before writing into the DB. HTTP method: POST Type: mandatory when mod_register is enabled Return values: 200 or 201 or 204 - success anything else - will be treated as false","title":"Method set_password"},{"location":"authentication-backends/HTTP-authentication-module/#method-remove_user","text":"Description: Removes a user account. HTTP method: POST Type: mandatory when mod_register is enabled Return values: 200 or 201 or 204 - success 404 - user does not exist 403 - not allowed for some reason 40X - will be treated as bad request","title":"Method remove_user"},{"location":"authentication-backends/HTTP-authentication-module/#method-remove_user_validate","text":"Description: Removes a user account only if the provided password is valid. HTTP method: POST Type: mandatory when mod_register is enabled Return values: 200 or 201 or 204 - success 404 - user does not exist 403 - invalid user password or not allowed for other reason 40X - will be treated as bad request","title":"Method remove_user_validate"},{"location":"authentication-backends/HTTP-authentication-module/#authentication-service-api-recipes","text":"Below you can find some examples of the auth service APIs and MongooseIM-side configuration along with use cases.","title":"Authentication service API recipes"},{"location":"authentication-backends/HTTP-authentication-module/#system-using-a-common-custom-auth-token","text":"An Auth token is provided as a password. Service implements: check_password , user_exists MongooseIM config: password_format : plain , mod_register disabled Client side: MUST NOT use DIGEST-MD5 mechanism; use PLAIN","title":"System using a common, custom auth token"},{"location":"authentication-backends/HTTP-authentication-module/#central-database-of-plaintext-passwords","text":"Service implements: check_password , get_password , user_exists MongooseIM config: password_format : plain , mod_register disabled Client side: May use any available auth method","title":"Central database of plaintext passwords"},{"location":"authentication-backends/HTTP-authentication-module/#central-database-able-to-process-scram","text":"Service implements: get_password , user_exists MongooseIM config: password_format : scram , mod_register disabled Client side: May use any available auth method","title":"Central database able to process SCRAM"},{"location":"authentication-backends/HTTP-authentication-module/#godlike-mongooseim","text":"Service implements: all methods MongooseIM config: password_format : scram (recommended) or plain , mod_register enabled Client side: May use any available auth method","title":"Godlike MongooseIM"},{"location":"authentication-backends/JWT-authentication-module/","text":"Overview JWT authentication backend can verify JSON Web Tokens provided by the clients. A wide range of signature algorithms is supported, including those using public key cryptography. The module checks the signature and validity of the following parameters: exp - an expired token is rejected, iat - a token must be issued in the past, nbf - a token might not be valid yet . Requires the SASL PLAIN method. Configuration options jwt_secret_source Description: A path to a file or an environment variable, which will be used as a JWT secret. Warning: Please note that while a direct path to a file is read only once during startup, a path in the environment variable is read on every auth request. Value: string, e.g. /etc/secrets/jwt or {env, \"env-variable-name\"} Default: none, either jwt_secret_source or jwt_secret must be set jwt_secret Description: A binary with a JWT secret. This option is ignored and overwritten, if jwt_secret_source is defined. Value: binary Default: none (either jwt_secret_source or jwt_secret must be set) jwt_algorithm Description: A name of the algorithm used to sign JWT. Valid values: \"HS256\", \"RS256\", \"ES256\", \"HS386\", \"RS386\", \"ES386\", \"HS512\", \"RS512\", \"ES512\" Default: none, it's a mandatory option jwt_username_key Description: A JWT key that contains the username to verify. Value: atom Default: none, it's a mandatory option","title":"JWT Authentication Module"},{"location":"authentication-backends/JWT-authentication-module/#overview","text":"JWT authentication backend can verify JSON Web Tokens provided by the clients. A wide range of signature algorithms is supported, including those using public key cryptography. The module checks the signature and validity of the following parameters: exp - an expired token is rejected, iat - a token must be issued in the past, nbf - a token might not be valid yet . Requires the SASL PLAIN method.","title":"Overview"},{"location":"authentication-backends/JWT-authentication-module/#configuration-options","text":"jwt_secret_source Description: A path to a file or an environment variable, which will be used as a JWT secret. Warning: Please note that while a direct path to a file is read only once during startup, a path in the environment variable is read on every auth request. Value: string, e.g. /etc/secrets/jwt or {env, \"env-variable-name\"} Default: none, either jwt_secret_source or jwt_secret must be set jwt_secret Description: A binary with a JWT secret. This option is ignored and overwritten, if jwt_secret_source is defined. Value: binary Default: none (either jwt_secret_source or jwt_secret must be set) jwt_algorithm Description: A name of the algorithm used to sign JWT. Valid values: \"HS256\", \"RS256\", \"ES256\", \"HS386\", \"RS386\", \"ES386\", \"HS512\", \"RS512\", \"ES512\" Default: none, it's a mandatory option jwt_username_key Description: A JWT key that contains the username to verify. Value: atom Default: none, it's a mandatory option","title":"Configuration options"},{"location":"authentication-backends/LDAP-authentication-module/","text":"Overview An LDAP authentication module. It provides a read-only abstraction over an LDAP directory. The following SASL methods are supported: SASL EXTERNAL User credentials are verified by performing an LDAP search with the user name provided by the client. This can be used to verify that the user is allowed to log in after the provided certificate has been verified. This method requires one connection pool with the default tag (unless you change it with the ldap_pool_tag option). You need to provide the root DN and password unless your LDAP password allows anonymous searches. Example: {outgoing_pools, [ {ldap, host, default, [{workers, 5}], [{servers, [\"ldap-server.example.com\"]}, {rootdn, \"cn=admin,dc=example,dc=com\"}, {password, \"ldap-admin-password\"}] } ]}. For more details see outgoing connections . SASL PLAIN User credentials are verified by performing an LDAP search followed by a bind with the user name and password provided by the client. To use SASL PLAIN, you need to configure two connection pools: one with the default tag (unless you change it with the ldap_pool_tag option) for the search operations (like for SASL EXTERNAL), one with the bind tag (unless you change it with the ldap_bind_pool_tag option) for the bind operations - for this one it is not necessary to provide the root DN and password as the bind operations will be performed with users' credentials. This pool has to be used exclusively for the bind operations as the authentication state of the connection changes with each request. Example: {outgoing_pools, [ {ldap, host, default, [{workers, 5}], [{servers, [\"ldap-server.example.com\"]}, {rootdn, \"cn=admin,dc=example,dc=com\"}, {password, \"ldap-admin-password\"}] }, {ldap, host, bind, [{workers, 5}], [{servers, [\"ldap-server.example.com\"]}] } ]}. For more details see outgoing connections . Configuration options The following options can be set in the auth_opts tuple in mongooseim.cfg . ldap_pool_tag: Description: Worker pool tag for the search operations. Value: Atom Default: default ldap_bind_pool_tag: Description: Worker pool tag for the search operations. Value: Atom Default: bind ldap_base: Description: LDAP base directory which stores user accounts. Value: String Default: This option is required ldap_uids: Description: An LDAP attribute holding a list of attributes to use as alternatives for getting the JID. The attributes take the following form: [{ldap_uidattr}] or [{ldap_uidattr, ldap_uidattr_format}] . You can use as many comma separated attributes as needed. Value: [ ldap_uidattr | {ldap_uidattr: ldap_uidattr_format} ] ldap_uidattr: An LDAP attribute holding the user\u2019s part of a JID. The default value is uid . ldap_uidattr_format: The format of the ldap_uidattr variable. It must contain one and only one pattern variable %u which will be replaced by the user\u2019s part of a JID (example: %u@example.org ). The default value is %u . Default [{uid, %u}] ldap_filter: Description: An LDAP filter. Please, do not forget to close the brackets and do not use superfluous whitespaces. Also do not use the ldap_uidattr attribute in the filter because it will be substituted in the LDAP filter automatically. Value: String. For example: \"(&(objectClass=shadowAccount)(memberOf=Jabber Users))\" Default: undefined ldap_dn_filter: Description: This filter is applied to the results returned by the main filter. It performs an additional LDAP lookup to provide the complete result. This is useful when you are unable to define all filter rules in the ldap_filter . You can define %u , %d , %s and %D pattern variables in the filter: %u is replaced by a user\u2019s part of a JID, %d is replaced by the corresponding domain (virtual host), all %s variables are consecutively replaced by values of FilterAttrs attributes and %D is replaced by the Distinguished Name. Since this filter makes additional LDAP lookups, use it only as the last resort; try to define all filter rules in ldap_filter if possible. Value: {Filter, [FilterAttributes]} . For example: {\"(&(name=%s)(owner=%D)(user=%u@%d))\": [\"sn\"]} Default: undefined ldap_local_filter: Description: If you can\u2019t use the ldap_filter due to performance reasons (the LDAP server has many users registered), you can use this local filter. The local filter checks an attribute in MongooseIM, not in LDAP, so this limits the load on the LDAP directory. Value: Filter . Example values: {ldap_local_filter, {notequal, {\"accountStatus\",[\"disabled\"]}}}. {ldap_local_filter, {equal, {\"accountStatus\",[\"enabled\"]}}}. {ldap_local_filter, undefined}. Default: undefined ldap_deref Description: Whether or not to dereference aliases Values: never , always , finding , searching Default: never Example: {auth_opts, [ {ldap_base, \"ou=Users,dc=example,dc=com\"}, {ldap_filter, \"(objectClass=inetOrgPerson)\"} ]}.","title":"LDAP Authentication Module"},{"location":"authentication-backends/LDAP-authentication-module/#overview","text":"An LDAP authentication module. It provides a read-only abstraction over an LDAP directory. The following SASL methods are supported:","title":"Overview"},{"location":"authentication-backends/LDAP-authentication-module/#sasl-external","text":"User credentials are verified by performing an LDAP search with the user name provided by the client. This can be used to verify that the user is allowed to log in after the provided certificate has been verified. This method requires one connection pool with the default tag (unless you change it with the ldap_pool_tag option). You need to provide the root DN and password unless your LDAP password allows anonymous searches. Example: {outgoing_pools, [ {ldap, host, default, [{workers, 5}], [{servers, [\"ldap-server.example.com\"]}, {rootdn, \"cn=admin,dc=example,dc=com\"}, {password, \"ldap-admin-password\"}] } ]}. For more details see outgoing connections .","title":"SASL EXTERNAL"},{"location":"authentication-backends/LDAP-authentication-module/#sasl-plain","text":"User credentials are verified by performing an LDAP search followed by a bind with the user name and password provided by the client. To use SASL PLAIN, you need to configure two connection pools: one with the default tag (unless you change it with the ldap_pool_tag option) for the search operations (like for SASL EXTERNAL), one with the bind tag (unless you change it with the ldap_bind_pool_tag option) for the bind operations - for this one it is not necessary to provide the root DN and password as the bind operations will be performed with users' credentials. This pool has to be used exclusively for the bind operations as the authentication state of the connection changes with each request. Example: {outgoing_pools, [ {ldap, host, default, [{workers, 5}], [{servers, [\"ldap-server.example.com\"]}, {rootdn, \"cn=admin,dc=example,dc=com\"}, {password, \"ldap-admin-password\"}] }, {ldap, host, bind, [{workers, 5}], [{servers, [\"ldap-server.example.com\"]}] } ]}. For more details see outgoing connections .","title":"SASL PLAIN"},{"location":"authentication-backends/LDAP-authentication-module/#configuration-options","text":"The following options can be set in the auth_opts tuple in mongooseim.cfg . ldap_pool_tag: Description: Worker pool tag for the search operations. Value: Atom Default: default ldap_bind_pool_tag: Description: Worker pool tag for the search operations. Value: Atom Default: bind ldap_base: Description: LDAP base directory which stores user accounts. Value: String Default: This option is required ldap_uids: Description: An LDAP attribute holding a list of attributes to use as alternatives for getting the JID. The attributes take the following form: [{ldap_uidattr}] or [{ldap_uidattr, ldap_uidattr_format}] . You can use as many comma separated attributes as needed. Value: [ ldap_uidattr | {ldap_uidattr: ldap_uidattr_format} ] ldap_uidattr: An LDAP attribute holding the user\u2019s part of a JID. The default value is uid . ldap_uidattr_format: The format of the ldap_uidattr variable. It must contain one and only one pattern variable %u which will be replaced by the user\u2019s part of a JID (example: %u@example.org ). The default value is %u . Default [{uid, %u}] ldap_filter: Description: An LDAP filter. Please, do not forget to close the brackets and do not use superfluous whitespaces. Also do not use the ldap_uidattr attribute in the filter because it will be substituted in the LDAP filter automatically. Value: String. For example: \"(&(objectClass=shadowAccount)(memberOf=Jabber Users))\" Default: undefined ldap_dn_filter: Description: This filter is applied to the results returned by the main filter. It performs an additional LDAP lookup to provide the complete result. This is useful when you are unable to define all filter rules in the ldap_filter . You can define %u , %d , %s and %D pattern variables in the filter: %u is replaced by a user\u2019s part of a JID, %d is replaced by the corresponding domain (virtual host), all %s variables are consecutively replaced by values of FilterAttrs attributes and %D is replaced by the Distinguished Name. Since this filter makes additional LDAP lookups, use it only as the last resort; try to define all filter rules in ldap_filter if possible. Value: {Filter, [FilterAttributes]} . For example: {\"(&(name=%s)(owner=%D)(user=%u@%d))\": [\"sn\"]} Default: undefined ldap_local_filter: Description: If you can\u2019t use the ldap_filter due to performance reasons (the LDAP server has many users registered), you can use this local filter. The local filter checks an attribute in MongooseIM, not in LDAP, so this limits the load on the LDAP directory. Value: Filter . Example values: {ldap_local_filter, {notequal, {\"accountStatus\",[\"disabled\"]}}}. {ldap_local_filter, {equal, {\"accountStatus\",[\"enabled\"]}}}. {ldap_local_filter, undefined}. Default: undefined ldap_deref Description: Whether or not to dereference aliases Values: never , always , finding , searching Default: never Example: {auth_opts, [ {ldap_base, \"ou=Users,dc=example,dc=com\"}, {ldap_filter, \"(objectClass=inetOrgPerson)\"} ]}.","title":"Configuration options"},{"location":"authentication-backends/PKI-authentication-module/","text":"Overview It is a simple auth backend, meant to be used with SASL EXTERNAL authentication mechanism. It simply accepts all usernames as long as they are validated by SASL logic. WARNING Some of its callbacks return hardcoded values, as it's impossible for this backend to properly acquire certain pieces of information. These include: Function Hardcoded value Explanation does_user_exist true PKI reponds with true to modules checking if user's interlocutor actually exists so e.g. messages to nonexistent users will always be stored by mod_mam . This is not necessarily a security threat but something to be aware of. dirty_get_registered_users , get_vh_registered_users , get_vh_registered_users_number [] Any metrics or statistics (e.g. available via mongooseimctl ) related to accounts list or numbers, won't display proper values, as this backend cannot possibly \"know\" how many users there are. Configuration options None.","title":"PKI Authentication Module"},{"location":"authentication-backends/PKI-authentication-module/#overview","text":"It is a simple auth backend, meant to be used with SASL EXTERNAL authentication mechanism. It simply accepts all usernames as long as they are validated by SASL logic.","title":"Overview"},{"location":"authentication-backends/PKI-authentication-module/#warning","text":"Some of its callbacks return hardcoded values, as it's impossible for this backend to properly acquire certain pieces of information. These include: Function Hardcoded value Explanation does_user_exist true PKI reponds with true to modules checking if user's interlocutor actually exists so e.g. messages to nonexistent users will always be stored by mod_mam . This is not necessarily a security threat but something to be aware of. dirty_get_registered_users , get_vh_registered_users , get_vh_registered_users_number [] Any metrics or statistics (e.g. available via mongooseimctl ) related to accounts list or numbers, won't display proper values, as this backend cannot possibly \"know\" how many users there are.","title":"WARNING"},{"location":"authentication-backends/PKI-authentication-module/#configuration-options","text":"None.","title":"Configuration options"},{"location":"authentication-methods/client-certificate/","text":"Overview Clients connected to MongooseIM may authenticate with their TLS certificates. This method uses the SASL EXTERNAL mechanism. Server-side prerequisites Properly configure ejabberd_c2s listener A server must request the certificate from a client, so you'll need to enable verify_peer option and provide a path to CA chain that may be used for client's certificate check ( cafile option). Please check Listener modules page for more information or simply follow the examples at the end of this section. Properly configure ejabberd_cowboy listener SASL EXTERNAL authentication is also possible for WebSocketSecure and BOSH connections over HTTPS. Similarly as in ejabberd_c2s case, the server must request the certificate from the client. In this case it's enabled by adding the following options to ssl option of ejabberd_cowboy : {verify, verify_peer} - this is to tell Erlang's SSL to request the cert from the client {cacertfile, \"/path/to/ca.pem\"} - this is to tell Erlang's SSL where the CA cert file is in order to check if the cert is correctly signed Please check Listener modules for more details regarding ejabberd_cowboy configuration. Enable SASL EXTERNAL method A SASL EXTERNAL authentication method is disabled by default. In order to enable it, please add sasl_mechanisms option to MongooseIM config file. Its value must include a cyrsasl_external item. Obviously the list may be longer, if the system should support both the certificate and password based authentication. The SASL EXTERNAL authentication method requires a digital client certificate. This digital certificate should contain xmppAddr field(s), which is always checked first. If there is more than one JID specified in the xmppAddr fields, the client must include the authorisation entity which corresponds to the one of the specified JIDs. When no xmppAddr is specified, the cn (common name) field might be used to provide client's username, but it is optional (not enabled by default). There are three possible ways of using the SASL EXTERNAL authentication method. It can be configured by adding one of the following options to the list of auth_opts in MongooseIM config file: {cyrsasl_external, standard} - do not accept a certificate with no xmpp_addrs field (default); {cyrsasl_external, use_common_name} - use the common_name field if it is provided in the certificate; {cyrsasl_external, allow_just_user_identity} - accept a certificate if there are no xmpp_addrs provided and use the user identity from the authentication request. If the client certificate does not contain a JID, the client must provide one in authorisation entity. For the details please refer to XEP-0178 Best Practices for Use of SASL EXTERNAL with Certificates . Enable compatible authentication backend You need to enable one of the following authentication backends by using the auth_method option in the MongooseIM configuration file. pki - accepts user credentials, ldap - accepts user credentials if a corresponding user account exists in LDAP. Self-signed certificates By default MongooseIM doesn't accept self-signed certs for the SASL-EXTERNAL authentication. For development purposes, it is possible to tell MongooseIM to accept them. Self-signed certificates for regular TCP/TLS connections In order to tell MongooseIM to accept self-signed certs, the ssl_options list needs to be added to ejabberd_c2s listener config like below: {ssl_options, [{verify_fun, {selfsigned_peer, DisconnectOnVerificationFailure}}]} where the DisconnectOnVerificationFailure is a boolean with the following meaning only for just_tls : true - the connection is closed if a certificate is invalid, false - the connection isn't closed, but the certificate is not returned if it's invalid. This leads to an authentication failure but allows the client to choose a different auth method if available. For fast_tls backend, the configuration is the same, only the DisconnectOnVerificationFailure is ignored. Self-signed certificates for WS or BOSH In order to accept self-signed certs for WS or BOSH connections, the ssl option list of ejabberd_cowboy must contain the following pair: {verify_mode, selfsigned_peer} Examples Certificate authentication only. {listen, [ (...) {5222, ejabberd_c2s, [ (...) {cafile, \"/path/to/ca.pem\"}, verify_peer, (...) ]}, (...) {5285, ejabberd_cowboy, [ {ssl, [(...), {verify, verify_peer}, {cacertfile, \"/path/to/ca.pem\"} ]}, {modules, [{mod_websockets, []}, {mod_bosh, []}]}, (...) ]}, (...) ]}. {auth_method, [pki]}. {sasl_mechanisms, [cyrsasl_external]}. Authentication with a client certificate (validated with provided CA chain) or password (validated with data stored in RDBMS). {listen, [ (...) {5222, ejabberd_c2s, [ (...) {cafile, \"/path/to/ca.pem\"}, verify_peer, (...) ]}, (...) ]}. {auth_method, [rdbms, pki]}. {sasl_mechanisms, [cyrsasl_scram, cyrsasl_external]}. Client certificate prerequisites SASL EXTERNAL will be offered by the server only when a client provides a valid certificate . Please check documentation of a specific authentication backend you're going to use. Usage example - Gajim Verified with Gajim 0.16.8, installed from package gajim-0.16.8-1.fc25.noarch . Generate client certificate openssl genrsa -des3 -out rootCA.key 4096 openssl req -x509 -new -nodes -key rootCA.key -sha256 -days 1024 -out rootCA.crt openssl genrsa -out client.key 2048 openssl req -new -key client.key -out client.csr # Remember to provide username as Common Name! openssl x509 -req -in client.csr -CA rootCA.crt -CAkey rootCA.key -CAcreateserial -out client.crt -days 500 -sha256 openssl pkcs12 -export -inkey client.key -in client.crt -out client.p12 Configure MongooseIM See examples in the section above. We recommend using the first snippet for simplicity. You don't need to pre-create a user account in order to log in with a certificate. Add an account in Gajim Edit -> Accounts -> Add. Pick \"I already have an account I want to use\". Jabber ID is [Common Name from certificate]@localhost (domain is different if you've changed it in hosts option). Press \"Next\". Untick \"Connect when I press Finish\" and press \"Advanced\". Unfold \"Client certificate\" and choose the .p12 you've created earlier. Tick \"Certificate is encrypted\". Click \"Close\" and set status to \"Available\". Tell Gajim to ingnore the unverified server certificate (by default it's self-signed). If Gajim fails to connect, try to restart it. Version 0.16.8 sometimes \"forgets\" to ask for the client certificate password.","title":"Client Certificate"},{"location":"authentication-methods/client-certificate/#overview","text":"Clients connected to MongooseIM may authenticate with their TLS certificates. This method uses the SASL EXTERNAL mechanism.","title":"Overview"},{"location":"authentication-methods/client-certificate/#server-side-prerequisites","text":"","title":"Server-side prerequisites"},{"location":"authentication-methods/client-certificate/#properly-configure-ejabberd_c2s-listener","text":"A server must request the certificate from a client, so you'll need to enable verify_peer option and provide a path to CA chain that may be used for client's certificate check ( cafile option). Please check Listener modules page for more information or simply follow the examples at the end of this section.","title":"Properly configure ejabberd_c2s listener"},{"location":"authentication-methods/client-certificate/#properly-configure-ejabberd_cowboy-listener","text":"SASL EXTERNAL authentication is also possible for WebSocketSecure and BOSH connections over HTTPS. Similarly as in ejabberd_c2s case, the server must request the certificate from the client. In this case it's enabled by adding the following options to ssl option of ejabberd_cowboy : {verify, verify_peer} - this is to tell Erlang's SSL to request the cert from the client {cacertfile, \"/path/to/ca.pem\"} - this is to tell Erlang's SSL where the CA cert file is in order to check if the cert is correctly signed Please check Listener modules for more details regarding ejabberd_cowboy configuration.","title":"Properly configure ejabberd_cowboy listener"},{"location":"authentication-methods/client-certificate/#enable-sasl-external-method","text":"A SASL EXTERNAL authentication method is disabled by default. In order to enable it, please add sasl_mechanisms option to MongooseIM config file. Its value must include a cyrsasl_external item. Obviously the list may be longer, if the system should support both the certificate and password based authentication. The SASL EXTERNAL authentication method requires a digital client certificate. This digital certificate should contain xmppAddr field(s), which is always checked first. If there is more than one JID specified in the xmppAddr fields, the client must include the authorisation entity which corresponds to the one of the specified JIDs. When no xmppAddr is specified, the cn (common name) field might be used to provide client's username, but it is optional (not enabled by default). There are three possible ways of using the SASL EXTERNAL authentication method. It can be configured by adding one of the following options to the list of auth_opts in MongooseIM config file: {cyrsasl_external, standard} - do not accept a certificate with no xmpp_addrs field (default); {cyrsasl_external, use_common_name} - use the common_name field if it is provided in the certificate; {cyrsasl_external, allow_just_user_identity} - accept a certificate if there are no xmpp_addrs provided and use the user identity from the authentication request. If the client certificate does not contain a JID, the client must provide one in authorisation entity. For the details please refer to XEP-0178 Best Practices for Use of SASL EXTERNAL with Certificates .","title":"Enable SASL EXTERNAL method"},{"location":"authentication-methods/client-certificate/#enable-compatible-authentication-backend","text":"You need to enable one of the following authentication backends by using the auth_method option in the MongooseIM configuration file. pki - accepts user credentials, ldap - accepts user credentials if a corresponding user account exists in LDAP.","title":"Enable compatible authentication backend"},{"location":"authentication-methods/client-certificate/#self-signed-certificates","text":"By default MongooseIM doesn't accept self-signed certs for the SASL-EXTERNAL authentication. For development purposes, it is possible to tell MongooseIM to accept them.","title":"Self-signed certificates"},{"location":"authentication-methods/client-certificate/#self-signed-certificates-for-regular-tcptls-connections","text":"In order to tell MongooseIM to accept self-signed certs, the ssl_options list needs to be added to ejabberd_c2s listener config like below: {ssl_options, [{verify_fun, {selfsigned_peer, DisconnectOnVerificationFailure}}]} where the DisconnectOnVerificationFailure is a boolean with the following meaning only for just_tls : true - the connection is closed if a certificate is invalid, false - the connection isn't closed, but the certificate is not returned if it's invalid. This leads to an authentication failure but allows the client to choose a different auth method if available. For fast_tls backend, the configuration is the same, only the DisconnectOnVerificationFailure is ignored.","title":"Self-signed certificates for regular TCP/TLS connections"},{"location":"authentication-methods/client-certificate/#self-signed-certificates-for-ws-or-bosh","text":"In order to accept self-signed certs for WS or BOSH connections, the ssl option list of ejabberd_cowboy must contain the following pair: {verify_mode, selfsigned_peer}","title":"Self-signed certificates for WS or BOSH"},{"location":"authentication-methods/client-certificate/#examples","text":"Certificate authentication only. {listen, [ (...) {5222, ejabberd_c2s, [ (...) {cafile, \"/path/to/ca.pem\"}, verify_peer, (...) ]}, (...) {5285, ejabberd_cowboy, [ {ssl, [(...), {verify, verify_peer}, {cacertfile, \"/path/to/ca.pem\"} ]}, {modules, [{mod_websockets, []}, {mod_bosh, []}]}, (...) ]}, (...) ]}. {auth_method, [pki]}. {sasl_mechanisms, [cyrsasl_external]}. Authentication with a client certificate (validated with provided CA chain) or password (validated with data stored in RDBMS). {listen, [ (...) {5222, ejabberd_c2s, [ (...) {cafile, \"/path/to/ca.pem\"}, verify_peer, (...) ]}, (...) ]}. {auth_method, [rdbms, pki]}. {sasl_mechanisms, [cyrsasl_scram, cyrsasl_external]}.","title":"Examples"},{"location":"authentication-methods/client-certificate/#client-certificate-prerequisites","text":"SASL EXTERNAL will be offered by the server only when a client provides a valid certificate . Please check documentation of a specific authentication backend you're going to use.","title":"Client certificate prerequisites"},{"location":"authentication-methods/client-certificate/#usage-example-gajim","text":"Verified with Gajim 0.16.8, installed from package gajim-0.16.8-1.fc25.noarch .","title":"Usage example - Gajim"},{"location":"authentication-methods/client-certificate/#generate-client-certificate","text":"openssl genrsa -des3 -out rootCA.key 4096 openssl req -x509 -new -nodes -key rootCA.key -sha256 -days 1024 -out rootCA.crt openssl genrsa -out client.key 2048 openssl req -new -key client.key -out client.csr # Remember to provide username as Common Name! openssl x509 -req -in client.csr -CA rootCA.crt -CAkey rootCA.key -CAcreateserial -out client.crt -days 500 -sha256 openssl pkcs12 -export -inkey client.key -in client.crt -out client.p12","title":"Generate client certificate"},{"location":"authentication-methods/client-certificate/#configure-mongooseim","text":"See examples in the section above. We recommend using the first snippet for simplicity. You don't need to pre-create a user account in order to log in with a certificate.","title":"Configure MongooseIM"},{"location":"authentication-methods/client-certificate/#add-an-account-in-gajim","text":"Edit -> Accounts -> Add. Pick \"I already have an account I want to use\". Jabber ID is [Common Name from certificate]@localhost (domain is different if you've changed it in hosts option). Press \"Next\". Untick \"Connect when I press Finish\" and press \"Advanced\". Unfold \"Client certificate\" and choose the .p12 you've created earlier. Tick \"Certificate is encrypted\". Click \"Close\" and set status to \"Available\". Tell Gajim to ingnore the unverified server certificate (by default it's self-signed). If Gajim fails to connect, try to restart it. Version 0.16.8 sometimes \"forgets\" to ask for the client certificate password.","title":"Add an account in Gajim"},{"location":"developers-guide/Basic-iq-handler/","text":"Basic IQ Handler XMPP stands for Extensible Messaging and Presence Protocol. One way the protocol can be extended is by defining new types of queries, or IQs , that XMPP entities should be able to handle. It's usual that a XEP defining some XMPP extension contains some new type of IQ. IQs can also be used to implement custom features - required in a particular problem domain - but not defined by any official XEP. This tutorial will show you how to add and test a simple module with an IQ handler to MongooseIM. gen_iq_handler module provides functionality for registering IQ handlers for specific namespaces. Clone & build See How-to-build for details on building MongooseIM from source code. Create a module & add a basic IQ handler Go to src/ and create a basic module implementing the gen_mod behaviour. In start/2 register the IQ handler with a specified namespace, type (IQ processing policy), and function which will handle the incoming IQ stanza. In stop/1 remove the registered handler. Implement the function for handler: If the incoming IQ stanza is of type get or set it will be returned with the type set to result . If the server doesn't recognise the hostname, the returning stanza will be of type error . See Server Rules for Processing XML Stanzas for more detailed information on the topic. -module(mod_iq_example). -behaviour(gen_mod). -include(\"mongoose.hrl\"). -include(\"jlib.hrl\"). %% gen_mod callbacks -export([start/2, stop/1]). %% IQ handlers -export([process_iq/4]). start(Host, _Opts) -> gen_iq_handler:add_iq_handler(ejabberd_sm, Host, <<\"erlang-solutions.com:example\">>, ?MODULE, process_iq, no_queue). stop(Host) -> gen_iq_handler:remove_iq_handler(ejabberd_sm, Host, <<\"erlang-solutions.com:example\">>). process_iq(_From, _To, Acc, IQ) -> IQRes = IQ#iq{type = result}, ?INFO_MSG(\"event=example_handler request=~w response=~w\", [IQ, IQRes]), {Acc, IQRes}. IQ processing policies The server may use one of the following strategies to handle incoming stanzas: no_queue registers a new IQ handler, which will be called in the context of a process serving the connection on which the IQ arrives one_queue spawns a new process by which the incoming IQ stanzas will be handled {queues, N} spawns N processes. Every incoming stanza will be then handled by one of those processes parallel registers the handler without spawning a new process, a new process will be spawned for each incoming stanza Test your handler Go to big_tests/tests and create a test suite for your handler. Implement the test case for success and failure. We will register two users, which are predefined in $REPO/big_tests/test.config : {alice, [ {username, <<\"alicE\">>}, {server, <<\"localhost\">>}, {password, <<\"matygrysa\">>}]}, {alice_bis, [ {username, <<\"alicE\">>}, {server, <<\"localhost.bis\">>}, {host, <<\"localhost\">>}, {password, <<\"matygrysa\">>}]}, Our IQ handler will be enabled only for one domain, localhost . After sending an IQ stanza to alice we should get a result, but as our IQ handler is not enabled for localhost.bis domain, we should get an error. -module(mod_iq_example_SUITE). -export([all/0, groups/0, suite/0, init_per_suite/1, end_per_suite/1, init_per_group/2, end_per_group/2, init_per_testcase/2, end_per_testcase/2]). %% Tests -export([should_return_result/1, should_return_error/1]). -include_lib(\"exml/include/exml.hrl\"). -define(EXAMPLE_NS, <<\"erlang-solutions.com:example\">>). -define(USERS, [alice, alice_bis]). -import(distributed_helper, [mim/0, require_rpc_nodes/1, rpc/4]). %%-------------------------------------------------------------------- %% Suite configuration %%-------------------------------------------------------------------- all() -> [{group, mod_iq_example}]. groups() -> G = [{mod_iq_example, [], [should_return_result, should_return_error]}], ct_helper:repeat_all_until_all_ok(G). suite() -> require_rpc_nodes([mim]) ++ escalus:suite(). %%-------------------------------------------------------------------- %% Init & teardown %%-------------------------------------------------------------------- init_per_suite(Config) -> Domain = ct:get_config({hosts, mim, domain}), dynamic_modules:start(Domain, mod_iq_example, [no_opts]), escalus:init_per_suite(Config). end_per_suite(Config) -> Domain = ct:get_config({hosts, mim, domain}), dynamic_modules:stop(Domain, mod_iq_example), escalus:end_per_suite(Config). init_per_group(_, Config) -> escalus:create_users(Config, ?USERS). end_per_group(_, Config) -> escalus:delete_users(Config, ?USERS). init_per_testcase(CaseName, Config) -> escalus:init_per_testcase(CaseName, Config). end_per_testcase(CaseName, Config) -> escalus:end_per_testcase(CaseName, Config). %%-------------------------------------------------------------------- %% Tests %%-------------------------------------------------------------------- should_return_result(Config) -> %% given escalus:story(Config, [{alice, 1}], fun(Alice) -> %% when sending a request Req = escalus_stanza:iq_get(?EXAMPLE_NS, [#xmlel{name = <<\"example\">>}]), ct:pal(\"req: ~p\", [Req]), escalus:send(Alice, Req), %% then we should get a result Res = escalus:wait_for_stanza(Alice), ct:pal(\"res: ~p\", [Res]), escalus:assert(is_iq, [<<\"result\">>, ?EXAMPLE_NS], Res) end). should_return_error(Config) -> %% given escalus:story(Config, [{alice_bis, 1}], fun(Alice) -> %% when sending a request with unregistered server Req = escalus_stanza:iq_get(?EXAMPLE_NS, [#xmlel{name = <<\"example\">>}]), ct:pal(\"req: ~p\", [Req]), escalus:send(Alice, Req), %% then we should get an error Res = escalus:wait_for_stanza(Alice), ct:pal(\"res: ~p\", [Res]), escalus:assert(is_iq, [<<\"error\">>, ?EXAMPLE_NS], Res), escalus:assert(is_error, [<<\"cancel\">>, <<\"service-unavailable\">>], Res) end). Run it Compile & generate releases for testing purposes according to How-to-build . Go to $REPO/_build/mim1/rel/mongooseim and start one MongooseIM node. $ bin/mongooseim live Open up a new terminal window, go to $REPO and use the test runner . Run single suite with the already started mim1 node. source tools/test-runner-complete.sh test-runner.sh --rerun-big-tests -- mod_iq_example","title":"Basic IQ Handler"},{"location":"developers-guide/Basic-iq-handler/#basic-iq-handler","text":"XMPP stands for Extensible Messaging and Presence Protocol. One way the protocol can be extended is by defining new types of queries, or IQs , that XMPP entities should be able to handle. It's usual that a XEP defining some XMPP extension contains some new type of IQ. IQs can also be used to implement custom features - required in a particular problem domain - but not defined by any official XEP. This tutorial will show you how to add and test a simple module with an IQ handler to MongooseIM. gen_iq_handler module provides functionality for registering IQ handlers for specific namespaces.","title":"Basic IQ Handler"},{"location":"developers-guide/Basic-iq-handler/#clone-build","text":"See How-to-build for details on building MongooseIM from source code.","title":"Clone &amp; build"},{"location":"developers-guide/Basic-iq-handler/#create-a-module-add-a-basic-iq-handler","text":"Go to src/ and create a basic module implementing the gen_mod behaviour. In start/2 register the IQ handler with a specified namespace, type (IQ processing policy), and function which will handle the incoming IQ stanza. In stop/1 remove the registered handler. Implement the function for handler: If the incoming IQ stanza is of type get or set it will be returned with the type set to result . If the server doesn't recognise the hostname, the returning stanza will be of type error . See Server Rules for Processing XML Stanzas for more detailed information on the topic. -module(mod_iq_example). -behaviour(gen_mod). -include(\"mongoose.hrl\"). -include(\"jlib.hrl\"). %% gen_mod callbacks -export([start/2, stop/1]). %% IQ handlers -export([process_iq/4]). start(Host, _Opts) -> gen_iq_handler:add_iq_handler(ejabberd_sm, Host, <<\"erlang-solutions.com:example\">>, ?MODULE, process_iq, no_queue). stop(Host) -> gen_iq_handler:remove_iq_handler(ejabberd_sm, Host, <<\"erlang-solutions.com:example\">>). process_iq(_From, _To, Acc, IQ) -> IQRes = IQ#iq{type = result}, ?INFO_MSG(\"event=example_handler request=~w response=~w\", [IQ, IQRes]), {Acc, IQRes}.","title":"Create a module &amp; add a basic IQ handler"},{"location":"developers-guide/Basic-iq-handler/#iq-processing-policies","text":"The server may use one of the following strategies to handle incoming stanzas: no_queue registers a new IQ handler, which will be called in the context of a process serving the connection on which the IQ arrives one_queue spawns a new process by which the incoming IQ stanzas will be handled {queues, N} spawns N processes. Every incoming stanza will be then handled by one of those processes parallel registers the handler without spawning a new process, a new process will be spawned for each incoming stanza","title":"IQ processing policies"},{"location":"developers-guide/Basic-iq-handler/#test-your-handler","text":"Go to big_tests/tests and create a test suite for your handler. Implement the test case for success and failure. We will register two users, which are predefined in $REPO/big_tests/test.config : {alice, [ {username, <<\"alicE\">>}, {server, <<\"localhost\">>}, {password, <<\"matygrysa\">>}]}, {alice_bis, [ {username, <<\"alicE\">>}, {server, <<\"localhost.bis\">>}, {host, <<\"localhost\">>}, {password, <<\"matygrysa\">>}]}, Our IQ handler will be enabled only for one domain, localhost . After sending an IQ stanza to alice we should get a result, but as our IQ handler is not enabled for localhost.bis domain, we should get an error. -module(mod_iq_example_SUITE). -export([all/0, groups/0, suite/0, init_per_suite/1, end_per_suite/1, init_per_group/2, end_per_group/2, init_per_testcase/2, end_per_testcase/2]). %% Tests -export([should_return_result/1, should_return_error/1]). -include_lib(\"exml/include/exml.hrl\"). -define(EXAMPLE_NS, <<\"erlang-solutions.com:example\">>). -define(USERS, [alice, alice_bis]). -import(distributed_helper, [mim/0, require_rpc_nodes/1, rpc/4]). %%-------------------------------------------------------------------- %% Suite configuration %%-------------------------------------------------------------------- all() -> [{group, mod_iq_example}]. groups() -> G = [{mod_iq_example, [], [should_return_result, should_return_error]}], ct_helper:repeat_all_until_all_ok(G). suite() -> require_rpc_nodes([mim]) ++ escalus:suite(). %%-------------------------------------------------------------------- %% Init & teardown %%-------------------------------------------------------------------- init_per_suite(Config) -> Domain = ct:get_config({hosts, mim, domain}), dynamic_modules:start(Domain, mod_iq_example, [no_opts]), escalus:init_per_suite(Config). end_per_suite(Config) -> Domain = ct:get_config({hosts, mim, domain}), dynamic_modules:stop(Domain, mod_iq_example), escalus:end_per_suite(Config). init_per_group(_, Config) -> escalus:create_users(Config, ?USERS). end_per_group(_, Config) -> escalus:delete_users(Config, ?USERS). init_per_testcase(CaseName, Config) -> escalus:init_per_testcase(CaseName, Config). end_per_testcase(CaseName, Config) -> escalus:end_per_testcase(CaseName, Config). %%-------------------------------------------------------------------- %% Tests %%-------------------------------------------------------------------- should_return_result(Config) -> %% given escalus:story(Config, [{alice, 1}], fun(Alice) -> %% when sending a request Req = escalus_stanza:iq_get(?EXAMPLE_NS, [#xmlel{name = <<\"example\">>}]), ct:pal(\"req: ~p\", [Req]), escalus:send(Alice, Req), %% then we should get a result Res = escalus:wait_for_stanza(Alice), ct:pal(\"res: ~p\", [Res]), escalus:assert(is_iq, [<<\"result\">>, ?EXAMPLE_NS], Res) end). should_return_error(Config) -> %% given escalus:story(Config, [{alice_bis, 1}], fun(Alice) -> %% when sending a request with unregistered server Req = escalus_stanza:iq_get(?EXAMPLE_NS, [#xmlel{name = <<\"example\">>}]), ct:pal(\"req: ~p\", [Req]), escalus:send(Alice, Req), %% then we should get an error Res = escalus:wait_for_stanza(Alice), ct:pal(\"res: ~p\", [Res]), escalus:assert(is_iq, [<<\"error\">>, ?EXAMPLE_NS], Res), escalus:assert(is_error, [<<\"cancel\">>, <<\"service-unavailable\">>], Res) end).","title":"Test your handler"},{"location":"developers-guide/Basic-iq-handler/#run-it","text":"Compile & generate releases for testing purposes according to How-to-build . Go to $REPO/_build/mim1/rel/mongooseim and start one MongooseIM node. $ bin/mongooseim live Open up a new terminal window, go to $REPO and use the test runner . Run single suite with the already started mim1 node. source tools/test-runner-complete.sh test-runner.sh --rerun-big-tests -- mod_iq_example","title":"Run it"},{"location":"developers-guide/Hooks-and-handlers/","text":"Hooks, handlers and accumulators The hooks and handlers mechanism is one of the core architectural features of MongooseIM. It allows for loose coupling between components of the system by calling only those which are available and configured to be used at runtime. It can be thought of as a simple eventing mechanism notifying about certain things happening in the server. That results in an extensible system with pluggable extra functionality. To focus our attention, we'll analyze mod_offline which is responsible for storing messages for delivery to users unavailable at the time of sending. mod_offline is an implementation of XEP-0203 . Running a hook Basic usage ejabberd_sm (ejabberd/MongooseIM session manager) is the module discovering whether the recipient of a message is available or not. That's where storing the message for later delivery takes place. It is possible, but not recommended, to save a message in an offline storage by calling mod_offline directly: mod_offline:store_packet(From, To, Packet) Note that in this example ejabberd_sm is coupled with mod_offline . I.e. if mod_offline was not available, the code would simply crash; if it was misconfigured or turned off, the behaviour would be undefined. To avoid that coupling and also to enable other ( possibly yet to be written ) code to carry out some action at this particular moment, ejabberd_sm instead calls: Acc1 = ejabberd_hooks:run_fold(offline_message_hook, LServer, Acc, [From, To, Packet]) The extra level of indirection introduced by this call gives the flexibility to determine at runtime what code actually gets run at this point. offline_message_hook is just the name of the hook (in other words of the event that is being signalled); From , To and Packet are the arguments passed to the handler just as they would in case of the function being called directly; LServer is the XMPP domain for which this hook is signalled . Getting results from handlers Hook handlers are called by \"folding\". This means that each handler on a list is passed a set of arguments and an initial value that it then modifies, returns and hands over to the next handler in line. A simple example would look like this: ListOfSomething = ejabberd_hooks:run_fold(a_certain_hook, StateData#state.server, [], [StateData#state.user, StateData#state.server]) The initial value of the accumulator being passed through the sequence of handlers (in this case an empty list [] ) is inserted between the XMPP domain StateData#state.server and handler arguments. In between the XMPP domain ( StateData#state.server ) and handler arguments is the initial value of the accumulator being passed through the sequence of handlers is inserted - in this case an empty list ( [] ). Sidenote: Folds If you haven't encountered the term fold before, think of it as reduce (like Array.reduce ) in Ruby-speak, roughly equivalent to the Reduce step in MapReduce, sometimes called accumulate , aggregate or compress . See Wikipedia for more. Using accumulators MongooseIM uses a dedicated data structure to accumulate data related to stanza processing (see \"Accumulators\" ). It is instantiated with an incoming stanza, passed along throughout the processing chain, supplied to and returned from certain hook calls, and terminated when stanza is leaving MongooseIM. If a Mongoose accumulator is passed to a hook, handlers should store their return values in one of 3 ways: * If it is a one-off value which doesn't need to be passed on along with the accumulator (can be overwritten any time), use mongoose_acc:set(hook, result, Value, Acc) . * If the value is to be passed on to be reused within the current processing context, use mongoose_acc:set(Namespace, Key, Value, Acc) . * If the value should be passed on to the recipient's session, pubsub node etc. use mongoose_acc:set_permanent(Namespace, Key, Value, Acc) . A real life example, then, with regard to mod_offline is the resend_offline_messages_hook run in ejabberd_c2s : Acc1 = ejabberd_hooks:run_fold(resend_offline_messages_hook, StateData#state.server, Acc, [StateData#state.user, StateData#state.server]), Rs = mongoose_acc:get(offline, messages, Acc1, []), Sidenote: something deprecated Occassionally you may find some calls to ejabberd_hooks:run/3 in the MongooseIM source code. Under the hood it calls the same handlers with ok as the initial accumulator. This is deprecated and some day will be removed. Error handling in hooks Hooks are meant to decouple modules; in other words, the caller signals that some event took place or that it intends to use a certain feature or a set of features, but how and if those features are implemented is beyond its interest. Fro that reason hook don't use the \"let it crash\" approach. Instead it is rather like \"fire-and-forget\", more similar in principle to the Pid ! signal way. In practical terms: if a handler throws an error the hook machine logs a message and proceeds to the next handler with unmodified accumulator. If there is no handlers registered for a given hook, the run_fold call has simply no effect. Sidenote: Code yet to be written Let's imagine, that when building a minimum viable product we settle on using mod_offline for delayed delivery of messages to unavailable clients. However, while the product evolves (or the relevant client software catches up) we might drop mod_offline in favour of a more sophisticated solution like Message Archive Management which would require a different action to be taken at the same point. Thanks to loose coupling and ejabberd_hooks it's possible to turn off mod_offline and turn on mod_mam without changing a single line of code in ejabberd_sm . The only required change is to the configuration (apart from deploying the new module) which can even be performed at runtime - without restarting the server. Sidenote: Multiple Domains A MongooseIM cluster may serve more than one domain at the same time. E.g. it's quite common that services like Multi User Chat or Publish-Subscribe are available as subdomains of the main XMPP domain served by an installation. Registering hook handlers In order to store a packet when ejabberd_sm runs offline_message_hook the relevant module must register a handler for this hook. To attain the runtime configurability the module should register the handlers when it's loaded and unregister them when it's unloaded. That's usually done in, respectively, start/2 and stop/1 functions. Here's the relevant snippet from mod_offline:start/2 : ejabberd_hooks:add(offline_message_hook, Host, ?MODULE, store_packet, 50) It's clearly visible that the handler is added to offline_message_hook . Host corresponds to LServer used in the aforementioned call to ejabberd_hooks:run_fold , i.e. it's the XMPP domain for which the handler is to be executed. The handler itself is specified as a module-function pair; the arity of the function is neither specified at registration nor verified when calling the handler, so be careful to pass the appropriate number of arguments to ejabberd_hooks:run_fold - otherwise the handler will crash. Multiple handlers may be registered for the same hook. The last argument, 50, is the sequence number of this handler in the handler chain. The higher the number, the later in the sequence the handler will be executed. It's reasonable to keep this number small (e.g. in the range 0-100), though there's no real limit other than the size of the integer type in the Erlang VM. Unregistering handlers Pluggability also requires the components to be unpluggable at will. For that purpose there's the option to unregister a hook handler. It's exercised as follows in mod_offline:stop/1 : ejabberd_hooks:delete(offline_message_hook, Host, ?MODULE, store_packet, 50) The arguments are exactly the same as passed to ejabberd_hooks:add/5 . Sidenote: Metrics Every time a hook is run, a corresponding metric of the same name in the same host is incremented by one. There are some exceptions though as some metrics were implemented before the generic hook metrics. List of hooks not updating generic metrics can be found in the mongoose_metrics:hook_to_name/1 function. Such skipped hooks update metrics defined in the mongoose_metrics_hooks module. Writing handlers The signature of a handler has to follow three rules: Correct arity (the numer of args passed to run_fold + 1). The first arg is a mutable accumulator (may be mongoose_acc in particular). Returns an accumulator of the same type as the input one. Let's look at this example, from MongooseIM codebase: process_iq_get(Acc, #jid{ lserver = FromS } = From, To, #iq{} = IQ, _ActiveList) -> MUCHost = gen_mod:get_module_opt_subhost(FromS, ?MODULE, default_host()), case {mod_muc_light_codec_backend:decode(From, To, IQ), gen_mod:get_module_opt_by_subhost(MUCHost, ?MODULE, blocking, ?DEFAULT_BLOCKING)} of {{ok, {get, #blocking{} = Blocking}}, true} -> Items = mod_muc_light_db_backend:get_blocking(jid:to_lus(From), MUCHost), mod_muc_light_codec_backend:encode( {get, Blocking#blocking{ items = Items }}, From, jid:to_lus(To), fun(_, _, Packet) -> put(encode_res, Packet) end), #xmlel{ children = ResponseChildren } = erase(encode_res), Result = {result, ResponseChildren}, {stop, mongoose_acc:set(hook, result, Result, Acc)}; {{ok, {get, #blocking{}}}, false} -> Result = {error, ?ERR_BAD_REQUEST}, {stop, mongoose_acc:set(hook, result, Result, Acc)}; _ -> Result = {error, ?ERR_BAD_REQUEST}, mongoose_acc:set(hook, result, Result, Acc) end. As seen in this example, a handler receives an accumulator, puts some value into it and returns it for further processing. There's also one important feature to note: in some cases our handler returns a tuple {stop, Acc} . This skips calling the latter actions in the handler sequence, while the call to run_fold returns the Acc. If a handler returns just an atom stop , then all later actions are skipped and run_fold returns stopped . Watch out! Different handlers may be registered for the same hook - the priority mechanism orders their execution. If a handler returns stop but runs early in the handler chain, it may prevent some other handler from running at all! That might or might not be intentional. It may be especially surprising in case of handlers from different modules registered for the same hook. Always ensure what handlers are registered for a given hook ( grep is your friend) and that you understand their interdependencies. Hooks list and how to extract it The following command should give you a list of all the hooks available in MongooseIM: $ find src/ -name '*.erl' -print | xargs ./tools/find-hooks.awk \\ > | sort | uniq adhoc_local_commands adhoc_local_items ... ... ... webadmin_user_parse_query Refer to grep / ack to find where they're used. Here are the contents of find-hooks.awk : #!/usr/bin/env awk -f BEGIN { RS=\")\" ORS=\"\" FS=\"[ (,]\" } $0 ~ /ejabberd_hooks:run/ { found = -1 for (i = 1; i < NF; i++) { if ($i ~ /ejabberd_hooks:run/) { found = i } } if (found != -1 && $(found+1) != \"\" && $(found+1) ~ /^[a-z]/) print $(found+1)\"\\n\" } Creating your own hooks There's no special function or any setup necessary to create a new hook. The only thing that needs to be done is calling ejabberd_hooks:run/3 or ejabberd_hooks:run_fold/4 with the name of the new hook and relevant arguments. Of course, as long as no module registers handlers for this hook just running, it won't have any effects. Similar is the case when a module registers handlers for some hook, but that hook is never run in the code. That won't have an effect either. The following is a self-contained example of a module which both runs and registers a few handlers for a completely new hook. The handlers are run sequentially using disparate priorities and passing over an accumulator value. One of the handlers stops the handler execution chain prematurely by returning {stop, NewVal} . It's also possible to try out what happens when the same hook is run with different XMPP domains by passing an argument to run_custom_hook/1 - we'll see that the handlers are registered for a particular domain only. At the end, you can see a printout of an accumulator with some debugging info. To cut the long story short: -module(mod_hook_example). -author(\"bartek\"). -behaviour(gen_mod). -include(\"mongoose.hrl\"). %% API -export([run_custom_hook/1]). %% gen_mod callbacks -export([start/2, stop/1]). %% Hook handlers -export([first_handler/2, stopping_handler/2, never_run_handler/2]). start(Host, _Opts) -> ejabberd_hooks:add(custom_new_hook, Host, ?MODULE, first_handler, 25), ejabberd_hooks:add(custom_new_hook, Host, ?MODULE, stopping_handler, 50), ejabberd_hooks:add(custom_new_hook, Host, ?MODULE, never_run_handler, 75). stop(Host) -> ejabberd_hooks:delete(custom_new_hook, Host, ?MODULE, first_handler, 25), ejabberd_hooks:delete(custom_new_hook, Host, ?MODULE, stopping_handler, 50), ejabberd_hooks:delete(custom_new_hook, Host, ?MODULE, never_run_handler, 75). run_custom_hook(Host) -> Acc = mongoose_acc:new(#{ location => ?LOCATION, lserver => Host, element => undefined }), Acc1 = mongoose_acc:set(example, value, 5, Acc), ResultAcc = ejabberd_hooks:run_fold(custom_new_hook, Host, Acc1, [2]), ResultValue = mongoose_acc:get(example, value, ResultAcc), ?INFO_MSG(\"Final hook result: ~p\", [ResultValue]), ?INFO_MSG(\"Returned accumulator: ~p\", [ResultAcc]). first_handler(Acc, Number) -> V0 = mongoose_acc:get(example, value, Acc), Result = V0 + Number, ?INFO_MSG(\"First handler~n\" \" value: ~p~n\" \" argument: ~p~n\" \" will return: ~p\", [V0, Number, Result]), mongoose_acc:set(example, value, Result, Acc). stopping_handler(Acc, Number) -> V0 = mongoose_acc:get(example, value, Acc), Result = V0 + Number, ?INFO_MSG(\"Stopping handler~n\" \" value: ~p~n\" \" argument: ~p~n\" \" will return: ~p\", [V0, Number, Result]), {stop, mongoose_acc:set(example, value, Result, Acc)}. never_run_handler(Acc, Number) -> ?INFO_MSG(\"This hook won't run as it's registered with a priority bigger \" \"than that of stopping_handler/2 is. \" \"It doesn't matter what it returns. \" \"This text should never get printed.\", []), Acc * Number. The module is intended to be used from the shell for educational purposes: (mongooseim@localhost)1> gen_mod:is_loaded(<<\"localhost\">>, mod_hook_example). false (mongooseim@localhost)2> gen_mod:start_module(<<\"localhost\">>, mod_hook_example, [no_opts]). {ok,ok} (mongooseim@localhost)3> gen_mod:is_loaded(<<\"localhost\">>, mod_hook_example). true (mongooseim@localhost)4> ejabberd_loglevel:set_custom(mod_hook_example, 4). [{{lager_file_backend,\"ejabberd.log\"},ok}, {lager_console_backend,ok}, {lager_manager_killer,ok}] (mongooseim@localhost)5> mod_hook_example:run_custom_hook(<<\"localhost\">>). 17:48:55.421 [info] First handler value: 5 argument: 2 will return: 7 ok 17:48:55.421 [info] Stopping handler value: 7 argument: 2 will return: 9 17:48:55.421 [info] Final hook result: 9 (mongooseim@localhost)6> 17:48:55.421 [info] Returned accumulator: #{lserver => <<\"localhost\">>,mongoose_acc => true,non_strippable => {set,0,16,16,8,80,48,{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]},{{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]}}},origin_location => {mod_hook_example,run_custom_hook,31},origin_pid => <0.1189.0>,origin_stanza => undefined,ref => #Ref<0.3348369203.60555266.196226>,stanza => undefined,timestamp => {1538,408935,405141},{example,value} => 9} (mongooseim@localhost)6> mod_hook_example:run_custom_hook(<<\"another-domain\">>). ok 17:49:11.672 [info] Final hook result: 5 (mongooseim@localhost)7> 17:49:11.673 [info] Returned accumulator: #{lserver => <<\"another-domain\">>,mongoose_acc => true,non_strippable => {set,0,16,16,8,80,48,{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]},{{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]}}},origin_location => {mod_hook_example,run_custom_hook,31},origin_pid => <0.1189.0>,origin_stanza => undefined,ref => #Ref<0.3348369203.60555270.195733>,stanza => undefined,timestamp => {1538,408951,672653},{example,value} => 5} (mongooseim@localhost)7> gen_mod:stop_module(<<\"localhost\">>, mod_hook_example). ok","title":"Hooks and Handlers"},{"location":"developers-guide/Hooks-and-handlers/#hooks-handlers-and-accumulators","text":"The hooks and handlers mechanism is one of the core architectural features of MongooseIM. It allows for loose coupling between components of the system by calling only those which are available and configured to be used at runtime. It can be thought of as a simple eventing mechanism notifying about certain things happening in the server. That results in an extensible system with pluggable extra functionality. To focus our attention, we'll analyze mod_offline which is responsible for storing messages for delivery to users unavailable at the time of sending. mod_offline is an implementation of XEP-0203 .","title":"Hooks, handlers and accumulators"},{"location":"developers-guide/Hooks-and-handlers/#running-a-hook","text":"","title":"Running a hook"},{"location":"developers-guide/Hooks-and-handlers/#basic-usage","text":"ejabberd_sm (ejabberd/MongooseIM session manager) is the module discovering whether the recipient of a message is available or not. That's where storing the message for later delivery takes place. It is possible, but not recommended, to save a message in an offline storage by calling mod_offline directly: mod_offline:store_packet(From, To, Packet) Note that in this example ejabberd_sm is coupled with mod_offline . I.e. if mod_offline was not available, the code would simply crash; if it was misconfigured or turned off, the behaviour would be undefined. To avoid that coupling and also to enable other ( possibly yet to be written ) code to carry out some action at this particular moment, ejabberd_sm instead calls: Acc1 = ejabberd_hooks:run_fold(offline_message_hook, LServer, Acc, [From, To, Packet]) The extra level of indirection introduced by this call gives the flexibility to determine at runtime what code actually gets run at this point. offline_message_hook is just the name of the hook (in other words of the event that is being signalled); From , To and Packet are the arguments passed to the handler just as they would in case of the function being called directly; LServer is the XMPP domain for which this hook is signalled .","title":"Basic usage"},{"location":"developers-guide/Hooks-and-handlers/#getting-results-from-handlers","text":"Hook handlers are called by \"folding\". This means that each handler on a list is passed a set of arguments and an initial value that it then modifies, returns and hands over to the next handler in line. A simple example would look like this: ListOfSomething = ejabberd_hooks:run_fold(a_certain_hook, StateData#state.server, [], [StateData#state.user, StateData#state.server]) The initial value of the accumulator being passed through the sequence of handlers (in this case an empty list [] ) is inserted between the XMPP domain StateData#state.server and handler arguments. In between the XMPP domain ( StateData#state.server ) and handler arguments is the initial value of the accumulator being passed through the sequence of handlers is inserted - in this case an empty list ( [] ).","title":"Getting results from handlers"},{"location":"developers-guide/Hooks-and-handlers/#sidenote-folds","text":"If you haven't encountered the term fold before, think of it as reduce (like Array.reduce ) in Ruby-speak, roughly equivalent to the Reduce step in MapReduce, sometimes called accumulate , aggregate or compress . See Wikipedia for more.","title":"Sidenote: Folds"},{"location":"developers-guide/Hooks-and-handlers/#using-accumulators","text":"MongooseIM uses a dedicated data structure to accumulate data related to stanza processing (see \"Accumulators\" ). It is instantiated with an incoming stanza, passed along throughout the processing chain, supplied to and returned from certain hook calls, and terminated when stanza is leaving MongooseIM. If a Mongoose accumulator is passed to a hook, handlers should store their return values in one of 3 ways: * If it is a one-off value which doesn't need to be passed on along with the accumulator (can be overwritten any time), use mongoose_acc:set(hook, result, Value, Acc) . * If the value is to be passed on to be reused within the current processing context, use mongoose_acc:set(Namespace, Key, Value, Acc) . * If the value should be passed on to the recipient's session, pubsub node etc. use mongoose_acc:set_permanent(Namespace, Key, Value, Acc) . A real life example, then, with regard to mod_offline is the resend_offline_messages_hook run in ejabberd_c2s : Acc1 = ejabberd_hooks:run_fold(resend_offline_messages_hook, StateData#state.server, Acc, [StateData#state.user, StateData#state.server]), Rs = mongoose_acc:get(offline, messages, Acc1, []),","title":"Using accumulators"},{"location":"developers-guide/Hooks-and-handlers/#sidenote-something-deprecated","text":"Occassionally you may find some calls to ejabberd_hooks:run/3 in the MongooseIM source code. Under the hood it calls the same handlers with ok as the initial accumulator. This is deprecated and some day will be removed.","title":"Sidenote: something deprecated"},{"location":"developers-guide/Hooks-and-handlers/#error-handling-in-hooks","text":"Hooks are meant to decouple modules; in other words, the caller signals that some event took place or that it intends to use a certain feature or a set of features, but how and if those features are implemented is beyond its interest. Fro that reason hook don't use the \"let it crash\" approach. Instead it is rather like \"fire-and-forget\", more similar in principle to the Pid ! signal way. In practical terms: if a handler throws an error the hook machine logs a message and proceeds to the next handler with unmodified accumulator. If there is no handlers registered for a given hook, the run_fold call has simply no effect.","title":"Error handling in hooks"},{"location":"developers-guide/Hooks-and-handlers/#sidenote-code-yet-to-be-written","text":"Let's imagine, that when building a minimum viable product we settle on using mod_offline for delayed delivery of messages to unavailable clients. However, while the product evolves (or the relevant client software catches up) we might drop mod_offline in favour of a more sophisticated solution like Message Archive Management which would require a different action to be taken at the same point. Thanks to loose coupling and ejabberd_hooks it's possible to turn off mod_offline and turn on mod_mam without changing a single line of code in ejabberd_sm . The only required change is to the configuration (apart from deploying the new module) which can even be performed at runtime - without restarting the server.","title":"Sidenote: Code yet to be written"},{"location":"developers-guide/Hooks-and-handlers/#sidenote-multiple-domains","text":"A MongooseIM cluster may serve more than one domain at the same time. E.g. it's quite common that services like Multi User Chat or Publish-Subscribe are available as subdomains of the main XMPP domain served by an installation.","title":"Sidenote: Multiple Domains"},{"location":"developers-guide/Hooks-and-handlers/#registering-hook-handlers","text":"In order to store a packet when ejabberd_sm runs offline_message_hook the relevant module must register a handler for this hook. To attain the runtime configurability the module should register the handlers when it's loaded and unregister them when it's unloaded. That's usually done in, respectively, start/2 and stop/1 functions. Here's the relevant snippet from mod_offline:start/2 : ejabberd_hooks:add(offline_message_hook, Host, ?MODULE, store_packet, 50) It's clearly visible that the handler is added to offline_message_hook . Host corresponds to LServer used in the aforementioned call to ejabberd_hooks:run_fold , i.e. it's the XMPP domain for which the handler is to be executed. The handler itself is specified as a module-function pair; the arity of the function is neither specified at registration nor verified when calling the handler, so be careful to pass the appropriate number of arguments to ejabberd_hooks:run_fold - otherwise the handler will crash. Multiple handlers may be registered for the same hook. The last argument, 50, is the sequence number of this handler in the handler chain. The higher the number, the later in the sequence the handler will be executed. It's reasonable to keep this number small (e.g. in the range 0-100), though there's no real limit other than the size of the integer type in the Erlang VM.","title":"Registering hook handlers"},{"location":"developers-guide/Hooks-and-handlers/#unregistering-handlers","text":"Pluggability also requires the components to be unpluggable at will. For that purpose there's the option to unregister a hook handler. It's exercised as follows in mod_offline:stop/1 : ejabberd_hooks:delete(offline_message_hook, Host, ?MODULE, store_packet, 50) The arguments are exactly the same as passed to ejabberd_hooks:add/5 .","title":"Unregistering handlers"},{"location":"developers-guide/Hooks-and-handlers/#sidenote-metrics","text":"Every time a hook is run, a corresponding metric of the same name in the same host is incremented by one. There are some exceptions though as some metrics were implemented before the generic hook metrics. List of hooks not updating generic metrics can be found in the mongoose_metrics:hook_to_name/1 function. Such skipped hooks update metrics defined in the mongoose_metrics_hooks module.","title":"Sidenote: Metrics"},{"location":"developers-guide/Hooks-and-handlers/#writing-handlers","text":"The signature of a handler has to follow three rules: Correct arity (the numer of args passed to run_fold + 1). The first arg is a mutable accumulator (may be mongoose_acc in particular). Returns an accumulator of the same type as the input one. Let's look at this example, from MongooseIM codebase: process_iq_get(Acc, #jid{ lserver = FromS } = From, To, #iq{} = IQ, _ActiveList) -> MUCHost = gen_mod:get_module_opt_subhost(FromS, ?MODULE, default_host()), case {mod_muc_light_codec_backend:decode(From, To, IQ), gen_mod:get_module_opt_by_subhost(MUCHost, ?MODULE, blocking, ?DEFAULT_BLOCKING)} of {{ok, {get, #blocking{} = Blocking}}, true} -> Items = mod_muc_light_db_backend:get_blocking(jid:to_lus(From), MUCHost), mod_muc_light_codec_backend:encode( {get, Blocking#blocking{ items = Items }}, From, jid:to_lus(To), fun(_, _, Packet) -> put(encode_res, Packet) end), #xmlel{ children = ResponseChildren } = erase(encode_res), Result = {result, ResponseChildren}, {stop, mongoose_acc:set(hook, result, Result, Acc)}; {{ok, {get, #blocking{}}}, false} -> Result = {error, ?ERR_BAD_REQUEST}, {stop, mongoose_acc:set(hook, result, Result, Acc)}; _ -> Result = {error, ?ERR_BAD_REQUEST}, mongoose_acc:set(hook, result, Result, Acc) end. As seen in this example, a handler receives an accumulator, puts some value into it and returns it for further processing. There's also one important feature to note: in some cases our handler returns a tuple {stop, Acc} . This skips calling the latter actions in the handler sequence, while the call to run_fold returns the Acc. If a handler returns just an atom stop , then all later actions are skipped and run_fold returns stopped . Watch out! Different handlers may be registered for the same hook - the priority mechanism orders their execution. If a handler returns stop but runs early in the handler chain, it may prevent some other handler from running at all! That might or might not be intentional. It may be especially surprising in case of handlers from different modules registered for the same hook. Always ensure what handlers are registered for a given hook ( grep is your friend) and that you understand their interdependencies.","title":"Writing handlers"},{"location":"developers-guide/Hooks-and-handlers/#hooks-list-and-how-to-extract-it","text":"The following command should give you a list of all the hooks available in MongooseIM: $ find src/ -name '*.erl' -print | xargs ./tools/find-hooks.awk \\ > | sort | uniq adhoc_local_commands adhoc_local_items ... ... ... webadmin_user_parse_query Refer to grep / ack to find where they're used. Here are the contents of find-hooks.awk : #!/usr/bin/env awk -f BEGIN { RS=\")\" ORS=\"\" FS=\"[ (,]\" } $0 ~ /ejabberd_hooks:run/ { found = -1 for (i = 1; i < NF; i++) { if ($i ~ /ejabberd_hooks:run/) { found = i } } if (found != -1 && $(found+1) != \"\" && $(found+1) ~ /^[a-z]/) print $(found+1)\"\\n\" }","title":"Hooks list and how to extract it"},{"location":"developers-guide/Hooks-and-handlers/#creating-your-own-hooks","text":"There's no special function or any setup necessary to create a new hook. The only thing that needs to be done is calling ejabberd_hooks:run/3 or ejabberd_hooks:run_fold/4 with the name of the new hook and relevant arguments. Of course, as long as no module registers handlers for this hook just running, it won't have any effects. Similar is the case when a module registers handlers for some hook, but that hook is never run in the code. That won't have an effect either. The following is a self-contained example of a module which both runs and registers a few handlers for a completely new hook. The handlers are run sequentially using disparate priorities and passing over an accumulator value. One of the handlers stops the handler execution chain prematurely by returning {stop, NewVal} . It's also possible to try out what happens when the same hook is run with different XMPP domains by passing an argument to run_custom_hook/1 - we'll see that the handlers are registered for a particular domain only. At the end, you can see a printout of an accumulator with some debugging info. To cut the long story short: -module(mod_hook_example). -author(\"bartek\"). -behaviour(gen_mod). -include(\"mongoose.hrl\"). %% API -export([run_custom_hook/1]). %% gen_mod callbacks -export([start/2, stop/1]). %% Hook handlers -export([first_handler/2, stopping_handler/2, never_run_handler/2]). start(Host, _Opts) -> ejabberd_hooks:add(custom_new_hook, Host, ?MODULE, first_handler, 25), ejabberd_hooks:add(custom_new_hook, Host, ?MODULE, stopping_handler, 50), ejabberd_hooks:add(custom_new_hook, Host, ?MODULE, never_run_handler, 75). stop(Host) -> ejabberd_hooks:delete(custom_new_hook, Host, ?MODULE, first_handler, 25), ejabberd_hooks:delete(custom_new_hook, Host, ?MODULE, stopping_handler, 50), ejabberd_hooks:delete(custom_new_hook, Host, ?MODULE, never_run_handler, 75). run_custom_hook(Host) -> Acc = mongoose_acc:new(#{ location => ?LOCATION, lserver => Host, element => undefined }), Acc1 = mongoose_acc:set(example, value, 5, Acc), ResultAcc = ejabberd_hooks:run_fold(custom_new_hook, Host, Acc1, [2]), ResultValue = mongoose_acc:get(example, value, ResultAcc), ?INFO_MSG(\"Final hook result: ~p\", [ResultValue]), ?INFO_MSG(\"Returned accumulator: ~p\", [ResultAcc]). first_handler(Acc, Number) -> V0 = mongoose_acc:get(example, value, Acc), Result = V0 + Number, ?INFO_MSG(\"First handler~n\" \" value: ~p~n\" \" argument: ~p~n\" \" will return: ~p\", [V0, Number, Result]), mongoose_acc:set(example, value, Result, Acc). stopping_handler(Acc, Number) -> V0 = mongoose_acc:get(example, value, Acc), Result = V0 + Number, ?INFO_MSG(\"Stopping handler~n\" \" value: ~p~n\" \" argument: ~p~n\" \" will return: ~p\", [V0, Number, Result]), {stop, mongoose_acc:set(example, value, Result, Acc)}. never_run_handler(Acc, Number) -> ?INFO_MSG(\"This hook won't run as it's registered with a priority bigger \" \"than that of stopping_handler/2 is. \" \"It doesn't matter what it returns. \" \"This text should never get printed.\", []), Acc * Number. The module is intended to be used from the shell for educational purposes: (mongooseim@localhost)1> gen_mod:is_loaded(<<\"localhost\">>, mod_hook_example). false (mongooseim@localhost)2> gen_mod:start_module(<<\"localhost\">>, mod_hook_example, [no_opts]). {ok,ok} (mongooseim@localhost)3> gen_mod:is_loaded(<<\"localhost\">>, mod_hook_example). true (mongooseim@localhost)4> ejabberd_loglevel:set_custom(mod_hook_example, 4). [{{lager_file_backend,\"ejabberd.log\"},ok}, {lager_console_backend,ok}, {lager_manager_killer,ok}] (mongooseim@localhost)5> mod_hook_example:run_custom_hook(<<\"localhost\">>). 17:48:55.421 [info] First handler value: 5 argument: 2 will return: 7 ok 17:48:55.421 [info] Stopping handler value: 7 argument: 2 will return: 9 17:48:55.421 [info] Final hook result: 9 (mongooseim@localhost)6> 17:48:55.421 [info] Returned accumulator: #{lserver => <<\"localhost\">>,mongoose_acc => true,non_strippable => {set,0,16,16,8,80,48,{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]},{{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]}}},origin_location => {mod_hook_example,run_custom_hook,31},origin_pid => <0.1189.0>,origin_stanza => undefined,ref => #Ref<0.3348369203.60555266.196226>,stanza => undefined,timestamp => {1538,408935,405141},{example,value} => 9} (mongooseim@localhost)6> mod_hook_example:run_custom_hook(<<\"another-domain\">>). ok 17:49:11.672 [info] Final hook result: 5 (mongooseim@localhost)7> 17:49:11.673 [info] Returned accumulator: #{lserver => <<\"another-domain\">>,mongoose_acc => true,non_strippable => {set,0,16,16,8,80,48,{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]},{{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]}}},origin_location => {mod_hook_example,run_custom_hook,31},origin_pid => <0.1189.0>,origin_stanza => undefined,ref => #Ref<0.3348369203.60555270.195733>,stanza => undefined,timestamp => {1538,408951,672653},{example,value} => 5} (mongooseim@localhost)7> gen_mod:stop_module(<<\"localhost\">>, mod_hook_example). ok","title":"Creating your own hooks"},{"location":"developers-guide/Moving-to-single-app-project-structure/","text":"Moving to single application project structure This document explains how MongooseIM codebase was migrated from the umbrella application structure to a single application rebar3 project. Moving official MongooseIM to the new structure Move all apps/ejabberd subdirectories to the repo root mv apps/ejabberd/src/* src/ mv apps/ejabberd/include/* include mv apps/ejabberd/priv/* priv mv apps/ejabberd/test/* test mv apps/ejabberd/c_src/* c_src mv apps/ejabberd/asn1/* asn1 When committing make sure that no new files were added (i.e. they are marked as renamed ). Move tools files cover.spec mv apps/ejabberd/src/cover.spec . rebar.config.script from apps/ejabberd/src copy the MaybeFIPSSupport/1 function paste it into rebar.config.script call it on a result of calling SetupIncludedApps/2 in rebar.config.script rebar.config In rebar.config remove {i, \"apps\"} line from erl_opts tuple Move {d, xml_nif} and {parse_tranform, lager_transform} lines to erl_opts tuple in rebar.config From apps/ejabberd/rebar.config move all three erl_first_files , xref_checks and port_specs tuples to rebar.config Add {cover_print_enabled, true} line below {conver_enabled, ... line in rebar.config In rebar.config , remove the whole [{override, ejabberd... structure from overrides tuple In rebar.config , pre tuple, add {compile, {pc, compile}} tuple (after {compile, {asn.. ) In rebar.config , post tuple, add {clean, {pc, clean}} tuple (after {clean, {asn.. ) Delete apps/ rm -rf apps/ Changes in source files Application resource files In src/ejabberd.app.src Change application name to mongooseim Change vsn to {cmd, \"tools/generate_vsn.sh\"} Delete src/mongooseim.app.src.disabled mv src/ejabberd.app.src src/mongooseim.app.src Includes This is the big one. Since we don't use the umbrella structure anymore, all -include(..) directives pointing to ejabberd/include need to be rewritten. (SED is sed on Linuxes or gsed on Macs) gsed -i 's/-include_lib(\"ejabberd\\/include\\//-include(\"/' -- src/*.erl src/*.hrl include/*.hrl test/*.erl gsed -i 's/-include_lib(\"ejabberd\\/src\\//-include(\"/' -- src/*.erl src/*.hrl include/*.hrl test/*.erl Release scripts In rel/files/mongooseim the variable EJABBERD_SO_PATH contains an ejabberd-2.1.8* fragment. Replace it with mongooseim-* . In rel/files/mongooseimctl the variable EJABBERD_EBIN_PATH contains an ejabberd-* fragment. Replace it with mongooseim-* . Tests & tools After previous changes, lots of tests fail, mostly because we changed the application name from ejabberd to mongooseim . Functions to look for are: - application:set_env - application:get_env - application:get_key - application:load - application:start - application:stop - application:ensure_all_started - code:priv_dir - application:which_applications Those function are also called via RPC from big test suites. A good method to find them all is to search using application.*ej regex. Files which require changes: - include/ejabberd.hrl - src/ejabberd.erl - src/ejabberd_app.erl - src/ejabberd_config.erl - src/mod_version.erl - src/translate.erl - test/ejabberd_config_SUITE.erl - test/ejabberd_helper.erl - test/ejabberd_listener_SUITE.erl - test/zlib_driver_SUITE.erl - big_tests/README.md - big_tests/run_common_test.erl - big_tests/tests/conf_reload_SUITE.erl - big_tests/tests/connect_SUITE.erl - big_tests/tests/reload_helper.erl - tools/extract_translations/extract_translations.erl - tools/xep_tool/xep_tool.escript - src/mongoose_cluster.erl (2 calls to when_app_stopped/1 function) We also need to remove remaining occurences of apps/ejabberd directory structure. Some of the files are scripts assembling the path programatically - the trick is to search for the apps/ keyword. Affected files: - CONTRIBUTING.md - Makefile - elvis.config - src/amp_strategy.erl - src/mod_mam_rdbms_arch.erl - big_tests/Makefile - big_tests/run_common_test.erl - big_tests/tests/vcard_SUITE.erl - tools/cd_tools/provision_mysql.sh - tools/cd_tools/provision_pgsql.sh - tools/fill_roster.erl - tools/privacy.erl - tools/travis-setup-db.sh - tools/travis-test.sh - tools/travis-upload-to-s3.sh - tools/zabbix_add_counters.py Moving a MongooseIM's fork to a new structure This section describes how to move a customized fork of MongooseIM to a new structure. Move all directories from the apps/ejabberd directory to the repository root, e.g. apps/ejabberd/src/ should be moved to just src/ . Be sure to move all the important files, because apps/ directory will be wiped out completely. Make all the changes described in the Move tools files section. If you've made any changes to apps/ejabberd/rebar.config or apps/ejabberd/rebar.config/script , be sure to merge these with rebar.config and rebar.config.script in the repository root. Remove apps/ directory. Make all the changes described in the Application resource files section. Make all the changes described in the Includes section. Make sure that none of the include directives in your source code (in src/ and test/ ) has the following structure -include_lib(\"ejabberd/include/<header_file>\") . They should now refer to bare header file names, i.e. -include(<header_file>) . Make all the changes described in the Release scripts section. Make sure that all customizations made to release scripts and release process are aware of the new directory structure (i.e. none of them assumes apps/ejabberd path exists). Make all the changes described in the Tests & tools section. Since ejabberd application was renamed to mongooseim , make sure that all the code which was starting or stopping ejabberd , now does the same for mongooseim . You might want to check the following function calls: most of the functions from the application module code:priv_dir/1 calls to rpc module which would call functions listed above","title":"Moving to single app project structure"},{"location":"developers-guide/Moving-to-single-app-project-structure/#moving-to-single-application-project-structure","text":"This document explains how MongooseIM codebase was migrated from the umbrella application structure to a single application rebar3 project.","title":"Moving to single application project structure"},{"location":"developers-guide/Moving-to-single-app-project-structure/#moving-official-mongooseim-to-the-new-structure","text":"","title":"Moving official MongooseIM to the new structure"},{"location":"developers-guide/Moving-to-single-app-project-structure/#move-all-appsejabberd-subdirectories-to-the-repo-root","text":"mv apps/ejabberd/src/* src/ mv apps/ejabberd/include/* include mv apps/ejabberd/priv/* priv mv apps/ejabberd/test/* test mv apps/ejabberd/c_src/* c_src mv apps/ejabberd/asn1/* asn1 When committing make sure that no new files were added (i.e. they are marked as renamed ).","title":"Move all apps/ejabberd subdirectories to the repo root"},{"location":"developers-guide/Moving-to-single-app-project-structure/#move-tools-files","text":"","title":"Move tools files"},{"location":"developers-guide/Moving-to-single-app-project-structure/#coverspec","text":"mv apps/ejabberd/src/cover.spec .","title":"cover.spec"},{"location":"developers-guide/Moving-to-single-app-project-structure/#rebarconfigscript","text":"from apps/ejabberd/src copy the MaybeFIPSSupport/1 function paste it into rebar.config.script call it on a result of calling SetupIncludedApps/2 in rebar.config.script","title":"rebar.config.script"},{"location":"developers-guide/Moving-to-single-app-project-structure/#rebarconfig","text":"In rebar.config remove {i, \"apps\"} line from erl_opts tuple Move {d, xml_nif} and {parse_tranform, lager_transform} lines to erl_opts tuple in rebar.config From apps/ejabberd/rebar.config move all three erl_first_files , xref_checks and port_specs tuples to rebar.config Add {cover_print_enabled, true} line below {conver_enabled, ... line in rebar.config In rebar.config , remove the whole [{override, ejabberd... structure from overrides tuple In rebar.config , pre tuple, add {compile, {pc, compile}} tuple (after {compile, {asn.. ) In rebar.config , post tuple, add {clean, {pc, clean}} tuple (after {clean, {asn.. )","title":"rebar.config"},{"location":"developers-guide/Moving-to-single-app-project-structure/#delete-apps","text":"rm -rf apps/","title":"Delete apps/"},{"location":"developers-guide/Moving-to-single-app-project-structure/#changes-in-source-files","text":"","title":"Changes in source files"},{"location":"developers-guide/Moving-to-single-app-project-structure/#application-resource-files","text":"In src/ejabberd.app.src Change application name to mongooseim Change vsn to {cmd, \"tools/generate_vsn.sh\"} Delete src/mongooseim.app.src.disabled mv src/ejabberd.app.src src/mongooseim.app.src","title":"Application resource files"},{"location":"developers-guide/Moving-to-single-app-project-structure/#includes","text":"This is the big one. Since we don't use the umbrella structure anymore, all -include(..) directives pointing to ejabberd/include need to be rewritten. (SED is sed on Linuxes or gsed on Macs) gsed -i 's/-include_lib(\"ejabberd\\/include\\//-include(\"/' -- src/*.erl src/*.hrl include/*.hrl test/*.erl gsed -i 's/-include_lib(\"ejabberd\\/src\\//-include(\"/' -- src/*.erl src/*.hrl include/*.hrl test/*.erl","title":"Includes"},{"location":"developers-guide/Moving-to-single-app-project-structure/#release-scripts","text":"In rel/files/mongooseim the variable EJABBERD_SO_PATH contains an ejabberd-2.1.8* fragment. Replace it with mongooseim-* . In rel/files/mongooseimctl the variable EJABBERD_EBIN_PATH contains an ejabberd-* fragment. Replace it with mongooseim-* .","title":"Release scripts"},{"location":"developers-guide/Moving-to-single-app-project-structure/#tests-tools","text":"After previous changes, lots of tests fail, mostly because we changed the application name from ejabberd to mongooseim . Functions to look for are: - application:set_env - application:get_env - application:get_key - application:load - application:start - application:stop - application:ensure_all_started - code:priv_dir - application:which_applications Those function are also called via RPC from big test suites. A good method to find them all is to search using application.*ej regex. Files which require changes: - include/ejabberd.hrl - src/ejabberd.erl - src/ejabberd_app.erl - src/ejabberd_config.erl - src/mod_version.erl - src/translate.erl - test/ejabberd_config_SUITE.erl - test/ejabberd_helper.erl - test/ejabberd_listener_SUITE.erl - test/zlib_driver_SUITE.erl - big_tests/README.md - big_tests/run_common_test.erl - big_tests/tests/conf_reload_SUITE.erl - big_tests/tests/connect_SUITE.erl - big_tests/tests/reload_helper.erl - tools/extract_translations/extract_translations.erl - tools/xep_tool/xep_tool.escript - src/mongoose_cluster.erl (2 calls to when_app_stopped/1 function) We also need to remove remaining occurences of apps/ejabberd directory structure. Some of the files are scripts assembling the path programatically - the trick is to search for the apps/ keyword. Affected files: - CONTRIBUTING.md - Makefile - elvis.config - src/amp_strategy.erl - src/mod_mam_rdbms_arch.erl - big_tests/Makefile - big_tests/run_common_test.erl - big_tests/tests/vcard_SUITE.erl - tools/cd_tools/provision_mysql.sh - tools/cd_tools/provision_pgsql.sh - tools/fill_roster.erl - tools/privacy.erl - tools/travis-setup-db.sh - tools/travis-test.sh - tools/travis-upload-to-s3.sh - tools/zabbix_add_counters.py","title":"Tests &amp; tools"},{"location":"developers-guide/Moving-to-single-app-project-structure/#moving-a-mongooseims-fork-to-a-new-structure","text":"This section describes how to move a customized fork of MongooseIM to a new structure. Move all directories from the apps/ejabberd directory to the repository root, e.g. apps/ejabberd/src/ should be moved to just src/ . Be sure to move all the important files, because apps/ directory will be wiped out completely. Make all the changes described in the Move tools files section. If you've made any changes to apps/ejabberd/rebar.config or apps/ejabberd/rebar.config/script , be sure to merge these with rebar.config and rebar.config.script in the repository root. Remove apps/ directory. Make all the changes described in the Application resource files section. Make all the changes described in the Includes section. Make sure that none of the include directives in your source code (in src/ and test/ ) has the following structure -include_lib(\"ejabberd/include/<header_file>\") . They should now refer to bare header file names, i.e. -include(<header_file>) . Make all the changes described in the Release scripts section. Make sure that all customizations made to release scripts and release process are aware of the new directory structure (i.e. none of them assumes apps/ejabberd path exists). Make all the changes described in the Tests & tools section. Since ejabberd application was renamed to mongooseim , make sure that all the code which was starting or stopping ejabberd , now does the same for mongooseim . You might want to check the following function calls: most of the functions from the application module code:priv_dir/1 calls to rpc module which would call functions listed above","title":"Moving a MongooseIM's fork to a new structure"},{"location":"developers-guide/OpenSSL-and-FIPS/","text":"OpenSSL FIPS Support for OpenSSL FIPS was added to MongooseIM in version 1.7.0. Incompatibilities Currently known incompatible features are: SASL auth mechanism DIGEST-MD5: due to a forbidden MD5 hash function in FIPS mode. Requirements Build Erlang/OTP with FIPS support Make sure the option --enable-fips is specified for configure command. If you want to use a different OpenSSL than the default one, specify the option --with-ssl=PATH_TO_YOUR_OPENSSL as well. Here's an example of a command for building Erlang/OTP with kerl: KERL_CONFIGURE_OPTIONS=\"--enable-fips\" ./kerl build 21.3 21.3-fips Building MongooseIM with a custom OpenSSL If you want to use a custom OpenSSL, please export the CFLAGS and LDFLAGS env vars pointing to a FIPS compliant OpenSSL before running ./rebar3 compile or make rel . OPENSSL_LIB=~/openssl/lib #put your path here OPENSSL_INC=~/openssl/inc #put your path here export LDFLAGS=\"-Wl,-rpath=$OPENSSL_LIB -L$OPENSSL_LIB\" export CFLAGS=\"-I$OPENSSL_INC\" How to enable/disable FIPS mode Find etc/app.config in the release directory. FIPS mode is an option of the crypto application. In order to enable/disable it, add the following section to app.config : {crypto, [{fips_mode, Value}]}, where Value is either true or false . How to check if the FIPS mode is enabled Log message When MongooseIM starts, it prints the following log message if FIPS mode is enabled 2015-02-25 14:30:54.501 [warning] <0.242.0>@mongoose_fips:do_notify:37 FIPS mode enabled Run-time check Run the following function in the MongooseIM console: mongoose_fips:status(). The function returns: * not_enabled - fips_mode is not set to true in etc/app.config * enabled - fips_mode is set to true in etc/app.config * not_supported - erlang compiled without fips support Cipher suites difference A test using a cipher_suites_test.sh script (available in the tools directory) can be performed on MongooseIM with FIPS mode enabled and disabled. We've used OpenSSL 1.0.1j-fips . Here are all the cipher suites available when the FIPS mode is enabled (the list may vary for different openssl versions): ECDHE-RSA-AES256-SHA DHE-RSA-AES256-SHA AES256-SHA ECDHE-RSA-DES-CBC3-SHA EDH-RSA-DES-CBC3-SHA DES-CBC3-SHA ECDHE-RSA-AES128-SHA DHE-RSA-AES128-SHA AES128-SHA Here are all the cipher suites available when the FIPS mode is disabled (the list may vary for different openssl versions): ECDHE-RSA-AES256-SHA DHE-RSA-AES256-SHA DHE-RSA-CAMELLIA256-SHA AES256-SHA CAMELLIA256-SHA ECDHE-RSA-DES-CBC3-SHA EDH-RSA-DES-CBC3-SHA DES-CBC3-SHA ECDHE-RSA-AES128-SHA DHE-RSA-AES128-SHA DHE-RSA-SEED-SHA DHE-RSA-CAMELLIA128-SHA AES128-SHA SEED-SHA CAMELLIA128-SHA ECDHE-RSA-RC4-SHA RC4-SHA RC4-MD5","title":"FIPS mode"},{"location":"developers-guide/OpenSSL-and-FIPS/#openssl-fips","text":"Support for OpenSSL FIPS was added to MongooseIM in version 1.7.0.","title":"OpenSSL FIPS"},{"location":"developers-guide/OpenSSL-and-FIPS/#incompatibilities","text":"Currently known incompatible features are: SASL auth mechanism DIGEST-MD5: due to a forbidden MD5 hash function in FIPS mode.","title":"Incompatibilities"},{"location":"developers-guide/OpenSSL-and-FIPS/#requirements","text":"","title":"Requirements"},{"location":"developers-guide/OpenSSL-and-FIPS/#build-erlangotp-with-fips-support","text":"Make sure the option --enable-fips is specified for configure command. If you want to use a different OpenSSL than the default one, specify the option --with-ssl=PATH_TO_YOUR_OPENSSL as well. Here's an example of a command for building Erlang/OTP with kerl: KERL_CONFIGURE_OPTIONS=\"--enable-fips\" ./kerl build 21.3 21.3-fips","title":"Build Erlang/OTP with FIPS support"},{"location":"developers-guide/OpenSSL-and-FIPS/#building-mongooseim-with-a-custom-openssl","text":"If you want to use a custom OpenSSL, please export the CFLAGS and LDFLAGS env vars pointing to a FIPS compliant OpenSSL before running ./rebar3 compile or make rel . OPENSSL_LIB=~/openssl/lib #put your path here OPENSSL_INC=~/openssl/inc #put your path here export LDFLAGS=\"-Wl,-rpath=$OPENSSL_LIB -L$OPENSSL_LIB\" export CFLAGS=\"-I$OPENSSL_INC\"","title":"Building MongooseIM with a custom OpenSSL"},{"location":"developers-guide/OpenSSL-and-FIPS/#how-to-enabledisable-fips-mode","text":"Find etc/app.config in the release directory. FIPS mode is an option of the crypto application. In order to enable/disable it, add the following section to app.config : {crypto, [{fips_mode, Value}]}, where Value is either true or false .","title":"How to enable/disable FIPS mode"},{"location":"developers-guide/OpenSSL-and-FIPS/#how-to-check-if-the-fips-mode-is-enabled","text":"","title":"How to check if the FIPS mode is enabled"},{"location":"developers-guide/OpenSSL-and-FIPS/#log-message","text":"When MongooseIM starts, it prints the following log message if FIPS mode is enabled 2015-02-25 14:30:54.501 [warning] <0.242.0>@mongoose_fips:do_notify:37 FIPS mode enabled","title":"Log message"},{"location":"developers-guide/OpenSSL-and-FIPS/#run-time-check","text":"Run the following function in the MongooseIM console: mongoose_fips:status(). The function returns: * not_enabled - fips_mode is not set to true in etc/app.config * enabled - fips_mode is set to true in etc/app.config * not_supported - erlang compiled without fips support","title":"Run-time check"},{"location":"developers-guide/OpenSSL-and-FIPS/#cipher-suites-difference","text":"A test using a cipher_suites_test.sh script (available in the tools directory) can be performed on MongooseIM with FIPS mode enabled and disabled. We've used OpenSSL 1.0.1j-fips . Here are all the cipher suites available when the FIPS mode is enabled (the list may vary for different openssl versions): ECDHE-RSA-AES256-SHA DHE-RSA-AES256-SHA AES256-SHA ECDHE-RSA-DES-CBC3-SHA EDH-RSA-DES-CBC3-SHA DES-CBC3-SHA ECDHE-RSA-AES128-SHA DHE-RSA-AES128-SHA AES128-SHA Here are all the cipher suites available when the FIPS mode is disabled (the list may vary for different openssl versions): ECDHE-RSA-AES256-SHA DHE-RSA-AES256-SHA DHE-RSA-CAMELLIA256-SHA AES256-SHA CAMELLIA256-SHA ECDHE-RSA-DES-CBC3-SHA EDH-RSA-DES-CBC3-SHA DES-CBC3-SHA ECDHE-RSA-AES128-SHA DHE-RSA-AES128-SHA DHE-RSA-SEED-SHA DHE-RSA-CAMELLIA128-SHA AES128-SHA SEED-SHA CAMELLIA128-SHA ECDHE-RSA-RC4-SHA RC4-SHA RC4-MD5","title":"Cipher suites difference"},{"location":"developers-guide/SCRAM-serialization/","text":"Overview This document describes the SCRAM serialization format used by MongooseIM. Developers can use this information to create advanced endpoints for ejabberd_auth_http or enable other software to read (i.e. share) the user authentication data. Format description ==SCRAM==,<stored key>,<server key>,<salt>,<iteration count> <stored key> - Base64-encoded Stored Key <server key> - Base64-encoded Server Key <salt> - Base64-encoded Salt <iteration count> - Iteration Count formatted as a human-readable integer In order to learn more about the meaning of the Stored Key, Server Key, Salt and Iteration Count, please check the SCRAM specification . Example Password: misio Erlang record: #scram{ storedkey = <<\"tmi5IE+9pceRV/jkPLFHEaVY33c=\">>, serverkey = <<\"MiWNa8T3dniVDwmh77ufJ41fpAQ=\">>, salt = <<\"inKXODlSY5y5SCsLxibi0w==\">>, iterationcount = 4096 } Serialized password: ==SCRAM==,tmi5IE+9pceRV/jkPLFHEaVY33c=,MiWNa8T3dniVDwmh77ufJ41fpAQ=,inKXODlSY5y5SCsLxibi0w==,4096","title":"SCRAM serialization format"},{"location":"developers-guide/SCRAM-serialization/#overview","text":"This document describes the SCRAM serialization format used by MongooseIM. Developers can use this information to create advanced endpoints for ejabberd_auth_http or enable other software to read (i.e. share) the user authentication data.","title":"Overview"},{"location":"developers-guide/SCRAM-serialization/#format-description","text":"==SCRAM==,<stored key>,<server key>,<salt>,<iteration count> <stored key> - Base64-encoded Stored Key <server key> - Base64-encoded Server Key <salt> - Base64-encoded Salt <iteration count> - Iteration Count formatted as a human-readable integer In order to learn more about the meaning of the Stored Key, Server Key, Salt and Iteration Count, please check the SCRAM specification .","title":"Format description"},{"location":"developers-guide/SCRAM-serialization/#example","text":"Password: misio Erlang record: #scram{ storedkey = <<\"tmi5IE+9pceRV/jkPLFHEaVY33c=\">>, serverkey = <<\"MiWNa8T3dniVDwmh77ufJ41fpAQ=\">>, salt = <<\"inKXODlSY5y5SCsLxibi0w==\">>, iterationcount = 4096 } Serialized password: ==SCRAM==,tmi5IE+9pceRV/jkPLFHEaVY33c=,MiWNa8T3dniVDwmh77ufJ41fpAQ=,inKXODlSY5y5SCsLxibi0w==,4096","title":"Example"},{"location":"developers-guide/Testing-MongooseIM/","text":"Test runner The test runner script is used to compile MongooseIM and run tests. IMPORTANT! Some examples in this guide use the MySQL database. Please keep in mind that MongooseIM cannot connect to MySQL via TLS on OTP 20.3 . ODBC preset can only be tested on Ubuntu Xenial x64 . SELinux may prevent containers from accessing the disk. Please either disable it or add proper rules to the policy. Requirements Docker Docker must be installed on the local system and the user executing the tests must have privileges to start new containers (usually achieved by adding the user to the docker group). MSSQL connectivity MongooseIM requires FreeTDS in order to connect to MSSQL container. First of all, please install the driver itself: # Ubuntu $ sudo apt install freetds-dev tdsodbc # CentOS $ sudo yum install freetds # macOS $ brew install freetds Then, please modify tools/travis-setup-db.sh script to use the proper FreeTDS paths. Find a configuration block starting with [mongoose-mssql] . In case of Ubuntu, you don't need to change anything. For CentOS, change Driver and Setup to point /usr/lib64/libtdsodbc.so.0 and /usr/lib64/libtdsS.so respectively. For macOS, remove the Setup line and set Driver to Driver = /usr/local/Cellar/freetds/[current version]/lib/libtdsodbc.so . How to print the instructions The help command prints a list of supported options. ./tools/test-runner.sh --help Test runner examples Usage example: ./tools/test-runner.sh --db redis --preset internal_mnesia The command runs both big (feature) and small (unit) tests. To view more examples, run: ./tools/test-runner.sh --examples Test runner completion Test runner supports shell TAB completion. To enable completion in bash or zsh, run: source tools/test-runner-complete.sh To view completion examples, run: ./tools/test-runner.sh --examples-complete Viewing test reports To view test execution results, run: ./tools/test-runner.sh --show-big-reports ./tools/test-runner.sh --show-small-reports Rerun big tests Very often we want to restart a specific suite when some test failed. For example, some test has failed in mam_SUITE . The command was used to execute tests: ./tools/test-runner.sh --skip-small-tests --db mysql --preset mysql_mnesia --skip-stop-nodes --skip-stop-nodes is optional here, because if any big test fails, then nodes would be still running. We can just execute the same command, but it would rebuild nodes and start them. The command can be used instead: ./tools/test-runner.sh --rerun-big-tests -- mam --rerun-big-tests expands into --skip-small-tests --skip-setup-db --dev-nodes --test-hosts --skip-cover --skip-preset . And mam is used to run mam_SUITE suite only. Unit tests (a.k.a. \"small tests\") These test suites are aimed at testing various modules and libraries standalone, without launching a MongooseIM instance. They are very useful for developing/debugging libraries. The test suites are located in test/ directory. To run all of them, use ./rebar3 ct ; to run just a selected suite, use ./rebar3 ct --suite test/my_selected_SUITE . Rebar recompiles all the code automatically, there is no need for a separate compilation step. If all the tests pass, you wll get no output and summary log will be available in ct.log. If any of the tests fail the summary log is printed to stdout. Detailed test results in a nice HTML format are saved in _build/test/logs/ct_run.[something][datetime]/ Unit test running example using test runner: # Run all small tests, show progress ./tools/test-runner.sh --skip-big-tests --verbose # Run sha_SUITE without cover ./tools/test-runner.sh --skip-big-tests sha --skip-cover # Run reload_cluster group in ejabberd_config_SUITE, show progress ./tools/test-runner.sh --skip-big-tests ejabberd_config:reload_cluster --verbose End-to-end tests (a.k.a. \"big tests\") Using test runner Most important options are preset and database: # Runs privacy_SUITE and private_SUITE with MySQL ./tools/test-runner.sh --skip-small-tests --db mysql --preset mysql_mnesia -- privacy private # Runs MAM tests for MUC light with MySQL and Postgres ./tools/test-runner.sh --skip-small-tests --db mysql pgsql --preset mysql_mnesia pgsql_mnesia -- mam:rdbms_muc_light # Runs rdbms_SUITE with MSSQL # Inits a single MongooseIM node (works for some tests only) # Disables cover ./tools/test-runner.sh --skip-small-tests --db mssql --preset rdbms_mssql_mnesia --test-hosts mim --dev-nodes mim1 -- rdbms --skip-cover TL;DR In shell #1: $ cd $MONGOOSEIM $ ./rebar3 compile $ make devrel In shell #2: $ cd $MONGOOSEIM/_build/mim1/rel/mongooseim $ ./bin/mongooseimctl live In shell #3: $ cd $MONGOOSEIM/_build/mim2/rel/mongooseim $ ./bin/mongooseimctl live In shell #4: $ cd $MONGOOSEIM/_build/mim3/rel/mongooseim $ ./bin/mongooseimctl live In shell #5: $ cd $MONGOOSEIM/_build/fed1/rel/mongooseim $ ./bin/mongooseimctl live In shell #6: $ cd $MONGOOSEIM/_build/reg1/rel/mongooseim $ ./bin/mongooseimctl live Back to shell #1: $ cd big_tests/ $ make quicktest Wait for the tests to finish and celebrate (or wallow in despair and grief)! One-liner alternative for tmux users: ./rebar3 compile make devrel tmux new-window -n mim1 '_build/mim1/rel/mongooseim/bin/mongooseimctl live' tmux new-window -n mim2 '_build/mim2/rel/mongooseim/bin/mongooseimctl live' tmux new-window -n mim3 '_build/mim3/rel/mongooseim/bin/mongooseimctl live' tmux new-window -n fed1 '_build/fed1/rel/mongooseim/bin/mongooseimctl live' tmux new-window -n reg1 '_build/fed1/rel/mongooseim/bin/mongooseimctl live' _build/mim1/rel/mongooseim/bin/mongooseimctl started _build/mim2/rel/mongooseim/bin/mongooseimctl started _build/mim3/rel/mongooseim/bin/mongooseimctl started _build/fed1/rel/mongooseim/bin/mongooseimctl started _build/reg1/rel/mongooseim/bin/mongooseimctl started make -C big_tests quicktest Start a new tmux and paste the commands. Step-by-step breakdown make devrel builds four server nodes, preconfigured for a wide range of features covered by end-to-end tests. $MONGOOSEIM/_build/mim1/rel , for most test SUITEs $MONGOOSEIM/_build/mim*/rel , in order to test cluster-related commands;; $MONGOOSEIM/_build/fed1/rel , in order to test XMPP federation (server to server communication, S2S). $MONGOOSEIM/_build/reg1/rel , in order to test global distribution feature. In general, running a server in the interactive mode (i.e. mongooseimctl live ) is not required to test it, but it's convenient as any warnings and errors can be spotted in real time. It's also easy to inspect the server state or trace execution (e.g. using dbg ) in case of anything going wrong in some of the tests. To run the server in the background instead of the interactive mode, use mongooseimctl start && mongooseimctl started . The quicktest configuration is a relatively comprehensive one, giving good overview of what does and what doesn't work in the system, without repeating tests. Why would we want to ever repeat the tests? In order to test different backends of the same parts of the system. E.g. a message archive might store messages in MySQL/PostgreSQL or Riak KV - the glue code between the XMPP logic module and database is different in each case, therefore repeating the same tests with different databases is necessary to guarantee a truthful code coverage measurement. Testing a feature in development / TDD The whole suite takes a significant amount of time to complete. When you develop a new feature, the speed of iterating is crucial to maintain the flow (who doesn't like the feeling?!) and not lose focus. In $MONGOOSEIM/big_tests/ we have: $ tree big_tests/ -L 1 -F big_tests/ \u251c\u2500\u2500 Makefile \u251c\u2500\u2500 README.md \u251c\u2500\u2500 default.spec \u251c\u2500\u2500 test.config \u251c\u2500\u2500 tests/ \u2514\u2500\u2500 ... tests/ is where the test suites reside. *.config files are the suite configuration files - they contain predefined XMPP client specifications, server addresses and XMPP domains to use, and options required by test support libraries (i.e. Escalus ). *.spec files are the test specifications - they define the configuration file to use, the suites, test groups or individual test cases to run or skip, and some less important things. default.spec is the default when running make quicktest , but it can be overridden with a TESTSPEC variable: # make sure we're in $MONGOOSEIM/big_tests/ cd $MONGOOSEIM/big_tests/ make quicktest TESTSPEC=my-feature.spec To speed up the development cycle, developers usually create a .spec file for each feature (or each project, if you're cloning away) and only enable the suites / test groups they are working on. The allows testing only the parts of the system that are actually being changed. It's worth running default.spec once in a while to check for regressions. Consult the default.spec file to see how to run only selected tests/groups/cases. If you're sure that none of the test dependencies have changed and you only edited the test suites and/or MongooseIM code, it's possible to speed up the tests by skipping the Rebar dependency and compilation checks by providing PREPARE= (i.e. an empty value): make quicktest PREPARE= Consult the big_tests/Makefile to see how it works. Applying code changes When working on a feature or a bug fix you often modify the code and check if it works as expected. In order to change the code on dev nodes that are already generated ( mim* and fed* ) recompile the code for a specific node. For example, to update the code on mim1 node all you have to do is: ./rebar3 as mim1 compile A similar command applies to other nodes, the important thing being rebar3's profile. When the above command finishes, the code can be reloaded on the server by either reloading changed module(s) in the node's shell, e.g. l(mongoose_riak) , or restarting the node. Reading test reports When finished, the test engine writes detailed html reports into a directory: big_tests/ct_report/ct_run.[gobbledygook][datetime]/ Each run is saved into a new directory. This snippet: #!/bin/bash lst=$(ls -rt ct_report | grep ct_run | tail -n 1) rm ct_report/lastrun ln -s $lst ct_report/lastrun can be of some help. Checking coverage If you want to check how much of the code is covered by tests, run: make cover_quicktest Note: You need all the mim nodes (mim1, mim2 and mim3) up and running, even if you only run some of the tests. If any of the nodes is down, the test will crash. This command will recompile and reload the code on dev nodes with coverage enabled and run test suites as defined in the spec. Coverage statistics will be available in big_tests/ct_report/cover.html and coverage subdirectory. Advanced topics There are many more options available. One of them is sequentially testing a number of preset configurations - we do it every day on Travis, testing MongooseIM with various OTP versions and database backends. Altogether, we have eight preset configuration. If you want to dig deeper, consult .travis.yml and tools/travis-test.sh , everything we do is there. Gathering test reports from Travis tests If you test your MongooseIM fork on Travis, you might want to access test reports (which also include node logs and crash dumps) that are created by the test runner. Uploading reports to S3 Our script uses AWS CLI to upload test results to an S3 bucket. Simply set relevant environment variables in your repository settings on Travis (at least AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY have to be set), and enjoy test reports landing straight into your bucket ( AWS_BUCKET variable should store the bucket's name). Uploading reports to Google Drive To store test results in Google Drive you need to create a new project and obtain service account credentials . You must also add Google Drive API to your project - to do this, navigate to APIs & Services in your project console and find & add Google Drive API in the Library tab. Once downloaded, encode the credentials file with base64 (e.g. cat serviceCreds.json | base64 ) and use the result as GDRIVE_SERVICE_ACCOUNT_CREDENTIALS environment variable in your Travis repository settings. Saving reports on your personal account The uploaded files will belong to the project that you created, i.e. will not be immediately visible from your personal Google Drive UI. To be able to upload files to your personal account, you can share the reports' directory with the project account. First, note the ID of the project's user that you created to gain the service account credentials (e.g. test-123@fair-smile-123456.iam.gserviceaccount.com ). You can see this on the Service Accounts tab of the project console . Now, create a directory on your Google Drive that will serve as the test root directory. Go into the directory's sharing options and paste in the project's user ID, granting it write access. Click to expand the advanced sharing options and note the ID of the shared directory that's displayed in the share link (e.g. if the link is https://drive.google.com/drive/folders/1234567890abcdef?usp=sharing , the directory's ID is 1234567890abcdef ). Finally, set GDRIVE_PARENT_DIR environment variable of your Travis build to the directory ID that you noted in the previous step. Load testing Alongside CI, we do also CLT (Continuous Load Testing). We have our own load testing infrastructure, called Tide, which is triggered after every successful test run, and gives us a feedback on changes to MongooseIM performance. Test results are publicly available on the Hello Tide! page.","title":"Testing MongooseIM"},{"location":"developers-guide/Testing-MongooseIM/#test-runner","text":"The test runner script is used to compile MongooseIM and run tests.","title":"Test runner"},{"location":"developers-guide/Testing-MongooseIM/#important","text":"Some examples in this guide use the MySQL database. Please keep in mind that MongooseIM cannot connect to MySQL via TLS on OTP 20.3 . ODBC preset can only be tested on Ubuntu Xenial x64 . SELinux may prevent containers from accessing the disk. Please either disable it or add proper rules to the policy.","title":"IMPORTANT!"},{"location":"developers-guide/Testing-MongooseIM/#requirements","text":"","title":"Requirements"},{"location":"developers-guide/Testing-MongooseIM/#docker","text":"Docker must be installed on the local system and the user executing the tests must have privileges to start new containers (usually achieved by adding the user to the docker group).","title":"Docker"},{"location":"developers-guide/Testing-MongooseIM/#mssql-connectivity","text":"MongooseIM requires FreeTDS in order to connect to MSSQL container. First of all, please install the driver itself: # Ubuntu $ sudo apt install freetds-dev tdsodbc # CentOS $ sudo yum install freetds # macOS $ brew install freetds Then, please modify tools/travis-setup-db.sh script to use the proper FreeTDS paths. Find a configuration block starting with [mongoose-mssql] . In case of Ubuntu, you don't need to change anything. For CentOS, change Driver and Setup to point /usr/lib64/libtdsodbc.so.0 and /usr/lib64/libtdsS.so respectively. For macOS, remove the Setup line and set Driver to Driver = /usr/local/Cellar/freetds/[current version]/lib/libtdsodbc.so .","title":"MSSQL connectivity"},{"location":"developers-guide/Testing-MongooseIM/#how-to-print-the-instructions","text":"The help command prints a list of supported options. ./tools/test-runner.sh --help","title":"How to print the instructions"},{"location":"developers-guide/Testing-MongooseIM/#test-runner-examples","text":"Usage example: ./tools/test-runner.sh --db redis --preset internal_mnesia The command runs both big (feature) and small (unit) tests. To view more examples, run: ./tools/test-runner.sh --examples","title":"Test runner examples"},{"location":"developers-guide/Testing-MongooseIM/#test-runner-completion","text":"Test runner supports shell TAB completion. To enable completion in bash or zsh, run: source tools/test-runner-complete.sh To view completion examples, run: ./tools/test-runner.sh --examples-complete","title":"Test runner completion"},{"location":"developers-guide/Testing-MongooseIM/#viewing-test-reports","text":"To view test execution results, run: ./tools/test-runner.sh --show-big-reports ./tools/test-runner.sh --show-small-reports","title":"Viewing test reports"},{"location":"developers-guide/Testing-MongooseIM/#rerun-big-tests","text":"Very often we want to restart a specific suite when some test failed. For example, some test has failed in mam_SUITE . The command was used to execute tests: ./tools/test-runner.sh --skip-small-tests --db mysql --preset mysql_mnesia --skip-stop-nodes --skip-stop-nodes is optional here, because if any big test fails, then nodes would be still running. We can just execute the same command, but it would rebuild nodes and start them. The command can be used instead: ./tools/test-runner.sh --rerun-big-tests -- mam --rerun-big-tests expands into --skip-small-tests --skip-setup-db --dev-nodes --test-hosts --skip-cover --skip-preset . And mam is used to run mam_SUITE suite only.","title":"Rerun big tests"},{"location":"developers-guide/Testing-MongooseIM/#unit-tests-aka-small-tests","text":"These test suites are aimed at testing various modules and libraries standalone, without launching a MongooseIM instance. They are very useful for developing/debugging libraries. The test suites are located in test/ directory. To run all of them, use ./rebar3 ct ; to run just a selected suite, use ./rebar3 ct --suite test/my_selected_SUITE . Rebar recompiles all the code automatically, there is no need for a separate compilation step. If all the tests pass, you wll get no output and summary log will be available in ct.log. If any of the tests fail the summary log is printed to stdout. Detailed test results in a nice HTML format are saved in _build/test/logs/ct_run.[something][datetime]/ Unit test running example using test runner: # Run all small tests, show progress ./tools/test-runner.sh --skip-big-tests --verbose # Run sha_SUITE without cover ./tools/test-runner.sh --skip-big-tests sha --skip-cover # Run reload_cluster group in ejabberd_config_SUITE, show progress ./tools/test-runner.sh --skip-big-tests ejabberd_config:reload_cluster --verbose","title":"Unit tests (a.k.a. \"small tests\")"},{"location":"developers-guide/Testing-MongooseIM/#end-to-end-tests-aka-big-tests","text":"","title":"End-to-end tests (a.k.a. \"big tests\")"},{"location":"developers-guide/Testing-MongooseIM/#using-test-runner","text":"Most important options are preset and database: # Runs privacy_SUITE and private_SUITE with MySQL ./tools/test-runner.sh --skip-small-tests --db mysql --preset mysql_mnesia -- privacy private # Runs MAM tests for MUC light with MySQL and Postgres ./tools/test-runner.sh --skip-small-tests --db mysql pgsql --preset mysql_mnesia pgsql_mnesia -- mam:rdbms_muc_light # Runs rdbms_SUITE with MSSQL # Inits a single MongooseIM node (works for some tests only) # Disables cover ./tools/test-runner.sh --skip-small-tests --db mssql --preset rdbms_mssql_mnesia --test-hosts mim --dev-nodes mim1 -- rdbms --skip-cover","title":"Using test runner"},{"location":"developers-guide/Testing-MongooseIM/#tldr","text":"In shell #1: $ cd $MONGOOSEIM $ ./rebar3 compile $ make devrel In shell #2: $ cd $MONGOOSEIM/_build/mim1/rel/mongooseim $ ./bin/mongooseimctl live In shell #3: $ cd $MONGOOSEIM/_build/mim2/rel/mongooseim $ ./bin/mongooseimctl live In shell #4: $ cd $MONGOOSEIM/_build/mim3/rel/mongooseim $ ./bin/mongooseimctl live In shell #5: $ cd $MONGOOSEIM/_build/fed1/rel/mongooseim $ ./bin/mongooseimctl live In shell #6: $ cd $MONGOOSEIM/_build/reg1/rel/mongooseim $ ./bin/mongooseimctl live Back to shell #1: $ cd big_tests/ $ make quicktest Wait for the tests to finish and celebrate (or wallow in despair and grief)! One-liner alternative for tmux users: ./rebar3 compile make devrel tmux new-window -n mim1 '_build/mim1/rel/mongooseim/bin/mongooseimctl live' tmux new-window -n mim2 '_build/mim2/rel/mongooseim/bin/mongooseimctl live' tmux new-window -n mim3 '_build/mim3/rel/mongooseim/bin/mongooseimctl live' tmux new-window -n fed1 '_build/fed1/rel/mongooseim/bin/mongooseimctl live' tmux new-window -n reg1 '_build/fed1/rel/mongooseim/bin/mongooseimctl live' _build/mim1/rel/mongooseim/bin/mongooseimctl started _build/mim2/rel/mongooseim/bin/mongooseimctl started _build/mim3/rel/mongooseim/bin/mongooseimctl started _build/fed1/rel/mongooseim/bin/mongooseimctl started _build/reg1/rel/mongooseim/bin/mongooseimctl started make -C big_tests quicktest Start a new tmux and paste the commands.","title":"TL;DR"},{"location":"developers-guide/Testing-MongooseIM/#step-by-step-breakdown","text":"make devrel builds four server nodes, preconfigured for a wide range of features covered by end-to-end tests. $MONGOOSEIM/_build/mim1/rel , for most test SUITEs $MONGOOSEIM/_build/mim*/rel , in order to test cluster-related commands;; $MONGOOSEIM/_build/fed1/rel , in order to test XMPP federation (server to server communication, S2S). $MONGOOSEIM/_build/reg1/rel , in order to test global distribution feature. In general, running a server in the interactive mode (i.e. mongooseimctl live ) is not required to test it, but it's convenient as any warnings and errors can be spotted in real time. It's also easy to inspect the server state or trace execution (e.g. using dbg ) in case of anything going wrong in some of the tests. To run the server in the background instead of the interactive mode, use mongooseimctl start && mongooseimctl started . The quicktest configuration is a relatively comprehensive one, giving good overview of what does and what doesn't work in the system, without repeating tests. Why would we want to ever repeat the tests? In order to test different backends of the same parts of the system. E.g. a message archive might store messages in MySQL/PostgreSQL or Riak KV - the glue code between the XMPP logic module and database is different in each case, therefore repeating the same tests with different databases is necessary to guarantee a truthful code coverage measurement.","title":"Step-by-step breakdown"},{"location":"developers-guide/Testing-MongooseIM/#testing-a-feature-in-development-tdd","text":"The whole suite takes a significant amount of time to complete. When you develop a new feature, the speed of iterating is crucial to maintain the flow (who doesn't like the feeling?!) and not lose focus. In $MONGOOSEIM/big_tests/ we have: $ tree big_tests/ -L 1 -F big_tests/ \u251c\u2500\u2500 Makefile \u251c\u2500\u2500 README.md \u251c\u2500\u2500 default.spec \u251c\u2500\u2500 test.config \u251c\u2500\u2500 tests/ \u2514\u2500\u2500 ... tests/ is where the test suites reside. *.config files are the suite configuration files - they contain predefined XMPP client specifications, server addresses and XMPP domains to use, and options required by test support libraries (i.e. Escalus ). *.spec files are the test specifications - they define the configuration file to use, the suites, test groups or individual test cases to run or skip, and some less important things. default.spec is the default when running make quicktest , but it can be overridden with a TESTSPEC variable: # make sure we're in $MONGOOSEIM/big_tests/ cd $MONGOOSEIM/big_tests/ make quicktest TESTSPEC=my-feature.spec To speed up the development cycle, developers usually create a .spec file for each feature (or each project, if you're cloning away) and only enable the suites / test groups they are working on. The allows testing only the parts of the system that are actually being changed. It's worth running default.spec once in a while to check for regressions. Consult the default.spec file to see how to run only selected tests/groups/cases. If you're sure that none of the test dependencies have changed and you only edited the test suites and/or MongooseIM code, it's possible to speed up the tests by skipping the Rebar dependency and compilation checks by providing PREPARE= (i.e. an empty value): make quicktest PREPARE= Consult the big_tests/Makefile to see how it works.","title":"Testing a feature in development / TDD"},{"location":"developers-guide/Testing-MongooseIM/#applying-code-changes","text":"When working on a feature or a bug fix you often modify the code and check if it works as expected. In order to change the code on dev nodes that are already generated ( mim* and fed* ) recompile the code for a specific node. For example, to update the code on mim1 node all you have to do is: ./rebar3 as mim1 compile A similar command applies to other nodes, the important thing being rebar3's profile. When the above command finishes, the code can be reloaded on the server by either reloading changed module(s) in the node's shell, e.g. l(mongoose_riak) , or restarting the node.","title":"Applying code changes"},{"location":"developers-guide/Testing-MongooseIM/#reading-test-reports","text":"When finished, the test engine writes detailed html reports into a directory: big_tests/ct_report/ct_run.[gobbledygook][datetime]/ Each run is saved into a new directory. This snippet: #!/bin/bash lst=$(ls -rt ct_report | grep ct_run | tail -n 1) rm ct_report/lastrun ln -s $lst ct_report/lastrun can be of some help.","title":"Reading test reports"},{"location":"developers-guide/Testing-MongooseIM/#checking-coverage","text":"If you want to check how much of the code is covered by tests, run: make cover_quicktest Note: You need all the mim nodes (mim1, mim2 and mim3) up and running, even if you only run some of the tests. If any of the nodes is down, the test will crash. This command will recompile and reload the code on dev nodes with coverage enabled and run test suites as defined in the spec. Coverage statistics will be available in big_tests/ct_report/cover.html and coverage subdirectory.","title":"Checking coverage"},{"location":"developers-guide/Testing-MongooseIM/#advanced-topics","text":"There are many more options available. One of them is sequentially testing a number of preset configurations - we do it every day on Travis, testing MongooseIM with various OTP versions and database backends. Altogether, we have eight preset configuration. If you want to dig deeper, consult .travis.yml and tools/travis-test.sh , everything we do is there.","title":"Advanced topics"},{"location":"developers-guide/Testing-MongooseIM/#gathering-test-reports-from-travis-tests","text":"If you test your MongooseIM fork on Travis, you might want to access test reports (which also include node logs and crash dumps) that are created by the test runner.","title":"Gathering test reports from Travis tests"},{"location":"developers-guide/Testing-MongooseIM/#uploading-reports-to-s3","text":"Our script uses AWS CLI to upload test results to an S3 bucket. Simply set relevant environment variables in your repository settings on Travis (at least AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY have to be set), and enjoy test reports landing straight into your bucket ( AWS_BUCKET variable should store the bucket's name).","title":"Uploading reports to S3"},{"location":"developers-guide/Testing-MongooseIM/#uploading-reports-to-google-drive","text":"To store test results in Google Drive you need to create a new project and obtain service account credentials . You must also add Google Drive API to your project - to do this, navigate to APIs & Services in your project console and find & add Google Drive API in the Library tab. Once downloaded, encode the credentials file with base64 (e.g. cat serviceCreds.json | base64 ) and use the result as GDRIVE_SERVICE_ACCOUNT_CREDENTIALS environment variable in your Travis repository settings.","title":"Uploading reports to Google Drive"},{"location":"developers-guide/Testing-MongooseIM/#saving-reports-on-your-personal-account","text":"The uploaded files will belong to the project that you created, i.e. will not be immediately visible from your personal Google Drive UI. To be able to upload files to your personal account, you can share the reports' directory with the project account. First, note the ID of the project's user that you created to gain the service account credentials (e.g. test-123@fair-smile-123456.iam.gserviceaccount.com ). You can see this on the Service Accounts tab of the project console . Now, create a directory on your Google Drive that will serve as the test root directory. Go into the directory's sharing options and paste in the project's user ID, granting it write access. Click to expand the advanced sharing options and note the ID of the shared directory that's displayed in the share link (e.g. if the link is https://drive.google.com/drive/folders/1234567890abcdef?usp=sharing , the directory's ID is 1234567890abcdef ). Finally, set GDRIVE_PARENT_DIR environment variable of your Travis build to the directory ID that you noted in the previous step.","title":"Saving reports on your personal account"},{"location":"developers-guide/Testing-MongooseIM/#load-testing","text":"Alongside CI, we do also CLT (Continuous Load Testing). We have our own load testing infrastructure, called Tide, which is triggered after every successful test run, and gives us a feedback on changes to MongooseIM performance. Test results are publicly available on the Hello Tide! page.","title":"Load testing"},{"location":"developers-guide/accumulators/","text":"Accumulators XMPP stanza processing starts in the ejabberd_c2s module, which receives the stanza from a socket, or in ejabberd_s2s_in which receives stanzas from federated XMPP clusters. The stanza is processed and eventually it and/or other messages are sent out, either to the original sender, to another c2s process within the same MongooseIM installation, or to another XMPP server. At the beginning of the main processing chain an accumulator is created containing following set of keys: ref - A unique reference of the acc, useful for tracing. timestamp - An Erlang timestamp retrieved from os:timestamp() . origin_pid - A PID of the process that created the accumulator. origin_location - {Module, Function Line} - A place in the code where the accumulator was created. origin_stanza - Original stanza that triggered the processing (in a binary). lserver - Nameprepped domain of the processing context. stanza - A map with information about the stanza being routed. May be missing in some processing chains (when they are not triggered by a stanza)! element - exml:element() with the current stanza being routed. from_jid , to_jid - jid:jid() with the sender and the recipient. name - A name of the top-level element in element . type - A value of type attribute of the top-level element. If the attribute is missing, this field contains undefined . ref - A reference of routed stanza. It is then passed through all the stages until it reaches the end of its life. Throughout the process it is the very same accumulator; it is therefore possible to store a value in it on one stage of the processing and retrieve the same value later on. The main assumption is that whatever MongooseIM does, it is always triggered by a stanza entering the system, with some exceptions, such as a couple of mongooseimctl operations, which create stanza-less accumulators. The stanza should always be packed into an accumulator and passed on, so that internally every action is performed the same way. There are three main benefits from this approach: a) performance - if we need to do something involving inspecting a stanza or more complicated operations (e.g. privacy check) we don't need to do it multiple times on various stages of processing - instead we can do it once and store the result in an accumulator b) debugging - it is now very easy to produce an exact track record of a stanza c) simplified implementation of modules which inherently involve multi-stage processing (e.g. mod_amp ) API mongoose_acc module exports t() type which is the accumulator type. new(new_acc_params()) A constructor for accumulators. new_acc_params() is a map with following supported keys: location - Should be a {Module, Function, Line} tuple (may be constructed with ?LOCATION macro from mongoose.hrl ). Its format is not enforced by the acc logic but Dialyzer will most probably complain about any other type. lserver - Nameprepped domain of a the processing context. element (optional) - If present, it will be used as a source for the stanza map. from_jid , to_jid (optional) - Values used to override from and to attributes of the element , respectively. If element is provided, the sender and recipient JIDs are extracted, either from the element itself, or from to_jid and from_jid parameters. The call will fail with an exception if it's not possible. While allowed, stanza-less accumulators usage should be avoided. Getters for predefined fields ref(t()) timestamp(t()) lserver(t()) element(t()) stanza_name(t()) - Returns name value from stanza map. stanza_type(t()) - Returns type value from stanza map. stanza_ref(t()) - Returns ref value from stanza map. This is not the same as ref(t()) ! update_stanza(stanza_params(), t()) Replaces the whole stanza field in accumulator with params provided in stanza_params() , which is a map of 3 fields: element , from_jid , to_jid . The same rules apply as in the case of constructor ( new/1 ) but this time element field is mandatory . Access to namespaced fields It is possible to store and retrieve any data in the accumulator, that is related to the processing. There is no scope protection, so every module may access all namespaces and keys inside them. set(Namespace :: any(), Key :: any(), Value :: any(), t()) set_permanent(Namespace :: any(), Key :: any(), Value :: any(), t()) - Upserts a field, which won't be removed during strip operation. append(Namespace :: any(), Key :: any(), Value :: any(), t()) - In order to use this function, a Namespace:Key field must not exist or must be a list. Value is appended to the end of this list. If Value is a list, then a OldValue ++ Value operation is performed. In other cases OldValue ++ [Value] is used. get(Namespace :: any(), Key :: any(), t()) - Returns a value of a specified field. Will crash if the NS:Key is not found. get(Namespace :: any(), Key :: any(), Default :: any(), t()) - Returns a value of a specified field or Default if NS:Key is not found. delete(Namespace :: any(), Key :: any(), t()) - Removes a specified field, no matter if it is permanent or not. Stripping Accumulator is used mostly to cache values for reuse within a c2s process; when it goes out to somewhere else, it is stripped of all unnecessary attributes except for: ref timestamp origin_pid origin_location origin_stanza non_strippable - A set of permanent NS:Key pairs. If you want it to carry some additional values along with it, please use a dedicated api for setting \"permanent\" fields: Acc2 = mongoose_acc:set_permanent(myns, myprop, 123, Acc1), Permanent fields may be retrieved with ordinary get/3,4 functions. The rationale behind stripping an accumulator is that some values stored in it are context-dependend. For example, at the beginning lserver refers to the host of the sender C2S. When an accumulator goes to the c2s of the recipient, the lserver attribute may change. There are also many cached values which are not valid anymore when user changes (e.g. privacy checks). In order to strip an accumulator, please use strip(strip_params(), t()) , where strip_params() is a map of: lserver - New host context. Obviously, may be equal to the old value. element , from_jid , to_jid - The same rules apply as in update_stanza/2 . Main principles of an accumulator processing An accumulator is created when a stanza enters the server. An XML stanza is never passed around as a pure exml:element() . An accumulator is stripped when it is passed to a different context (e.g. another c2s process). If a process produces more stanzas to be routed, they must reuse original acc but with stanza replaced with update_stanza/2 . Hooks Many of the MongooseIM functionalities are implemented in submodules which attach their handlers to hooks (this is covered in detail in \"Hooks and handlers\" . When it comes to the accumulators, the following rules apply: If a hook is related to stanza processing and is executed with run_fold , a Mongoose accumulator should be provided. A hook handler may modify an accumulator in every permitted way (i.e. shouldn't directly modify acc fields, bypassing mongoose_acc API) and should return the execution result in the hook:result field. This is not enforced but should be followed by convention. Avoid passing superfluous arguments to handlers - e.g. an LServer in hook args is redundant since it is already present in the accumulator. Do not use run - it is still present in API but executes run_fold with ok as an initial accumulator anyway. Handlers have been rewritten so that they accept an acc as the first arg. Note that run is deprecated now and at some point will be removed. Most handlers have already been modified so that they accept an instance of mongoose_acc:t() as the first argument and return value by storing it inside it. How the accumulator is used within a module is up to the implementors of the module. IQs and accumulators mongoose_iq module exposes a dedicated API for accessing IQ-related accumulator fields. These are: info(Acc) - Returns a #iq{} record produced from a stanza stored in the accumulator. May be invalid or not_iq if the stanza is not a valid IQ. xmlns(Acc) - Returns XMLNS of the first subelement inside an IQ. In most cases it is a namespace of <query/> subelement. May be undefined . command(Acc) - Returns the name of a first subelement inside an IQ. May be undefined . These functions ensure that cached information matches the accumulator's stanza, so all of them return a tuple with a possibly updated acc as a second element. Sample usage, actual and potential Privacy check Stanzas are often checked against privacy lists. According to the current mongoose_privacy:privacy_check_packet implementation, the result is stored in an accumulator so if a check has to be repeated it is just one map read. Tracing origin_stanza field is fully immutable for the lifespan of a single accumulator, so it's easier to correlate one of the stanzas sent by a client with some \"unexpected\" stanza routed from a completely different part of a server. There are many places in the server, where an accumulator may be created, so origin_location makes it much easier to find out what event has triggered the processing. Performance measurement Given that each accumulator has a timestamp denoting its creation time, it is now very easy to implement a metric showing the stanza processing time, or even multiple metrics splitting it into stages.","title":"Accumulators"},{"location":"developers-guide/accumulators/#accumulators","text":"XMPP stanza processing starts in the ejabberd_c2s module, which receives the stanza from a socket, or in ejabberd_s2s_in which receives stanzas from federated XMPP clusters. The stanza is processed and eventually it and/or other messages are sent out, either to the original sender, to another c2s process within the same MongooseIM installation, or to another XMPP server. At the beginning of the main processing chain an accumulator is created containing following set of keys: ref - A unique reference of the acc, useful for tracing. timestamp - An Erlang timestamp retrieved from os:timestamp() . origin_pid - A PID of the process that created the accumulator. origin_location - {Module, Function Line} - A place in the code where the accumulator was created. origin_stanza - Original stanza that triggered the processing (in a binary). lserver - Nameprepped domain of the processing context. stanza - A map with information about the stanza being routed. May be missing in some processing chains (when they are not triggered by a stanza)! element - exml:element() with the current stanza being routed. from_jid , to_jid - jid:jid() with the sender and the recipient. name - A name of the top-level element in element . type - A value of type attribute of the top-level element. If the attribute is missing, this field contains undefined . ref - A reference of routed stanza. It is then passed through all the stages until it reaches the end of its life. Throughout the process it is the very same accumulator; it is therefore possible to store a value in it on one stage of the processing and retrieve the same value later on. The main assumption is that whatever MongooseIM does, it is always triggered by a stanza entering the system, with some exceptions, such as a couple of mongooseimctl operations, which create stanza-less accumulators. The stanza should always be packed into an accumulator and passed on, so that internally every action is performed the same way. There are three main benefits from this approach: a) performance - if we need to do something involving inspecting a stanza or more complicated operations (e.g. privacy check) we don't need to do it multiple times on various stages of processing - instead we can do it once and store the result in an accumulator b) debugging - it is now very easy to produce an exact track record of a stanza c) simplified implementation of modules which inherently involve multi-stage processing (e.g. mod_amp )","title":"Accumulators"},{"location":"developers-guide/accumulators/#api","text":"mongoose_acc module exports t() type which is the accumulator type.","title":"API"},{"location":"developers-guide/accumulators/#newnew_acc_params","text":"A constructor for accumulators. new_acc_params() is a map with following supported keys: location - Should be a {Module, Function, Line} tuple (may be constructed with ?LOCATION macro from mongoose.hrl ). Its format is not enforced by the acc logic but Dialyzer will most probably complain about any other type. lserver - Nameprepped domain of a the processing context. element (optional) - If present, it will be used as a source for the stanza map. from_jid , to_jid (optional) - Values used to override from and to attributes of the element , respectively. If element is provided, the sender and recipient JIDs are extracted, either from the element itself, or from to_jid and from_jid parameters. The call will fail with an exception if it's not possible. While allowed, stanza-less accumulators usage should be avoided.","title":"new(new_acc_params())"},{"location":"developers-guide/accumulators/#getters-for-predefined-fields","text":"ref(t()) timestamp(t()) lserver(t()) element(t()) stanza_name(t()) - Returns name value from stanza map. stanza_type(t()) - Returns type value from stanza map. stanza_ref(t()) - Returns ref value from stanza map. This is not the same as ref(t()) !","title":"Getters for predefined fields"},{"location":"developers-guide/accumulators/#update_stanzastanza_params-t","text":"Replaces the whole stanza field in accumulator with params provided in stanza_params() , which is a map of 3 fields: element , from_jid , to_jid . The same rules apply as in the case of constructor ( new/1 ) but this time element field is mandatory .","title":"update_stanza(stanza_params(), t())"},{"location":"developers-guide/accumulators/#access-to-namespaced-fields","text":"It is possible to store and retrieve any data in the accumulator, that is related to the processing. There is no scope protection, so every module may access all namespaces and keys inside them. set(Namespace :: any(), Key :: any(), Value :: any(), t()) set_permanent(Namespace :: any(), Key :: any(), Value :: any(), t()) - Upserts a field, which won't be removed during strip operation. append(Namespace :: any(), Key :: any(), Value :: any(), t()) - In order to use this function, a Namespace:Key field must not exist or must be a list. Value is appended to the end of this list. If Value is a list, then a OldValue ++ Value operation is performed. In other cases OldValue ++ [Value] is used. get(Namespace :: any(), Key :: any(), t()) - Returns a value of a specified field. Will crash if the NS:Key is not found. get(Namespace :: any(), Key :: any(), Default :: any(), t()) - Returns a value of a specified field or Default if NS:Key is not found. delete(Namespace :: any(), Key :: any(), t()) - Removes a specified field, no matter if it is permanent or not.","title":"Access to namespaced fields"},{"location":"developers-guide/accumulators/#stripping","text":"Accumulator is used mostly to cache values for reuse within a c2s process; when it goes out to somewhere else, it is stripped of all unnecessary attributes except for: ref timestamp origin_pid origin_location origin_stanza non_strippable - A set of permanent NS:Key pairs. If you want it to carry some additional values along with it, please use a dedicated api for setting \"permanent\" fields: Acc2 = mongoose_acc:set_permanent(myns, myprop, 123, Acc1), Permanent fields may be retrieved with ordinary get/3,4 functions. The rationale behind stripping an accumulator is that some values stored in it are context-dependend. For example, at the beginning lserver refers to the host of the sender C2S. When an accumulator goes to the c2s of the recipient, the lserver attribute may change. There are also many cached values which are not valid anymore when user changes (e.g. privacy checks). In order to strip an accumulator, please use strip(strip_params(), t()) , where strip_params() is a map of: lserver - New host context. Obviously, may be equal to the old value. element , from_jid , to_jid - The same rules apply as in update_stanza/2 .","title":"Stripping"},{"location":"developers-guide/accumulators/#main-principles-of-an-accumulator-processing","text":"An accumulator is created when a stanza enters the server. An XML stanza is never passed around as a pure exml:element() . An accumulator is stripped when it is passed to a different context (e.g. another c2s process). If a process produces more stanzas to be routed, they must reuse original acc but with stanza replaced with update_stanza/2 .","title":"Main principles of an accumulator processing"},{"location":"developers-guide/accumulators/#hooks","text":"Many of the MongooseIM functionalities are implemented in submodules which attach their handlers to hooks (this is covered in detail in \"Hooks and handlers\" . When it comes to the accumulators, the following rules apply: If a hook is related to stanza processing and is executed with run_fold , a Mongoose accumulator should be provided. A hook handler may modify an accumulator in every permitted way (i.e. shouldn't directly modify acc fields, bypassing mongoose_acc API) and should return the execution result in the hook:result field. This is not enforced but should be followed by convention. Avoid passing superfluous arguments to handlers - e.g. an LServer in hook args is redundant since it is already present in the accumulator. Do not use run - it is still present in API but executes run_fold with ok as an initial accumulator anyway. Handlers have been rewritten so that they accept an acc as the first arg. Note that run is deprecated now and at some point will be removed. Most handlers have already been modified so that they accept an instance of mongoose_acc:t() as the first argument and return value by storing it inside it. How the accumulator is used within a module is up to the implementors of the module.","title":"Hooks"},{"location":"developers-guide/accumulators/#iqs-and-accumulators","text":"mongoose_iq module exposes a dedicated API for accessing IQ-related accumulator fields. These are: info(Acc) - Returns a #iq{} record produced from a stanza stored in the accumulator. May be invalid or not_iq if the stanza is not a valid IQ. xmlns(Acc) - Returns XMLNS of the first subelement inside an IQ. In most cases it is a namespace of <query/> subelement. May be undefined . command(Acc) - Returns the name of a first subelement inside an IQ. May be undefined . These functions ensure that cached information matches the accumulator's stanza, so all of them return a tuple with a possibly updated acc as a second element.","title":"IQs and accumulators"},{"location":"developers-guide/accumulators/#sample-usage-actual-and-potential","text":"","title":"Sample usage, actual and potential"},{"location":"developers-guide/accumulators/#privacy-check","text":"Stanzas are often checked against privacy lists. According to the current mongoose_privacy:privacy_check_packet implementation, the result is stored in an accumulator so if a check has to be repeated it is just one map read.","title":"Privacy check"},{"location":"developers-guide/accumulators/#tracing","text":"origin_stanza field is fully immutable for the lifespan of a single accumulator, so it's easier to correlate one of the stanzas sent by a client with some \"unexpected\" stanza routed from a completely different part of a server. There are many places in the server, where an accumulator may be created, so origin_location makes it much easier to find out what event has triggered the processing.","title":"Tracing"},{"location":"developers-guide/accumulators/#performance-measurement","text":"Given that each accumulator has a timestamp denoting its creation time, it is now very easy to implement a metric showing the stanza processing time, or even multiple metrics splitting it into stages.","title":"Performance measurement"},{"location":"developers-guide/flat_options/","text":"Flat options format 'FLAT' means that the value was separated into more options. For example, module options are separated into a list of module_opt -s. Each flat option key starts with an option type: l - local options h - local host options g - global options Flat options example {[l,listen],'FLAT'}. {[l,listener,{5280,{0,0,0,0},tcp},ejabberd_cowboy],'FLAT'}. {[l,listener_opt,{5280,{0,0,0,0},tcp},ejabberd_cowboy,num_acceptors],10}. {[l,listener_opt,{5280,{0,0,0,0},tcp},ejabberd_cowboy,transport_options], [{max_connections,1024}]}. {[l,listener_opt,{5280,{0,0,0,0},tcp},ejabberd_cowboy,modules], [{\"_\",\"/http-bind\",mod_bosh}, {\"_\",\"/ws-xmpp\",mod_websockets, [{ejabberd_service,[{access,all}, {shaper_rule,fast}, {ip,{127,0,0,1}}, {password,\"secret\"}]}]}]}. {[l,listener,{5285,{0,0,0,0},tcp},ejabberd_cowboy],'FLAT'}. {[l,listener_opt,{5285,{0,0,0,0},tcp},ejabberd_cowboy,num_acceptors],10}. {[l,listener_opt,{5285,{0,0,0,0},tcp},ejabberd_cowboy,transport_options], [{max_connections,1024}]}. {[l,listener_opt,{5285,{0,0,0,0},tcp},ejabberd_cowboy,ssl], [{certfile,\"priv/ssl/fake_cert.pem\"}, {keyfile,\"priv/ssl/fake_key.pem\"}, {password,[]}]}. {[l,listener_opt,{5285,{0,0,0,0},tcp},ejabberd_cowboy,modules], [{\"_\",\"/http-bind\",mod_bosh},{\"_\",\"/ws-xmpp\",mod_websockets,[]}]}. {[l,listener,{8088,{127,0,0,1},tcp},ejabberd_cowboy],'FLAT'}. {[l,listener_opt,{8088,{127,0,0,1},tcp},ejabberd_cowboy,num_acceptors],10}. {[l,listener_opt,{8088,{127,0,0,1},tcp},ejabberd_cowboy,transport_options], [{max_connections,1024}]}. {[l,listener_opt,{8088,{127,0,0,1},tcp},ejabberd_cowboy,modules], [{\"localhost\",\"/api\",mongoose_api_admin,[]}]}. {[l,listener,{8089,{0,0,0,0},tcp},ejabberd_cowboy],'FLAT'}. {[l,listener_opt,{8089,{0,0,0,0},tcp},ejabberd_cowboy,num_acceptors],10}. {[l,listener_opt,{8089,{0,0,0,0},tcp},ejabberd_cowboy,transport_options], [{max_connections,1024}]}. {[l,listener_opt,{8089,{0,0,0,0},tcp},ejabberd_cowboy,protocol_options], [{compress,true}]}. {[l,listener_opt,{8089,{0,0,0,0},tcp},ejabberd_cowboy,ssl], [{certfile,\"priv/ssl/fake_cert.pem\"}, {keyfile,\"priv/ssl/fake_key.pem\"}, {password,[]}]}. {[l,listener_opt,{8089,{0,0,0,0},tcp},ejabberd_cowboy,modules], [{\"_\",\"/api/sse\",lasse_handler,[mongoose_client_api_sse]}, {\"_\",\"/api/messages/[:with]\",mongoose_client_api_messages,[]}, {\"_\",\"/api/contacts/[:jid]\",mongoose_client_api_contacts,[]}, {\"_\",\"/api/rooms/[:id]\",mongoose_client_api_rooms,[]}, {\"_\",\"/api/rooms/:id/users/[:user]\",mongoose_client_api_rooms_users,[]}, {\"_\",\"/api/rooms/[:id]/messages\",mongoose_client_api_rooms_messages,[]}]}. {[l,listener,{5288,{127,0,0,1},tcp},ejabberd_cowboy],'FLAT'}. {[l,listener_opt,{5288,{127,0,0,1},tcp},ejabberd_cowboy,num_acceptors],10}. {[l,listener_opt,{5288,{127,0,0,1},tcp},ejabberd_cowboy,transport_options], [{max_connections,1024}]}. {[l,listener_opt,{5288,{127,0,0,1},tcp},ejabberd_cowboy,modules], [{\"localhost\",\"/api\",mongoose_api, [{handlers,[mongoose_api_metrics,mongoose_api_users]}]}]}. {[l,listener,{5222,{0,0,0,0},tcp},ejabberd_c2s],'FLAT'}. {[l,listener_opt,{5222,{0,0,0,0},tcp},ejabberd_c2s,certfile], \"priv/ssl/fake_server.pem\"}. {[l,listener_simple_opt,{5222,{0,0,0,0},tcp},ejabberd_c2s,starttls],simple}. {[l,listener_opt,{5222,{0,0,0,0},tcp},ejabberd_c2s,zlib],10000}. {[l,listener_opt,{5222,{0,0,0,0},tcp},ejabberd_c2s,access],c2s}. {[l,listener_opt,{5222,{0,0,0,0},tcp},ejabberd_c2s,shaper],c2s_shaper}. {[l,listener_opt,{5222,{0,0,0,0},tcp},ejabberd_c2s,max_stanza_size],65536}. {[l,listener_opt,{5222,{0,0,0,0},tcp},ejabberd_c2s,protocol_options], [\"no_sslv3\"]}. {[l,listener_opt,{5222,{0,0,0,0},tcp},ejabberd_c2s,dhfile], \"priv/ssl/fake_dh_server.pem\"}. {[l,listener,{5223,{0,0,0,0},tcp},ejabberd_c2s],'FLAT'}. {[l,listener_opt,{5223,{0,0,0,0},tcp},ejabberd_c2s,zlib],4096}. {[l,listener_opt,{5223,{0,0,0,0},tcp},ejabberd_c2s,access],c2s}. {[l,listener_opt,{5223,{0,0,0,0},tcp},ejabberd_c2s,shaper],c2s_shaper}. {[l,listener_opt,{5223,{0,0,0,0},tcp},ejabberd_c2s,max_stanza_size],65536}. {[l,listener,{5269,{0,0,0,0},tcp},ejabberd_s2s_in],'FLAT'}. {[l,listener_opt,{5269,{0,0,0,0},tcp},ejabberd_s2s_in,shaper],s2s_shaper}. {[l,listener_opt,{5269,{0,0,0,0},tcp},ejabberd_s2s_in,max_stanza_size],131072}. {[l,listener_opt,{5269,{0,0,0,0},tcp},ejabberd_s2s_in,protocol_options], [\"no_sslv3\"]}. {[l,listener_opt,{5269,{0,0,0,0},tcp},ejabberd_s2s_in,dhfile], \"priv/ssl/fake_dh_server.pem\"}. {[l,listener,{8888,{127,0,0,1},tcp},ejabberd_service],'FLAT'}. {[l,listener_opt,{8888,{127,0,0,1},tcp},ejabberd_service,access],all}. {[l,listener_opt,{8888,{127,0,0,1},tcp},ejabberd_service,shaper_rule],fast}. {[l,listener_opt,{8888,{127,0,0,1},tcp},ejabberd_service,password],\"secret\"}. {[l,listener,{8189,{127,0,0,1},tcp},ejabberd_service],'FLAT'}. {[l,listener_opt,{8189,{127,0,0,1},tcp},ejabberd_service,access],all}. {[l,listener_opt,{8189,{127,0,0,1},tcp},ejabberd_service,hidden_components], true}. {[l,listener_opt,{8189,{127,0,0,1},tcp},ejabberd_service,shaper_rule],fast}. {[l,listener_opt,{8189,{127,0,0,1},tcp},ejabberd_service,password],\"secret\"}. {[l,all_metrics_are_global],false}. {[l,s2s_certfile],\"priv/ssl/fake_server.pem\"}. {[l,node_start],{1530,15976,143119}}. {[l,rdbms_pools],[]}. {[l,registration_timeout],infinity}. {[l,outgoing_s2s_port],5299}. {[l,services], [{service_admin_extra,[{submods,[node,accounts,sessions,vcard,roster,last, private,stanza,stats]}]}]}. {[l,max_fsm_queue],1000}. {[l,s2s_use_starttls],optional}. {[h,<<\"anonymous.localhost\">>,auth_method],anonymous}. {[h,<<\"anonymous.localhost\">>,s2s_default_policy],allow}. {[h,<<\"localhost.bis\">>,modules],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_carboncopy],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_stream_management],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_muc_commands],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_amp],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_offline],'FLAT'}. {[h,<<\"localhost.bis\">>,module_opt,mod_offline,access_max_user_messages], max_user_offline_messages}. {[h,<<\"localhost.bis\">>,module,mod_last],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_roster],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_bosh],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_blocking],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_vcard],'FLAT'}. {[h,<<\"localhost.bis\">>,module_opt,mod_vcard,host],\"vjud.@HOST@\"}. {[h,<<\"localhost.bis\">>,module,mod_muc_light_commands],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_commands],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_disco],'FLAT'}. {[h,<<\"localhost.bis\">>,module_opt,mod_disco,users_can_see_hidden_services], false}. {[h,<<\"localhost.bis\">>,module,mod_privacy],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_private],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_sic],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_adhoc],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_register],'FLAT'}. {[h,<<\"localhost.bis\">>,module_opt,mod_register,welcome_message],{[]}}. {[h,<<\"localhost.bis\">>,module_opt,mod_register,ip_access],'FLAT'}. {[h,<<\"localhost.bis\">>,module_subopt,mod_register,ip_access,allow], \"127.0.0.0/8\"}. {[h,<<\"localhost.bis\">>,module_subopt,mod_register,ip_access,deny], \"0.0.0.0/0\"}. {[h,<<\"localhost.bis\">>,module_opt,mod_register,access],register}. {[h,<<\"localhost\">>,modules],'FLAT'}. {[h,<<\"localhost\">>,module,mod_carboncopy],'FLAT'}. {[h,<<\"localhost\">>,module,mod_stream_management],'FLAT'}. {[h,<<\"localhost\">>,module,mod_muc_commands],'FLAT'}. {[h,<<\"localhost\">>,module,mod_amp],'FLAT'}. {[h,<<\"localhost\">>,module,mod_offline],'FLAT'}. {[h,<<\"localhost\">>,module_opt,mod_offline,access_max_user_messages], max_user_offline_messages}. {[h,<<\"localhost\">>,module,mod_last],'FLAT'}. {[h,<<\"localhost\">>,module,mod_roster],'FLAT'}. {[h,<<\"localhost\">>,module,mod_bosh],'FLAT'}. {[h,<<\"localhost\">>,module,mod_blocking],'FLAT'}. {[h,<<\"localhost\">>,module,mod_vcard],'FLAT'}. {[h,<<\"localhost\">>,module_opt,mod_vcard,host],\"vjud.@HOST@\"}. {[h,<<\"localhost\">>,module,mod_muc_light_commands],'FLAT'}. {[h,<<\"localhost\">>,module,mod_commands],'FLAT'}. {[h,<<\"localhost\">>,module,mod_disco],'FLAT'}. {[h,<<\"localhost\">>,module_opt,mod_disco,users_can_see_hidden_services],false}. {[h,<<\"localhost\">>,module,mod_privacy],'FLAT'}. {[h,<<\"localhost\">>,module,mod_private],'FLAT'}. {[h,<<\"localhost\">>,module,mod_sic],'FLAT'}. {[h,<<\"localhost\">>,module,mod_adhoc],'FLAT'}. {[h,<<\"localhost\">>,module,mod_register],'FLAT'}. {[h,<<\"localhost\">>,module_opt,mod_register,welcome_message],{[]}}. {[h,<<\"localhost\">>,module_opt,mod_register,ip_access],'FLAT'}. {[h,<<\"localhost\">>,module_subopt,mod_register,ip_access,allow],\"127.0.0.0/8\"}. {[h,<<\"localhost\">>,module_subopt,mod_register,ip_access,deny],\"0.0.0.0/0\"}. {[h,<<\"localhost\">>,module_opt,mod_register,access],register}. {[h,<<\"localhost\">>,auth_method],internal}. {[h,<<\"anonymous.localhost\">>,auth_opts],[]}. {[h,<<\"fed1\">>,s2s_addr],{127,0,0,1}}. {[h,<<\"localhost.bis\">>,auth_opts],[]}. {[h,<<\"localhost\">>,auth_opts],[]}. {[h,<<\"anonymous.localhost\">>,modules],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module,mod_carboncopy],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module,mod_stream_management],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module,mod_muc_commands],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module,mod_amp],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module,mod_offline],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module_opt,mod_offline,access_max_user_messages], max_user_offline_messages}. {[h,<<\"anonymous.localhost\">>,module,mod_last],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module,mod_roster],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module,mod_bosh],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module,mod_blocking],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module,mod_vcard],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module_opt,mod_vcard,host],\"vjud.@HOST@\"}. {[h,<<\"anonymous.localhost\">>,module,mod_muc_light_commands],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module,mod_commands],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module,mod_disco],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module_opt,mod_disco, users_can_see_hidden_services], false}. {[h,<<\"anonymous.localhost\">>,module,mod_privacy],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module,mod_private],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module,mod_sic],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module,mod_adhoc],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module,mod_register],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module_opt,mod_register,welcome_message],{[]}}. {[h,<<\"anonymous.localhost\">>,module_opt,mod_register,ip_access],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module_subopt,mod_register,ip_access,allow], \"127.0.0.0/8\"}. {[h,<<\"anonymous.localhost\">>,module_subopt,mod_register,ip_access,deny], \"0.0.0.0/0\"}. {[h,<<\"anonymous.localhost\">>,module_opt,mod_register,access],register}. {[h,<<\"anonymous.localhost\">>,allow_multiple_connections],true}. {[h,<<\"localhost.bis\">>,auth_method],internal}. {[h,<<\"localhost.bis\">>,s2s_default_policy],allow}. {[h,<<\"localhost\">>,s2s_default_policy],allow}. {[h,<<\"anonymous.localhost\">>,anonymous_protocol],both}.","title":"Flat options format"},{"location":"developers-guide/flat_options/#flat-options-format","text":"'FLAT' means that the value was separated into more options. For example, module options are separated into a list of module_opt -s. Each flat option key starts with an option type: l - local options h - local host options g - global options","title":"Flat options format"},{"location":"developers-guide/flat_options/#flat-options-example","text":"{[l,listen],'FLAT'}. {[l,listener,{5280,{0,0,0,0},tcp},ejabberd_cowboy],'FLAT'}. {[l,listener_opt,{5280,{0,0,0,0},tcp},ejabberd_cowboy,num_acceptors],10}. {[l,listener_opt,{5280,{0,0,0,0},tcp},ejabberd_cowboy,transport_options], [{max_connections,1024}]}. {[l,listener_opt,{5280,{0,0,0,0},tcp},ejabberd_cowboy,modules], [{\"_\",\"/http-bind\",mod_bosh}, {\"_\",\"/ws-xmpp\",mod_websockets, [{ejabberd_service,[{access,all}, {shaper_rule,fast}, {ip,{127,0,0,1}}, {password,\"secret\"}]}]}]}. {[l,listener,{5285,{0,0,0,0},tcp},ejabberd_cowboy],'FLAT'}. {[l,listener_opt,{5285,{0,0,0,0},tcp},ejabberd_cowboy,num_acceptors],10}. {[l,listener_opt,{5285,{0,0,0,0},tcp},ejabberd_cowboy,transport_options], [{max_connections,1024}]}. {[l,listener_opt,{5285,{0,0,0,0},tcp},ejabberd_cowboy,ssl], [{certfile,\"priv/ssl/fake_cert.pem\"}, {keyfile,\"priv/ssl/fake_key.pem\"}, {password,[]}]}. {[l,listener_opt,{5285,{0,0,0,0},tcp},ejabberd_cowboy,modules], [{\"_\",\"/http-bind\",mod_bosh},{\"_\",\"/ws-xmpp\",mod_websockets,[]}]}. {[l,listener,{8088,{127,0,0,1},tcp},ejabberd_cowboy],'FLAT'}. {[l,listener_opt,{8088,{127,0,0,1},tcp},ejabberd_cowboy,num_acceptors],10}. {[l,listener_opt,{8088,{127,0,0,1},tcp},ejabberd_cowboy,transport_options], [{max_connections,1024}]}. {[l,listener_opt,{8088,{127,0,0,1},tcp},ejabberd_cowboy,modules], [{\"localhost\",\"/api\",mongoose_api_admin,[]}]}. {[l,listener,{8089,{0,0,0,0},tcp},ejabberd_cowboy],'FLAT'}. {[l,listener_opt,{8089,{0,0,0,0},tcp},ejabberd_cowboy,num_acceptors],10}. {[l,listener_opt,{8089,{0,0,0,0},tcp},ejabberd_cowboy,transport_options], [{max_connections,1024}]}. {[l,listener_opt,{8089,{0,0,0,0},tcp},ejabberd_cowboy,protocol_options], [{compress,true}]}. {[l,listener_opt,{8089,{0,0,0,0},tcp},ejabberd_cowboy,ssl], [{certfile,\"priv/ssl/fake_cert.pem\"}, {keyfile,\"priv/ssl/fake_key.pem\"}, {password,[]}]}. {[l,listener_opt,{8089,{0,0,0,0},tcp},ejabberd_cowboy,modules], [{\"_\",\"/api/sse\",lasse_handler,[mongoose_client_api_sse]}, {\"_\",\"/api/messages/[:with]\",mongoose_client_api_messages,[]}, {\"_\",\"/api/contacts/[:jid]\",mongoose_client_api_contacts,[]}, {\"_\",\"/api/rooms/[:id]\",mongoose_client_api_rooms,[]}, {\"_\",\"/api/rooms/:id/users/[:user]\",mongoose_client_api_rooms_users,[]}, {\"_\",\"/api/rooms/[:id]/messages\",mongoose_client_api_rooms_messages,[]}]}. {[l,listener,{5288,{127,0,0,1},tcp},ejabberd_cowboy],'FLAT'}. {[l,listener_opt,{5288,{127,0,0,1},tcp},ejabberd_cowboy,num_acceptors],10}. {[l,listener_opt,{5288,{127,0,0,1},tcp},ejabberd_cowboy,transport_options], [{max_connections,1024}]}. {[l,listener_opt,{5288,{127,0,0,1},tcp},ejabberd_cowboy,modules], [{\"localhost\",\"/api\",mongoose_api, [{handlers,[mongoose_api_metrics,mongoose_api_users]}]}]}. {[l,listener,{5222,{0,0,0,0},tcp},ejabberd_c2s],'FLAT'}. {[l,listener_opt,{5222,{0,0,0,0},tcp},ejabberd_c2s,certfile], \"priv/ssl/fake_server.pem\"}. {[l,listener_simple_opt,{5222,{0,0,0,0},tcp},ejabberd_c2s,starttls],simple}. {[l,listener_opt,{5222,{0,0,0,0},tcp},ejabberd_c2s,zlib],10000}. {[l,listener_opt,{5222,{0,0,0,0},tcp},ejabberd_c2s,access],c2s}. {[l,listener_opt,{5222,{0,0,0,0},tcp},ejabberd_c2s,shaper],c2s_shaper}. {[l,listener_opt,{5222,{0,0,0,0},tcp},ejabberd_c2s,max_stanza_size],65536}. {[l,listener_opt,{5222,{0,0,0,0},tcp},ejabberd_c2s,protocol_options], [\"no_sslv3\"]}. {[l,listener_opt,{5222,{0,0,0,0},tcp},ejabberd_c2s,dhfile], \"priv/ssl/fake_dh_server.pem\"}. {[l,listener,{5223,{0,0,0,0},tcp},ejabberd_c2s],'FLAT'}. {[l,listener_opt,{5223,{0,0,0,0},tcp},ejabberd_c2s,zlib],4096}. {[l,listener_opt,{5223,{0,0,0,0},tcp},ejabberd_c2s,access],c2s}. {[l,listener_opt,{5223,{0,0,0,0},tcp},ejabberd_c2s,shaper],c2s_shaper}. {[l,listener_opt,{5223,{0,0,0,0},tcp},ejabberd_c2s,max_stanza_size],65536}. {[l,listener,{5269,{0,0,0,0},tcp},ejabberd_s2s_in],'FLAT'}. {[l,listener_opt,{5269,{0,0,0,0},tcp},ejabberd_s2s_in,shaper],s2s_shaper}. {[l,listener_opt,{5269,{0,0,0,0},tcp},ejabberd_s2s_in,max_stanza_size],131072}. {[l,listener_opt,{5269,{0,0,0,0},tcp},ejabberd_s2s_in,protocol_options], [\"no_sslv3\"]}. {[l,listener_opt,{5269,{0,0,0,0},tcp},ejabberd_s2s_in,dhfile], \"priv/ssl/fake_dh_server.pem\"}. {[l,listener,{8888,{127,0,0,1},tcp},ejabberd_service],'FLAT'}. {[l,listener_opt,{8888,{127,0,0,1},tcp},ejabberd_service,access],all}. {[l,listener_opt,{8888,{127,0,0,1},tcp},ejabberd_service,shaper_rule],fast}. {[l,listener_opt,{8888,{127,0,0,1},tcp},ejabberd_service,password],\"secret\"}. {[l,listener,{8189,{127,0,0,1},tcp},ejabberd_service],'FLAT'}. {[l,listener_opt,{8189,{127,0,0,1},tcp},ejabberd_service,access],all}. {[l,listener_opt,{8189,{127,0,0,1},tcp},ejabberd_service,hidden_components], true}. {[l,listener_opt,{8189,{127,0,0,1},tcp},ejabberd_service,shaper_rule],fast}. {[l,listener_opt,{8189,{127,0,0,1},tcp},ejabberd_service,password],\"secret\"}. {[l,all_metrics_are_global],false}. {[l,s2s_certfile],\"priv/ssl/fake_server.pem\"}. {[l,node_start],{1530,15976,143119}}. {[l,rdbms_pools],[]}. {[l,registration_timeout],infinity}. {[l,outgoing_s2s_port],5299}. {[l,services], [{service_admin_extra,[{submods,[node,accounts,sessions,vcard,roster,last, private,stanza,stats]}]}]}. {[l,max_fsm_queue],1000}. {[l,s2s_use_starttls],optional}. {[h,<<\"anonymous.localhost\">>,auth_method],anonymous}. {[h,<<\"anonymous.localhost\">>,s2s_default_policy],allow}. {[h,<<\"localhost.bis\">>,modules],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_carboncopy],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_stream_management],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_muc_commands],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_amp],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_offline],'FLAT'}. {[h,<<\"localhost.bis\">>,module_opt,mod_offline,access_max_user_messages], max_user_offline_messages}. {[h,<<\"localhost.bis\">>,module,mod_last],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_roster],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_bosh],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_blocking],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_vcard],'FLAT'}. {[h,<<\"localhost.bis\">>,module_opt,mod_vcard,host],\"vjud.@HOST@\"}. {[h,<<\"localhost.bis\">>,module,mod_muc_light_commands],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_commands],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_disco],'FLAT'}. {[h,<<\"localhost.bis\">>,module_opt,mod_disco,users_can_see_hidden_services], false}. {[h,<<\"localhost.bis\">>,module,mod_privacy],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_private],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_sic],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_adhoc],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_register],'FLAT'}. {[h,<<\"localhost.bis\">>,module_opt,mod_register,welcome_message],{[]}}. {[h,<<\"localhost.bis\">>,module_opt,mod_register,ip_access],'FLAT'}. {[h,<<\"localhost.bis\">>,module_subopt,mod_register,ip_access,allow], \"127.0.0.0/8\"}. {[h,<<\"localhost.bis\">>,module_subopt,mod_register,ip_access,deny], \"0.0.0.0/0\"}. {[h,<<\"localhost.bis\">>,module_opt,mod_register,access],register}. {[h,<<\"localhost\">>,modules],'FLAT'}. {[h,<<\"localhost\">>,module,mod_carboncopy],'FLAT'}. {[h,<<\"localhost\">>,module,mod_stream_management],'FLAT'}. {[h,<<\"localhost\">>,module,mod_muc_commands],'FLAT'}. {[h,<<\"localhost\">>,module,mod_amp],'FLAT'}. {[h,<<\"localhost\">>,module,mod_offline],'FLAT'}. {[h,<<\"localhost\">>,module_opt,mod_offline,access_max_user_messages], max_user_offline_messages}. {[h,<<\"localhost\">>,module,mod_last],'FLAT'}. {[h,<<\"localhost\">>,module,mod_roster],'FLAT'}. {[h,<<\"localhost\">>,module,mod_bosh],'FLAT'}. {[h,<<\"localhost\">>,module,mod_blocking],'FLAT'}. {[h,<<\"localhost\">>,module,mod_vcard],'FLAT'}. {[h,<<\"localhost\">>,module_opt,mod_vcard,host],\"vjud.@HOST@\"}. {[h,<<\"localhost\">>,module,mod_muc_light_commands],'FLAT'}. {[h,<<\"localhost\">>,module,mod_commands],'FLAT'}. {[h,<<\"localhost\">>,module,mod_disco],'FLAT'}. {[h,<<\"localhost\">>,module_opt,mod_disco,users_can_see_hidden_services],false}. {[h,<<\"localhost\">>,module,mod_privacy],'FLAT'}. {[h,<<\"localhost\">>,module,mod_private],'FLAT'}. {[h,<<\"localhost\">>,module,mod_sic],'FLAT'}. {[h,<<\"localhost\">>,module,mod_adhoc],'FLAT'}. {[h,<<\"localhost\">>,module,mod_register],'FLAT'}. {[h,<<\"localhost\">>,module_opt,mod_register,welcome_message],{[]}}. {[h,<<\"localhost\">>,module_opt,mod_register,ip_access],'FLAT'}. {[h,<<\"localhost\">>,module_subopt,mod_register,ip_access,allow],\"127.0.0.0/8\"}. {[h,<<\"localhost\">>,module_subopt,mod_register,ip_access,deny],\"0.0.0.0/0\"}. {[h,<<\"localhost\">>,module_opt,mod_register,access],register}. {[h,<<\"localhost\">>,auth_method],internal}. {[h,<<\"anonymous.localhost\">>,auth_opts],[]}. {[h,<<\"fed1\">>,s2s_addr],{127,0,0,1}}. {[h,<<\"localhost.bis\">>,auth_opts],[]}. {[h,<<\"localhost\">>,auth_opts],[]}. {[h,<<\"anonymous.localhost\">>,modules],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module,mod_carboncopy],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module,mod_stream_management],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module,mod_muc_commands],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module,mod_amp],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module,mod_offline],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module_opt,mod_offline,access_max_user_messages], max_user_offline_messages}. {[h,<<\"anonymous.localhost\">>,module,mod_last],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module,mod_roster],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module,mod_bosh],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module,mod_blocking],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module,mod_vcard],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module_opt,mod_vcard,host],\"vjud.@HOST@\"}. {[h,<<\"anonymous.localhost\">>,module,mod_muc_light_commands],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module,mod_commands],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module,mod_disco],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module_opt,mod_disco, users_can_see_hidden_services], false}. {[h,<<\"anonymous.localhost\">>,module,mod_privacy],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module,mod_private],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module,mod_sic],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module,mod_adhoc],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module,mod_register],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module_opt,mod_register,welcome_message],{[]}}. {[h,<<\"anonymous.localhost\">>,module_opt,mod_register,ip_access],'FLAT'}. {[h,<<\"anonymous.localhost\">>,module_subopt,mod_register,ip_access,allow], \"127.0.0.0/8\"}. {[h,<<\"anonymous.localhost\">>,module_subopt,mod_register,ip_access,deny], \"0.0.0.0/0\"}. {[h,<<\"anonymous.localhost\">>,module_opt,mod_register,access],register}. {[h,<<\"anonymous.localhost\">>,allow_multiple_connections],true}. {[h,<<\"localhost.bis\">>,auth_method],internal}. {[h,<<\"localhost.bis\">>,s2s_default_policy],allow}. {[h,<<\"localhost\">>,s2s_default_policy],allow}. {[h,<<\"anonymous.localhost\">>,anonymous_protocol],both}.","title":"Flat options example"},{"location":"developers-guide/hooks_description/","text":"Selected hooks description This is a brief documentation for a few selected hooks. Though hooks & handlers differ in what they are there to do, it is not necessary to describe them all, because the mechanism is general. The following is meant to give you the idea of how hooks work, what they are used for and the various purposes they can serve. user_send_packet ejabberd_hooks:run(user_send_packet, Server, [FromJID, ToJID, Stanza]) This hook is run in ejabberd_c2s after the user sends a packet. Some rudimentary verification of the stanza is done once it is received from the socket: if present, the from attribute of the stanza is checked against the identity of the user whose session the process in question serves; if the identity does not match the contents of the attribute, an error is returned, the recipient JID ( to attribute) format is verified. The hook is not run for stanzas which do not pass these basic validity checks. Neither are such stanzas further processed by the server. The hook is not run for stanzas in the jabber:iq:privacy or urn:xmpp:blocking namespaces. This hook won't be called for stanzas arriving from a user served by a federated server (i.e. on a server-to-server connection handled by ejabberd_s2s ) intended for a user served by the relevant ejabberd instance. It is handled by the following modules: mod_caps - detects and caches capability information sent with certain messages for later use mod_carboncopy - if the packet being sent is a message, it forwards it to all the user's resources which have carbon copying enabled mod_event_pusher - if configured, sends selected messages to an external service mod_mam - stores outgoing messages in an archive mod_ping - upon reception of every message from the client, this module (re)starts a timer; if nothing more is received from the client within 60 seconds, it sends an IQ ping, to which the client should reply - which starts another timer. user_receive_packet ejabberd_hooks:run(user_receive_packet, Server, [Jid, From, To, FixedPacket]) The hook is run just before a packet received by server is sent to the user. Prior to sending, the packet is verified against any relevant privacy lists (the mechanism is described in XEP-0016 ). The privacy list mechanism itself is not mandatory and requires mod_privacy to be configured; otherwise all stanzas are allowed to pass. This hook won't run for stanzas which are destined to users of a different XMPP domain served by a federated server, connection to which is handled by ejabberd_s2s . It is handled by the following modules: mod_caps - detects and caches capability information sent with certain messages for later use mod_carboncopy - if the received packet is a message, it forwards it to all the user's resources which have carbon copying enabled filter_packet ejabberd_hooks:run_fold(filter_packet, {OrigFrom, OrigTo, OrigPacket}, []) This hook is run by mongoose_router_global when the packet is being routed by ejaberd_router:route/3 . It is in fact the first call made within the routing procedure. If a function hooked in to filter_packet returns drop , the packet is not processed. The ejaberd_router:route/3 fun is the most general function used to route stanzas across the entire cluster and its calls are scattered all over ejabberd code. ejabberd_c2s calls it after it receives a packet from ejabberd_receiver (i.e. the socket) and multiple modules use it for sending replies and errors. As seen in the example, the handlers take no arguments. The accumulator is the packet which may or may not be filtered out (in case the handler chain returns drop ) or modified. Note that this hook is run with ejabberd_hooks:run_fold/3 , not the usual and already mentioned ejabberd_hooks:run_fold/4 . The ternary variant doesn't take the XMPP domain argument and hence it's not possible to register per-domain handlers for this hook. Keep that in mind when registering the handlers and appropriately use ejabberd_hooks:add/4 instead of ejabberd_hooks:add/5 . offline_message_hook ejabberd_hooks:run(offline_message_hook, Server, [From, To, Packet]) ejabberd_sm runs this hook once it determines that a routed stanza is a message and while it ordinarily could be delivered, no resource (i.e. device or desktop client application) of its recipient is available online for delivery. The hook is first handled by mod_offline , which should store that message in a persistent way until the recipient comes online and the message can be successfully delivered. The handler in mod_offline stores the message and returns stop , which terminates the call and no more hook handlers are called. If the mod_offline handler fails to store the message, we should notify the user that the message could not be stored. To this end, there is another handler registered, but with a greater sequence number, so that it is called after mod_offline . If mod_offline fails, ejabberd_sm:bounce_offline_message is called and the user gets their notification. remove_user ejabberd_hooks:run(remove_user, Server, [User, Server]) remove_user is run by ejabberd_auth - the authentication module - when a request is made to remove the user from the database of the server. This one is rather complex, since removing a user requires many cleanup operations: mod_last removes last activity information (xep 0012); mod_mam removes the user's message archive; mod_muc_light quits multi-user chat rooms; mod_offline deletes the user's offline messages; mod_privacy removes the user's privacy lists; mod_private removes the user's private xml data storage; mod_pubsub unsubscribes from publish/subsribe channels; and mod_roster removes the user's roster from database. node_cleanup ejabberd_hooks:run(node_cleanup, [Node]) node_cleanup is run by a mongooseim_cleaner process which subscribes to nodedown messages. Currently the hook is run inside a global transaction (via global:trans/4 ). The job of this hook is to remove all processes registered in Mnesia. MongooseIM uses Mnesia to store processes through which messages are then routed - like user sessions or server-to-server communication channels - or various handlers, e.g. IQ request handlers. Those must obviously be removed when a node goes down, and to do this the modules ejabberd_local , ejabberd_s2s , ejabberd_sm and mod_bosh register their handlers with this hook. Number of retries for this transaction is set to 1 which means that in some situations the hook may be run on more than one node in the cluster, especially when there is little garbage to clean after the dead node. Setting retries to 0 is not good decision as it was observed that in some setups it may abort the transaction on all nodes. session_opening_allowed_for_user ejabberd_hooks:run_fold(session_opening_allowed_for_user, Server, allow, [JID]). This hook is run after authenticating when user sends the IQ opening a session. Handler function are expected to return: allow if a given JID is allowed to open a new sessions (the default) deny if the JID is not allowed but other handlers should be run {stop, deny} if the JID is not allowed but other handlers should not be run In the default implementation the hook is not used, built-in user control methods are supported elsewhere. This is the perfect place to plug in custom security control. other hooks adhoc_local_items adhoc_sm_items amp_check_condition amp_check_packet amp_determine_strategy amp_error_action_triggered amp_notify_action_triggered amp_verify_support anonymous_purge_hook auth_failed c2s_broadcast_recipients c2s_filter_packet c2s_loop_debug c2s_preprocessing_hook c2s_presence_in c2s_stream_features c2s_unauthenticated_iq c2s_update_presence can_access_identity can_access_room caps_add caps_recognised caps_update check_bl_c2s disco_info disco_local_features disco_local_identity disco_local_items disco_sm_features disco_sm_identity disco_sm_items ejabberd_ctl_process empty failed_to_store_message filter_local_packet filter_packet filter_room_packet find_s2s_bridge forbidden_session_hook forget_room get_key host_config_update inbox_unread_count invitation_sent is_muc_room_owner join_room leave_room local_send_to_resource_hook mam_archive_id mam_archive_message mam_archive_size mam_drop_iq mam_drop_message mam_drop_messages mam_flush_messages mam_get_behaviour mam_get_prefs mam_lookup_messages mam_muc_archive_id mam_muc_archive_message mam_muc_archive_size mam_muc_drop_iq mam_muc_drop_message mam_muc_flush_messages mam_muc_get_behaviour mam_muc_get_prefs mam_muc_lookup_messages mam_muc_remove_archive mam_muc_set_prefs mam_remove_archive mam_set_prefs mod_global_distrib_known_recipient mod_global_distrib_unknown_recipient muc_room_pid offline_groupchat_message_hook offline_message_hook packet_to_component presence_probe_hook privacy_check_packet privacy_get_user_list privacy_iq_get privacy_iq_set privacy_updated_list pubsub_create_node pubsub_delete_node pubsub_publish_item push_notifications register_command register_subhost register_user remove_user resend_offline_messages_hook rest_user_send_packet room_packet room_send_packet roster_get roster_get_jid_info roster_get_subscription_lists roster_get_versioning_feature roster_groups roster_in_subscription roster_out_subscription roster_process_item roster_push roster_set s2s_allow_host s2s_connect_hook s2s_loop_debug s2s_receive_packet s2s_send_packet s2s_stream_features session_cleanup session_opening_allowed_for_user set_presence_hook set_vcard sm_broadcast sm_filter_offline_message sm_register_connection_hook sm_remove_connection_hook unregister_command unregister_subhost unset_presence_hook update_inbox_for_muc user_available_hook user_ping_timeout user_receive_packet user_send_packet user_sent_keep_alive vcard_set xmpp_bounce_message xmpp_send_element xmpp_stanza_dropped","title":"Hooks description"},{"location":"developers-guide/hooks_description/#selected-hooks-description","text":"This is a brief documentation for a few selected hooks. Though hooks & handlers differ in what they are there to do, it is not necessary to describe them all, because the mechanism is general. The following is meant to give you the idea of how hooks work, what they are used for and the various purposes they can serve.","title":"Selected hooks description"},{"location":"developers-guide/hooks_description/#user_send_packet","text":"ejabberd_hooks:run(user_send_packet, Server, [FromJID, ToJID, Stanza]) This hook is run in ejabberd_c2s after the user sends a packet. Some rudimentary verification of the stanza is done once it is received from the socket: if present, the from attribute of the stanza is checked against the identity of the user whose session the process in question serves; if the identity does not match the contents of the attribute, an error is returned, the recipient JID ( to attribute) format is verified. The hook is not run for stanzas which do not pass these basic validity checks. Neither are such stanzas further processed by the server. The hook is not run for stanzas in the jabber:iq:privacy or urn:xmpp:blocking namespaces. This hook won't be called for stanzas arriving from a user served by a federated server (i.e. on a server-to-server connection handled by ejabberd_s2s ) intended for a user served by the relevant ejabberd instance. It is handled by the following modules: mod_caps - detects and caches capability information sent with certain messages for later use mod_carboncopy - if the packet being sent is a message, it forwards it to all the user's resources which have carbon copying enabled mod_event_pusher - if configured, sends selected messages to an external service mod_mam - stores outgoing messages in an archive mod_ping - upon reception of every message from the client, this module (re)starts a timer; if nothing more is received from the client within 60 seconds, it sends an IQ ping, to which the client should reply - which starts another timer.","title":"user_send_packet"},{"location":"developers-guide/hooks_description/#user_receive_packet","text":"ejabberd_hooks:run(user_receive_packet, Server, [Jid, From, To, FixedPacket]) The hook is run just before a packet received by server is sent to the user. Prior to sending, the packet is verified against any relevant privacy lists (the mechanism is described in XEP-0016 ). The privacy list mechanism itself is not mandatory and requires mod_privacy to be configured; otherwise all stanzas are allowed to pass. This hook won't run for stanzas which are destined to users of a different XMPP domain served by a federated server, connection to which is handled by ejabberd_s2s . It is handled by the following modules: mod_caps - detects and caches capability information sent with certain messages for later use mod_carboncopy - if the received packet is a message, it forwards it to all the user's resources which have carbon copying enabled","title":"user_receive_packet"},{"location":"developers-guide/hooks_description/#filter_packet","text":"ejabberd_hooks:run_fold(filter_packet, {OrigFrom, OrigTo, OrigPacket}, []) This hook is run by mongoose_router_global when the packet is being routed by ejaberd_router:route/3 . It is in fact the first call made within the routing procedure. If a function hooked in to filter_packet returns drop , the packet is not processed. The ejaberd_router:route/3 fun is the most general function used to route stanzas across the entire cluster and its calls are scattered all over ejabberd code. ejabberd_c2s calls it after it receives a packet from ejabberd_receiver (i.e. the socket) and multiple modules use it for sending replies and errors. As seen in the example, the handlers take no arguments. The accumulator is the packet which may or may not be filtered out (in case the handler chain returns drop ) or modified. Note that this hook is run with ejabberd_hooks:run_fold/3 , not the usual and already mentioned ejabberd_hooks:run_fold/4 . The ternary variant doesn't take the XMPP domain argument and hence it's not possible to register per-domain handlers for this hook. Keep that in mind when registering the handlers and appropriately use ejabberd_hooks:add/4 instead of ejabberd_hooks:add/5 .","title":"filter_packet"},{"location":"developers-guide/hooks_description/#offline_message_hook","text":"ejabberd_hooks:run(offline_message_hook, Server, [From, To, Packet]) ejabberd_sm runs this hook once it determines that a routed stanza is a message and while it ordinarily could be delivered, no resource (i.e. device or desktop client application) of its recipient is available online for delivery. The hook is first handled by mod_offline , which should store that message in a persistent way until the recipient comes online and the message can be successfully delivered. The handler in mod_offline stores the message and returns stop , which terminates the call and no more hook handlers are called. If the mod_offline handler fails to store the message, we should notify the user that the message could not be stored. To this end, there is another handler registered, but with a greater sequence number, so that it is called after mod_offline . If mod_offline fails, ejabberd_sm:bounce_offline_message is called and the user gets their notification.","title":"offline_message_hook"},{"location":"developers-guide/hooks_description/#remove_user","text":"ejabberd_hooks:run(remove_user, Server, [User, Server]) remove_user is run by ejabberd_auth - the authentication module - when a request is made to remove the user from the database of the server. This one is rather complex, since removing a user requires many cleanup operations: mod_last removes last activity information (xep 0012); mod_mam removes the user's message archive; mod_muc_light quits multi-user chat rooms; mod_offline deletes the user's offline messages; mod_privacy removes the user's privacy lists; mod_private removes the user's private xml data storage; mod_pubsub unsubscribes from publish/subsribe channels; and mod_roster removes the user's roster from database.","title":"remove_user"},{"location":"developers-guide/hooks_description/#node_cleanup","text":"ejabberd_hooks:run(node_cleanup, [Node]) node_cleanup is run by a mongooseim_cleaner process which subscribes to nodedown messages. Currently the hook is run inside a global transaction (via global:trans/4 ). The job of this hook is to remove all processes registered in Mnesia. MongooseIM uses Mnesia to store processes through which messages are then routed - like user sessions or server-to-server communication channels - or various handlers, e.g. IQ request handlers. Those must obviously be removed when a node goes down, and to do this the modules ejabberd_local , ejabberd_s2s , ejabberd_sm and mod_bosh register their handlers with this hook. Number of retries for this transaction is set to 1 which means that in some situations the hook may be run on more than one node in the cluster, especially when there is little garbage to clean after the dead node. Setting retries to 0 is not good decision as it was observed that in some setups it may abort the transaction on all nodes.","title":"node_cleanup"},{"location":"developers-guide/hooks_description/#session_opening_allowed_for_user","text":"ejabberd_hooks:run_fold(session_opening_allowed_for_user, Server, allow, [JID]). This hook is run after authenticating when user sends the IQ opening a session. Handler function are expected to return: allow if a given JID is allowed to open a new sessions (the default) deny if the JID is not allowed but other handlers should be run {stop, deny} if the JID is not allowed but other handlers should not be run In the default implementation the hook is not used, built-in user control methods are supported elsewhere. This is the perfect place to plug in custom security control.","title":"session_opening_allowed_for_user"},{"location":"developers-guide/hooks_description/#other-hooks","text":"adhoc_local_items adhoc_sm_items amp_check_condition amp_check_packet amp_determine_strategy amp_error_action_triggered amp_notify_action_triggered amp_verify_support anonymous_purge_hook auth_failed c2s_broadcast_recipients c2s_filter_packet c2s_loop_debug c2s_preprocessing_hook c2s_presence_in c2s_stream_features c2s_unauthenticated_iq c2s_update_presence can_access_identity can_access_room caps_add caps_recognised caps_update check_bl_c2s disco_info disco_local_features disco_local_identity disco_local_items disco_sm_features disco_sm_identity disco_sm_items ejabberd_ctl_process empty failed_to_store_message filter_local_packet filter_packet filter_room_packet find_s2s_bridge forbidden_session_hook forget_room get_key host_config_update inbox_unread_count invitation_sent is_muc_room_owner join_room leave_room local_send_to_resource_hook mam_archive_id mam_archive_message mam_archive_size mam_drop_iq mam_drop_message mam_drop_messages mam_flush_messages mam_get_behaviour mam_get_prefs mam_lookup_messages mam_muc_archive_id mam_muc_archive_message mam_muc_archive_size mam_muc_drop_iq mam_muc_drop_message mam_muc_flush_messages mam_muc_get_behaviour mam_muc_get_prefs mam_muc_lookup_messages mam_muc_remove_archive mam_muc_set_prefs mam_remove_archive mam_set_prefs mod_global_distrib_known_recipient mod_global_distrib_unknown_recipient muc_room_pid offline_groupchat_message_hook offline_message_hook packet_to_component presence_probe_hook privacy_check_packet privacy_get_user_list privacy_iq_get privacy_iq_set privacy_updated_list pubsub_create_node pubsub_delete_node pubsub_publish_item push_notifications register_command register_subhost register_user remove_user resend_offline_messages_hook rest_user_send_packet room_packet room_send_packet roster_get roster_get_jid_info roster_get_subscription_lists roster_get_versioning_feature roster_groups roster_in_subscription roster_out_subscription roster_process_item roster_push roster_set s2s_allow_host s2s_connect_hook s2s_loop_debug s2s_receive_packet s2s_send_packet s2s_stream_features session_cleanup session_opening_allowed_for_user set_presence_hook set_vcard sm_broadcast sm_filter_offline_message sm_register_connection_hook sm_remove_connection_hook unregister_command unregister_subhost unset_presence_hook update_inbox_for_muc user_available_hook user_ping_timeout user_receive_packet user_send_packet user_sent_keep_alive vcard_set xmpp_bounce_message xmpp_send_element xmpp_stanza_dropped","title":"other hooks"},{"location":"developers-guide/logging/","text":"Logging To use logger in your module, include -include(\"mongoose_logger.hrl\"). or -include(\"mongoose.hrl\"). Logging macros There are several macroses: DEBUG(\"event=debug_event info=~1000p\", [Arg]), INFO_MSG(\"event=info_event info=~1000p\", [Arg]), ERROR_MSG(\"event=error_event reason=~1000p\", [Arg]), WARNING_MSG(\"event=warning_event reason=~1000p\", [Arg]), Use them to log on corresponding log level. Don't use ERROR_MSG for cases that are not errors. Logging levels A system operator can choose log level by setting loglevel in mongooseim.cfg . level 5 - debug level 4 - info level 3 - warning level 2 - error level 1 - critical level 0 - none While there is a macro to log on level 1, we rarely use it. If an user sets log level 5, than he would see all messages in logs. Levels 3 or 2 are usually used for production systems. Logging format We use modified logfmt format. This format is Splunk and ELK friendly. event=something_interesting field is required. reason=~1000p field is commonly used. ?ERROR_MSG(\"event=check_password_failed \" \"reason=~p user=~ts\", [Error, LUser]), try ... catch Class:Reason -> Stacktrace = erlang:get_stacktrace(), ?ERROR_MSG(\"event=check_password_failed \" \"reason=~p:~p user=~ts stacktrace=~1000p\", [Class, Reason, LUser, Stacktrace]), erlang:raise(Class, Reason, Stacktrace) end user=~ts is often used too. A common way to name an error event is event=function_name_failed . For example, event=remove_user_failed . Use the advice critically, it would not work well for any function. Counter example: handle_info(Info, State) -> ?ERROR_MSG(\"issue=unexpected_info_received info=~1000p\", [Info]), {noreply, State}. Log messages should not contain new lines. We usually use ~1000p to log long datastructures. Use whitespace as a field separator: %% Use ?ERROR_MSG(\"event=check_password_failed reason=~p\", [Reason]) %% Don't use ?ERROR_MSG(\"event=check_password_failed, reason=~p\", [Reason]) Filtering logs by module Setting loglevel to debug leads to a flood of messages in logs. To set different loglevel for just one module, call: ejabberd_loglevel:set(3). ejabberd_loglevel:set_custom(mod_mam, 5). This code sets loglevel error for all messages, except generated by mod_mam . All messages from mod_mam would be logged.","title":"Logging"},{"location":"developers-guide/logging/#logging","text":"To use logger in your module, include -include(\"mongoose_logger.hrl\"). or -include(\"mongoose.hrl\").","title":"Logging"},{"location":"developers-guide/logging/#logging-macros","text":"There are several macroses: DEBUG(\"event=debug_event info=~1000p\", [Arg]), INFO_MSG(\"event=info_event info=~1000p\", [Arg]), ERROR_MSG(\"event=error_event reason=~1000p\", [Arg]), WARNING_MSG(\"event=warning_event reason=~1000p\", [Arg]), Use them to log on corresponding log level. Don't use ERROR_MSG for cases that are not errors.","title":"Logging macros"},{"location":"developers-guide/logging/#logging-levels","text":"A system operator can choose log level by setting loglevel in mongooseim.cfg . level 5 - debug level 4 - info level 3 - warning level 2 - error level 1 - critical level 0 - none While there is a macro to log on level 1, we rarely use it. If an user sets log level 5, than he would see all messages in logs. Levels 3 or 2 are usually used for production systems.","title":"Logging levels"},{"location":"developers-guide/logging/#logging-format","text":"We use modified logfmt format. This format is Splunk and ELK friendly. event=something_interesting field is required. reason=~1000p field is commonly used. ?ERROR_MSG(\"event=check_password_failed \" \"reason=~p user=~ts\", [Error, LUser]), try ... catch Class:Reason -> Stacktrace = erlang:get_stacktrace(), ?ERROR_MSG(\"event=check_password_failed \" \"reason=~p:~p user=~ts stacktrace=~1000p\", [Class, Reason, LUser, Stacktrace]), erlang:raise(Class, Reason, Stacktrace) end user=~ts is often used too. A common way to name an error event is event=function_name_failed . For example, event=remove_user_failed . Use the advice critically, it would not work well for any function. Counter example: handle_info(Info, State) -> ?ERROR_MSG(\"issue=unexpected_info_received info=~1000p\", [Info]), {noreply, State}. Log messages should not contain new lines. We usually use ~1000p to log long datastructures. Use whitespace as a field separator: %% Use ?ERROR_MSG(\"event=check_password_failed reason=~p\", [Reason]) %% Don't use ?ERROR_MSG(\"event=check_password_failed, reason=~p\", [Reason])","title":"Logging format"},{"location":"developers-guide/logging/#filtering-logs-by-module","text":"Setting loglevel to debug leads to a flood of messages in logs. To set different loglevel for just one module, call: ejabberd_loglevel:set(3). ejabberd_loglevel:set_custom(mod_mam, 5). This code sets loglevel error for all messages, except generated by mod_mam . All messages from mod_mam would be logged.","title":"Filtering logs by module"},{"location":"developers-guide/message_routing/","text":"Route of a message through the system Let's examine the flow of a message sent from user A to user B, both of whom are served by the same domain. Note that hooks are called at various stages of routing - they perform many tasks, in fact, many MongooseIM functionalities are implemented through hooks & handlers. For a general introduction to hooks, see Hooks and Handlers ; to get a closer look at a core few, see hooks description . 1. Receiving the stanza User A's ejabberd_receiver receives the stanza and passes it to ejabberd_c2s . 2. Call to user_send_packet Upon some minimal validation of the stanza, a hook user_send_packet is called. This is handled by a couple of modules which subscribe to this hook. Those modules do various complementary tasks, like storing the message in an archive, sending carbon copies, etc. 3. Privacy lists and ejabberd_router:route/3 The stanza is checked against any privacy lists in use and, in the case of being allowed, it will be routed by ejabberd_router:route/3 . This also takes into account \"blocking commands\", which are part of the privacy system. 4. Chain of routing Further on, the behaviour is configurable: ejabberd_router:route/3 passes the stanza through a chain of routing modules and applies Mod:filter/3 and Mod:route/3 from each of them. Each of those modules has to implement xmpp_router behaviour. There are a few actions available to the module: it can drop or route the stanza, it can pass the stanza on unchanged or modify it and pass the result on. A set of routing modules can be set in configuration as routing_modules . The default behaviour is the following: mongoose_router_global : runs a global filter_packet hook mongoose_router_external_local : checks if there is an external component registered for the destination domain on the current node, possibly routes the stanza to it mongoose_router_external : checks if there is an external component registered for the destination domain on any node in the cluster, possibly routes the stanza to it mongoose_router_localdomain : checks if there is a local route registered for the destination domain (i.e. there is an entry in mnesia route table), possibly routes the stanza to it ejabberd_s2s : tries to find or establish a connection to another server and send the stanza there 5. Look up external_component and route An external component and a local route are obtained by looking up external_component and route mnesia tables, respectively. The items stored in the tables provide funs to call and MFs to apply: ```erlang (ejabberd@localhost)2> ets:tab2list(route). [{route,<<\"vjud.localhost\">>, {apply_fun,#Fun<ejabberd_router.2.123745223>}}, {route,<<\"muc.localhost\">>, {apply_fun,#Fun<mod_muc.2.63726579>}}, {route,<<\"localhost\">>,{apply,ejabberd_local,route}}] ``` Here we see that for a domain \"localhost\" ejabberd_local:route() is called. Routing the stanza there means calling mongoose_local_delivery:do_route/5 , which calls filter_local_packet hook and, if passed, runs the fun or applies the handler. In most cases, the handler is ejabberd_local:route/3 . 6. ejabberd_local to ejabberd_sm ejabberd_local routes the stanza to ejabberd_sm given it has at least a bare JID as the recipient. 7. ejabberd_sm ejabberd_sm determines the available resources of User B, takes into account their priorities and whether the message is addressed to a particular resource or a bare JID. It appropriately replicates (or not) the message and sends it to the recipient's ejabberd_c2s process(es). In case no resources are available for delivery (hence no ejabberd_c2s processes to pass the message to), offline_message_hook is run. 8. ejabberd_c2s ejabberd_c2s verifies the stanza against relevant privacy lists and sends it to the socket. user_receive_packet hook is run to notify the rest of the system about the stanza delivery to User B.","title":"Stanza routing"},{"location":"developers-guide/message_routing/#route-of-a-message-through-the-system","text":"Let's examine the flow of a message sent from user A to user B, both of whom are served by the same domain. Note that hooks are called at various stages of routing - they perform many tasks, in fact, many MongooseIM functionalities are implemented through hooks & handlers. For a general introduction to hooks, see Hooks and Handlers ; to get a closer look at a core few, see hooks description . 1. Receiving the stanza User A's ejabberd_receiver receives the stanza and passes it to ejabberd_c2s . 2. Call to user_send_packet Upon some minimal validation of the stanza, a hook user_send_packet is called. This is handled by a couple of modules which subscribe to this hook. Those modules do various complementary tasks, like storing the message in an archive, sending carbon copies, etc. 3. Privacy lists and ejabberd_router:route/3 The stanza is checked against any privacy lists in use and, in the case of being allowed, it will be routed by ejabberd_router:route/3 . This also takes into account \"blocking commands\", which are part of the privacy system. 4. Chain of routing Further on, the behaviour is configurable: ejabberd_router:route/3 passes the stanza through a chain of routing modules and applies Mod:filter/3 and Mod:route/3 from each of them. Each of those modules has to implement xmpp_router behaviour. There are a few actions available to the module: it can drop or route the stanza, it can pass the stanza on unchanged or modify it and pass the result on. A set of routing modules can be set in configuration as routing_modules . The default behaviour is the following: mongoose_router_global : runs a global filter_packet hook mongoose_router_external_local : checks if there is an external component registered for the destination domain on the current node, possibly routes the stanza to it mongoose_router_external : checks if there is an external component registered for the destination domain on any node in the cluster, possibly routes the stanza to it mongoose_router_localdomain : checks if there is a local route registered for the destination domain (i.e. there is an entry in mnesia route table), possibly routes the stanza to it ejabberd_s2s : tries to find or establish a connection to another server and send the stanza there 5. Look up external_component and route An external component and a local route are obtained by looking up external_component and route mnesia tables, respectively. The items stored in the tables provide funs to call and MFs to apply: ```erlang (ejabberd@localhost)2> ets:tab2list(route). [{route,<<\"vjud.localhost\">>, {apply_fun,#Fun<ejabberd_router.2.123745223>}}, {route,<<\"muc.localhost\">>, {apply_fun,#Fun<mod_muc.2.63726579>}}, {route,<<\"localhost\">>,{apply,ejabberd_local,route}}] ``` Here we see that for a domain \"localhost\" ejabberd_local:route() is called. Routing the stanza there means calling mongoose_local_delivery:do_route/5 , which calls filter_local_packet hook and, if passed, runs the fun or applies the handler. In most cases, the handler is ejabberd_local:route/3 . 6. ejabberd_local to ejabberd_sm ejabberd_local routes the stanza to ejabberd_sm given it has at least a bare JID as the recipient. 7. ejabberd_sm ejabberd_sm determines the available resources of User B, takes into account their priorities and whether the message is addressed to a particular resource or a bare JID. It appropriately replicates (or not) the message and sends it to the recipient's ejabberd_c2s process(es). In case no resources are available for delivery (hence no ejabberd_c2s processes to pass the message to), offline_message_hook is run. 8. ejabberd_c2s ejabberd_c2s verifies the stanza against relevant privacy lists and sends it to the socket. user_receive_packet hook is run to notify the rest of the system about the stanza delivery to User B.","title":"Route of a message through the system"},{"location":"developers-guide/mod_amp_developers_guide/","text":"The Developer's Guide to mod_amp This is a quick, introductory guide for developers wishing to extend mod_amp or plug into the message processing system. Source Files, Headers and Tests include/amp.hrl This header file contains the amp XML namespace and the types used by mod_amp: amp_rule() and amp_strategy() are the top-level points of interest. src/mod_amp.erl This module is responsible for plugging in all the other components. It's main driving function is filter_packet . After determining that a given message contains amp rules, the module proceeds by determining its strategy for the message and comparing it against the rules. The server may return an error at multiple points in its work-flow. This is signaled by calling the function send_error_and_drop/3 or send_errors_and_drop/2 . src/amp.erl This module is responsible for parsing rules from incoming elements and serializing server responses in the proper format. binaries_to_rule/3 can return either a proper amp_rule() , or an amp_invalid_rule() , which does not contain sensible values, but can be used by the server to create an appropriate error message. test/amp_SUITE.erl Tests for the API functions exported by amp.erl src/amp_strategy.erl This module is where the server-side hook for determining a default action for a given message is performed. Calls to ejabberd_sm are made here. src/amp_resolver.erl This module models the resolution of amp rules, given a certain strategy. Also, the function verify_rule_support is hard-coded here to return an unsupported- type error for unsupported rule actions and values. test/amp_resolver_SUITE.erl These tests verify that the amp_resolver:check_condition/4 hook works as intended, i.e: that the rules which would be triggered given a particular server-side strategy actually do get triggered, and that all others get rejected. test/amp_gen.erl This module contains PropEr generators for server-side strategies, as well as valid and invalid amp rules. Used in both test suites. Hooks for Other Modules If your module would like to have some say in the amp decision making process, please refer to the hooks: amp_determine_strategy and amp_check_condition . Remeber that the hook for check_condition is a fold on a boolean(), and should behave like a variadic or . I.e: once a rule is deemed to apply, other hooks SHOULD NOT revert this value to false. Cf. this code from amp_resolver : -spec check_condition(any(), amp_strategy(), amp_condition(), amp_value()) -> boolean(). check_condition(HookAcc, Strategy, Condition, Value) -> case HookAcc of true -> true; %% SOME OTHER HOOK HAS DECIDED THAT THIS RULE APPLIES %% _ -> resolve(Strategy, Condition, Value) %% PERFORM LOCAL CHECK %% end. Ideas for Further Development Easy Implement the 'alert' and 'drop' action types. Implement support for the 'stored' value for 'deliver' Medium Implement the security policy described in the third bullet point of XEP-0079, Section 9 (Security Considerations). This will require that amp_resolver:verify_support also take the {From, To, Packet} :: hook_data() parameter and check that From is permitted to know about To 's presence. If they are not, then the server should treat this as a not-acceptable amp request. Make support for various actions, conditions and values configurable. This will require implementing an intelligent mechanism for matching the user-supplied rules with what's configured server-side. Currently, server-side support is hard-coded in several places: Disco announcements are in mod_amp:amp_features/0 Rule support is in amp_resolver:verify_rule_support/1 Every other function that deals with rules can handle unsupported rules, but ignores their meaning and decides that these rules don't apply. Hard Implement support for the 'expire-at' condition.","title":"mod_amp development"},{"location":"developers-guide/mod_amp_developers_guide/#the-developers-guide-to-mod_amp","text":"This is a quick, introductory guide for developers wishing to extend mod_amp or plug into the message processing system.","title":"The Developer's Guide to mod_amp"},{"location":"developers-guide/mod_amp_developers_guide/#source-files-headers-and-tests","text":"include/amp.hrl This header file contains the amp XML namespace and the types used by mod_amp: amp_rule() and amp_strategy() are the top-level points of interest. src/mod_amp.erl This module is responsible for plugging in all the other components. It's main driving function is filter_packet . After determining that a given message contains amp rules, the module proceeds by determining its strategy for the message and comparing it against the rules. The server may return an error at multiple points in its work-flow. This is signaled by calling the function send_error_and_drop/3 or send_errors_and_drop/2 . src/amp.erl This module is responsible for parsing rules from incoming elements and serializing server responses in the proper format. binaries_to_rule/3 can return either a proper amp_rule() , or an amp_invalid_rule() , which does not contain sensible values, but can be used by the server to create an appropriate error message. test/amp_SUITE.erl Tests for the API functions exported by amp.erl src/amp_strategy.erl This module is where the server-side hook for determining a default action for a given message is performed. Calls to ejabberd_sm are made here. src/amp_resolver.erl This module models the resolution of amp rules, given a certain strategy. Also, the function verify_rule_support is hard-coded here to return an unsupported- type error for unsupported rule actions and values. test/amp_resolver_SUITE.erl These tests verify that the amp_resolver:check_condition/4 hook works as intended, i.e: that the rules which would be triggered given a particular server-side strategy actually do get triggered, and that all others get rejected. test/amp_gen.erl This module contains PropEr generators for server-side strategies, as well as valid and invalid amp rules. Used in both test suites.","title":"Source Files, Headers and Tests"},{"location":"developers-guide/mod_amp_developers_guide/#hooks-for-other-modules","text":"If your module would like to have some say in the amp decision making process, please refer to the hooks: amp_determine_strategy and amp_check_condition . Remeber that the hook for check_condition is a fold on a boolean(), and should behave like a variadic or . I.e: once a rule is deemed to apply, other hooks SHOULD NOT revert this value to false. Cf. this code from amp_resolver : -spec check_condition(any(), amp_strategy(), amp_condition(), amp_value()) -> boolean(). check_condition(HookAcc, Strategy, Condition, Value) -> case HookAcc of true -> true; %% SOME OTHER HOOK HAS DECIDED THAT THIS RULE APPLIES %% _ -> resolve(Strategy, Condition, Value) %% PERFORM LOCAL CHECK %% end.","title":"Hooks for Other Modules"},{"location":"developers-guide/mod_amp_developers_guide/#ideas-for-further-development","text":"","title":"Ideas for Further Development"},{"location":"developers-guide/mod_amp_developers_guide/#easy","text":"Implement the 'alert' and 'drop' action types. Implement support for the 'stored' value for 'deliver'","title":"Easy"},{"location":"developers-guide/mod_amp_developers_guide/#medium","text":"Implement the security policy described in the third bullet point of XEP-0079, Section 9 (Security Considerations). This will require that amp_resolver:verify_support also take the {From, To, Packet} :: hook_data() parameter and check that From is permitted to know about To 's presence. If they are not, then the server should treat this as a not-acceptable amp request. Make support for various actions, conditions and values configurable. This will require implementing an intelligent mechanism for matching the user-supplied rules with what's configured server-side. Currently, server-side support is hard-coded in several places: Disco announcements are in mod_amp:amp_features/0 Rule support is in amp_resolver:verify_rule_support/1 Every other function that deals with rules can handle unsupported rules, but ignores their meaning and decides that these rules don't apply.","title":"Medium"},{"location":"developers-guide/mod_amp_developers_guide/#hard","text":"Implement support for the 'expire-at' condition.","title":"Hard"},{"location":"developers-guide/mod_muc_light_developers_guide/","text":"The Developer's Guide to mod_muc_light This is an in-depth guide on mod_muc_light design decisions and implementation. Source, header and test suite files All source files can be found in src/ . mod_muc_light.erl Main module. It implements the gen_mod behaviour. It subscribes to some essential hooks and exports several functions, mostly callbacks. It handles integration with mod_disco , mod_privacy and mod_roster . All operations that take place outside the room (including the room creation) are implemented here. Last but not least - this module prevents service-unavailable errors being sent when an offline user receives a groupchat message. mod_muc_light_codec.erl A behaviour implemented by modules that translate the MUC Light internal data format to stanzas for clients and vice versa. Besides specifying callbacks, it implements generic error encoder function. mod_muc_light_codec_legacy.erl An implementation of XEP-0045 compatibility mode. Note, that while some parts of the legacy mode are implemented directly in mod_muc_light.erl , the stanza translation takes place here. It does not utilise the full potential of the MUC Light extension but allows using the standard MUC implementation in XMPP client libraries for prototyping or the transition phase. Not recommended for production systems (less efficient than modern codec and requires more round-trips). mod_muc_light_codec_modern.erl An implementation of a modern MUC Light protocol, described in the XEP. Supports all MUC Light features. mod_muc_light_commands.erl MUC Light-related commands. They are registered in the mongoose_commands module, so they are available via the REST API. mod_muc_light_db.erl A behaviour implemented by database backends for the MUC Light extension. mod_muc_light_db_mnesia.erl A Mnesia backend for this extension. Uses transactions for room metadata updates (configuration and affiliation list) and dirty reads whenever possible. mod_muc_light_db_rdbms.erl An SQL backend for mod_muc_light . create_room , destroy_room , remove_user , set_config , modify_aff_users execute at least one query in a single transaction. room_exists , get_user_rooms , get_user_rooms_count , get_config , get_blocking , set_blocking , get_aff_users execute only one query per function call. get_info executes 3 SELECT queries, not protected by a transaction. mod_muc_light_db_rdbms_sql.erl SQL queries for mod_muc_light_db_rdbms.erl . mod_muc_light_room.erl This module handles everything that occurs inside the room: access checks, metadata changes, message broadcasting etc. mod_muc_light_utils.erl Utilities shared by other MUC Light modules. It includes the room configuration processing and the affiliation logic. The header file can be found in include/ . mod_muc_light.hrl It contains definitions of MUC Light namespaces, default configuration options and several common data types and records. There are 2 test suites and one helper module in big_tests/tests . muc_light_SUITE.erl Main test suite, checks all the most important functionalities of the MUC Light extension. muc_light_legacy_SUITE.erl muc_light_SUITE.erl equivalent that uses XEP-0045 compatibility mode. muc_helper.erl Provides handy iterators over room participants. Used in MUC Light suites but in the future could be used in muc_SUITE as well. Hooks handled by this extension offline_groupchat_message_hook handled by mod_muc_light:prevent_service_unavailable/3 - Prevents the default behaviour of sending service-unavailable error to the room when a groupchat message is sent to an offline occupant. remove_user handled by mod_muc_light:remove_user/2 - Triggers DB cleanup of all data related to the removed user. Includes a broadcast of a notification about user removal from occupied rooms. disco_local_items handled by mod_muc_light:get_muc_service/5 - Adds a MUC service item to the Disco result. Uses either a MUC Light or a classic MUC namespace when the legacy mode is enabled. roster_get handled by mod_muc_light:add_rooms_to_roster/2 - Injects room items to the user's roster. privacy_iq_get , privacy_iq_set handled by mod_muc_light:process_iq_get/5 and mod_muc_light:process_iq_set/4 respectively - These callbacks handle blocking settings when legacy mode is enabled. is_muc_room_owner , muc_room_pid , can_access_room , can_access_identity used by mod_muc_light:is_room_owner/3 , mod_muc_light:muc_room_pid/2 , mod_muc_light:can_access_room/3 and mod_muc_light:can_access_identity/3 respectively - Callbacks that provide essential data for the mod_mam_muc extension. Hooks executed by this extension filter_room_packet by codecs - Allows mod_mam_muc to archive groupchat messages. room_send_packet by codecs forget_room by mod_muc_light_db_mnesia and mod_muc_light_room - It is a part of mod_mam_muc integration as well. A hook used for MAM cleanup upon room destruction. Advantages and drawbacks (compared to classic MUC) The new MUC implementation brings quite a few benefits to the table: It is fully distributed - Does not have SPOF, concurrent senders do not block each other, especially in large rooms. Message broadcasting is being done in sender c2s context. It does not use presences - Much less traffic and stable membership information, especially on mobile networks. It provides built-in blocking support - Instead of blocking traffic like Privacy Lists do, it handles blocklists internally, preventing the blocker from being added to or by blocked entities. Less round-trips - A room can be created and configured with an initial list of occupants with a single request. Versioning - Reduces traffic and allows clients to reliably and quickly detect that the room state has changed. Isolation - Processing errors are contained in a sender context, not affecting other room occupants. Fully customisable room configuration - Your users can store any meta room information you allow. Drawbacks are: Requires DB transactions to ensure Room state consistency. Fetches the occupant list from DB for every message that is broadcasted. Due to concurrent message broadcast, it is possible for occupants to receive messages in a different order (given the messages are broadcasted at the exactly same time). With stream resumption disabled or when resumption times out, user may miss a message in a following scenario: Message A archived Message B archived Message B delivered to the user User loses connection Resumption timeout User queries MAM for all messages after B and misses A Ideas for Further Development Easy Add more tests for negative cases Medium Add optional per-room processes to avoid the need of DB transactions and ensure message ordering (maybe \"hard\"?). Riak backend Redis backend Hard Room metadata cache (maybe \"medium\"?).","title":"mod_muc_light developers doc"},{"location":"developers-guide/mod_muc_light_developers_guide/#the-developers-guide-to-mod_muc_light","text":"This is an in-depth guide on mod_muc_light design decisions and implementation.","title":"The Developer's Guide to mod_muc_light"},{"location":"developers-guide/mod_muc_light_developers_guide/#source-header-and-test-suite-files","text":"All source files can be found in src/ . mod_muc_light.erl Main module. It implements the gen_mod behaviour. It subscribes to some essential hooks and exports several functions, mostly callbacks. It handles integration with mod_disco , mod_privacy and mod_roster . All operations that take place outside the room (including the room creation) are implemented here. Last but not least - this module prevents service-unavailable errors being sent when an offline user receives a groupchat message. mod_muc_light_codec.erl A behaviour implemented by modules that translate the MUC Light internal data format to stanzas for clients and vice versa. Besides specifying callbacks, it implements generic error encoder function. mod_muc_light_codec_legacy.erl An implementation of XEP-0045 compatibility mode. Note, that while some parts of the legacy mode are implemented directly in mod_muc_light.erl , the stanza translation takes place here. It does not utilise the full potential of the MUC Light extension but allows using the standard MUC implementation in XMPP client libraries for prototyping or the transition phase. Not recommended for production systems (less efficient than modern codec and requires more round-trips). mod_muc_light_codec_modern.erl An implementation of a modern MUC Light protocol, described in the XEP. Supports all MUC Light features. mod_muc_light_commands.erl MUC Light-related commands. They are registered in the mongoose_commands module, so they are available via the REST API. mod_muc_light_db.erl A behaviour implemented by database backends for the MUC Light extension. mod_muc_light_db_mnesia.erl A Mnesia backend for this extension. Uses transactions for room metadata updates (configuration and affiliation list) and dirty reads whenever possible. mod_muc_light_db_rdbms.erl An SQL backend for mod_muc_light . create_room , destroy_room , remove_user , set_config , modify_aff_users execute at least one query in a single transaction. room_exists , get_user_rooms , get_user_rooms_count , get_config , get_blocking , set_blocking , get_aff_users execute only one query per function call. get_info executes 3 SELECT queries, not protected by a transaction. mod_muc_light_db_rdbms_sql.erl SQL queries for mod_muc_light_db_rdbms.erl . mod_muc_light_room.erl This module handles everything that occurs inside the room: access checks, metadata changes, message broadcasting etc. mod_muc_light_utils.erl Utilities shared by other MUC Light modules. It includes the room configuration processing and the affiliation logic. The header file can be found in include/ . mod_muc_light.hrl It contains definitions of MUC Light namespaces, default configuration options and several common data types and records. There are 2 test suites and one helper module in big_tests/tests . muc_light_SUITE.erl Main test suite, checks all the most important functionalities of the MUC Light extension. muc_light_legacy_SUITE.erl muc_light_SUITE.erl equivalent that uses XEP-0045 compatibility mode. muc_helper.erl Provides handy iterators over room participants. Used in MUC Light suites but in the future could be used in muc_SUITE as well.","title":"Source, header and test suite files"},{"location":"developers-guide/mod_muc_light_developers_guide/#hooks-handled-by-this-extension","text":"offline_groupchat_message_hook handled by mod_muc_light:prevent_service_unavailable/3 - Prevents the default behaviour of sending service-unavailable error to the room when a groupchat message is sent to an offline occupant. remove_user handled by mod_muc_light:remove_user/2 - Triggers DB cleanup of all data related to the removed user. Includes a broadcast of a notification about user removal from occupied rooms. disco_local_items handled by mod_muc_light:get_muc_service/5 - Adds a MUC service item to the Disco result. Uses either a MUC Light or a classic MUC namespace when the legacy mode is enabled. roster_get handled by mod_muc_light:add_rooms_to_roster/2 - Injects room items to the user's roster. privacy_iq_get , privacy_iq_set handled by mod_muc_light:process_iq_get/5 and mod_muc_light:process_iq_set/4 respectively - These callbacks handle blocking settings when legacy mode is enabled. is_muc_room_owner , muc_room_pid , can_access_room , can_access_identity used by mod_muc_light:is_room_owner/3 , mod_muc_light:muc_room_pid/2 , mod_muc_light:can_access_room/3 and mod_muc_light:can_access_identity/3 respectively - Callbacks that provide essential data for the mod_mam_muc extension.","title":"Hooks handled by this extension"},{"location":"developers-guide/mod_muc_light_developers_guide/#hooks-executed-by-this-extension","text":"filter_room_packet by codecs - Allows mod_mam_muc to archive groupchat messages. room_send_packet by codecs forget_room by mod_muc_light_db_mnesia and mod_muc_light_room - It is a part of mod_mam_muc integration as well. A hook used for MAM cleanup upon room destruction.","title":"Hooks executed by this extension"},{"location":"developers-guide/mod_muc_light_developers_guide/#advantages-and-drawbacks-compared-to-classic-muc","text":"The new MUC implementation brings quite a few benefits to the table: It is fully distributed - Does not have SPOF, concurrent senders do not block each other, especially in large rooms. Message broadcasting is being done in sender c2s context. It does not use presences - Much less traffic and stable membership information, especially on mobile networks. It provides built-in blocking support - Instead of blocking traffic like Privacy Lists do, it handles blocklists internally, preventing the blocker from being added to or by blocked entities. Less round-trips - A room can be created and configured with an initial list of occupants with a single request. Versioning - Reduces traffic and allows clients to reliably and quickly detect that the room state has changed. Isolation - Processing errors are contained in a sender context, not affecting other room occupants. Fully customisable room configuration - Your users can store any meta room information you allow. Drawbacks are: Requires DB transactions to ensure Room state consistency. Fetches the occupant list from DB for every message that is broadcasted. Due to concurrent message broadcast, it is possible for occupants to receive messages in a different order (given the messages are broadcasted at the exactly same time). With stream resumption disabled or when resumption times out, user may miss a message in a following scenario: Message A archived Message B archived Message B delivered to the user User loses connection Resumption timeout User queries MAM for all messages after B and misses A","title":"Advantages and drawbacks (compared to classic MUC)"},{"location":"developers-guide/mod_muc_light_developers_guide/#ideas-for-further-development","text":"","title":"Ideas for Further Development"},{"location":"developers-guide/mod_muc_light_developers_guide/#easy","text":"Add more tests for negative cases","title":"Easy"},{"location":"developers-guide/mod_muc_light_developers_guide/#medium","text":"Add optional per-room processes to avoid the need of DB transactions and ensure message ordering (maybe \"hard\"?). Riak backend Redis backend","title":"Medium"},{"location":"developers-guide/mod_muc_light_developers_guide/#hard","text":"Room metadata cache (maybe \"medium\"?).","title":"Hard"},{"location":"developers-guide/mongoose_wpool/","text":"mongoose_wpool All the outgoing pools configured by the outgoing_pools option are hidden behind the mongoose_wpool API. Every pool is described by a tuple {Type, Host, Tag, PoolOptions, ConnectionOptions} (see outgoing pools for details about each element of the tuple). Supervision tree mongoose_wpool_sup supervisor for every type of the pool. Under it there can be many children of: mongoose_wpool_type_sup is started on-demand when a pool of given type is started. Many pools of the same type are supervised by the supervisor. Its children are: mongoose_wpool_mgr all the pools of the same type are managed by a manager. It's responsible for starting, stopping and restarting the pool. Restarting happens when the main worker_pool process for the pool is stopped unintentionally. This usually happens when there was too many restarts of worker processes. many worker_pool supervisors holding a specific pool are on the same level as the manager. The mongoose_wpool_mgr manages the pool by setting monitor for every started pool. Implementing new pool type To add a new pool type, create a mongoose_wpool_NEW_TYPE module implementing the mongoose_wpool behaviour. This means that for a new type xyz we need to create a mongoose_wpool_xyz module. Then we can use the xyz type to start the pool via outgoing_pools option or directly via the mongoose_wpool API.","title":"mongoose_wpool"},{"location":"developers-guide/mongoose_wpool/#mongoose_wpool","text":"All the outgoing pools configured by the outgoing_pools option are hidden behind the mongoose_wpool API. Every pool is described by a tuple {Type, Host, Tag, PoolOptions, ConnectionOptions} (see outgoing pools for details about each element of the tuple).","title":"mongoose_wpool"},{"location":"developers-guide/mongoose_wpool/#supervision-tree","text":"mongoose_wpool_sup supervisor for every type of the pool. Under it there can be many children of: mongoose_wpool_type_sup is started on-demand when a pool of given type is started. Many pools of the same type are supervised by the supervisor. Its children are: mongoose_wpool_mgr all the pools of the same type are managed by a manager. It's responsible for starting, stopping and restarting the pool. Restarting happens when the main worker_pool process for the pool is stopped unintentionally. This usually happens when there was too many restarts of worker processes. many worker_pool supervisors holding a specific pool are on the same level as the manager. The mongoose_wpool_mgr manages the pool by setting monitor for every started pool.","title":"Supervision tree"},{"location":"developers-guide/mongoose_wpool/#implementing-new-pool-type","text":"To add a new pool type, create a mongoose_wpool_NEW_TYPE module implementing the mongoose_wpool behaviour. This means that for a new type xyz we need to create a mongoose_wpool_xyz module. Then we can use the xyz type to start the pool via outgoing_pools option or directly via the mongoose_wpool API.","title":"Implementing new pool type"},{"location":"developers-guide/xep_tool/","text":"XEP-tool usage The XEP-tool is the answer for developers who wonder how to maintain an actual list of supported XEPs. It's a fast and easy way to automatically produce documentation from raw, beam files. This is a quick guide on how to enjoy the usage of the XEP-tool. Sign your module file first The architecture of MongooseIM determines that almost every XEP or feature implementation resides in its own file. It is not strictly enforced but usually the file is named with a mod_ prefix. For example mod_privacy file implements XEP-0016: Privacy Lists . Mandatory xep and version In order to let the XEP-tool know about your module, we add a special attribute xep at the begining of the mod_privacy module: -xep([{xep, 16}, {version, \"1.6\"}]). Now we know that this module implements to XEP-0016: Privacy Lists with version 1.6. It gives the tool enough information to generate a URL to the XEP homepage. There are also some variations of the xep attribute like: You ought to remember to specify xep and version attributes every time. You can also put several xep attributes in one module. For example mod_mam_muc implements attributes of XEP-0313: Message Archive Management and also XEP-0045: Multi-User Chat . Just list them one after another: -xep([{xep, 45}, {version, \"1.25\"}]). -xep([{xep, 313}, {version, \"0.5.1\"}]). Specific URL -xep([{xep, 16}, {version, \"1.6\"}, {url, \"http://xmpp.org/extensions/xep-0016.html\"}]). Comment -xep([{xep, 16}, {version, \"1.6\"}, {comment, \"Example comment: Partial Implemented\"}]). And the XEP-tool will do the work! Compile and run You've just finished marking your modules. The only thing left is to make compile MongooseIM in order to generate the .beam files. To run the XEP tool, you must issue an additional subcommand. There are two choices: markdown : to produce a markdown list of supported XEPs. This option also needs an output file as an argument. list : to print out supported XEPs to the console. For example, to run our XEP-tool with a markdown command, type: make xeplist Or do it manually: $MONGOOSEIM_ROOT/tools/xep_tool/xep_tool.escript markdown <PATH_TO_EBIN> <OPTIONAL_OUTPUT_FILE> In our case, from MongooseIM root directory: ./tools/xep_tool/xep_tool.escript markdown ebin list.md The Markdown list with unique XEP names and URLs is saved to file list.md You can copy-paste the content of this file to your main README file. Generated file example XEP-0012: Last Activity XEP-0016: Privacy Lists XEP-0018: Invisible Presence XEP-0022: Message Events XEP-0023: Message Expiration XEP-0030: Service Discovery XEP-0045: Multi-User Chat XEP-0049: Private XML Storage XEP-0050: Ad-Hoc Commands XEP-0054: vcard-temp XEP-0055: Jabber Search XEP-0059: Result Set Management XEP-0068: Field Standardization for Data Forms XEP-0077: In-Band Registration XEP-0078: Non-SASL Authentication XEP-0079: Advanced Message Processing XEP-0082: XMPP Date and Time Profiles XEP-0083: Nested Roster Groups XEP-0085: Chat State Notifications XEP-0086: Error Condition Mappings XEP-0093: Roster Item Exchange XEP-0114: Jabber Component Protocol XEP-0124: Bidirectional-streams Over Synchronous HTTP (BOSH) XEP-0126: Invisibility XEP-0138: Stream Compression XEP-0157: Contact Addresses for XMPP Services XEP-0160: Best Practices for Handling Offline Messages XEP-0170: Recommended Order of Stream Feature Negotiation XEP-0175: Best Practices for Use of SASL ANONYMOUS XEP-0198: Stream Management XEP-0199: XMPP Ping XEP-0202: Entity Time XEP-0206: XMPP Over BOSH XEP-0212: XMPP Basic Server 2008 XEP-0237: Roster Versioning XEP-0279: Server IP Check XEP-0280: Message Carbons XEP-0313: Message Archive Management","title":"xep-tool usage"},{"location":"developers-guide/xep_tool/#xep-tool-usage","text":"The XEP-tool is the answer for developers who wonder how to maintain an actual list of supported XEPs. It's a fast and easy way to automatically produce documentation from raw, beam files. This is a quick guide on how to enjoy the usage of the XEP-tool.","title":"XEP-tool usage"},{"location":"developers-guide/xep_tool/#sign-your-module-file-first","text":"The architecture of MongooseIM determines that almost every XEP or feature implementation resides in its own file. It is not strictly enforced but usually the file is named with a mod_ prefix. For example mod_privacy file implements XEP-0016: Privacy Lists .","title":"Sign your module file first"},{"location":"developers-guide/xep_tool/#mandatory-xep-and-version","text":"In order to let the XEP-tool know about your module, we add a special attribute xep at the begining of the mod_privacy module: -xep([{xep, 16}, {version, \"1.6\"}]). Now we know that this module implements to XEP-0016: Privacy Lists with version 1.6. It gives the tool enough information to generate a URL to the XEP homepage. There are also some variations of the xep attribute like: You ought to remember to specify xep and version attributes every time. You can also put several xep attributes in one module. For example mod_mam_muc implements attributes of XEP-0313: Message Archive Management and also XEP-0045: Multi-User Chat . Just list them one after another: -xep([{xep, 45}, {version, \"1.25\"}]). -xep([{xep, 313}, {version, \"0.5.1\"}]).","title":"Mandatory xep and version"},{"location":"developers-guide/xep_tool/#specific-url","text":"-xep([{xep, 16}, {version, \"1.6\"}, {url, \"http://xmpp.org/extensions/xep-0016.html\"}]).","title":"Specific URL"},{"location":"developers-guide/xep_tool/#comment","text":"-xep([{xep, 16}, {version, \"1.6\"}, {comment, \"Example comment: Partial Implemented\"}]). And the XEP-tool will do the work!","title":"Comment"},{"location":"developers-guide/xep_tool/#compile-and-run","text":"You've just finished marking your modules. The only thing left is to make compile MongooseIM in order to generate the .beam files. To run the XEP tool, you must issue an additional subcommand. There are two choices: markdown : to produce a markdown list of supported XEPs. This option also needs an output file as an argument. list : to print out supported XEPs to the console. For example, to run our XEP-tool with a markdown command, type: make xeplist Or do it manually: $MONGOOSEIM_ROOT/tools/xep_tool/xep_tool.escript markdown <PATH_TO_EBIN> <OPTIONAL_OUTPUT_FILE> In our case, from MongooseIM root directory: ./tools/xep_tool/xep_tool.escript markdown ebin list.md The Markdown list with unique XEP names and URLs is saved to file list.md You can copy-paste the content of this file to your main README file.","title":"Compile and run"},{"location":"developers-guide/xep_tool/#generated-file-example","text":"XEP-0012: Last Activity XEP-0016: Privacy Lists XEP-0018: Invisible Presence XEP-0022: Message Events XEP-0023: Message Expiration XEP-0030: Service Discovery XEP-0045: Multi-User Chat XEP-0049: Private XML Storage XEP-0050: Ad-Hoc Commands XEP-0054: vcard-temp XEP-0055: Jabber Search XEP-0059: Result Set Management XEP-0068: Field Standardization for Data Forms XEP-0077: In-Band Registration XEP-0078: Non-SASL Authentication XEP-0079: Advanced Message Processing XEP-0082: XMPP Date and Time Profiles XEP-0083: Nested Roster Groups XEP-0085: Chat State Notifications XEP-0086: Error Condition Mappings XEP-0093: Roster Item Exchange XEP-0114: Jabber Component Protocol XEP-0124: Bidirectional-streams Over Synchronous HTTP (BOSH) XEP-0126: Invisibility XEP-0138: Stream Compression XEP-0157: Contact Addresses for XMPP Services XEP-0160: Best Practices for Handling Offline Messages XEP-0170: Recommended Order of Stream Feature Negotiation XEP-0175: Best Practices for Use of SASL ANONYMOUS XEP-0198: Stream Management XEP-0199: XMPP Ping XEP-0202: Entity Time XEP-0206: XMPP Over BOSH XEP-0212: XMPP Basic Server 2008 XEP-0237: Roster Versioning XEP-0279: Server IP Check XEP-0280: Message Carbons XEP-0313: Message Archive Management","title":"Generated file example"},{"location":"migrations/3.1.1_3.2.0/","text":"odbc renamed to rdbms in module names and options For MongooseIM users: simply replace all instances of odbc in your config files with rdbms . E.g. {auth_method, odbc}. would now be {auth_method, rdbms}. . It's also important to note that all metrics that previously contained odbc in their names have also been renamed to contain rdbms instead. Please note that odbc_server has been completely replaced with new outgoing_pools (see one of the next sections of this document) config element. For developers calling MongooseIM modules: most modules, functions and atoms had odbc in their names replaced with rdbms . The only exceptions to this rule were names actually pertaining to the ODBC driver, e.g. mongoose_rdbms_odbc . ejabberd.cfg renamed to mongooseim.cfg Rename the existing config file of MongooseIM from ejabberd.cfg to mongooseim.cfg . Pools configuration Configuring pools to external services has changed, please see Outgoing Connection doc for more details. NOTE: Keep in mind that outgoing_pools is a list of pools, it may turn out that you will have more than one entry in the list when more than a single outgoing pool is needed. Example - Old format {elasticsearch_server, [{host, \"elastic.host.com\"}, {port, 9042}]}. {riak_server, [{pool_size, 20}, {address, \"127.0.0.1\"}, {port, 8087}, {riak_pb_socket_opts, []}]}. {http_connections, [{conn1, [{server, \"http://server:8080\"}, {pool_size, 50}]} ]}. {cassandra_servers, [ {default, 100, [ {servers, [ {\"cassandra_server1.example.com\", 9042}, {\"cassandra_server2.example.com\", 9042}, {\"cassandra_server3.example.com\", 9042}, {\"cassandra_server4.example.com\", 9042} ] }, {keyspace, \"big_mongooseim\"} ] } ] }. Example - New format This section provides direct \"translation\" of configuration from \"Old format\" section. {outgoing_pools, [ {elastic, global, default, [], [{host, \"elastic.host.com\"}, {port, 9042}]}, {riak, global, default, [{workers, 20}], [{address, \"127.0.0.1\"}, {port, 8087}]}, {http, global, conn1, [{workers, 50}], [{server, \"http://server:8080\"}]}, {cassandra, global, default, [{workers, 100}], [ {servers, [ {\"cassandra_server1.example.com\", 9042}, {\"cassandra_server2.example.com\", 9042}, {\"cassandra_server3.example.com\", 9042}, {\"cassandra_server4.example.com\", 9042} ]}, {keyspace, \"big_mongooseim\"} ]} ]}. RDBMS configuration migration RDBMS pools are no longer configured by a {pool, odbc, _} tuple, instead using the generic outgoing pools mechanism. The connection configuration is now passed via server option of the pool insted of being configured via a top-level {odbc_server, _} tuple. Similarly, the number of workers is no longer configured by odbc_pool_size , and the default pool no longer set by odbc_pool . A top-level odbc_keepalive_interval is now also specified as an option for a specific pool. For example: {odbc_pool_size, 10}. {pool, odbc, default}. {odbc_server_type, mssql}. {odbc_server, \"DSN=mongoose-mssql;UID=sa;PWD=mongooseim_secret+ESL123\"}. {odbc_keepalive_interval, 10}. will now become: {rdbms_server_type, mssql}. {outgoing_pools, [ {rdbms, global, default, [{workers, 10}], [{server, \"DSN=mongoose-mssql;UID=sa;PWD=mongooseim_secret+ESL123\"}, {keepalive_interval, 10}]} ]}. Note that odbc_server_type was only renamed to rdbms_server_type and still remains a top-level configuration value. sm_backend If you had the sm_backend set to redis like below: {sm_backend, {redis, [{pool_size, 3}, {worker_config, [{host, \"localhost\"}, {port, 6379}]}]}}. The pool needs to be defined inside outgoing_pools like this: {outgoing_pools, [ {redis, global, default, [{workers, 3}], [{host, \"localhost\"}, {port, 6379}]} ]}. and the sm_backend configuration needs to changed to just: {sm_backend, {redis, []}}. mod_global_distrib If you had mod_global_distrib configured in the following way: {mod_global_distrib, [ (...) {redis, [ {pool_size, 24}, {server, \"172.16.0.3\"} ]} ]} The redis pool needs to be defined inside outgoing_pools : {outgoing_pools, [ {redis, global, global_distrib, [{workers, 24}], [{host, \"172.16.0.3\"}]} ]}.","title":"3.1.1 to 3.2.0"},{"location":"migrations/3.1.1_3.2.0/#odbc-renamed-to-rdbms-in-module-names-and-options","text":"For MongooseIM users: simply replace all instances of odbc in your config files with rdbms . E.g. {auth_method, odbc}. would now be {auth_method, rdbms}. . It's also important to note that all metrics that previously contained odbc in their names have also been renamed to contain rdbms instead. Please note that odbc_server has been completely replaced with new outgoing_pools (see one of the next sections of this document) config element. For developers calling MongooseIM modules: most modules, functions and atoms had odbc in their names replaced with rdbms . The only exceptions to this rule were names actually pertaining to the ODBC driver, e.g. mongoose_rdbms_odbc .","title":"odbc renamed to rdbms in module names and options"},{"location":"migrations/3.1.1_3.2.0/#ejabberdcfg-renamed-to-mongooseimcfg","text":"Rename the existing config file of MongooseIM from ejabberd.cfg to mongooseim.cfg .","title":"ejabberd.cfg renamed to mongooseim.cfg"},{"location":"migrations/3.1.1_3.2.0/#pools-configuration","text":"Configuring pools to external services has changed, please see Outgoing Connection doc for more details. NOTE: Keep in mind that outgoing_pools is a list of pools, it may turn out that you will have more than one entry in the list when more than a single outgoing pool is needed.","title":"Pools configuration"},{"location":"migrations/3.1.1_3.2.0/#example-old-format","text":"{elasticsearch_server, [{host, \"elastic.host.com\"}, {port, 9042}]}. {riak_server, [{pool_size, 20}, {address, \"127.0.0.1\"}, {port, 8087}, {riak_pb_socket_opts, []}]}. {http_connections, [{conn1, [{server, \"http://server:8080\"}, {pool_size, 50}]} ]}. {cassandra_servers, [ {default, 100, [ {servers, [ {\"cassandra_server1.example.com\", 9042}, {\"cassandra_server2.example.com\", 9042}, {\"cassandra_server3.example.com\", 9042}, {\"cassandra_server4.example.com\", 9042} ] }, {keyspace, \"big_mongooseim\"} ] } ] }.","title":"Example - Old format"},{"location":"migrations/3.1.1_3.2.0/#example-new-format","text":"This section provides direct \"translation\" of configuration from \"Old format\" section. {outgoing_pools, [ {elastic, global, default, [], [{host, \"elastic.host.com\"}, {port, 9042}]}, {riak, global, default, [{workers, 20}], [{address, \"127.0.0.1\"}, {port, 8087}]}, {http, global, conn1, [{workers, 50}], [{server, \"http://server:8080\"}]}, {cassandra, global, default, [{workers, 100}], [ {servers, [ {\"cassandra_server1.example.com\", 9042}, {\"cassandra_server2.example.com\", 9042}, {\"cassandra_server3.example.com\", 9042}, {\"cassandra_server4.example.com\", 9042} ]}, {keyspace, \"big_mongooseim\"} ]} ]}.","title":"Example - New format"},{"location":"migrations/3.1.1_3.2.0/#rdbms-configuration-migration","text":"RDBMS pools are no longer configured by a {pool, odbc, _} tuple, instead using the generic outgoing pools mechanism. The connection configuration is now passed via server option of the pool insted of being configured via a top-level {odbc_server, _} tuple. Similarly, the number of workers is no longer configured by odbc_pool_size , and the default pool no longer set by odbc_pool . A top-level odbc_keepalive_interval is now also specified as an option for a specific pool. For example: {odbc_pool_size, 10}. {pool, odbc, default}. {odbc_server_type, mssql}. {odbc_server, \"DSN=mongoose-mssql;UID=sa;PWD=mongooseim_secret+ESL123\"}. {odbc_keepalive_interval, 10}. will now become: {rdbms_server_type, mssql}. {outgoing_pools, [ {rdbms, global, default, [{workers, 10}], [{server, \"DSN=mongoose-mssql;UID=sa;PWD=mongooseim_secret+ESL123\"}, {keepalive_interval, 10}]} ]}. Note that odbc_server_type was only renamed to rdbms_server_type and still remains a top-level configuration value.","title":"RDBMS configuration migration"},{"location":"migrations/3.1.1_3.2.0/#sm_backend","text":"If you had the sm_backend set to redis like below: {sm_backend, {redis, [{pool_size, 3}, {worker_config, [{host, \"localhost\"}, {port, 6379}]}]}}. The pool needs to be defined inside outgoing_pools like this: {outgoing_pools, [ {redis, global, default, [{workers, 3}], [{host, \"localhost\"}, {port, 6379}]} ]}. and the sm_backend configuration needs to changed to just: {sm_backend, {redis, []}}.","title":"sm_backend"},{"location":"migrations/3.1.1_3.2.0/#mod_global_distrib","text":"If you had mod_global_distrib configured in the following way: {mod_global_distrib, [ (...) {redis, [ {pool_size, 24}, {server, \"172.16.0.3\"} ]} ]} The redis pool needs to be defined inside outgoing_pools : {outgoing_pools, [ {redis, global, global_distrib, [{workers, 24}], [{host, \"172.16.0.3\"}]} ]}.","title":"mod_global_distrib"},{"location":"migrations/3.3.0_3.4.0/","text":"New field in Message Archive Management MUC entries: Sender ID As a part of ensuring GDPR compliance, it is essential to be able to efficiently query MAM MUC data via sender ID (to retrieve user's personal data). Originally, the sender JID could be found only as a part of an encoded XML message element, so finding all items sent by a certain user would be extremely inefficient (or rather: anti-efficient). MongooseIM 3.4.0 uses a modified schema for MAM MUC backends which enables a more efficient extraction. Below you may find migration instructions specific to your MAM backend. RDBMS Step 1 Please execute the following SQL statements on your MIM database: MySQL ALTER TABLE mam_muc_message ADD COLUMN sender_id INT UNSIGNED; CREATE INDEX i_mam_muc_message_sender_id USING BTREE ON mam_muc_message(sender_id); PostgreSQL ALTER TABLE mam_muc_message ADD COLUMN sender_id INT; CREATE INDEX i_mam_muc_message_sender_id ON mam_muc_message USING BTREE (sender_id); MSSQL ALTER TABLE [dbo].[mam_muc_message] ADD sender_id bigint; CREATE INDEX i_mam_muc_message_sender_id ON mam_muc_message(sender_id); Step 2 Now you have a schema that is compatible with MIM 3.4.0 but isn't GDPR-compliant yet because the new column has no meaningful data. Please pick your favourite scripting/programming language and populate the new column with the help of a dedicated script . You'll need to iterate over the whole mam_muc_message table with the following algorithm: Provide message column content to the script. The script returns sender's JID as username@server string. You need to split it to get a separate username and server. Select ID from mam_server_user by the username and server. If it doesn't exist, insert a new one ( id column is automatically incremented). Update the sender_id column in mam_muc_message with the retrieved ID. Cassandra Step 1 Please execute the following CQL statements on your MIM database: USE mongooseim; ALTER TABLE mam_muc_message ADD from_jid varchar; CREATE INDEX ON mam_muc_message (from_jid); DESC mam_muc_message; Step 2 Now you have a schema that is compatible with MIM 3.4.0 but isn't GDPR-compliant yet because the new column has no meaningful data. Please pick your favourite scripting/programming language and populate the new column with the help of a dedicated script . You'll need to iterate over the whole mam_muc_message table with the following algorithm: Extract the whole mam_muc_message table. Please make sure to use the paging feature of your Cassandra client, as the MAM tables tend to be very large. SELECT * FROM mam_muc_message; To make data extraction faster, MongooseIM stores 2 copies of the message in the table: cqlsh:mongooseim> SELECT * FROM mam_muc_message WHERE id = 399582233150625537 ALLOW FILTERING; room_jid | with_nick | id | from_jid | message | nick_name -------------------------------+-----------+--------------------+----------+--------------------------------+----------- room-ad1d999b9e@muc.localhost | | 399582233150625537 | null | 0x8350000001...998de2fa8426837 | Sid room-ad1d999b9e@muc.localhost | Sid | 399582233150625537 | null | 0x8350000001...998de2fa8426837 | Sid The copy with an empty with_nick column must be updated. Extract the sender's JID from the message column in the same way as described in the RDBMS migration section. By default cassandra backend uses the eterm format. Update the from_jid column with the value of the extracted sender's JID : cqlsh:mongooseim> UPDATE mam_muc_message SET from_jid = 'username@server' WHERE id = 399582233150625537 AND with_nick = '' AND room_jid = 'room-ad1d999b9e@muc.localhost'; cqlsh:mongooseim> SELECT * FROM mam_muc_message WHERE id = 399582233150625537 ALLOW FILTERING; room_jid | with_nick | id | from_jid | message | nick_name -------------------------------+-----------+--------------------+-----------------+--------------------------------+----------- room-ad1d999b9e@muc.localhost | | 399582233150625537 | username@server | 0x8350000001...998de2fa8426837 | Sid room-ad1d999b9e@muc.localhost | Sid | 399582233150625537 | null | 0x8350000001...998de2fa8426837 | Sid Riak Changes to Riak schema are backward compatible with the current MongooseIM release. This means that skipping the migration will cause only some of the new features (namely GDPR data retrival) to not work correctly. Step 1 Please update the Riak schema: # Set the RIAK_HOST to your Riak HTTP endpoint # Set the RIAK_MAM_SCHEMA_PATH to point to new schema path, which # by default is: RIAK_MAM_SCHEMA_PATH=tools/mam_search_schema.xml curl -v -XPUT $RIAK_HOST/search/schema/mam \\ -H 'Content-Type:application/xml' \\ --data-binary @${RIAK_MAM_SCHEMA_PATH} After that we need to either reload all Riak nodes (restart them) or manually reload the schema on live nodes. Reloading the schema on live nodes requires access to Erlang Shell of one of the Riak nodes (any of them). The instruction on how to get to Riak's Erlang shell is beyond this guide, but if you manage to get to it, just call: yz_index:reload(<<\"mam\">>). Step 2 After the schema is posted and reloaded, all \"new\" objects will be indexed properly as long they contain 2 new fields: msg_owner_jid and mam_type . The new MongooseIM code will insert both of them for all new MAM entires, but for all existing ones need to have the fields added. In order to do that, we need to create a migration script (just pick your favourite scripting/programming language) that will do the following for each object in each bucket of type mam_yz (the object will be referred as obj ): Use this dedicated script to convert the obj.packet_register field value into a so called $SENDER_JID . If the script returns $SENDER_JID correctly: set obj.mam_type = 'muc' set obj.msg_owner_jid = $SENDER_JID If the script returns error code -2 set obj.mam_type = 'pm' based on obj_yz_rk formatted as $LOCAL_JID/$REMOTE_JID/$MSG_ID , set obj.msg_owner_jid = $LOCAL_JID Save the modified obj ElasticSearch Step 1 Please update the mapping for muc_messages : PUT muc_messages/_mapping/muc { \"properties\": { \"mam_id\": { \"type\": \"long\" }, \"room\": { \"type\": \"keyword\" }, \"from_jid\" : { \"type\": \"keyword\" }, \"source_jid\": { \"type\": \"keyword\" }, \"message\": { \"type\": \"text\", \"index\": false }, \"body\": { \"type\": \"text\", \"analyzer\": \"english\" } } } Step 2 Now you have a schema that is compatible with MIM 3.4.0 but isn't GDPR-compliant yet because the new field has no meaningful data. Please pick your favourite scripting/programming language and populate the new column with the help of a dedicated script . You'll need to iterate over the all muc_messages documents with the following algorithm: Extract some documents (notice the size parameter) for conversion: GET muc_messages/_search/?size=100&q=!_exists_:from_jid Extract the sender's JID from the message field in the same way as described in the RDBMS migration section. Elasticsearch backend uses exclusively the xml format. Update the from_jid column with the value of the extracted sender's JID : POST localhost:9200/muc_messages/muc/%_id%/_update { \"doc\": { \"from_jid\" : \"%sender's jid%\" } } Repeat all the actions until the full conversion of the database is done.","title":"3.3.0 to 3.4.0"},{"location":"migrations/3.3.0_3.4.0/#new-field-in-message-archive-management-muc-entries-sender-id","text":"As a part of ensuring GDPR compliance, it is essential to be able to efficiently query MAM MUC data via sender ID (to retrieve user's personal data). Originally, the sender JID could be found only as a part of an encoded XML message element, so finding all items sent by a certain user would be extremely inefficient (or rather: anti-efficient). MongooseIM 3.4.0 uses a modified schema for MAM MUC backends which enables a more efficient extraction. Below you may find migration instructions specific to your MAM backend.","title":"New field in Message Archive Management MUC entries: Sender ID"},{"location":"migrations/3.3.0_3.4.0/#rdbms","text":"","title":"RDBMS"},{"location":"migrations/3.3.0_3.4.0/#step-1","text":"Please execute the following SQL statements on your MIM database: MySQL ALTER TABLE mam_muc_message ADD COLUMN sender_id INT UNSIGNED; CREATE INDEX i_mam_muc_message_sender_id USING BTREE ON mam_muc_message(sender_id); PostgreSQL ALTER TABLE mam_muc_message ADD COLUMN sender_id INT; CREATE INDEX i_mam_muc_message_sender_id ON mam_muc_message USING BTREE (sender_id); MSSQL ALTER TABLE [dbo].[mam_muc_message] ADD sender_id bigint; CREATE INDEX i_mam_muc_message_sender_id ON mam_muc_message(sender_id);","title":"Step 1"},{"location":"migrations/3.3.0_3.4.0/#step-2","text":"Now you have a schema that is compatible with MIM 3.4.0 but isn't GDPR-compliant yet because the new column has no meaningful data. Please pick your favourite scripting/programming language and populate the new column with the help of a dedicated script . You'll need to iterate over the whole mam_muc_message table with the following algorithm: Provide message column content to the script. The script returns sender's JID as username@server string. You need to split it to get a separate username and server. Select ID from mam_server_user by the username and server. If it doesn't exist, insert a new one ( id column is automatically incremented). Update the sender_id column in mam_muc_message with the retrieved ID.","title":"Step 2"},{"location":"migrations/3.3.0_3.4.0/#cassandra","text":"","title":"Cassandra"},{"location":"migrations/3.3.0_3.4.0/#step-1_1","text":"Please execute the following CQL statements on your MIM database: USE mongooseim; ALTER TABLE mam_muc_message ADD from_jid varchar; CREATE INDEX ON mam_muc_message (from_jid); DESC mam_muc_message;","title":"Step 1"},{"location":"migrations/3.3.0_3.4.0/#step-2_1","text":"Now you have a schema that is compatible with MIM 3.4.0 but isn't GDPR-compliant yet because the new column has no meaningful data. Please pick your favourite scripting/programming language and populate the new column with the help of a dedicated script . You'll need to iterate over the whole mam_muc_message table with the following algorithm: Extract the whole mam_muc_message table. Please make sure to use the paging feature of your Cassandra client, as the MAM tables tend to be very large. SELECT * FROM mam_muc_message; To make data extraction faster, MongooseIM stores 2 copies of the message in the table: cqlsh:mongooseim> SELECT * FROM mam_muc_message WHERE id = 399582233150625537 ALLOW FILTERING; room_jid | with_nick | id | from_jid | message | nick_name -------------------------------+-----------+--------------------+----------+--------------------------------+----------- room-ad1d999b9e@muc.localhost | | 399582233150625537 | null | 0x8350000001...998de2fa8426837 | Sid room-ad1d999b9e@muc.localhost | Sid | 399582233150625537 | null | 0x8350000001...998de2fa8426837 | Sid The copy with an empty with_nick column must be updated. Extract the sender's JID from the message column in the same way as described in the RDBMS migration section. By default cassandra backend uses the eterm format. Update the from_jid column with the value of the extracted sender's JID : cqlsh:mongooseim> UPDATE mam_muc_message SET from_jid = 'username@server' WHERE id = 399582233150625537 AND with_nick = '' AND room_jid = 'room-ad1d999b9e@muc.localhost'; cqlsh:mongooseim> SELECT * FROM mam_muc_message WHERE id = 399582233150625537 ALLOW FILTERING; room_jid | with_nick | id | from_jid | message | nick_name -------------------------------+-----------+--------------------+-----------------+--------------------------------+----------- room-ad1d999b9e@muc.localhost | | 399582233150625537 | username@server | 0x8350000001...998de2fa8426837 | Sid room-ad1d999b9e@muc.localhost | Sid | 399582233150625537 | null | 0x8350000001...998de2fa8426837 | Sid","title":"Step 2"},{"location":"migrations/3.3.0_3.4.0/#riak","text":"Changes to Riak schema are backward compatible with the current MongooseIM release. This means that skipping the migration will cause only some of the new features (namely GDPR data retrival) to not work correctly.","title":"Riak"},{"location":"migrations/3.3.0_3.4.0/#step-1_2","text":"Please update the Riak schema: # Set the RIAK_HOST to your Riak HTTP endpoint # Set the RIAK_MAM_SCHEMA_PATH to point to new schema path, which # by default is: RIAK_MAM_SCHEMA_PATH=tools/mam_search_schema.xml curl -v -XPUT $RIAK_HOST/search/schema/mam \\ -H 'Content-Type:application/xml' \\ --data-binary @${RIAK_MAM_SCHEMA_PATH} After that we need to either reload all Riak nodes (restart them) or manually reload the schema on live nodes. Reloading the schema on live nodes requires access to Erlang Shell of one of the Riak nodes (any of them). The instruction on how to get to Riak's Erlang shell is beyond this guide, but if you manage to get to it, just call: yz_index:reload(<<\"mam\">>).","title":"Step 1"},{"location":"migrations/3.3.0_3.4.0/#step-2_2","text":"After the schema is posted and reloaded, all \"new\" objects will be indexed properly as long they contain 2 new fields: msg_owner_jid and mam_type . The new MongooseIM code will insert both of them for all new MAM entires, but for all existing ones need to have the fields added. In order to do that, we need to create a migration script (just pick your favourite scripting/programming language) that will do the following for each object in each bucket of type mam_yz (the object will be referred as obj ): Use this dedicated script to convert the obj.packet_register field value into a so called $SENDER_JID . If the script returns $SENDER_JID correctly: set obj.mam_type = 'muc' set obj.msg_owner_jid = $SENDER_JID If the script returns error code -2 set obj.mam_type = 'pm' based on obj_yz_rk formatted as $LOCAL_JID/$REMOTE_JID/$MSG_ID , set obj.msg_owner_jid = $LOCAL_JID Save the modified obj","title":"Step 2"},{"location":"migrations/3.3.0_3.4.0/#elasticsearch","text":"","title":"ElasticSearch"},{"location":"migrations/3.3.0_3.4.0/#step-1_3","text":"Please update the mapping for muc_messages : PUT muc_messages/_mapping/muc { \"properties\": { \"mam_id\": { \"type\": \"long\" }, \"room\": { \"type\": \"keyword\" }, \"from_jid\" : { \"type\": \"keyword\" }, \"source_jid\": { \"type\": \"keyword\" }, \"message\": { \"type\": \"text\", \"index\": false }, \"body\": { \"type\": \"text\", \"analyzer\": \"english\" } } }","title":"Step 1"},{"location":"migrations/3.3.0_3.4.0/#step-2_3","text":"Now you have a schema that is compatible with MIM 3.4.0 but isn't GDPR-compliant yet because the new field has no meaningful data. Please pick your favourite scripting/programming language and populate the new column with the help of a dedicated script . You'll need to iterate over the all muc_messages documents with the following algorithm: Extract some documents (notice the size parameter) for conversion: GET muc_messages/_search/?size=100&q=!_exists_:from_jid Extract the sender's JID from the message field in the same way as described in the RDBMS migration section. Elasticsearch backend uses exclusively the xml format. Update the from_jid column with the value of the extracted sender's JID : POST localhost:9200/muc_messages/muc/%_id%/_update { \"doc\": { \"from_jid\" : \"%sender's jid%\" } } Repeat all the actions until the full conversion of the database is done.","title":"Step 2"},{"location":"migrations/jid-from-mam-muc-script/","text":"The purpose of sender-jid-from-mam-message.escript This script may be used as a part of migration from MongooseIM 3.3.0 (or older). It is able to extract a JID of a groupchat message sender from an XML payload. This piece of information is essential for GDPR commands (retrieve data and remove user) to work properly, as without it the operations on MAM MUC data in DB would be extremely inefficient. Please consult \"3.3.0 to...\" migration guide for details. DB-specific sections describe where the payloads are stored and what you should do with the extracted JID. Requirements This script may be executed in every *nix environment which has OTP 19.0 (or newer) installed and escript executable is in PATH . It doesn't depend on any MongooseIM code or library, so it may be used as a standalone file. How to use? sender-jid-from-mam-message.escript (eterm | xml) The only parameter required by the script is the input format. You should use eterm if (in MongooseIM config file): You haven't set db_message_format option for MAM at all. db_message_format is set to mam_message_compressed_eterm or mam_message_eterm You should use the xml option if: db_message_format is set to mam_message_xml . Once started, the script will run in an infinite loop (until killed or interrupted), expecting a stream of inputs. For every provided payload, a JID will be returned immediately. All communication with the script is done via stdio . Input format For both eterm and xml mode, the script expects an input in a very similar format. The high-level overview is: LENGTH\\nPAYLOAD LENGTH is the PAYLOAD length in bytes; if the data retrieved from a DBMS is a Unicode string, LENGTH is equal to the number of bytes used to encode this string PAYLOAD is a sequence of bytes; if a DBMS returns binary data encoded as hex, then it has to be decoded to raw bytes LENGTH and PAYLOAD are separated with a newline character (ASCII code 10 / 0x0a) Output format The script output format is very similar to the input: LENGTH\\nJID LENGTH is the number of bytes in a JID JID is a sequence of bytes, which encodes a Unicode string LENGTH and PAYLOAD are separated with a newline character (ASCII code 10 / 0x0a) In case of an error (that is not a critical error, like I/O failure), script will print -N\\n (where N is an error code) and will continue to work. Technically it's -N for LENGTH , followed by a newline character and no PAYLOAD part (or 0-length PAYLOAD if you like). The following error codes are supported: * -1\\n - Unknown error. Something went wrong with the JID extraction (most likely malformed input). * -2\\n - Invalid message type. The message / stanza has been decoded successfully, but it's not a groupchat message. Examples tools/migration folder contains two files: sender-jid-from-mam-message.example.eterm and sender-jid-from-mam-message.example.xml . They are input samples for the script and may be used as a reference for the script usage. You can test them by running: tools/migration/sender-jid-from-mam-message.escript eterm < sender-jid-from-mam-message.example.eterm > out tools/migration/sender-jid-from-mam-message.escript xml < sender-jid-from-mam-message.example.xml > out In both cases the out file should have the following content: 37 g\u017ceg\u017c\u00f3\u0142ka@brz\u0119czyszczykiewicz.pl Debug If an environment variable DEBUG is set to 1 , the script will store error messages in a /tmp/script-debug file.","title":"MAM MUC migration helper"},{"location":"migrations/jid-from-mam-muc-script/#the-purpose-of-sender-jid-from-mam-messageescript","text":"This script may be used as a part of migration from MongooseIM 3.3.0 (or older). It is able to extract a JID of a groupchat message sender from an XML payload. This piece of information is essential for GDPR commands (retrieve data and remove user) to work properly, as without it the operations on MAM MUC data in DB would be extremely inefficient. Please consult \"3.3.0 to...\" migration guide for details. DB-specific sections describe where the payloads are stored and what you should do with the extracted JID.","title":"The purpose of sender-jid-from-mam-message.escript"},{"location":"migrations/jid-from-mam-muc-script/#requirements","text":"This script may be executed in every *nix environment which has OTP 19.0 (or newer) installed and escript executable is in PATH . It doesn't depend on any MongooseIM code or library, so it may be used as a standalone file.","title":"Requirements"},{"location":"migrations/jid-from-mam-muc-script/#how-to-use","text":"sender-jid-from-mam-message.escript (eterm | xml) The only parameter required by the script is the input format. You should use eterm if (in MongooseIM config file): You haven't set db_message_format option for MAM at all. db_message_format is set to mam_message_compressed_eterm or mam_message_eterm You should use the xml option if: db_message_format is set to mam_message_xml . Once started, the script will run in an infinite loop (until killed or interrupted), expecting a stream of inputs. For every provided payload, a JID will be returned immediately. All communication with the script is done via stdio .","title":"How to use?"},{"location":"migrations/jid-from-mam-muc-script/#input-format","text":"For both eterm and xml mode, the script expects an input in a very similar format. The high-level overview is: LENGTH\\nPAYLOAD LENGTH is the PAYLOAD length in bytes; if the data retrieved from a DBMS is a Unicode string, LENGTH is equal to the number of bytes used to encode this string PAYLOAD is a sequence of bytes; if a DBMS returns binary data encoded as hex, then it has to be decoded to raw bytes LENGTH and PAYLOAD are separated with a newline character (ASCII code 10 / 0x0a)","title":"Input format"},{"location":"migrations/jid-from-mam-muc-script/#output-format","text":"The script output format is very similar to the input: LENGTH\\nJID LENGTH is the number of bytes in a JID JID is a sequence of bytes, which encodes a Unicode string LENGTH and PAYLOAD are separated with a newline character (ASCII code 10 / 0x0a) In case of an error (that is not a critical error, like I/O failure), script will print -N\\n (where N is an error code) and will continue to work. Technically it's -N for LENGTH , followed by a newline character and no PAYLOAD part (or 0-length PAYLOAD if you like). The following error codes are supported: * -1\\n - Unknown error. Something went wrong with the JID extraction (most likely malformed input). * -2\\n - Invalid message type. The message / stanza has been decoded successfully, but it's not a groupchat message.","title":"Output format"},{"location":"migrations/jid-from-mam-muc-script/#examples","text":"tools/migration folder contains two files: sender-jid-from-mam-message.example.eterm and sender-jid-from-mam-message.example.xml . They are input samples for the script and may be used as a reference for the script usage. You can test them by running: tools/migration/sender-jid-from-mam-message.escript eterm < sender-jid-from-mam-message.example.eterm > out tools/migration/sender-jid-from-mam-message.escript xml < sender-jid-from-mam-message.example.xml > out In both cases the out file should have the following content: 37 g\u017ceg\u017c\u00f3\u0142ka@brz\u0119czyszczykiewicz.pl","title":"Examples"},{"location":"migrations/jid-from-mam-muc-script/#debug","text":"If an environment variable DEBUG is set to 1 , the script will store error messages in a /tmp/script-debug file.","title":"Debug"},{"location":"modules/mod_adhoc/","text":"Module Description This module implements XEP-0050: Ad-Hoc Commands . It allows XMPP entities to remotely execute various commands using forms. Options iqdisc (default: one_queue ) report_commands_node (boolean, default: false ): determines whether the Ad-Hoc Commands should be announced upon Service Discovery Example configuration {mod_adhoc, [{report_commands_node, true}]}","title":"mod_adhoc"},{"location":"modules/mod_adhoc/#module-description","text":"This module implements XEP-0050: Ad-Hoc Commands . It allows XMPP entities to remotely execute various commands using forms.","title":"Module Description"},{"location":"modules/mod_adhoc/#options","text":"iqdisc (default: one_queue ) report_commands_node (boolean, default: false ): determines whether the Ad-Hoc Commands should be announced upon Service Discovery","title":"Options"},{"location":"modules/mod_adhoc/#example-configuration","text":"{mod_adhoc, [{report_commands_node, true}]}","title":"Example configuration"},{"location":"modules/mod_amp/","text":"Module Description This module enables support for a subset of the functionality described under XEP-0079: Advanced Message Processing . It currently does not provide features related to timed delivery, i.e the expire-at condition. The error and notify actions are supported, while alert and drop are not. See more below, under XEP Support. Options none Example Configuration {mod_amp, []}, XEP Support What follows is a short description of which parts of the XEP-0079 specification mod_amp supports. 2.1.1 Service Discovery Both the service discovery information response (Ex.1, 2) and the request/response for individual actions and conditions (Ex.3, 4) are supported . 2.1.2 Specifying Semantics \"Per-hop\" rule semantics are not supported , i.e. ignored. 2.2 Server Processing 2.2.1 Validating Semantics: Performed as in the XEP. The first message to fail validation determines the error message. 2.2.2 supported to spec. 2.2.3 supported to spec. 2.2.4 supported for actions: error and notify . 2.2.5 supported for events: error and notify . 3.3 Defined Conditions 3.3.1 deliver: supported for values: direct , stored , and none . The stored condition works with mod_mam and mod_offline . 3.3.2 expire-at: not supported 3.3.3 match-resource: supported 3.4 Defined Actions 3.4.1 alert: not supported 3.4.2 drop: not supported 3.4.3 error: supported 3.4.4 notify: supported . Notifications for the stored and direct conditions are sent as soon as the message has been stored or sent to the recipient. Error Handling 6.2.1 Unsupported Action: supported 6.2.2 Unsupported Condition: supported 6.2.3 Not Acceptable: supported 6.2.4 Service Unavailable is not supported , as it pertains to \"per-hop\" rule processing 6.2.5 Undefined Condition: supported Stream Feature supported Security Considerations Currently, the security measures described in this section have not been implemented. It follows that mod_amp , in its current state, should only be enabled for servers/domains where user presence leaks are not a threat, i.e services where all users can see each other's presence by default.","title":"mod_amp"},{"location":"modules/mod_amp/#module-description","text":"This module enables support for a subset of the functionality described under XEP-0079: Advanced Message Processing . It currently does not provide features related to timed delivery, i.e the expire-at condition. The error and notify actions are supported, while alert and drop are not. See more below, under XEP Support.","title":"Module Description"},{"location":"modules/mod_amp/#options","text":"none","title":"Options"},{"location":"modules/mod_amp/#example-configuration","text":"{mod_amp, []},","title":"Example Configuration"},{"location":"modules/mod_amp/#xep-support","text":"What follows is a short description of which parts of the XEP-0079 specification mod_amp supports. 2.1.1 Service Discovery Both the service discovery information response (Ex.1, 2) and the request/response for individual actions and conditions (Ex.3, 4) are supported . 2.1.2 Specifying Semantics \"Per-hop\" rule semantics are not supported , i.e. ignored. 2.2 Server Processing 2.2.1 Validating Semantics: Performed as in the XEP. The first message to fail validation determines the error message. 2.2.2 supported to spec. 2.2.3 supported to spec. 2.2.4 supported for actions: error and notify . 2.2.5 supported for events: error and notify . 3.3 Defined Conditions 3.3.1 deliver: supported for values: direct , stored , and none . The stored condition works with mod_mam and mod_offline . 3.3.2 expire-at: not supported 3.3.3 match-resource: supported 3.4 Defined Actions 3.4.1 alert: not supported 3.4.2 drop: not supported 3.4.3 error: supported 3.4.4 notify: supported . Notifications for the stored and direct conditions are sent as soon as the message has been stored or sent to the recipient. Error Handling 6.2.1 Unsupported Action: supported 6.2.2 Unsupported Condition: supported 6.2.3 Not Acceptable: supported 6.2.4 Service Unavailable is not supported , as it pertains to \"per-hop\" rule processing 6.2.5 Undefined Condition: supported Stream Feature supported Security Considerations Currently, the security measures described in this section have not been implemented. It follows that mod_amp , in its current state, should only be enabled for servers/domains where user presence leaks are not a threat, i.e services where all users can see each other's presence by default.","title":"XEP Support"},{"location":"modules/mod_auth_token/","text":"Module Description This module implements handling of tokens in an OAuth-like authentication scheme. It provides services necessary to: deserialize/serialize binary tokens received and issued by the server, validate incoming binary tokens, i.e.: check integrity using Message Authentication Codes (MAC) with server-side stored user keys, check validity against the configured validity duration times, check revocation status, handle token requests from logged in users. The module itself does not implement protocol related details - these are implemented in cyrsasl.erl . Generation of keys necessary to sign binary tokens is delegated to module mod_keystore.erl . Options Validity periods Validity periods of access and refresh tokens can be defined independently. Allowed units are: days hours minutes seconds The default values for tokens are: 1 hour for an access token 25 days for a refresh token Example configuration from mongooseim.cfg , inside modules section: {modules, [ {mod_auth_token, [{{validity_period, access}, {13, minutes}}, {{validity_period, refresh}, {13, days}}] ]}. Validity period configuration for provision tokens happens outside the module since the server does not generate provision tokens - it only validates them. Required keys Keys are used for signing binary tokens using an HMAC with SHA-2 family function SHA-384. Therefore, mod_auth_token requires mod_keystore to provide some predefined keys. The required keys are (example from mongooseim.cfg ): {mod_keystore, [{keys, [{token_secret, ram}, {provision_pre_shared, {file, \"priv/provision_pre_shared.key\"}}]}]} token_secret is a RAM-only (i.e. generated on cluster startup, never written to disk) key used for signing and verifying access and refresh tokens. provision_pre_shared is a key read from a file. As its name suggests, it's shared with a service issuing provision tokens. Clients then use these provision tokens to authenticate with MongooseIM. While it's not enforced by the server and left completely to the operator, provision_pre_shared keys probably should not be shared between virtual XMPP domains hosted by the server. That is, make sure the module configuration specifying a provision_pre_shared key is specific to an XMPP domain. MongooseIM can't generate provision tokens on its own (neither can it distribute them to clients), so while configuring a provision_pre_shared key to be RAM-only is technically possible, it would in practice disable the provision token support (as no external service could generate a valid token with this particular RAM key). Token types Three token types are supported: access tokens : These are short lived tokens which grants aren't tracked by the server (i.e. there's no need to store anything in a database). Access tokens can be used as a payload for the X-OAUTH authentication mechanism and grant access to the system. Access tokens can't be revoked. An access token is valid only until its expiry date is reached. refresh tokens : These are longer lived tokens which are tracked by the server and therefore require persistent storage (as of now only PostgreSQL is supported). Refresh tokens can be used as a payload for the X-OAUTH authentication mechanism and to grant access to the system. Also they can result in a new set of tokens being returned upon successful authentication. They can be revoked - if a refresh token hasn't been revoked, it is valid until it has expired. On revocation, it immediately becomes invalid. As the server stores information about granted tokens, it can also persistently mark them as revoked. provision tokens : These tokens are generated by a service external to the server. They grant the owner a permission to create an account. A provision token may contain information which the server can use to provision the VCard for the newly created account. Using a provision token to create an account (and inject VCard data) is done similarly to other token types, i.e. by passing it as payload for the X-OAUTH mechanism. The XMPP server has no way of tracking and revoking provision tokens, as they come from an outside source. Token serialization format All tokens (access, refresh, provision) are to be exchanged as Base64 encoded binary data. Serialization format of the token before encoding with Base64 is dependent on its type: 'access' \\0 <BARE_JID> \\0 <EXPIRES_AT> \\0 <MAC> 'refresh' \\0 <BARE_JID> \\0 <EXPIRES_AT> \\0 <SEQUENCE_NO> \\0 <MAC> 'provision' \\0 <BARE_JID> \\0 <EXPIRES_AT> \\0 <VCARD> \\0 <MAC> For example (these tokens are randomly generated, hence field values don't make much sense - line breaks are inserted only for the sake of formatting, <vCard/> inner XML is snipped): 'access' \\0 Q8@localhost \\0 64875466454 \\0 0acd0a66d06934791d046060cf9f1ad3c2abb3274cc7e7d7b2bc7e2ac4453ed774b6c6813b40ebec2bbc3774d59d4087 'refresh' \\0 qp@localhost \\0 64875466457 \\0 6 \\0 8f57cb019cd6dc6e7779be165b9558611baf71ee4a40d03e77b78b069f482f96c9d23b1ac1ef69f64c1a1db3d36a96ad 'provision' \\0 Xmi4@localhost \\0 64875466458 \\0 <vCard>...</vCard> \\0 86cd344c98b345390c1961e12cd4005659b4b0b3c7ec475bde9acc9d47eec27e8ddc67003696af582747fb52e578a715 Requesting access or refresh tokens when logged in <iq type='get' to='john@localhost' id='123'> <query xmlns='erlang-solutions.com:xmpp:token-auth:0'/> </iq> To request access and refresh tokens for the first time a client should send an IQ stanza after they have successfully authenticated for the first time using some other method. Token response format Requested tokens are being returned by the server wrapped in IQ stanza with the following fields: id : value taken from the request IQ stanza type : result from : bare user JID to : full user JID Example response (encoded tokens have been truncated in this example): <iq id='123' type='result' from='john@localhost' to='john@localhost/res1'> <items xmlns='erlang-solutions.com:xmpp:token-auth:0'> <access_token>cmVmcmVzaAGQ1Mzk1MmZlYzhkYjhlOTQzM2UxMw==</access_token> <refresh_token>cmVmcmVzaAGQ1Mzk1MmZlYzhkYjhlOTQzM2UxMw==</refresh_token> </items> </iq> Once a client has obtained a token, they may start authenticating using the X-OAUTH SASL mechanism when reaching the authentication phase of an XMPP connection initiation. Login with access or refresh token In order to log into the XMPP server using a previously requested token, a client should send the following stanza: <auth xmlns=\"urn:ietf:params:xml:ns:xmpp-sasl\" mechanism=\"X-OAUTH\"> cmVmcmVzaAGQ1Mzk1MmZlYzhkYjhlOTQzM2UxMw== </auth> The Base64 encoded content is a token obtained prior to authentication. Authentication will succeed unless the used tokens are expired, revoked, or the keys required for MAC verification could not be found by the server. When using a refresh token to authenticate with the server , the server will respond with a new access token : <success xmlns=\"urn:ietf:params:xml:ns:xmpp-sasl\"> cmVmcmVzaAGQ1Mzk1MmZlYzhkYjhlOTQzM2UxMw== </success> The above response is to be expected unless the refresh token used is expired or there were some problems processing the key on the server side. Token revocation using command line tool Refresh tokens issued by the server can be used to: log in a user: as an authentication valet, request a new access token with refreshed expiry date. An administrator may revoke a refresh token: mongooseimctl revoke_token owner@xmpphost A client can no longer use a revoked token either for authentication or requesting new access tokens. After a client's token has been revoked, in order to obtain a new refresh token a client has to log in using some other method. Caveat: as of now, the user's session is not terminated automatically on token revocation. Therefore, the user might request a new set of tokens for as long as the session is active, even though their previous token was just revoked (possibly due to a breach / token leak). Moreover, an access token still kept on a compromised device can be used to establish a new session for as long as it's valid - access tokens can't be revoked. To alleviate rerequesting tokens by the user, an operator can use mod_admin extension allowing to terminate the user's connection. Access token validity can't be sidestepped right now. Example configuration {modules, [ {mod_auth_token, [{{validity_period, access}, {13, minutes}}, {{validity_period, refresh}, {13, days}}] ]}.","title":"mod_auth_token"},{"location":"modules/mod_auth_token/#module-description","text":"This module implements handling of tokens in an OAuth-like authentication scheme. It provides services necessary to: deserialize/serialize binary tokens received and issued by the server, validate incoming binary tokens, i.e.: check integrity using Message Authentication Codes (MAC) with server-side stored user keys, check validity against the configured validity duration times, check revocation status, handle token requests from logged in users. The module itself does not implement protocol related details - these are implemented in cyrsasl.erl . Generation of keys necessary to sign binary tokens is delegated to module mod_keystore.erl .","title":"Module Description"},{"location":"modules/mod_auth_token/#options","text":"","title":"Options"},{"location":"modules/mod_auth_token/#validity-periods","text":"Validity periods of access and refresh tokens can be defined independently. Allowed units are: days hours minutes seconds The default values for tokens are: 1 hour for an access token 25 days for a refresh token Example configuration from mongooseim.cfg , inside modules section: {modules, [ {mod_auth_token, [{{validity_period, access}, {13, minutes}}, {{validity_period, refresh}, {13, days}}] ]}. Validity period configuration for provision tokens happens outside the module since the server does not generate provision tokens - it only validates them.","title":"Validity periods"},{"location":"modules/mod_auth_token/#required-keys","text":"Keys are used for signing binary tokens using an HMAC with SHA-2 family function SHA-384. Therefore, mod_auth_token requires mod_keystore to provide some predefined keys. The required keys are (example from mongooseim.cfg ): {mod_keystore, [{keys, [{token_secret, ram}, {provision_pre_shared, {file, \"priv/provision_pre_shared.key\"}}]}]} token_secret is a RAM-only (i.e. generated on cluster startup, never written to disk) key used for signing and verifying access and refresh tokens. provision_pre_shared is a key read from a file. As its name suggests, it's shared with a service issuing provision tokens. Clients then use these provision tokens to authenticate with MongooseIM. While it's not enforced by the server and left completely to the operator, provision_pre_shared keys probably should not be shared between virtual XMPP domains hosted by the server. That is, make sure the module configuration specifying a provision_pre_shared key is specific to an XMPP domain. MongooseIM can't generate provision tokens on its own (neither can it distribute them to clients), so while configuring a provision_pre_shared key to be RAM-only is technically possible, it would in practice disable the provision token support (as no external service could generate a valid token with this particular RAM key).","title":"Required keys"},{"location":"modules/mod_auth_token/#token-types","text":"Three token types are supported: access tokens : These are short lived tokens which grants aren't tracked by the server (i.e. there's no need to store anything in a database). Access tokens can be used as a payload for the X-OAUTH authentication mechanism and grant access to the system. Access tokens can't be revoked. An access token is valid only until its expiry date is reached. refresh tokens : These are longer lived tokens which are tracked by the server and therefore require persistent storage (as of now only PostgreSQL is supported). Refresh tokens can be used as a payload for the X-OAUTH authentication mechanism and to grant access to the system. Also they can result in a new set of tokens being returned upon successful authentication. They can be revoked - if a refresh token hasn't been revoked, it is valid until it has expired. On revocation, it immediately becomes invalid. As the server stores information about granted tokens, it can also persistently mark them as revoked. provision tokens : These tokens are generated by a service external to the server. They grant the owner a permission to create an account. A provision token may contain information which the server can use to provision the VCard for the newly created account. Using a provision token to create an account (and inject VCard data) is done similarly to other token types, i.e. by passing it as payload for the X-OAUTH mechanism. The XMPP server has no way of tracking and revoking provision tokens, as they come from an outside source.","title":"Token types"},{"location":"modules/mod_auth_token/#token-serialization-format","text":"All tokens (access, refresh, provision) are to be exchanged as Base64 encoded binary data. Serialization format of the token before encoding with Base64 is dependent on its type: 'access' \\0 <BARE_JID> \\0 <EXPIRES_AT> \\0 <MAC> 'refresh' \\0 <BARE_JID> \\0 <EXPIRES_AT> \\0 <SEQUENCE_NO> \\0 <MAC> 'provision' \\0 <BARE_JID> \\0 <EXPIRES_AT> \\0 <VCARD> \\0 <MAC> For example (these tokens are randomly generated, hence field values don't make much sense - line breaks are inserted only for the sake of formatting, <vCard/> inner XML is snipped): 'access' \\0 Q8@localhost \\0 64875466454 \\0 0acd0a66d06934791d046060cf9f1ad3c2abb3274cc7e7d7b2bc7e2ac4453ed774b6c6813b40ebec2bbc3774d59d4087 'refresh' \\0 qp@localhost \\0 64875466457 \\0 6 \\0 8f57cb019cd6dc6e7779be165b9558611baf71ee4a40d03e77b78b069f482f96c9d23b1ac1ef69f64c1a1db3d36a96ad 'provision' \\0 Xmi4@localhost \\0 64875466458 \\0 <vCard>...</vCard> \\0 86cd344c98b345390c1961e12cd4005659b4b0b3c7ec475bde9acc9d47eec27e8ddc67003696af582747fb52e578a715","title":"Token serialization format"},{"location":"modules/mod_auth_token/#requesting-access-or-refresh-tokens-when-logged-in","text":"<iq type='get' to='john@localhost' id='123'> <query xmlns='erlang-solutions.com:xmpp:token-auth:0'/> </iq> To request access and refresh tokens for the first time a client should send an IQ stanza after they have successfully authenticated for the first time using some other method.","title":"Requesting access or refresh tokens when logged in"},{"location":"modules/mod_auth_token/#token-response-format","text":"Requested tokens are being returned by the server wrapped in IQ stanza with the following fields: id : value taken from the request IQ stanza type : result from : bare user JID to : full user JID Example response (encoded tokens have been truncated in this example): <iq id='123' type='result' from='john@localhost' to='john@localhost/res1'> <items xmlns='erlang-solutions.com:xmpp:token-auth:0'> <access_token>cmVmcmVzaAGQ1Mzk1MmZlYzhkYjhlOTQzM2UxMw==</access_token> <refresh_token>cmVmcmVzaAGQ1Mzk1MmZlYzhkYjhlOTQzM2UxMw==</refresh_token> </items> </iq> Once a client has obtained a token, they may start authenticating using the X-OAUTH SASL mechanism when reaching the authentication phase of an XMPP connection initiation.","title":"Token response format"},{"location":"modules/mod_auth_token/#login-with-access-or-refresh-token","text":"In order to log into the XMPP server using a previously requested token, a client should send the following stanza: <auth xmlns=\"urn:ietf:params:xml:ns:xmpp-sasl\" mechanism=\"X-OAUTH\"> cmVmcmVzaAGQ1Mzk1MmZlYzhkYjhlOTQzM2UxMw== </auth> The Base64 encoded content is a token obtained prior to authentication. Authentication will succeed unless the used tokens are expired, revoked, or the keys required for MAC verification could not be found by the server. When using a refresh token to authenticate with the server , the server will respond with a new access token : <success xmlns=\"urn:ietf:params:xml:ns:xmpp-sasl\"> cmVmcmVzaAGQ1Mzk1MmZlYzhkYjhlOTQzM2UxMw== </success> The above response is to be expected unless the refresh token used is expired or there were some problems processing the key on the server side.","title":"Login with access or refresh token"},{"location":"modules/mod_auth_token/#token-revocation-using-command-line-tool","text":"Refresh tokens issued by the server can be used to: log in a user: as an authentication valet, request a new access token with refreshed expiry date. An administrator may revoke a refresh token: mongooseimctl revoke_token owner@xmpphost A client can no longer use a revoked token either for authentication or requesting new access tokens. After a client's token has been revoked, in order to obtain a new refresh token a client has to log in using some other method. Caveat: as of now, the user's session is not terminated automatically on token revocation. Therefore, the user might request a new set of tokens for as long as the session is active, even though their previous token was just revoked (possibly due to a breach / token leak). Moreover, an access token still kept on a compromised device can be used to establish a new session for as long as it's valid - access tokens can't be revoked. To alleviate rerequesting tokens by the user, an operator can use mod_admin extension allowing to terminate the user's connection. Access token validity can't be sidestepped right now.","title":"Token revocation using command line tool"},{"location":"modules/mod_auth_token/#example-configuration","text":"{modules, [ {mod_auth_token, [{{validity_period, access}, {13, minutes}}, {{validity_period, refresh}, {13, days}}] ]}.","title":"Example configuration"},{"location":"modules/mod_blocking/","text":"Module Description This module implements XEP-0191: Blocking command . The extension allows blocking the whole communication with a user (or a group of users) with a single command. The protocol is much simpler than privacy lists. Options Example Configuration {mod_blocking, []}, The module is not configurable because internally it is an interface to privacy lists, so settings like storage backend apply to it automatically. Issuing a blocking command creates a privacy list named \"blocking\" (if it didn't exist), adds to it items being blocked and sets this list as the default. Unblocking contacts removes them from \"blocking\" privacy list. If the user has other online resources which use privacy lists it may result in a different behaviour per resource; this is normal, and provided for in XEP. Similar to privacy lists, a blocked contact sees the user as offline no matter what their real status is. If the contact being blocked is subscribed to the user's presence, they receive an \"unavailable\" presence; when unblocked, they receive the current status of the user.","title":"mod_blocking"},{"location":"modules/mod_blocking/#module-description","text":"This module implements XEP-0191: Blocking command . The extension allows blocking the whole communication with a user (or a group of users) with a single command. The protocol is much simpler than privacy lists.","title":"Module Description"},{"location":"modules/mod_blocking/#options","text":"","title":"Options"},{"location":"modules/mod_blocking/#example-configuration","text":"{mod_blocking, []}, The module is not configurable because internally it is an interface to privacy lists, so settings like storage backend apply to it automatically. Issuing a blocking command creates a privacy list named \"blocking\" (if it didn't exist), adds to it items being blocked and sets this list as the default. Unblocking contacts removes them from \"blocking\" privacy list. If the user has other online resources which use privacy lists it may result in a different behaviour per resource; this is normal, and provided for in XEP. Similar to privacy lists, a blocked contact sees the user as offline no matter what their real status is. If the contact being blocked is subscribed to the user's presence, they receive an \"unavailable\" presence; when unblocked, they receive the current status of the user.","title":"Example Configuration"},{"location":"modules/mod_bosh/","text":"Module Description This module implements XEP-0206: XMPP Over BOSH (using XEP-0124: Bidirectional-streams Over Synchronous HTTP (BOSH) ), allowing clients to connect to MongooseIM over regular HTTP long-lived connections. If you want to use BOSH, you must enable it both in the listen section of mongooseim.cfg ( Listener Modules ) and as a module. Options inactivity (positive integer or infinity , default: 30): Maximum allowed inactivity time for a BOSH connection. Please note that a long-polling request is not considered to be an inactivity. max_wait (positive integer or infinity , default: infinity ): This is the longest time (in seconds) that the connection manager will wait before responding to any request during the session. server_acks (boolean, default: false ): Enables/disables acks sent by server. backend (atom, default: mnesia ): Backend used for storing BOSH session data. mnesia is the only supported value. maxpause (positive integer, default: 120): Maximum allowed pause in seconds (e.g. to switch between pages and then resume connection) to request by client-side. Example Configuration In the listener section: {listen, [ { 5280, ejabberd_cowboy, [ {num_acceptors, 10}, {max_connections, 1024}, {modules, [ {\"_\", \"/http-bind\", mod_bosh} ]} ]} In the module section: {mod_bosh, []}","title":"mod_bosh"},{"location":"modules/mod_bosh/#module-description","text":"This module implements XEP-0206: XMPP Over BOSH (using XEP-0124: Bidirectional-streams Over Synchronous HTTP (BOSH) ), allowing clients to connect to MongooseIM over regular HTTP long-lived connections. If you want to use BOSH, you must enable it both in the listen section of mongooseim.cfg ( Listener Modules ) and as a module.","title":"Module Description"},{"location":"modules/mod_bosh/#options","text":"inactivity (positive integer or infinity , default: 30): Maximum allowed inactivity time for a BOSH connection. Please note that a long-polling request is not considered to be an inactivity. max_wait (positive integer or infinity , default: infinity ): This is the longest time (in seconds) that the connection manager will wait before responding to any request during the session. server_acks (boolean, default: false ): Enables/disables acks sent by server. backend (atom, default: mnesia ): Backend used for storing BOSH session data. mnesia is the only supported value. maxpause (positive integer, default: 120): Maximum allowed pause in seconds (e.g. to switch between pages and then resume connection) to request by client-side.","title":"Options"},{"location":"modules/mod_bosh/#example-configuration","text":"In the listener section: {listen, [ { 5280, ejabberd_cowboy, [ {num_acceptors, 10}, {max_connections, 1024}, {modules, [ {\"_\", \"/http-bind\", mod_bosh} ]} ]} In the module section: {mod_bosh, []}","title":"Example Configuration"},{"location":"modules/mod_caps/","text":"Module description This module provides a presence-based mechanism for exchanging information about entity capabilities as defined in XEP-0115 . Additionally, it filters out PEP messages that the recipient declared (in announced caps) being not capable of handling. It is not this module's responsibility to intercept and answer disco requests routed between clients. Options This module expects two optional arguments that apply to cache tab : * cache_size (default: 1000) - the size of a cache_tab (the amount of entries) holding the information about capabilities of each user. * cache_life_time (default: 86) - time (in seconds) after which entries will be removed","title":"mod_caps"},{"location":"modules/mod_caps/#module-description","text":"This module provides a presence-based mechanism for exchanging information about entity capabilities as defined in XEP-0115 . Additionally, it filters out PEP messages that the recipient declared (in announced caps) being not capable of handling. It is not this module's responsibility to intercept and answer disco requests routed between clients.","title":"Module description"},{"location":"modules/mod_caps/#options","text":"This module expects two optional arguments that apply to cache tab : * cache_size (default: 1000) - the size of a cache_tab (the amount of entries) holding the information about capabilities of each user. * cache_life_time (default: 86) - time (in seconds) after which entries will be removed","title":"Options"},{"location":"modules/mod_carboncopy/","text":"Module Description Discovering Support The server uses a disco query to inform if carbons are enabled. Enabling and disabling Carbons from the client Carbons are not enabled by default. Every client app has to enable carbons to get messages sent to other clients of the user. Carbons are enabled and disabled with an iq stanza with a child element - <enable xmlns='urn:xmpp:carbons:2'/> or <disable xmlns='urn:xmpp:carbons:2'/> . Receiving messages to a bare JID Each message to a bare JID is forked and sent to all carbon enabled resources of the recipient, and not just to the highest priority resource. Sending multiple copies to same resource is avoided. Receiving messages to full JID Each directed message to a full JID is also forwarded to all carbon enabled resources of the recipient. The message is wrapped in the <forwarded xmlns='urn:xmpp:forward:0'></forwarded> tag and directed towards each carbon enabled resource. Sending Messages Just as when receiving messages to a full JID, each sent message is forwarded to all carbon enabled resources of recipient. The message is wrapped in the <forwarded xmlns='urn:xmpp:forward:0'></forwarded> tag and is directed towards each carbon enabled resource. Private Messages Private messages are tagged <private/> and are not forwarded to any carbon enabled resource of the sender and recipient if the to attribute contains a full JID. However, if the message is sent to a bare JID, it is forked to all highest priority resources. This is not done through mod_carboncopy but is an expected outcome. Multiple enable/disable requests Multiple enable/disable requests are not treated as an error even if they come from the same resource. Behavior with other modules mod_offline : Offline messages are delivered as they are. Since, only one resource can connect at a time and there will be a finite time delay between login from two resources, mod_carboncopy has no role to play and only one resource can receive offline messages. Other resources can retrieve old messages from the archive. mod_mam : mod_mam covers only direct messages from one user to another. All the forked messages for a message sent with a bare JID are ignored by mod_mam . Similarly, all the carbon messages are also ignored by mod_mam . Retrieving archive from multiple resources A resource can retrieve archives of messages sent to a specific resource of a friend which will not contain any carbon messages. It will only contain messages directed towards that resource or messages sent with a bare jid when that resource was at the highest priority. A request to mod_mam with a bare JID of the chosen user will retrieve all messages to them from any resource. There are no instances of copies of same messages being sent by mod_mam . This is because mod_mam does not archive carbon messages. Testing with a client The module and its behavior have been tested with mod_offline and mod_mam using a desktop client made in Java using the Smack library. The standard Smack library for carbons is able to unpack and read the carbon messages. Also, the standard library supports checking for carbon support by the server using disco and sending enable and disable requests for carbon messages. A client needs to synchronize with mod_offline and mod_mam . Once a client is online and enables carbons, it will not receive all the messages. mod_mam does not capture any carbon messages so it does not send any duplicates during any archive request. Only the simple chat messages are archived and they can be accessed by using the bare JID of the user for whom the archive is requested. For an Erlang-based test suite, please see [/esl/ejabberd_tests/blob/master/tests/carboncopy_SUITE.erl]. Options iqdisc (default: no_queue) Example Configuration {mod_carboncopy, []}","title":"mod_carboncopy"},{"location":"modules/mod_carboncopy/#module-description","text":"","title":"Module Description"},{"location":"modules/mod_carboncopy/#discovering-support","text":"The server uses a disco query to inform if carbons are enabled.","title":"Discovering Support"},{"location":"modules/mod_carboncopy/#enabling-and-disabling-carbons-from-the-client","text":"Carbons are not enabled by default. Every client app has to enable carbons to get messages sent to other clients of the user. Carbons are enabled and disabled with an iq stanza with a child element - <enable xmlns='urn:xmpp:carbons:2'/> or <disable xmlns='urn:xmpp:carbons:2'/> .","title":"Enabling and disabling Carbons from the client"},{"location":"modules/mod_carboncopy/#receiving-messages-to-a-bare-jid","text":"Each message to a bare JID is forked and sent to all carbon enabled resources of the recipient, and not just to the highest priority resource. Sending multiple copies to same resource is avoided.","title":"Receiving messages to a bare JID"},{"location":"modules/mod_carboncopy/#receiving-messages-to-full-jid","text":"Each directed message to a full JID is also forwarded to all carbon enabled resources of the recipient. The message is wrapped in the <forwarded xmlns='urn:xmpp:forward:0'></forwarded> tag and directed towards each carbon enabled resource.","title":"Receiving messages to full JID"},{"location":"modules/mod_carboncopy/#sending-messages","text":"Just as when receiving messages to a full JID, each sent message is forwarded to all carbon enabled resources of recipient. The message is wrapped in the <forwarded xmlns='urn:xmpp:forward:0'></forwarded> tag and is directed towards each carbon enabled resource.","title":"Sending Messages"},{"location":"modules/mod_carboncopy/#private-messages","text":"Private messages are tagged <private/> and are not forwarded to any carbon enabled resource of the sender and recipient if the to attribute contains a full JID. However, if the message is sent to a bare JID, it is forked to all highest priority resources. This is not done through mod_carboncopy but is an expected outcome.","title":"Private Messages"},{"location":"modules/mod_carboncopy/#multiple-enabledisable-requests","text":"Multiple enable/disable requests are not treated as an error even if they come from the same resource.","title":"Multiple enable/disable requests"},{"location":"modules/mod_carboncopy/#behavior-with-other-modules","text":"mod_offline : Offline messages are delivered as they are. Since, only one resource can connect at a time and there will be a finite time delay between login from two resources, mod_carboncopy has no role to play and only one resource can receive offline messages. Other resources can retrieve old messages from the archive. mod_mam : mod_mam covers only direct messages from one user to another. All the forked messages for a message sent with a bare JID are ignored by mod_mam . Similarly, all the carbon messages are also ignored by mod_mam .","title":"Behavior with other modules"},{"location":"modules/mod_carboncopy/#retrieving-archive-from-multiple-resources","text":"A resource can retrieve archives of messages sent to a specific resource of a friend which will not contain any carbon messages. It will only contain messages directed towards that resource or messages sent with a bare jid when that resource was at the highest priority. A request to mod_mam with a bare JID of the chosen user will retrieve all messages to them from any resource. There are no instances of copies of same messages being sent by mod_mam . This is because mod_mam does not archive carbon messages.","title":"Retrieving archive from multiple resources"},{"location":"modules/mod_carboncopy/#testing-with-a-client","text":"The module and its behavior have been tested with mod_offline and mod_mam using a desktop client made in Java using the Smack library. The standard Smack library for carbons is able to unpack and read the carbon messages. Also, the standard library supports checking for carbon support by the server using disco and sending enable and disable requests for carbon messages. A client needs to synchronize with mod_offline and mod_mam . Once a client is online and enables carbons, it will not receive all the messages. mod_mam does not capture any carbon messages so it does not send any duplicates during any archive request. Only the simple chat messages are archived and they can be accessed by using the bare JID of the user for whom the archive is requested. For an Erlang-based test suite, please see [/esl/ejabberd_tests/blob/master/tests/carboncopy_SUITE.erl].","title":"Testing with a client"},{"location":"modules/mod_carboncopy/#options","text":"iqdisc (default: no_queue)","title":"Options"},{"location":"modules/mod_carboncopy/#example-configuration","text":"{mod_carboncopy, []}","title":"Example Configuration"},{"location":"modules/mod_commands/","text":"MongooseIM's command set Purpose This is a basic set of administration and client commands. Our goal is to provide a consistent, easy to use API for MongooseIM. Both backend and client commands provide enough information to allow auto-generating access methods. We currently use it in our admin and client REST API interface. In the future it may replace the current mongooseimctl implementation. Configuration This module contains command definitions loaded when the module is activated. There are no more configuration parameters, so the following entry in the config file is sufficient: {mod_commands, []]}, Command definition The module contains a list of command definitions. Each definition contains the following entries: name (uniquely identifies the command) category (used for listing commands and for generating URLs for REST API) subcategory (optional) desc (a brief description) module, function (what is called when the command is executed) action (create|read|update|delete) optional: security_policy (info to be used by the caller) args (a list of two-element tuples specifying name and type of an argument) result (what the command (and its underlying function) is supposed to return) A simple command definition may look like this: [ {name, list_contacts}, {category, <<\"contacts\">>}, {desc, <<\"Get roster\">>}, {module, ?MODULE}, {function, list_contacts}, {action, read}, {security_policy, [user]}, {args, [{caller, binary}]}, {result, []} ] Command registration and interface Command registry is managed by mongoose_commands module. To register a command simply call: mongoose_commands:register(list_of_command_definitions) The registry provides functions for listing commands, retrieving their signatures, and also calling. To call the above method you should do: mongoose_commands:execute(admin, list_contacts) % if you want superuser privileges or mongoose_commands:execute(<<\"alice@wonderland.lit\">>, list_contacts) and it will return a list of JIDs. REST API would expose this command as http://localhost/api/contacts % use GET, since it is 'read' and return a JSON list of strings. Since this is a user command, REST would expose it on the \"client\" interface and require authorisation headers.","title":"mod_commands"},{"location":"modules/mod_commands/#mongooseims-command-set","text":"","title":"MongooseIM's command set"},{"location":"modules/mod_commands/#purpose","text":"This is a basic set of administration and client commands. Our goal is to provide a consistent, easy to use API for MongooseIM. Both backend and client commands provide enough information to allow auto-generating access methods. We currently use it in our admin and client REST API interface. In the future it may replace the current mongooseimctl implementation.","title":"Purpose"},{"location":"modules/mod_commands/#configuration","text":"This module contains command definitions loaded when the module is activated. There are no more configuration parameters, so the following entry in the config file is sufficient: {mod_commands, []]},","title":"Configuration"},{"location":"modules/mod_commands/#command-definition","text":"The module contains a list of command definitions. Each definition contains the following entries: name (uniquely identifies the command) category (used for listing commands and for generating URLs for REST API) subcategory (optional) desc (a brief description) module, function (what is called when the command is executed) action (create|read|update|delete) optional: security_policy (info to be used by the caller) args (a list of two-element tuples specifying name and type of an argument) result (what the command (and its underlying function) is supposed to return) A simple command definition may look like this: [ {name, list_contacts}, {category, <<\"contacts\">>}, {desc, <<\"Get roster\">>}, {module, ?MODULE}, {function, list_contacts}, {action, read}, {security_policy, [user]}, {args, [{caller, binary}]}, {result, []} ]","title":"Command definition"},{"location":"modules/mod_commands/#command-registration-and-interface","text":"Command registry is managed by mongoose_commands module. To register a command simply call: mongoose_commands:register(list_of_command_definitions) The registry provides functions for listing commands, retrieving their signatures, and also calling. To call the above method you should do: mongoose_commands:execute(admin, list_contacts) % if you want superuser privileges or mongoose_commands:execute(<<\"alice@wonderland.lit\">>, list_contacts) and it will return a list of JIDs. REST API would expose this command as http://localhost/api/contacts % use GET, since it is 'read' and return a JSON list of strings. Since this is a user command, REST would expose it on the \"client\" interface and require authorisation headers.","title":"Command registration and interface"},{"location":"modules/mod_csi/","text":"Module Description Enables XEP-0352: Client State Indication functionality. It is implemented mostly in ejabberd_c2s , this module is just a \"starter\", to advertise the csi stream feature. The Client State Indication functionality will be possible to use even without enabling this module, but the feature will not be present in the stream features list. The XEP doesn't require any specific server behaviour in response to CSI stanzas, there are only some suggestions. The implementation in MongooseIM will simply buffer all packets (up to a configured limit) when the session is \"inactive\" and will flush the buffer when it becomes \"active\" again. Options buffer_max (default: 20): Buffer size for messages queued when session was inactive Example Configuration {mod_csi, [{buffer_max, 40}]}, Metrics If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Name Type Description (when it gets incremented) [Host, modCSIInactive] spiral A client becomes inactive. [Host, modCSIActive] spiral A client becomes active.","title":"mod_csi"},{"location":"modules/mod_csi/#module-description","text":"Enables XEP-0352: Client State Indication functionality. It is implemented mostly in ejabberd_c2s , this module is just a \"starter\", to advertise the csi stream feature. The Client State Indication functionality will be possible to use even without enabling this module, but the feature will not be present in the stream features list. The XEP doesn't require any specific server behaviour in response to CSI stanzas, there are only some suggestions. The implementation in MongooseIM will simply buffer all packets (up to a configured limit) when the session is \"inactive\" and will flush the buffer when it becomes \"active\" again.","title":"Module Description"},{"location":"modules/mod_csi/#options","text":"buffer_max (default: 20): Buffer size for messages queued when session was inactive","title":"Options"},{"location":"modules/mod_csi/#example-configuration","text":"{mod_csi, [{buffer_max, 40}]},","title":"Example Configuration"},{"location":"modules/mod_csi/#metrics","text":"If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Name Type Description (when it gets incremented) [Host, modCSIInactive] spiral A client becomes inactive. [Host, modCSIActive] spiral A client becomes active.","title":"Metrics"},{"location":"modules/mod_disco/","text":"Module Description Implements XEP-0030: Service Discovery . The module itself provides only the essential disco interface, the actual capabilities announced by Service Discovery are gathered via executing a fold-type hook. Options iqdisc (default: one_queue ) extra_domains (list of binaries, default: [] ): Adds domains that are not registered with other means to a local item announcement (response to http://jabber.org/protocol/disco#items IQ get). Please note that mod_disco doesn't verify these domains, so if no handlers are registered later for them, a client will receive a service-unavailable error for every stanza sent to one of these hosts. server_info (list of tuples {[Module] | all, Name, [URL]} , default: [] ): Adds extra disco information to all or chosen modules. Example: {server_info, [{all, \"abuse-address\", [\"admin@example.com\"]}, {[mod_muc, mod_disco], \"friendly-spirits\", [\"spirit1@localhost\", \"spirit2@localhost\"]}]} . New fields will be added in a manner compliant with XEP-0157. users_can_see_hidden_services (boolean, default: true ): MongooseIM node with this option set to false will exclude \"hidden services\" from disco results sent to clients (identified by bare or full JID). Other entities, with empty username part in their JIDs (e.g. component.example.com ), will still receive full disco results. Example Configuration {mod_disco, []}","title":"mod_disco"},{"location":"modules/mod_disco/#module-description","text":"Implements XEP-0030: Service Discovery . The module itself provides only the essential disco interface, the actual capabilities announced by Service Discovery are gathered via executing a fold-type hook.","title":"Module Description"},{"location":"modules/mod_disco/#options","text":"iqdisc (default: one_queue ) extra_domains (list of binaries, default: [] ): Adds domains that are not registered with other means to a local item announcement (response to http://jabber.org/protocol/disco#items IQ get). Please note that mod_disco doesn't verify these domains, so if no handlers are registered later for them, a client will receive a service-unavailable error for every stanza sent to one of these hosts. server_info (list of tuples {[Module] | all, Name, [URL]} , default: [] ): Adds extra disco information to all or chosen modules. Example: {server_info, [{all, \"abuse-address\", [\"admin@example.com\"]}, {[mod_muc, mod_disco], \"friendly-spirits\", [\"spirit1@localhost\", \"spirit2@localhost\"]}]} . New fields will be added in a manner compliant with XEP-0157. users_can_see_hidden_services (boolean, default: true ): MongooseIM node with this option set to false will exclude \"hidden services\" from disco results sent to clients (identified by bare or full JID). Other entities, with empty username part in their JIDs (e.g. component.example.com ), will still receive full disco results.","title":"Options"},{"location":"modules/mod_disco/#example-configuration","text":"{mod_disco, []}","title":"Example Configuration"},{"location":"modules/mod_event_pusher/","text":"Module Description This module is a generic interface for event pushing backends. It defines a single hook, push_event/3 that forwards the event to all registered backends. Each backend decides how and if to handle the event in its push_event/2 implementation. The events are standardized as records that can be found in mod_event_pusher_events.hrl file. Common events like user presence changes (offline and online), chat and groupchat messages (incoming and outgoing) are already hooked up to the frontend via mod_event_pusher_hook_translator which is a proxy between various hooks and push_event/3 hook handler. Options backends (required, list) - Specifies backends to register with the frontend, along with arguments that will be passed to the backend. Currently supported backends include sns , push and http_notification . Refer to their specific documentation to learn more about their functions and configuration options. Example configuration {mod_event_pusher, [ {backends, [ {sns, [ {access_key_id, \"AKIAIOSFODNN7EXAMPLE\"}, {secret_access_key, \"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\"}, % ... ]}, {push, [ {backend, mnesia}, {wpool, [{workers, 200}]}, {plugin_module, mod_event_pusher_push_plugin_defaults} ]} ]} ]}","title":"mod_event_pusher"},{"location":"modules/mod_event_pusher/#module-description","text":"This module is a generic interface for event pushing backends. It defines a single hook, push_event/3 that forwards the event to all registered backends. Each backend decides how and if to handle the event in its push_event/2 implementation. The events are standardized as records that can be found in mod_event_pusher_events.hrl file. Common events like user presence changes (offline and online), chat and groupchat messages (incoming and outgoing) are already hooked up to the frontend via mod_event_pusher_hook_translator which is a proxy between various hooks and push_event/3 hook handler.","title":"Module Description"},{"location":"modules/mod_event_pusher/#options","text":"backends (required, list) - Specifies backends to register with the frontend, along with arguments that will be passed to the backend. Currently supported backends include sns , push and http_notification . Refer to their specific documentation to learn more about their functions and configuration options.","title":"Options"},{"location":"modules/mod_event_pusher/#example-configuration","text":"{mod_event_pusher, [ {backends, [ {sns, [ {access_key_id, \"AKIAIOSFODNN7EXAMPLE\"}, {secret_access_key, \"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\"}, % ... ]}, {push, [ {backend, mnesia}, {wpool, [{workers, 200}]}, {plugin_module, mod_event_pusher_push_plugin_defaults} ]} ]} ]}","title":"Example configuration"},{"location":"modules/mod_event_pusher_http/","text":"Module description This module is a backend of mod_event_pusher that enables forwarding certain events (messages, presence, etc.) via HTTP to external services such as push (by mobile, email or SMS), big data, or analytics services. How it works The module hooks on all packets sent by connected users. When the hook is triggered, the module: runs a callback module's should_make_req/6 function to see if a notification should be sent runs a callback module's prepare_headers/7 to get http headers to be used runs a callback module's prepare_body/7 sends a POST request composed of {Host::binary(), Sender::binary(), Receiver::binary(), Message::binary()} to the http notification server You can make multiple configuration entries for this backend to handle more complicated pushing scenarios (e.g. sending various types of messages to different backends). Callback module To find out what and how to send MongooseIM calls the following callback module's functions: Mod:should_make_req(Acc::mongoose_acc:t(), Dir::in|out, Packet::xmlel(), From::jid(), To::jid(), Opts :: [{atom(), term()}]) . Mod:prepare_headers(Acc::mongoose_acc:t(), Dir::in|out, Host::jid:lserver(), Message::binary(), Sender::jid:luser(), Receiver::luser(), Opts :: [{atom(), term()}]) . Mod:prepare_body(Acc::mongoose_acc:t(), Dir::in|out, Host::jid:lserver(), Message::binary(), Sender::jid:luser(), Receiver::luser(), Opts :: [{atom(), term()}]) . By default it uses the function in mod_event_pusher_http itself, which ships all non-empty chat messages. Prerequisites This module uses a connection pool created by mongoose_http_client. It must be defined in the outgoing_pools settings . Options pool_name : name of the pool to use (as defined in outgoing_pools) path : path part of an URL to which a request should be sent (will be appended to the pool's prefix path). callback_module : name of a module which should be used to check whether a notification should be sent. Example configuration {outgoing_pools, [ {http, global, http_pool, [{workers, 50}], [{server, \"http://localhost:8000\"}, {path_prefix, \"/webservice\"}]} ]}. {mod_event_pusher, [ {backends, [ {http, [ {pool_name, http_pool}, {path, \"/notifications\"} ]} ]} ]} Notifications will be POSTed to http://localhost:8000/webservice/notifications . {mod_event_pusher, [ {backends, [ {http, [ {pool_name, http_pool}, {path, \"/notifications\"}, {callback_module, mod_event_pusher_http_notifications} ]}, {http, [ {pool_name, http_pool}, {path, \"/alerts\"}, {callback_module, mod_event_pusher_http_alerts} ]} ]} ]} Here, some notifications will be POSTed to http://localhost:8000/webservice/notifications and some to http://localhost:8000/webservice/alerts , depending on implementation of should_make_req/6 in the two callback modules. Default payload format The default HTTP event pusher sends a POST request with Content-Type application/x-www-form-urlencoded . The form has the following fields: * author : username of the user who authored the message * server : name of the server from where the message originates * receiver : username of the user who the message is for * message : content of <body> element of the message The contents of the author, server and receiver fields are processed by stringprep . As a result, these values are all lower case. Example Below is an example of what the body of an HTTP POST request can look like: \"author=alice&server=localhost&receiver=bob&message=Hi, Bob!\" Metrics If you'd like to learn more about metrics in MongooseIM, please visit [MongooseIM metrics](../operation-and-maintenance/Mongoose-metrics.md** page. Warning: the metrics' names may change once the deprecated mod_http_notification is removed from MongooseIM. Name Type Description (when it gets incremented) [Host, mod_http_notifications, sent] spiral An HTTP notification is sent successfully. [Host, mod_http_notifications, failed] spiral An HTTP notification failed. [Host, mod_http_notifications, response_time] histogram Does not include timings of failed requests.","title":"HTTP backend"},{"location":"modules/mod_event_pusher_http/#module-description","text":"This module is a backend of mod_event_pusher that enables forwarding certain events (messages, presence, etc.) via HTTP to external services such as push (by mobile, email or SMS), big data, or analytics services.","title":"Module description"},{"location":"modules/mod_event_pusher_http/#how-it-works","text":"The module hooks on all packets sent by connected users. When the hook is triggered, the module: runs a callback module's should_make_req/6 function to see if a notification should be sent runs a callback module's prepare_headers/7 to get http headers to be used runs a callback module's prepare_body/7 sends a POST request composed of {Host::binary(), Sender::binary(), Receiver::binary(), Message::binary()} to the http notification server You can make multiple configuration entries for this backend to handle more complicated pushing scenarios (e.g. sending various types of messages to different backends).","title":"How it works"},{"location":"modules/mod_event_pusher_http/#callback-module","text":"To find out what and how to send MongooseIM calls the following callback module's functions: Mod:should_make_req(Acc::mongoose_acc:t(), Dir::in|out, Packet::xmlel(), From::jid(), To::jid(), Opts :: [{atom(), term()}]) . Mod:prepare_headers(Acc::mongoose_acc:t(), Dir::in|out, Host::jid:lserver(), Message::binary(), Sender::jid:luser(), Receiver::luser(), Opts :: [{atom(), term()}]) . Mod:prepare_body(Acc::mongoose_acc:t(), Dir::in|out, Host::jid:lserver(), Message::binary(), Sender::jid:luser(), Receiver::luser(), Opts :: [{atom(), term()}]) . By default it uses the function in mod_event_pusher_http itself, which ships all non-empty chat messages.","title":"Callback module"},{"location":"modules/mod_event_pusher_http/#prerequisites","text":"This module uses a connection pool created by mongoose_http_client. It must be defined in the outgoing_pools settings .","title":"Prerequisites"},{"location":"modules/mod_event_pusher_http/#options","text":"pool_name : name of the pool to use (as defined in outgoing_pools) path : path part of an URL to which a request should be sent (will be appended to the pool's prefix path). callback_module : name of a module which should be used to check whether a notification should be sent.","title":"Options"},{"location":"modules/mod_event_pusher_http/#example-configuration","text":"{outgoing_pools, [ {http, global, http_pool, [{workers, 50}], [{server, \"http://localhost:8000\"}, {path_prefix, \"/webservice\"}]} ]}. {mod_event_pusher, [ {backends, [ {http, [ {pool_name, http_pool}, {path, \"/notifications\"} ]} ]} ]} Notifications will be POSTed to http://localhost:8000/webservice/notifications . {mod_event_pusher, [ {backends, [ {http, [ {pool_name, http_pool}, {path, \"/notifications\"}, {callback_module, mod_event_pusher_http_notifications} ]}, {http, [ {pool_name, http_pool}, {path, \"/alerts\"}, {callback_module, mod_event_pusher_http_alerts} ]} ]} ]} Here, some notifications will be POSTed to http://localhost:8000/webservice/notifications and some to http://localhost:8000/webservice/alerts , depending on implementation of should_make_req/6 in the two callback modules.","title":"Example configuration"},{"location":"modules/mod_event_pusher_http/#default-payload-format","text":"The default HTTP event pusher sends a POST request with Content-Type application/x-www-form-urlencoded . The form has the following fields: * author : username of the user who authored the message * server : name of the server from where the message originates * receiver : username of the user who the message is for * message : content of <body> element of the message The contents of the author, server and receiver fields are processed by stringprep . As a result, these values are all lower case.","title":"Default payload format"},{"location":"modules/mod_event_pusher_http/#example","text":"Below is an example of what the body of an HTTP POST request can look like: \"author=alice&server=localhost&receiver=bob&message=Hi, Bob!\"","title":"Example"},{"location":"modules/mod_event_pusher_http/#metrics","text":"If you'd like to learn more about metrics in MongooseIM, please visit [MongooseIM metrics](../operation-and-maintenance/Mongoose-metrics.md** page. Warning: the metrics' names may change once the deprecated mod_http_notification is removed from MongooseIM. Name Type Description (when it gets incremented) [Host, mod_http_notifications, sent] spiral An HTTP notification is sent successfully. [Host, mod_http_notifications, failed] spiral An HTTP notification failed. [Host, mod_http_notifications, response_time] histogram Does not include timings of failed requests.","title":"Metrics"},{"location":"modules/mod_event_pusher_push/","text":"Module Description This module is a backend of mod_event_pusher that implements XEP-0357: Push Notifications . It enables a service that notifies PubSub of a user's choice about every message that they could miss while being offline. There are two control stanzas that the client can send to this module: enable and disable . The enable stanza enables push notifications and forwards them to a specified PubSub node. This stanza may also contain an optional Data Form that will be added to each and every notification to PubSub node as publish-options . Please be sure to provide all form fields required by the specified PubSub node. Any publish error may result in disabling push notifications to this node. Options backend (atom, default: mnesia ) - Backend to use for storing the registrations. Currently only mnesia may be used. wpool (list, default: [] ) - List of options that will be passed to the worker_pool library that handles all the requests. Please refer to the Project Site for more details. plugin_module (atom, default: mod_event_pusher_push_plugin_defaults ) - module implementing mod_event_pusher_push_plugin behaviour, used for dynamic configuration of push notifications. Read more about it here Plugin module A plugin module handles dynamic configuration of push notifications. It implements mod_event_pusher_push_plugin behaviour which requires two callbacks: should_publish/3 - callback used for filtering push notifications. A push notification is triggered for given a message only if this callback returns true . -spec should_publish(From :: ejabberd:jid(), To :: ejabberd:jid(), Packet :: jlib:xmlel()) -> boolean(). publish_notification/5 - does the actual push. By default it pushes to the registered pubsub nodes. -spec publish_notification(Acc :: mongooseim_acc:t(), From :: jid:jid(), To :: jid:jid(), Packet :: exml:element(), Services :: [mod_event_pusher_push:publish_service()]) -> mongooseim_acc:t(). Example configuration {mod_event_pusher, [ {backends, [ {push, [ {backend, mnesia}, {wpool, [{workers, 200}]}, {plugin_module, mod_event_pusher_push_plugin_defaults} ]} ]} ]}","title":"Push backend"},{"location":"modules/mod_event_pusher_push/#module-description","text":"This module is a backend of mod_event_pusher that implements XEP-0357: Push Notifications . It enables a service that notifies PubSub of a user's choice about every message that they could miss while being offline. There are two control stanzas that the client can send to this module: enable and disable . The enable stanza enables push notifications and forwards them to a specified PubSub node. This stanza may also contain an optional Data Form that will be added to each and every notification to PubSub node as publish-options . Please be sure to provide all form fields required by the specified PubSub node. Any publish error may result in disabling push notifications to this node.","title":"Module Description"},{"location":"modules/mod_event_pusher_push/#options","text":"backend (atom, default: mnesia ) - Backend to use for storing the registrations. Currently only mnesia may be used. wpool (list, default: [] ) - List of options that will be passed to the worker_pool library that handles all the requests. Please refer to the Project Site for more details. plugin_module (atom, default: mod_event_pusher_push_plugin_defaults ) - module implementing mod_event_pusher_push_plugin behaviour, used for dynamic configuration of push notifications. Read more about it here","title":"Options"},{"location":"modules/mod_event_pusher_push/#plugin-module","text":"A plugin module handles dynamic configuration of push notifications. It implements mod_event_pusher_push_plugin behaviour which requires two callbacks: should_publish/3 - callback used for filtering push notifications. A push notification is triggered for given a message only if this callback returns true . -spec should_publish(From :: ejabberd:jid(), To :: ejabberd:jid(), Packet :: jlib:xmlel()) -> boolean(). publish_notification/5 - does the actual push. By default it pushes to the registered pubsub nodes. -spec publish_notification(Acc :: mongooseim_acc:t(), From :: jid:jid(), To :: jid:jid(), Packet :: exml:element(), Services :: [mod_event_pusher_push:publish_service()]) -> mongooseim_acc:t().","title":"Plugin module"},{"location":"modules/mod_event_pusher_push/#example-configuration","text":"{mod_event_pusher, [ {backends, [ {push, [ {backend, mnesia}, {wpool, [{workers, 200}]}, {plugin_module, mod_event_pusher_push_plugin_defaults} ]} ]} ]}","title":"Example configuration"},{"location":"modules/mod_event_pusher_rabbit/","text":"Current status This module is still in an experimental phase. Module Description This module is a backend of mod_event_pusher that enables support for the RabbitMQ integration. Currently there are 5 available notifications: user presence changed - Carries the user id (full jid by default) and a boolean field corresponding to the current user online status. private message sent/received - Carries the user ids (both sender and receiver) along with the message body. group message sent/received - Carries the user id and the room id (full jids by default) along with the message body. All these notifications are sent as JSON strings to RabbitMQ exchanges. Type of exchanges can be chosen as desired. Each type of the notifications is sent to its dedicated exchange. There are three exchanges created on startup of the module, for presences, private messages and group chat messages related events. Messages are published to a RabbitMQ server with routing key being set to a user bare jid ( user@domain ) and configurable topic e.g alice@localhost.private_message_sent . The module requires rabbit pool of AMQP connections to be configured in order to make the module work. It's well advised to read through Advanced configuration/Outgoing connections section before enabling the module. Options presence_exchange - Defines presence exchange options, such as: name - (string, default: <<\"presence\">> ) - Defines RabbitMQ presence exchange name; type (string, default: <<\"topic\">> ) - Defines RabbitMQ presence exchange type; chat_msg_exchange - Defines chat message exchange options, such as: name - (string, default: <<\"chat_msg\">> ) - Defines RabbitMQ chat message exchange name; type (string, default: <<\"topic\">> ) - Defines RabbitMQ chat message exchange type; sent_topic - (string, default: <<\"chat_msg_sent\">> ) - Defines RabbitMQ chat message sent topic name; recv_topic - (string, default: <<\"chat_msg_recv\">> ) - Defines RabbitMQ chat message received topic name; groupchat_msg_exchange - Defines group chat message exchange options, such as: name - (string, default: <<\"groupchat_msg\">> ) - Defines RabbitMQ group chat message exchange name; type (string, default: <<\"topic\">> ) - Defines RabbitMQ group chat message exchange type; sent_topic (string, default: <<\"groupchat_msg_sent\">> ) - Defines RabbitMQ group chat message sent topic name; recv_topic (string, default: <<\"groupchat_msg_recv\">> ) - Defines RabbitMQ group chat message received topic name; Example configuration {mod_event_pusher, [ {backends, [ {rabbit, [ {presence_exchange, [{name, <<\"presence\">>}, {type, <<\"topic\">>}]}, {chat_msg_exchange, [{name, <<\"chat_msg\">>}, {sent_topic, <<\"chat_msg_sent\">>}, {recv_topic, <<\"chat_msg_recv\">>}]}, {groupchat_msg_exchange, [{name, <<\"groupchat_msg\">>}, {sent_topic, <<\"groupchat_msg_sent\">>}, {recv_topic, <<\"groupchat_msg_recv\">>}]} ]} ]} ]} JSON Schema examples The different kinds of notifications deliver slightly different messages. The messages are delivered in a JSON format. Presence updates The JSON format for an online presence update notification is: { \"user_id\": \"alice@localhost/res1\", \"present\": true } For offline presence updates, the present boolean value is set to false: { \"user_id\": \"alice@localhost/res1\", \"present\": false } Sent/received messages The JSON format for a private message notification is: { \"to_user_id\": \"bob@localhost/res1\", \"message\": \"Hello, Bob\", \"from_user_id\": \"alice@localhost/res1\" } The notification is similar for group messages. For example for \"sent\" events: { \"to_user_id\": \"muc_publish@muc.localhost\", \"message\": \"Hi, Everyone!\", \"from_user_id\": \"bob@localhost/res1\" } and for \"received\" events: { \"to_user_id\": \"bob@localhost/res1\", \"message\": \"Hi, Everyone!\", \"from_user_id\": \"muc_publish@muc.localhost/alice\" } Metrics The module provides some metrics related to RabbitMQ connections and messages as well. Provided metrics: name type description (when it gets incremented/decremented) [ Host , connections_active ] spiral A connection to a RabbitMQ server is opened(+1)/closed(-1). [ Host , connections_opened ] spiral A connection to a RabbitMQ server is opened. [ Host , connections_closed ] spiral A connection to a RabbitMQ server is closed. [ Host , connection_failed ] spiral A try to open a connection to a RabbitMQ server failed. [ Host , messages_published ] spiral A message to a RabbitMQ server is published. [ Host , messages_failed ] spiral A message to a RabbitMQ server is rejected. [ Host , messages_timeout ] spiral A message to a RabbitMQ server timed out (weren't confirmed by the server). [ Host , message_publish_time ] histogram Amount of time it takes to publish a message to a RabbitMQ server and receive a confirmation. It's measured only for successful messages. [ Host , message_payload_size ] histogram Size of a message (in bytes) that was published to a RabbitMQ server (including message properties). It's measured only for successful messages. All the above metrics have a prefix which looks as follows: <xmpp_host>.backends.mod_event_pusher_rabbit.<metric_name> . For example a proper metric name would look like: localhost.backends.mod_event_pusher_rabbit.connections_active Guarantees There are no guarantees. The current implementation uses \"best effort\" approach which means that we don't care if a message is delivered to a RabbitMQ server. If publisher confirms are enabled and a message couldn't be delivered to the server for some reason (the server sent negative acknowledgment/didn't sent it at all or there was a channel exception) the module just updates appropriate metrics and prints some log messages. Notice that there might be situations when a message silently gets lost. Type of exchanges By default all the exchanges used are of type topic . Using topic exchanges gives a lot of flexibility when binding queues to such an exchange by using # and * in binding keys. But flexibility comes at the cost of performance - imagine a scenario where there are thousands of users and AMQP consumers use binding keys for particular users which look like user_N@host.# . In such case RabbitMQ has to go through all the users in order to find out where a message should be sent to. This operations is proved to be costly. In a load test with 100k users a delay caused by this operation was substantial (about an order of magnitude higher than compared to a load test with 60k users). If performance is a top priority go for direct exchanges. Using this type of exchanges is proved to work efficiently with 100k users. Keep in mind it gives up flexibility over performance. Publisher confirms By default publisher confirmations are disabled. However, one-to-one confirmations can be enabled (see RabbitMQ connection setup section). When a worker sends a message to a RabbitMQ server it waits for a confirmation from the server before it starts to process next message. This approach allows to introduce backpressure on a RabbitMQ server connection cause the server can reject/not confirm messages when it's overloaded. On the other hand it can cause performance degradation. Worker selection strategy The module uses mongoose_wpool for managing worker processes and best_worker strategy, for choosing a worker, is in use by default. Different strategies imply different behaviors of the system. Event messages queuing When available_worker strategy is in use all the event messages are queued in single worker pool manager process state. When different strategy is set e.g best_worker those messages are placed in worker processes inboxes. Worker selection strategy can be set in rabbit pool configuration. Event messages ordering None of worker selection strategies ensures that user events will be delivered to a RabbitMQ server properly ordered in time.","title":"RabbitMQ backend"},{"location":"modules/mod_event_pusher_rabbit/#current-status","text":"This module is still in an experimental phase.","title":"Current status"},{"location":"modules/mod_event_pusher_rabbit/#module-description","text":"This module is a backend of mod_event_pusher that enables support for the RabbitMQ integration. Currently there are 5 available notifications: user presence changed - Carries the user id (full jid by default) and a boolean field corresponding to the current user online status. private message sent/received - Carries the user ids (both sender and receiver) along with the message body. group message sent/received - Carries the user id and the room id (full jids by default) along with the message body. All these notifications are sent as JSON strings to RabbitMQ exchanges. Type of exchanges can be chosen as desired. Each type of the notifications is sent to its dedicated exchange. There are three exchanges created on startup of the module, for presences, private messages and group chat messages related events. Messages are published to a RabbitMQ server with routing key being set to a user bare jid ( user@domain ) and configurable topic e.g alice@localhost.private_message_sent . The module requires rabbit pool of AMQP connections to be configured in order to make the module work. It's well advised to read through Advanced configuration/Outgoing connections section before enabling the module.","title":"Module Description"},{"location":"modules/mod_event_pusher_rabbit/#options","text":"presence_exchange - Defines presence exchange options, such as: name - (string, default: <<\"presence\">> ) - Defines RabbitMQ presence exchange name; type (string, default: <<\"topic\">> ) - Defines RabbitMQ presence exchange type; chat_msg_exchange - Defines chat message exchange options, such as: name - (string, default: <<\"chat_msg\">> ) - Defines RabbitMQ chat message exchange name; type (string, default: <<\"topic\">> ) - Defines RabbitMQ chat message exchange type; sent_topic - (string, default: <<\"chat_msg_sent\">> ) - Defines RabbitMQ chat message sent topic name; recv_topic - (string, default: <<\"chat_msg_recv\">> ) - Defines RabbitMQ chat message received topic name; groupchat_msg_exchange - Defines group chat message exchange options, such as: name - (string, default: <<\"groupchat_msg\">> ) - Defines RabbitMQ group chat message exchange name; type (string, default: <<\"topic\">> ) - Defines RabbitMQ group chat message exchange type; sent_topic (string, default: <<\"groupchat_msg_sent\">> ) - Defines RabbitMQ group chat message sent topic name; recv_topic (string, default: <<\"groupchat_msg_recv\">> ) - Defines RabbitMQ group chat message received topic name;","title":"Options"},{"location":"modules/mod_event_pusher_rabbit/#example-configuration","text":"{mod_event_pusher, [ {backends, [ {rabbit, [ {presence_exchange, [{name, <<\"presence\">>}, {type, <<\"topic\">>}]}, {chat_msg_exchange, [{name, <<\"chat_msg\">>}, {sent_topic, <<\"chat_msg_sent\">>}, {recv_topic, <<\"chat_msg_recv\">>}]}, {groupchat_msg_exchange, [{name, <<\"groupchat_msg\">>}, {sent_topic, <<\"groupchat_msg_sent\">>}, {recv_topic, <<\"groupchat_msg_recv\">>}]} ]} ]} ]}","title":"Example configuration"},{"location":"modules/mod_event_pusher_rabbit/#json-schema-examples","text":"The different kinds of notifications deliver slightly different messages. The messages are delivered in a JSON format.","title":"JSON Schema examples"},{"location":"modules/mod_event_pusher_rabbit/#presence-updates","text":"The JSON format for an online presence update notification is: { \"user_id\": \"alice@localhost/res1\", \"present\": true } For offline presence updates, the present boolean value is set to false: { \"user_id\": \"alice@localhost/res1\", \"present\": false }","title":"Presence updates"},{"location":"modules/mod_event_pusher_rabbit/#sentreceived-messages","text":"The JSON format for a private message notification is: { \"to_user_id\": \"bob@localhost/res1\", \"message\": \"Hello, Bob\", \"from_user_id\": \"alice@localhost/res1\" } The notification is similar for group messages. For example for \"sent\" events: { \"to_user_id\": \"muc_publish@muc.localhost\", \"message\": \"Hi, Everyone!\", \"from_user_id\": \"bob@localhost/res1\" } and for \"received\" events: { \"to_user_id\": \"bob@localhost/res1\", \"message\": \"Hi, Everyone!\", \"from_user_id\": \"muc_publish@muc.localhost/alice\" }","title":"Sent/received messages"},{"location":"modules/mod_event_pusher_rabbit/#metrics","text":"The module provides some metrics related to RabbitMQ connections and messages as well. Provided metrics: name type description (when it gets incremented/decremented) [ Host , connections_active ] spiral A connection to a RabbitMQ server is opened(+1)/closed(-1). [ Host , connections_opened ] spiral A connection to a RabbitMQ server is opened. [ Host , connections_closed ] spiral A connection to a RabbitMQ server is closed. [ Host , connection_failed ] spiral A try to open a connection to a RabbitMQ server failed. [ Host , messages_published ] spiral A message to a RabbitMQ server is published. [ Host , messages_failed ] spiral A message to a RabbitMQ server is rejected. [ Host , messages_timeout ] spiral A message to a RabbitMQ server timed out (weren't confirmed by the server). [ Host , message_publish_time ] histogram Amount of time it takes to publish a message to a RabbitMQ server and receive a confirmation. It's measured only for successful messages. [ Host , message_payload_size ] histogram Size of a message (in bytes) that was published to a RabbitMQ server (including message properties). It's measured only for successful messages. All the above metrics have a prefix which looks as follows: <xmpp_host>.backends.mod_event_pusher_rabbit.<metric_name> . For example a proper metric name would look like: localhost.backends.mod_event_pusher_rabbit.connections_active","title":"Metrics"},{"location":"modules/mod_event_pusher_rabbit/#guarantees","text":"There are no guarantees. The current implementation uses \"best effort\" approach which means that we don't care if a message is delivered to a RabbitMQ server. If publisher confirms are enabled and a message couldn't be delivered to the server for some reason (the server sent negative acknowledgment/didn't sent it at all or there was a channel exception) the module just updates appropriate metrics and prints some log messages. Notice that there might be situations when a message silently gets lost.","title":"Guarantees"},{"location":"modules/mod_event_pusher_rabbit/#type-of-exchanges","text":"By default all the exchanges used are of type topic . Using topic exchanges gives a lot of flexibility when binding queues to such an exchange by using # and * in binding keys. But flexibility comes at the cost of performance - imagine a scenario where there are thousands of users and AMQP consumers use binding keys for particular users which look like user_N@host.# . In such case RabbitMQ has to go through all the users in order to find out where a message should be sent to. This operations is proved to be costly. In a load test with 100k users a delay caused by this operation was substantial (about an order of magnitude higher than compared to a load test with 60k users). If performance is a top priority go for direct exchanges. Using this type of exchanges is proved to work efficiently with 100k users. Keep in mind it gives up flexibility over performance.","title":"Type of exchanges"},{"location":"modules/mod_event_pusher_rabbit/#publisher-confirms","text":"By default publisher confirmations are disabled. However, one-to-one confirmations can be enabled (see RabbitMQ connection setup section). When a worker sends a message to a RabbitMQ server it waits for a confirmation from the server before it starts to process next message. This approach allows to introduce backpressure on a RabbitMQ server connection cause the server can reject/not confirm messages when it's overloaded. On the other hand it can cause performance degradation.","title":"Publisher confirms"},{"location":"modules/mod_event_pusher_rabbit/#worker-selection-strategy","text":"The module uses mongoose_wpool for managing worker processes and best_worker strategy, for choosing a worker, is in use by default. Different strategies imply different behaviors of the system.","title":"Worker selection strategy"},{"location":"modules/mod_event_pusher_rabbit/#event-messages-queuing","text":"When available_worker strategy is in use all the event messages are queued in single worker pool manager process state. When different strategy is set e.g best_worker those messages are placed in worker processes inboxes. Worker selection strategy can be set in rabbit pool configuration.","title":"Event messages queuing"},{"location":"modules/mod_event_pusher_rabbit/#event-messages-ordering","text":"None of worker selection strategies ensures that user events will be delivered to a RabbitMQ server properly ordered in time.","title":"Event messages ordering"},{"location":"modules/mod_event_pusher_sns/","text":"Module Description This module is a backend of mod_event_pusher that enables support for the Amazon SNS service. Currently there are 3 available notifications: user presence changed - Carries the user id (bare jid by default) and a boolean field corresponding to the current user online status. private message sent - Carries the user ids (both sender and receiver) along with the message body. group message sent - Carries the user id and the room id (bare jids by default) along with the message body. All these notifications are sent as a JSON string to Amazon SNS along with custom MessageAttributes (see http://docs.aws.amazon.com/sns/latest/api/API_Publish.html). MessageAttributes can be specified via a plugin module (more details in Options section). Full topics for notifications (ARN as defined in Amazon Resource Names ) are constructed as arn:aws:sns:{region}:{account_id}:{topic} where {region} and {account_id} are substituted with corresponding values from configuration options. {topic} is pulled from configuration option presence_updates_topic , pm_messages_topic or muc_messages_topic based on the notification type. Options presence_updates_topic (string, default: unset) - Defines Amazon SNS Topic for presence change notifications. Remove this option to disable these notifications. pm_messages_topic (string, default: unset) - Defines Amazon SNS Topic for private message notifications. Remove this option to disable these notifications. muc_messages_topic (string, default: unset) - Defines Amazon SNS Topic for group message notifications. Remove this option to disable these notifications. plugin_module (atom, default: 'mod_event_pusher_sns_defaults') - Sets a callback module used for creating user's GUID used in notifications (from user's JID) and for defining custom attributes attached to a published SNS message. muc_host (string, default: \"conference.@HOST@\") - Messages from this MUC host will be sent to the set SNS topic for MUCs. sns_host (string, default: unset) - URL to the Amazon SNS service. The URL may be in virtual host form , and for AWS needs to point at a specific regional endpoint. The scheme, port and path specified in the URL will be used to publish notifications via HTTP POST method. region (string, default: unset) - The AWS region to use for requests. access_key_id (string, default: unset) - ID of the access key to use for authorization. secret_access_key (string, default: unset) - Secret access key to use for authorization. account_id (string, default: unset) - 12 digit number as defined in AWS Account Identifiers to use for creating TopicArn for publishing notifications. pool_size (integer, default: 100) - Worker pool size for publishing notifications publish_retry_count (integer, default: 2) - Retry count in case of a publish error publish_retry_time_ms (integer, default: 50) - Base exponential backoff time (in ms) for publish errors Example configuration {mod_event_pusher, [ {backends, [ {sns, [ {access_key_id, \"AKIAIOSFODNN7EXAMPLE\"}, {secret_access_key, \"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\"}, {region, \"eu-west-1\"}, {account_id, \"123456789012\"}, {sns_host, \"sns.eu-west-1.amazonaws.com\"}, {plugin_module, mod_event_pusher_sns_defaults}, {presence_updates_topic, \"user_presence_updated\"}, {pm_messages_topic, \"user_message_sent\"}, {muc_messages_topic, \"user_messagegroup_sent\"}, {pool_size, 100}, {publish_retry_count, 2}, {publish_retry_time_ms, 50} ]} ]} ]} JSON Schema examples The different kinds of notifications deliver slightly different messages. The messages are delivered in a JSON format. Presence updates The JSON format for an online presence update notification is: { \"user_id\": \"alice@localhost\", \"present\": true } For offline presence updates, the present boolean value is set to false: { \"user_id\": \"alice@localhost\", \"present\": false } Sent messages The JSON format for a private message notification is: { \"to_user_id\": \"bob@localhost\", \"message\": \"Hello, Bob\", \"from_user_id\": \"alice@localhost\" } The notification is similar for group messages except that the to_user_id is the recipient room JID. For example: { \"to_user_id\": \"muc_publish@muc.localhost\", \"message\": \"Hi, Everyone!\", \"from_user_id\": \"bob@localhost\" }","title":"SNS backend"},{"location":"modules/mod_event_pusher_sns/#module-description","text":"This module is a backend of mod_event_pusher that enables support for the Amazon SNS service. Currently there are 3 available notifications: user presence changed - Carries the user id (bare jid by default) and a boolean field corresponding to the current user online status. private message sent - Carries the user ids (both sender and receiver) along with the message body. group message sent - Carries the user id and the room id (bare jids by default) along with the message body. All these notifications are sent as a JSON string to Amazon SNS along with custom MessageAttributes (see http://docs.aws.amazon.com/sns/latest/api/API_Publish.html). MessageAttributes can be specified via a plugin module (more details in Options section). Full topics for notifications (ARN as defined in Amazon Resource Names ) are constructed as arn:aws:sns:{region}:{account_id}:{topic} where {region} and {account_id} are substituted with corresponding values from configuration options. {topic} is pulled from configuration option presence_updates_topic , pm_messages_topic or muc_messages_topic based on the notification type.","title":"Module Description"},{"location":"modules/mod_event_pusher_sns/#options","text":"presence_updates_topic (string, default: unset) - Defines Amazon SNS Topic for presence change notifications. Remove this option to disable these notifications. pm_messages_topic (string, default: unset) - Defines Amazon SNS Topic for private message notifications. Remove this option to disable these notifications. muc_messages_topic (string, default: unset) - Defines Amazon SNS Topic for group message notifications. Remove this option to disable these notifications. plugin_module (atom, default: 'mod_event_pusher_sns_defaults') - Sets a callback module used for creating user's GUID used in notifications (from user's JID) and for defining custom attributes attached to a published SNS message. muc_host (string, default: \"conference.@HOST@\") - Messages from this MUC host will be sent to the set SNS topic for MUCs. sns_host (string, default: unset) - URL to the Amazon SNS service. The URL may be in virtual host form , and for AWS needs to point at a specific regional endpoint. The scheme, port and path specified in the URL will be used to publish notifications via HTTP POST method. region (string, default: unset) - The AWS region to use for requests. access_key_id (string, default: unset) - ID of the access key to use for authorization. secret_access_key (string, default: unset) - Secret access key to use for authorization. account_id (string, default: unset) - 12 digit number as defined in AWS Account Identifiers to use for creating TopicArn for publishing notifications. pool_size (integer, default: 100) - Worker pool size for publishing notifications publish_retry_count (integer, default: 2) - Retry count in case of a publish error publish_retry_time_ms (integer, default: 50) - Base exponential backoff time (in ms) for publish errors","title":"Options"},{"location":"modules/mod_event_pusher_sns/#example-configuration","text":"{mod_event_pusher, [ {backends, [ {sns, [ {access_key_id, \"AKIAIOSFODNN7EXAMPLE\"}, {secret_access_key, \"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\"}, {region, \"eu-west-1\"}, {account_id, \"123456789012\"}, {sns_host, \"sns.eu-west-1.amazonaws.com\"}, {plugin_module, mod_event_pusher_sns_defaults}, {presence_updates_topic, \"user_presence_updated\"}, {pm_messages_topic, \"user_message_sent\"}, {muc_messages_topic, \"user_messagegroup_sent\"}, {pool_size, 100}, {publish_retry_count, 2}, {publish_retry_time_ms, 50} ]} ]} ]}","title":"Example configuration"},{"location":"modules/mod_event_pusher_sns/#json-schema-examples","text":"The different kinds of notifications deliver slightly different messages. The messages are delivered in a JSON format.","title":"JSON Schema examples"},{"location":"modules/mod_event_pusher_sns/#presence-updates","text":"The JSON format for an online presence update notification is: { \"user_id\": \"alice@localhost\", \"present\": true } For offline presence updates, the present boolean value is set to false: { \"user_id\": \"alice@localhost\", \"present\": false }","title":"Presence updates"},{"location":"modules/mod_event_pusher_sns/#sent-messages","text":"The JSON format for a private message notification is: { \"to_user_id\": \"bob@localhost\", \"message\": \"Hello, Bob\", \"from_user_id\": \"alice@localhost\" } The notification is similar for group messages except that the to_user_id is the recipient room JID. For example: { \"to_user_id\": \"muc_publish@muc.localhost\", \"message\": \"Hi, Everyone!\", \"from_user_id\": \"bob@localhost\" }","title":"Sent messages"},{"location":"modules/mod_global_distrib/","text":"Module Description This module enables global distribution of a single XMPP domain. With mod_global_distrib , multiple distinct MongooseIM clusters can share a single domain name and route messages to the specific datacenter where the recipient is available. How it works There are multiple subsystems that cooperate to enable global distribution: Metadata sharing Sharing of metadata is done by leveraging a database with cross-datacenter replication. Currently, only Redis is supported, with Dynomite layer for replication. The most important metadata stored in the database is a session/routing table . The table stores mappings between currently logged users' JIDs and datacenters on which they are logged in. Because access to the session table is very frequent, its entries are additionally cached on each node. To preserve consistency between database instances, all data is stored with a set expiration time and is periodically refreshed. Each node of each cluster is responsible for refreshing its own data. Thus, in an event of a netsplit, datacenters' information about unreachable datacenters' users will expire, as those users are now unreachable; but once the connection is reestablished, the data will be replicated again as datacenters refresh their entries. Additionally, to prevent edge cases where an incoming message is received and replied to before the datacenter learns about the sender's host, an incoming message also carries information about its origin which may be used to temporarily update the local routing table. Redis entries Following structures are stored in Redis: JID mappings are stored as normal key-value entries, where user's JID (full and bare) is the key, and the value is the local hostname where the user is logged in. Example: \"user1@example.com/res\" -> \"dc2.example.com\" . Domains of components and services registered on the globally distributed host are stored in per-node set structures where the key is <local_host>#<node_name>#{domains} , and the values are the domain names. Example: \"dc1.example.com#mongoose1@dc1.example.com#{domains}\" -> {\"muc1.example.com\", \"muc2.example.com\"} . Domains of non-hidden components and services (see ejabberd_service documentation) are stored in per-node set structures where the key is <local_host>#<node_name>#{public_domains} , and the values are the domain names. Declared endpoints available on a node are similarly stored in a per-node set structure where the key is <local_host>#<node_name>#{endpoints} and the values represent the TCP endpoints of the node. Example: \"dc1.example.com#mongoose1@dc1.example.com#{endpoints}\" -> {\"172.16.2.14#8231\", \"2001:0db8:85a3:0000:0000:8a2e:0370:7334#8882\"} . Nodes that comprise a host are stored in a set structure with key <local_host>#{nodes} and values being the names of the nodes. Example: \"dc2.example.com#{nodes}\" -> {\"node1@dc2.example.com\", \"node3@dc2.example.com\"} . Hosts are stored in a set with key hosts and values being the individual local XMPP domains. Example: \"hosts\" -> {\"dc1.example.com\", \"dc2.example.com\"} . Message routing mod_global_distrib establishes its own listeners and dedicated TCP/TLS connections for message routing. Each node listens on preconfigured endpoints, where each node in a datacenter can have any number of endpoints, including none. The endpoints are shared between all datacenters. If a node becomes unavailable, its endpoint entries in the database will expire and will be readded once the node comes back online. Connections between nodes in distinct datacenters are opened on the first request and then maintained as long as the destination endpoint is present in Redis. When a node needs to connect to a remote cluster, specified number of connections are opened to every endpoint reported by that datacenter. Global distribution features automatic rebalancing feature that will \"disable\" connections when their respective endpoints disappear from Redis. A new pool of connections is created each time a new endpoint is recognised. Whenever a node receives a message that is determined (by consulting the session table) to be destined for another datacenter, the routing procedure in the current datacenter is interrupted, the message is transported to the other datacenter via the dedicated connections, and the routing procedure is restarted there by a dedicated (but potentially short lived) worker process bound to the sender's JID (or subdomain if the sender's JIDs does not belong to the globally distributed domain). Client's process binds itself to a connection to a remote datacenter on first use, and henceforth always uses this connection to route messages directed to this datacenter. This - along with the dedicated worker process on the receiver's side - ensures that simple cross-datacenter messages between two entities are delivered in their sending order. It may happen that a message is rerouted through multiple datacenters (e.g. if the user has reconnected to a different datacenter while the message was already in flight). Messages are given a TTL parameter by the source datacenter so that they cannot be rerouted indefinitely. The TTL is decreased on each reroute. Note that in the edge case of multi-datacenter routing, the messages may be received out-of-order at the destination datacenter. Bounce Consider the following edge case: user U1 logged into datacenter DC2 quickly reconnects to datacenter DC3 . Because session table has not yet been replicated, DC2 does not see U1 in the session table, while a different datacenter DC1 still sees U1 logged into DC2 . When U2 , logged into DC1 , sends a message to U1 , it will now be rerouted to DC2 even though the user is now available at DC3 . Bounce mechanism solves this and similar edge cases by storing messages for which there is no known routing in the current datacenter. The stored messages are then assigned a bounce-TTL value and periodically - with backoff - are attempted to be routed again. In the example above, the message from U2 would be temporarily stored at DC2 and rerouted successfully once DC2 learns (via replication) that U1 is available at DC3 . Note: bounce mechanism, similarly to multi-datacenter routing, may result in out-of-order messages being received at the destination datacenter. Metrics Global distribution modules expose several per-datacenter metrics that can be used to monitor health of the system. All metrics begin with global.mod_global_distrib prefix: outgoing.messages.<host> : number of cross-datacenter messages sent by this cluster to a given host. incoming.messages.<host> : number of cross-datacenter messages received by this cluster from a given host. incoming.transfer_time.<host> [us] : time elapsed between sending and receiving the message over the network from a given host. The duration is calculated using wall clock times on sender and receiver node. outgoing.queue_time.<host> [us] : time elapsed while message waits in a queue of a sender's connection to a given host. High value of this metric may be remedied by increasing the number of connections to other hosts. incoming.queue_time [us] : time elapsed while message waits in routing worker's queue. This value is not reported per-host as routing workers are bound to the sender's JID. incoming.established : incremented when a new connection is established from another cluster. At this point the origin domain of the cluster is not known, so this metric is common for all of them. incoming.first_packet.<host> : incremented when a receiver process gets the first packet from a remote cluster and learns its local domain. incoming.closed.<host> : incremented when an incoming connection gets closed. incoming.errored.<host> : incremented when an incoming connection gets closed with an error. outgoing.established.<host> : incremented when an outgoing connection is established. outgoing.closed.<host> : incremented when an outgoing connection gets closed. outgoing.errored.<host> : incremented when an outgoing connection gets closed with an error. mapping_fetch_time [us] : time spent on fetching an entry from the session table, cached or otherwise. mapping_fetches : number of fetches of session table entries, cached or otherwise. mapping_cache_misses : number of fetches of session table entries that hit the database. delivered_with_ttl : A histogram of packets' TTL values recorded when the global routing layer decides to route them locally (but not due to TTL = 0). stop_ttl_zero : A number of packets that weren't processed by global routing due to TTL=0. bounce_queue_size : a number of messages enqueued for rerouting (the value of this metric is individual per MongooseIM node!). Notes You should only start mod_global_distrib by configuring it under modules option in mongooseim.cfg . Do not add it as host-specific module via host_config . Do not use mod_offline on domains given via global_host or local_host options, as it will decrease messaging robustness; the users logged in other datacenters will not be registered as available by mod_offline , and so the messages will not be flushed. Options global_host (string, required): The XMPP domain that will be shared between datacenters. Note: this needs to be one of the domains given in host option in mongooseim.cfg . local_host (string, required): XMPP domain that maps uniquely to the local datacenter; it will be used for inter-center routing. Note: this needs to be one of the domains given in host option in mongooseim.cfg . message_ttl (integer, default: 4 ): Number of times a message can be rerouted between datacenters. connections (list, default: [] ): Options for connections maintained by the module; see Connections' options section. cache (list, default: [] ): Options for caching database lookups; see Database cache options section. bounce (list | false , default: [] ): Options for message bouncing; if false , message bouncing is disabled. See Message bouncing options section. redis (list, default: [] ): Options for Redis session storage backend. hosts_refresh_interval (integer, default: 3000) - The interval (in milliseconds) telling how often Redis should be asked if new hosts appeared. Connections' options endpoints (list, default: [{LocalHost, 5555}] ): A list of {Host, Port} tuples on which the server will listen for connections. Host can be given as a hostname, in which case it will be resolved to an IP address before first on module start. The endpoint list will be shared with other datacenters via the replicated backend. advertised_endpoints (list | false, default: false): A list of {Host, Port} tuples which will be advertised in Redis and therefore used to establish connection with this node by other nodes. If not specified, endpoints value (after resolution) is considered advertised_endpoints . The host may be either IP or domain, just like in case of endpoints. The difference is, the domain name won't be resolved but inserted directly to the mappings backend instead. connections_per_endpoint (integer, default: 1 ): Number of outgoing connections that will be established from the current node to each endpoint assigned to a remote domain. endpoint_refresh_interval (seconds, default: 60 ): An interval between remote endpoint list refresh (and connection rebalancing). A separate timer is maintained for every remote domain. disabled_gc_interval (seconds, default: 60 ): An interval between disabled endpoints \"garbage collection\". It means that disabled endpoints are periodically verified and if Global Distribution detects that connections is no longer alive, the connection pool is closed completely. tls_opts (list, required): Options for TLS connections passed to the fast_tls driver. May be set to false , in which case all data will be sent via standard TCP connections. Otherwise, they should at least include certfile and cafile options. Redis session storage options pool (atom, default: global_distrib ): Name of the redis pool defined in outgoing pools . expire_after (integer, default: 120 ): Number of seconds after which a session entry written by this cluster will expire. refresh_after (integer, default: 60 ): Number of seconds after which session's expiration timer will be refreshed. Database cache options cache_missed (boolean, default: true ): Determines whether an internal session cache should cache lookup failures. When false , only successful database lookups will result in the value being cached. Changing this option has great negative impact on performance. domain_lifetime_seconds (integer, default: 600 ): How long should subdomain mappings be cached (e.g. muc.example.com -> datacenter1.test ). jid_lifetime_seconds (integer, default: 5 ): How long should full and bare JID mappings be cached (e.g. user1@example.com/res1 -> datacenter1.test ). max_jids (integer, default: 10000 ): The maximum number of JID entries that can be stored in cache at any point in time. Message bouncing options resend_after_ms (integer, default: 200 ): Time after which message will be resent in case of delivery error. max_retries (integer, default: 4 ): Number of times message delivery will be retried in case of errors. Global Distribution and Service Discovery mod_global_distrib extension relies on mod_disco 's option users_can_see_hidden_services , when provided. If it is not configured, the default value is true . mod_disco does not have to be enabled for mod_global_distrib to work, as this parameter is used only for processing Disco requests by Global Distribution. Overriding remote datacenter endpoints There may be cases when the endpoint list given via endpoints option does not accurately specify endpoints on which the node may be reached from other datacenters; e.g. in case the node is behind NAT, or in testing environment. The endpoints used for connection to a remote datacenter may be overridden by global option { {global_distrib_addr, Host}, [{IP, Port}] } . Example configuration Configuring mod_global_distrib {mod_global_distrib, [ {global_host, \"example.com\"}, {local_host, \"datacenter1.example.com\"}, {connections, [ {endpoints, [{\"172.16.0.2\", 5555}]}, {num_of_connections, 22}, {tls_opts, [ {certfile, \"/home/user/dc1.pem\"}, {cafile, \"/home/user/ca.pem\"} ]} ]}, {cache, [ {domain_lifetime_seconds, 60} ]}, {bounce, [ {resend_after_ms, 300}, {max_retries, 3} ]}, {redis, [ {pool, global_distrib} ]} ]} Overriding endpoints to a remote datacenter { {global_distrib_addr, \"datacenter2.example.com\"}, [{\"124.12.4.3\", 5556}, {\"182.172.23.55\", 5555}] }. Configuring Dynomite For more information about Dynomite configuration, consult Dynomite wiki . dyn_o_mite: datacenter: dc1 rack: rack1 dyn_listen: 172.16.0.3:8101 dyn_seeds: - 124.12.4.4:8101:rack1:dc2:1383429731 listen: 172.16.0.3:8102 servers: - 172.16.0.4:6379:1 tokens: '138342973' secure_server_option: datacenter pem_key_file: dynomite.pem data_store: 0 stats_listen: 0.0.0.0:22221 dyn_o_mite: datacenter: dc2 rack: rack1 dyn_listen: 124.12.4.4:8101 dyn_seeds: - 172.16.0.3:8101:rack1:dc1:1383429731 listen: 124.12.4.4:8102 servers: - 124.12.4.5:6379:1 tokens: '138342973' secure_server_option: datacenter pem_key_file: dynomite.pem data_store: 0 stats_listen: 0.0.0.0:22221","title":"mod_global_distrib"},{"location":"modules/mod_global_distrib/#module-description","text":"This module enables global distribution of a single XMPP domain. With mod_global_distrib , multiple distinct MongooseIM clusters can share a single domain name and route messages to the specific datacenter where the recipient is available.","title":"Module Description"},{"location":"modules/mod_global_distrib/#how-it-works","text":"There are multiple subsystems that cooperate to enable global distribution:","title":"How it works"},{"location":"modules/mod_global_distrib/#metadata-sharing","text":"Sharing of metadata is done by leveraging a database with cross-datacenter replication. Currently, only Redis is supported, with Dynomite layer for replication. The most important metadata stored in the database is a session/routing table . The table stores mappings between currently logged users' JIDs and datacenters on which they are logged in. Because access to the session table is very frequent, its entries are additionally cached on each node. To preserve consistency between database instances, all data is stored with a set expiration time and is periodically refreshed. Each node of each cluster is responsible for refreshing its own data. Thus, in an event of a netsplit, datacenters' information about unreachable datacenters' users will expire, as those users are now unreachable; but once the connection is reestablished, the data will be replicated again as datacenters refresh their entries. Additionally, to prevent edge cases where an incoming message is received and replied to before the datacenter learns about the sender's host, an incoming message also carries information about its origin which may be used to temporarily update the local routing table.","title":"Metadata sharing"},{"location":"modules/mod_global_distrib/#redis-entries","text":"Following structures are stored in Redis: JID mappings are stored as normal key-value entries, where user's JID (full and bare) is the key, and the value is the local hostname where the user is logged in. Example: \"user1@example.com/res\" -> \"dc2.example.com\" . Domains of components and services registered on the globally distributed host are stored in per-node set structures where the key is <local_host>#<node_name>#{domains} , and the values are the domain names. Example: \"dc1.example.com#mongoose1@dc1.example.com#{domains}\" -> {\"muc1.example.com\", \"muc2.example.com\"} . Domains of non-hidden components and services (see ejabberd_service documentation) are stored in per-node set structures where the key is <local_host>#<node_name>#{public_domains} , and the values are the domain names. Declared endpoints available on a node are similarly stored in a per-node set structure where the key is <local_host>#<node_name>#{endpoints} and the values represent the TCP endpoints of the node. Example: \"dc1.example.com#mongoose1@dc1.example.com#{endpoints}\" -> {\"172.16.2.14#8231\", \"2001:0db8:85a3:0000:0000:8a2e:0370:7334#8882\"} . Nodes that comprise a host are stored in a set structure with key <local_host>#{nodes} and values being the names of the nodes. Example: \"dc2.example.com#{nodes}\" -> {\"node1@dc2.example.com\", \"node3@dc2.example.com\"} . Hosts are stored in a set with key hosts and values being the individual local XMPP domains. Example: \"hosts\" -> {\"dc1.example.com\", \"dc2.example.com\"} .","title":"Redis entries"},{"location":"modules/mod_global_distrib/#message-routing","text":"mod_global_distrib establishes its own listeners and dedicated TCP/TLS connections for message routing. Each node listens on preconfigured endpoints, where each node in a datacenter can have any number of endpoints, including none. The endpoints are shared between all datacenters. If a node becomes unavailable, its endpoint entries in the database will expire and will be readded once the node comes back online. Connections between nodes in distinct datacenters are opened on the first request and then maintained as long as the destination endpoint is present in Redis. When a node needs to connect to a remote cluster, specified number of connections are opened to every endpoint reported by that datacenter. Global distribution features automatic rebalancing feature that will \"disable\" connections when their respective endpoints disappear from Redis. A new pool of connections is created each time a new endpoint is recognised. Whenever a node receives a message that is determined (by consulting the session table) to be destined for another datacenter, the routing procedure in the current datacenter is interrupted, the message is transported to the other datacenter via the dedicated connections, and the routing procedure is restarted there by a dedicated (but potentially short lived) worker process bound to the sender's JID (or subdomain if the sender's JIDs does not belong to the globally distributed domain). Client's process binds itself to a connection to a remote datacenter on first use, and henceforth always uses this connection to route messages directed to this datacenter. This - along with the dedicated worker process on the receiver's side - ensures that simple cross-datacenter messages between two entities are delivered in their sending order. It may happen that a message is rerouted through multiple datacenters (e.g. if the user has reconnected to a different datacenter while the message was already in flight). Messages are given a TTL parameter by the source datacenter so that they cannot be rerouted indefinitely. The TTL is decreased on each reroute. Note that in the edge case of multi-datacenter routing, the messages may be received out-of-order at the destination datacenter.","title":"Message routing"},{"location":"modules/mod_global_distrib/#bounce","text":"Consider the following edge case: user U1 logged into datacenter DC2 quickly reconnects to datacenter DC3 . Because session table has not yet been replicated, DC2 does not see U1 in the session table, while a different datacenter DC1 still sees U1 logged into DC2 . When U2 , logged into DC1 , sends a message to U1 , it will now be rerouted to DC2 even though the user is now available at DC3 . Bounce mechanism solves this and similar edge cases by storing messages for which there is no known routing in the current datacenter. The stored messages are then assigned a bounce-TTL value and periodically - with backoff - are attempted to be routed again. In the example above, the message from U2 would be temporarily stored at DC2 and rerouted successfully once DC2 learns (via replication) that U1 is available at DC3 . Note: bounce mechanism, similarly to multi-datacenter routing, may result in out-of-order messages being received at the destination datacenter.","title":"Bounce"},{"location":"modules/mod_global_distrib/#metrics","text":"Global distribution modules expose several per-datacenter metrics that can be used to monitor health of the system. All metrics begin with global.mod_global_distrib prefix: outgoing.messages.<host> : number of cross-datacenter messages sent by this cluster to a given host. incoming.messages.<host> : number of cross-datacenter messages received by this cluster from a given host. incoming.transfer_time.<host> [us] : time elapsed between sending and receiving the message over the network from a given host. The duration is calculated using wall clock times on sender and receiver node. outgoing.queue_time.<host> [us] : time elapsed while message waits in a queue of a sender's connection to a given host. High value of this metric may be remedied by increasing the number of connections to other hosts. incoming.queue_time [us] : time elapsed while message waits in routing worker's queue. This value is not reported per-host as routing workers are bound to the sender's JID. incoming.established : incremented when a new connection is established from another cluster. At this point the origin domain of the cluster is not known, so this metric is common for all of them. incoming.first_packet.<host> : incremented when a receiver process gets the first packet from a remote cluster and learns its local domain. incoming.closed.<host> : incremented when an incoming connection gets closed. incoming.errored.<host> : incremented when an incoming connection gets closed with an error. outgoing.established.<host> : incremented when an outgoing connection is established. outgoing.closed.<host> : incremented when an outgoing connection gets closed. outgoing.errored.<host> : incremented when an outgoing connection gets closed with an error. mapping_fetch_time [us] : time spent on fetching an entry from the session table, cached or otherwise. mapping_fetches : number of fetches of session table entries, cached or otherwise. mapping_cache_misses : number of fetches of session table entries that hit the database. delivered_with_ttl : A histogram of packets' TTL values recorded when the global routing layer decides to route them locally (but not due to TTL = 0). stop_ttl_zero : A number of packets that weren't processed by global routing due to TTL=0. bounce_queue_size : a number of messages enqueued for rerouting (the value of this metric is individual per MongooseIM node!).","title":"Metrics"},{"location":"modules/mod_global_distrib/#notes","text":"You should only start mod_global_distrib by configuring it under modules option in mongooseim.cfg . Do not add it as host-specific module via host_config . Do not use mod_offline on domains given via global_host or local_host options, as it will decrease messaging robustness; the users logged in other datacenters will not be registered as available by mod_offline , and so the messages will not be flushed.","title":"Notes"},{"location":"modules/mod_global_distrib/#options","text":"global_host (string, required): The XMPP domain that will be shared between datacenters. Note: this needs to be one of the domains given in host option in mongooseim.cfg . local_host (string, required): XMPP domain that maps uniquely to the local datacenter; it will be used for inter-center routing. Note: this needs to be one of the domains given in host option in mongooseim.cfg . message_ttl (integer, default: 4 ): Number of times a message can be rerouted between datacenters. connections (list, default: [] ): Options for connections maintained by the module; see Connections' options section. cache (list, default: [] ): Options for caching database lookups; see Database cache options section. bounce (list | false , default: [] ): Options for message bouncing; if false , message bouncing is disabled. See Message bouncing options section. redis (list, default: [] ): Options for Redis session storage backend. hosts_refresh_interval (integer, default: 3000) - The interval (in milliseconds) telling how often Redis should be asked if new hosts appeared.","title":"Options"},{"location":"modules/mod_global_distrib/#connections-options","text":"endpoints (list, default: [{LocalHost, 5555}] ): A list of {Host, Port} tuples on which the server will listen for connections. Host can be given as a hostname, in which case it will be resolved to an IP address before first on module start. The endpoint list will be shared with other datacenters via the replicated backend. advertised_endpoints (list | false, default: false): A list of {Host, Port} tuples which will be advertised in Redis and therefore used to establish connection with this node by other nodes. If not specified, endpoints value (after resolution) is considered advertised_endpoints . The host may be either IP or domain, just like in case of endpoints. The difference is, the domain name won't be resolved but inserted directly to the mappings backend instead. connections_per_endpoint (integer, default: 1 ): Number of outgoing connections that will be established from the current node to each endpoint assigned to a remote domain. endpoint_refresh_interval (seconds, default: 60 ): An interval between remote endpoint list refresh (and connection rebalancing). A separate timer is maintained for every remote domain. disabled_gc_interval (seconds, default: 60 ): An interval between disabled endpoints \"garbage collection\". It means that disabled endpoints are periodically verified and if Global Distribution detects that connections is no longer alive, the connection pool is closed completely. tls_opts (list, required): Options for TLS connections passed to the fast_tls driver. May be set to false , in which case all data will be sent via standard TCP connections. Otherwise, they should at least include certfile and cafile options.","title":"Connections' options"},{"location":"modules/mod_global_distrib/#redis-session-storage-options","text":"pool (atom, default: global_distrib ): Name of the redis pool defined in outgoing pools . expire_after (integer, default: 120 ): Number of seconds after which a session entry written by this cluster will expire. refresh_after (integer, default: 60 ): Number of seconds after which session's expiration timer will be refreshed.","title":"Redis session storage options"},{"location":"modules/mod_global_distrib/#database-cache-options","text":"cache_missed (boolean, default: true ): Determines whether an internal session cache should cache lookup failures. When false , only successful database lookups will result in the value being cached. Changing this option has great negative impact on performance. domain_lifetime_seconds (integer, default: 600 ): How long should subdomain mappings be cached (e.g. muc.example.com -> datacenter1.test ). jid_lifetime_seconds (integer, default: 5 ): How long should full and bare JID mappings be cached (e.g. user1@example.com/res1 -> datacenter1.test ). max_jids (integer, default: 10000 ): The maximum number of JID entries that can be stored in cache at any point in time.","title":"Database cache options"},{"location":"modules/mod_global_distrib/#message-bouncing-options","text":"resend_after_ms (integer, default: 200 ): Time after which message will be resent in case of delivery error. max_retries (integer, default: 4 ): Number of times message delivery will be retried in case of errors.","title":"Message bouncing options"},{"location":"modules/mod_global_distrib/#global-distribution-and-service-discovery","text":"mod_global_distrib extension relies on mod_disco 's option users_can_see_hidden_services , when provided. If it is not configured, the default value is true . mod_disco does not have to be enabled for mod_global_distrib to work, as this parameter is used only for processing Disco requests by Global Distribution.","title":"Global Distribution and Service Discovery"},{"location":"modules/mod_global_distrib/#overriding-remote-datacenter-endpoints","text":"There may be cases when the endpoint list given via endpoints option does not accurately specify endpoints on which the node may be reached from other datacenters; e.g. in case the node is behind NAT, or in testing environment. The endpoints used for connection to a remote datacenter may be overridden by global option { {global_distrib_addr, Host}, [{IP, Port}] } .","title":"Overriding remote datacenter endpoints"},{"location":"modules/mod_global_distrib/#example-configuration","text":"","title":"Example configuration"},{"location":"modules/mod_global_distrib/#configuring-mod_global_distrib","text":"{mod_global_distrib, [ {global_host, \"example.com\"}, {local_host, \"datacenter1.example.com\"}, {connections, [ {endpoints, [{\"172.16.0.2\", 5555}]}, {num_of_connections, 22}, {tls_opts, [ {certfile, \"/home/user/dc1.pem\"}, {cafile, \"/home/user/ca.pem\"} ]} ]}, {cache, [ {domain_lifetime_seconds, 60} ]}, {bounce, [ {resend_after_ms, 300}, {max_retries, 3} ]}, {redis, [ {pool, global_distrib} ]} ]}","title":"Configuring mod_global_distrib"},{"location":"modules/mod_global_distrib/#overriding-endpoints-to-a-remote-datacenter","text":"{ {global_distrib_addr, \"datacenter2.example.com\"}, [{\"124.12.4.3\", 5556}, {\"182.172.23.55\", 5555}] }.","title":"Overriding endpoints to a remote datacenter"},{"location":"modules/mod_global_distrib/#configuring-dynomite","text":"For more information about Dynomite configuration, consult Dynomite wiki . dyn_o_mite: datacenter: dc1 rack: rack1 dyn_listen: 172.16.0.3:8101 dyn_seeds: - 124.12.4.4:8101:rack1:dc2:1383429731 listen: 172.16.0.3:8102 servers: - 172.16.0.4:6379:1 tokens: '138342973' secure_server_option: datacenter pem_key_file: dynomite.pem data_store: 0 stats_listen: 0.0.0.0:22221 dyn_o_mite: datacenter: dc2 rack: rack1 dyn_listen: 124.12.4.4:8101 dyn_seeds: - 172.16.0.3:8101:rack1:dc1:1383429731 listen: 124.12.4.4:8102 servers: - 124.12.4.5:6379:1 tokens: '138342973' secure_server_option: datacenter pem_key_file: dynomite.pem data_store: 0 stats_listen: 0.0.0.0:22221","title":"Configuring Dynomite"},{"location":"modules/mod_http_upload/","text":"Module Description This module implements XEP-0363: HTTP File Upload . It enables a service that on user request creates an upload \"slot\". A slot is a pair of URLs, one of which can be used with a PUT method to upload user's file, the other with a GET method to retrieve the file. Currently, the module supports only the S3 backend using AWS Signature Version 4 . Options iqdisc (default: one_queue ) host (string, default: \"upload.@HOST@\" ): Subdomain for the upload service to reside under. @HOST@ is replaced with each served domain. backend (atom, default: s3 ) - Backend to use for generating slots. Currently only s3 can be used. expiration_time (integer, default: 60 ) - Duration (in seconds) after which the generated PUT URL will become invalid. token_bytes (integer, default: 32 ) - Number of random bytes of a token that will be used in a generated URL. The text representation of the token will be twice as long as the number of bytes, e.g. for the default value the token in URL will be 64 characters long. max_file_size (integer, default: 10485760 (10 MB)) - Maximum file size (in bytes) accepted by the module. Disabled if set to undefined . s3 (list, default: unset) - Options specific to S3 backend. S3 backend options bucket_url (string, default: unset) - A complete URL pointing at the used bucket. The URL may be in virtual host form , and for AWS needs to point at a specific regional endpoint for the bucket. The scheme, port and path specified in the URL will be used to create PUT URLs for slots, e.g. specifying a value of \"https://s3-eu-west-1.amazonaws.com/mybucket/custom/prefix\" will result in PUT URLs of form \"https://s3-eu-west-1.amazonaws.com/mybucket/custom/prefix/<RANDOM_TOKEN>/<FILENAME>?<AUTHENTICATION_PARAMETERS>\" . add_acl (boolean, default: true ) - If true , adds x-amz-acl=public-read parameter to the PUT request. This allows users to read the uploaded files even if the bucket is private. region (string, default: unset) - The AWS region to use for requests. access_key_id (string, default: unset) - ID of the access key to use for authorization. secret_access_key (string, default: unset) - Secret access key to use for authorization. Example configuration {mod_http_upload, [ {host, \"upload.@HOST@\"}, {backend, s3}, {expiration_time, 120}, {s3, [ {bucket_url, \"https://s3-eu-west-1.amazonaws.com/mybucket\"}, {region, \"eu-west-1\"}, {access_key_id, \"AKIAIOSFODNN7EXAMPLE\"}, {secret_access_key, \"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\"} ]} ]}. Metrics If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Backend action Description (when it gets incremented) create_slot An upload slot is allocated.","title":"mod_http_upload"},{"location":"modules/mod_http_upload/#module-description","text":"This module implements XEP-0363: HTTP File Upload . It enables a service that on user request creates an upload \"slot\". A slot is a pair of URLs, one of which can be used with a PUT method to upload user's file, the other with a GET method to retrieve the file. Currently, the module supports only the S3 backend using AWS Signature Version 4 .","title":"Module Description"},{"location":"modules/mod_http_upload/#options","text":"iqdisc (default: one_queue ) host (string, default: \"upload.@HOST@\" ): Subdomain for the upload service to reside under. @HOST@ is replaced with each served domain. backend (atom, default: s3 ) - Backend to use for generating slots. Currently only s3 can be used. expiration_time (integer, default: 60 ) - Duration (in seconds) after which the generated PUT URL will become invalid. token_bytes (integer, default: 32 ) - Number of random bytes of a token that will be used in a generated URL. The text representation of the token will be twice as long as the number of bytes, e.g. for the default value the token in URL will be 64 characters long. max_file_size (integer, default: 10485760 (10 MB)) - Maximum file size (in bytes) accepted by the module. Disabled if set to undefined . s3 (list, default: unset) - Options specific to S3 backend.","title":"Options"},{"location":"modules/mod_http_upload/#s3-backend-options","text":"bucket_url (string, default: unset) - A complete URL pointing at the used bucket. The URL may be in virtual host form , and for AWS needs to point at a specific regional endpoint for the bucket. The scheme, port and path specified in the URL will be used to create PUT URLs for slots, e.g. specifying a value of \"https://s3-eu-west-1.amazonaws.com/mybucket/custom/prefix\" will result in PUT URLs of form \"https://s3-eu-west-1.amazonaws.com/mybucket/custom/prefix/<RANDOM_TOKEN>/<FILENAME>?<AUTHENTICATION_PARAMETERS>\" . add_acl (boolean, default: true ) - If true , adds x-amz-acl=public-read parameter to the PUT request. This allows users to read the uploaded files even if the bucket is private. region (string, default: unset) - The AWS region to use for requests. access_key_id (string, default: unset) - ID of the access key to use for authorization. secret_access_key (string, default: unset) - Secret access key to use for authorization.","title":"S3 backend options"},{"location":"modules/mod_http_upload/#example-configuration","text":"{mod_http_upload, [ {host, \"upload.@HOST@\"}, {backend, s3}, {expiration_time, 120}, {s3, [ {bucket_url, \"https://s3-eu-west-1.amazonaws.com/mybucket\"}, {region, \"eu-west-1\"}, {access_key_id, \"AKIAIOSFODNN7EXAMPLE\"}, {secret_access_key, \"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\"} ]} ]}.","title":"Example configuration"},{"location":"modules/mod_http_upload/#metrics","text":"If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Backend action Description (when it gets incremented) create_slot An upload slot is allocated.","title":"Metrics"},{"location":"modules/mod_inbox/","text":"Module Description Inbox is an experimental feature implemented as a few separate modules. To use it, enable mod_inbox in the config file. Options backend (atom, default: rdbms ) - Database backend to use. For now, only rdbms is supported. reset_markers (list, default: [displayed] ) - List of atom chat markers that when sent, will reset the unread message counter for a conversation. This works when Chat Markers are enabled on the client side. Possible values are from the set: displayed , received , acknowledged . Setting as empty list (not recommended) means that no chat marker can decrease the counter value. groupchat (list, default: [muclight] ) - The list indicating which groupchats will be included in inbox. Possible values are muclight Multi-User Chat Light or muc Multi-User Chat . aff_changes (boolean, default: true ) - use this option when muclight is enabled. Indicates if MUC Light affiliation change messages should be included in the conversation inbox. Only changes that affect the user directly will be stored in their inbox. remove_on_kicked (boolean, default: true ) - use this option when muclight is enabled. If true, the inbox conversation is removed for a user when they are removed from the groupchat. iqdisc (atom, default: no_queue ) Note about supported RDBMS mod_inbox executes upsert queries, which have different syntax in every supported RDBMS. Inbox currently supports the following DBs: MySQL via native driver PgSQL via native driver MSSQL via ODBC driver Legacy MUC support Inbox comes with support for the legacy MUC as well. It stores all groupchat messages sent to room in each sender's and recipient's inboxes and private messages. Currently it is not possible to configure it to store system messages like subject or affiliation change. Filtering and ordering Inbox query results may be filtered by time range and sorted by timestamp. By default, mod_inbox returns all conversations, listing the ones updated most recently first. A client may specify three parameters: Start date for the result set (variable start , value: ISO timestamp) End date for the result set (variable end , value: ISO timestamp) Order by timestamp (variable order , values: asc , desc ) Show only conversations with unread messages (variable hidden_read , values: true , false ) They are encoded inside a standard XMPP Data Forms format. Dates must be formatted according to XMPP Date and Time Profiles . It is not mandatory to add an empty data form if a client prefers to use default values ( <query/> element may be empty). However, the IQ type must be \"set\", even when data form is missing. Your client application may request the currently supported form with IQ get: Client: <iq type='get' id='c94a88ddf4957128eafd08e233f4b964'> <query xmlns='erlang-solutions.com:xmpp:inbox:0'/> </iq> Server: <iq from='alicE@localhost' to='alicE@localhost/res1' id='c94a88ddf4957128eafd08e233f4b964' type='result'> <query xmlns='erlang-solutions.com:xmpp:inbox:0'> <x xmlns='jabber:x:data' type='form'> <field type='hidden' var='FORM_TYPE'><value>erlang-solutions.com:xmpp:inbox:0</value></field> <field var='start' type='text-single'/> <field var='end' type='text-single'/> <field var='order' type='list-single'> <value>desc</value> <option label='Ascending by timestamp'><value>asc</value></option> <option label='Descending by timestamp'><value>desc</value></option> </field> <field var='hidden_read' type='text-single' value='false'/> </x> </query> </iq> Reseting inbox You can reset the inbox with the following stanza: <iq type='set'> <reset xmlns='erlang-solutions.com:xmpp:inbox:0#conversation' jid='interlocutor_bare_jid'/> </iq> Here jid is the bare jid of the user whose inbox we want to reset. This action does not change the last message stored in inbox; meaning that neither this stanza nor anything given within will be stored; the only change is the inbox unread_count is set to zero. Resetting the inbox count will also skip the forwarding of messages. While a typical chat marker will be forwarded to the interlocutor(s), (including the case of a big groupchat with thousands of participants!), this reset stanza will not. Example Request Alice sends: <message type=\"chat\" to=\"bOb@localhost/res1\" id=\u201d123\u201d> <body>Hello</body> </message> Bob receives: <message from=\"alicE@localhost/res1\" to=\"bOb@localhost/res1\" id=\u201c123\u201d xml:lang=\"en\" type=\"chat\"> <body>Hello</body> </message> Alice sends: <iq type=\"set\" id=\"10bca\"> <inbox xmlns=\u201derlang-solutions.com:xmpp:inbox:0\u201d queryid=\"b6\"> <x xmlns='jabber:x:data' type='form'> <field type='hidden' var='FORM_TYPE'><value>erlang-solutions.com:xmpp:inbox:0</value></field> <field type='text-single' var='start'><value>2018-07-10T12:00:00Z</value></field> <field type='text-single' var='end'><value>2018-07-11T12:00:00Z</value></field> <field type='list-single' var='order'><value>asc</value></field> <field type='text-single' var='hidden_read'><value>true</value></field> </x> </inbox> </iq> Alice receives: <message from=\"alicE@localhost\" to=\"alicE@localhost\" id=\"9b759\"> <result xmlns=\"erlang-solutions.com:xmpp:inbox:0\" unread=\"0\" queryid=\"b6\"> <forwarded xmlns=\"urn:xmpp:forward:0\"> <delay xmlns=\"urn:xmpp:delay\" stamp=\"2018-07-10T23:08:25.123456Z\"/> <message xml:lang=\"en\" type=\"chat\" to=\"bOb@localhost/res1\" from=\"alicE@localhost/res1\" id=\u201d123\u201d> <body>Hello</body> </message> </forwarded> </result> </message> <iq from=\"alicE@localhost\" to=\"alicE@localhost/res1\" id=\"b6\" type=\"result\"> <fin xmlns='erlang-solutions.com:xmpp:inbox:0'> <count>1</count> <unread-messages>0</unread-messages> <active-conversations>0</active-conversations> </fin> </iq> Inbox query result IQ stanza returns the following values: count : the total number of conversations (if hidden_read value was set to true, this value will be equal to active_conversations ) unread-messages : total number of unread messages from all conversations active-conversations : the number of conversations with unread message(s) Example error response Alice sends request with invalid value of start field: <iq type='set' id='a78478f20103ff8354d7834d0ba2fdb2'> <inbox xmlns='erlang-solutions.com:xmpp:inbox:0'> <x xmlns='jabber:x:data' type='submit'> <field type='text-single' var='start'> <value>invalid</value> </field> </x> </inbox> </iq> Alice receives an error with description of the first encountered invalid value: <iq from='alicE@localhost' to='alicE@localhost/res1' id='a78478f20103ff8354d7834d0ba2fdb2' type='error'> <error code='400' type='modify'> <bad-rquest xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/> <text xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'> Invalid inbox form field value, field=start, value=invalid </text> </error> </iq> Example Configuration {mod_inbox, [{backend, rdbms}, {reset_markers, [displayed]}, {aff_changes, true}, {remove_on_kicked, true}, {groupchat, [muclight]} ]},","title":"mod_inbox"},{"location":"modules/mod_inbox/#module-description","text":"Inbox is an experimental feature implemented as a few separate modules. To use it, enable mod_inbox in the config file.","title":"Module Description"},{"location":"modules/mod_inbox/#options","text":"backend (atom, default: rdbms ) - Database backend to use. For now, only rdbms is supported. reset_markers (list, default: [displayed] ) - List of atom chat markers that when sent, will reset the unread message counter for a conversation. This works when Chat Markers are enabled on the client side. Possible values are from the set: displayed , received , acknowledged . Setting as empty list (not recommended) means that no chat marker can decrease the counter value. groupchat (list, default: [muclight] ) - The list indicating which groupchats will be included in inbox. Possible values are muclight Multi-User Chat Light or muc Multi-User Chat . aff_changes (boolean, default: true ) - use this option when muclight is enabled. Indicates if MUC Light affiliation change messages should be included in the conversation inbox. Only changes that affect the user directly will be stored in their inbox. remove_on_kicked (boolean, default: true ) - use this option when muclight is enabled. If true, the inbox conversation is removed for a user when they are removed from the groupchat. iqdisc (atom, default: no_queue )","title":"Options"},{"location":"modules/mod_inbox/#note-about-supported-rdbms","text":"mod_inbox executes upsert queries, which have different syntax in every supported RDBMS. Inbox currently supports the following DBs: MySQL via native driver PgSQL via native driver MSSQL via ODBC driver","title":"Note about supported RDBMS"},{"location":"modules/mod_inbox/#legacy-muc-support","text":"Inbox comes with support for the legacy MUC as well. It stores all groupchat messages sent to room in each sender's and recipient's inboxes and private messages. Currently it is not possible to configure it to store system messages like subject or affiliation change.","title":"Legacy MUC support"},{"location":"modules/mod_inbox/#filtering-and-ordering","text":"Inbox query results may be filtered by time range and sorted by timestamp. By default, mod_inbox returns all conversations, listing the ones updated most recently first. A client may specify three parameters: Start date for the result set (variable start , value: ISO timestamp) End date for the result set (variable end , value: ISO timestamp) Order by timestamp (variable order , values: asc , desc ) Show only conversations with unread messages (variable hidden_read , values: true , false ) They are encoded inside a standard XMPP Data Forms format. Dates must be formatted according to XMPP Date and Time Profiles . It is not mandatory to add an empty data form if a client prefers to use default values ( <query/> element may be empty). However, the IQ type must be \"set\", even when data form is missing. Your client application may request the currently supported form with IQ get: Client: <iq type='get' id='c94a88ddf4957128eafd08e233f4b964'> <query xmlns='erlang-solutions.com:xmpp:inbox:0'/> </iq> Server: <iq from='alicE@localhost' to='alicE@localhost/res1' id='c94a88ddf4957128eafd08e233f4b964' type='result'> <query xmlns='erlang-solutions.com:xmpp:inbox:0'> <x xmlns='jabber:x:data' type='form'> <field type='hidden' var='FORM_TYPE'><value>erlang-solutions.com:xmpp:inbox:0</value></field> <field var='start' type='text-single'/> <field var='end' type='text-single'/> <field var='order' type='list-single'> <value>desc</value> <option label='Ascending by timestamp'><value>asc</value></option> <option label='Descending by timestamp'><value>desc</value></option> </field> <field var='hidden_read' type='text-single' value='false'/> </x> </query> </iq>","title":"Filtering and ordering"},{"location":"modules/mod_inbox/#reseting-inbox","text":"You can reset the inbox with the following stanza: <iq type='set'> <reset xmlns='erlang-solutions.com:xmpp:inbox:0#conversation' jid='interlocutor_bare_jid'/> </iq> Here jid is the bare jid of the user whose inbox we want to reset. This action does not change the last message stored in inbox; meaning that neither this stanza nor anything given within will be stored; the only change is the inbox unread_count is set to zero. Resetting the inbox count will also skip the forwarding of messages. While a typical chat marker will be forwarded to the interlocutor(s), (including the case of a big groupchat with thousands of participants!), this reset stanza will not.","title":"Reseting inbox"},{"location":"modules/mod_inbox/#example-request","text":"Alice sends: <message type=\"chat\" to=\"bOb@localhost/res1\" id=\u201d123\u201d> <body>Hello</body> </message> Bob receives: <message from=\"alicE@localhost/res1\" to=\"bOb@localhost/res1\" id=\u201c123\u201d xml:lang=\"en\" type=\"chat\"> <body>Hello</body> </message> Alice sends: <iq type=\"set\" id=\"10bca\"> <inbox xmlns=\u201derlang-solutions.com:xmpp:inbox:0\u201d queryid=\"b6\"> <x xmlns='jabber:x:data' type='form'> <field type='hidden' var='FORM_TYPE'><value>erlang-solutions.com:xmpp:inbox:0</value></field> <field type='text-single' var='start'><value>2018-07-10T12:00:00Z</value></field> <field type='text-single' var='end'><value>2018-07-11T12:00:00Z</value></field> <field type='list-single' var='order'><value>asc</value></field> <field type='text-single' var='hidden_read'><value>true</value></field> </x> </inbox> </iq> Alice receives: <message from=\"alicE@localhost\" to=\"alicE@localhost\" id=\"9b759\"> <result xmlns=\"erlang-solutions.com:xmpp:inbox:0\" unread=\"0\" queryid=\"b6\"> <forwarded xmlns=\"urn:xmpp:forward:0\"> <delay xmlns=\"urn:xmpp:delay\" stamp=\"2018-07-10T23:08:25.123456Z\"/> <message xml:lang=\"en\" type=\"chat\" to=\"bOb@localhost/res1\" from=\"alicE@localhost/res1\" id=\u201d123\u201d> <body>Hello</body> </message> </forwarded> </result> </message> <iq from=\"alicE@localhost\" to=\"alicE@localhost/res1\" id=\"b6\" type=\"result\"> <fin xmlns='erlang-solutions.com:xmpp:inbox:0'> <count>1</count> <unread-messages>0</unread-messages> <active-conversations>0</active-conversations> </fin> </iq> Inbox query result IQ stanza returns the following values: count : the total number of conversations (if hidden_read value was set to true, this value will be equal to active_conversations ) unread-messages : total number of unread messages from all conversations active-conversations : the number of conversations with unread message(s)","title":"Example Request"},{"location":"modules/mod_inbox/#example-error-response","text":"Alice sends request with invalid value of start field: <iq type='set' id='a78478f20103ff8354d7834d0ba2fdb2'> <inbox xmlns='erlang-solutions.com:xmpp:inbox:0'> <x xmlns='jabber:x:data' type='submit'> <field type='text-single' var='start'> <value>invalid</value> </field> </x> </inbox> </iq> Alice receives an error with description of the first encountered invalid value: <iq from='alicE@localhost' to='alicE@localhost/res1' id='a78478f20103ff8354d7834d0ba2fdb2' type='error'> <error code='400' type='modify'> <bad-rquest xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/> <text xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'> Invalid inbox form field value, field=start, value=invalid </text> </error> </iq>","title":"Example error response"},{"location":"modules/mod_inbox/#example-configuration","text":"{mod_inbox, [{backend, rdbms}, {reset_markers, [displayed]}, {aff_changes, true}, {remove_on_kicked, true}, {groupchat, [muclight]} ]},","title":"Example Configuration"},{"location":"modules/mod_jingle_sip/","text":"Module Description This module enables Jingle to SIP and SIP to Jingle translation. When this module is enabled, MongooseIM will intercept any Jingle IQ set stanza with action: session-initiate session-terminate session-accept transport-info and translate it to SIP messages with appropriate SDP content based on the details in the Jingle stanza. The translation back from SIP to Jingle is done for the following SIP requests: INVITE re-INVITE - INVITE message sent for an accepted session CANCEL BYE INFO and following responses to the INVITE request: 200 when the call invite was accepted 180 and 183 to indicate that the invitation was sent to the device 486 when the call's recipient rejects it from 400 to 600 - other error codes indicating session termination Jingle to SIP translation The table below summarises the bilateral translation for standard Jingle and SIP messages: Jingle action SIP message comment session-initiate INVITE request session-accept 200 OK response session-terminate with reason success BYE request Only for accepted session session-terminate with reason decline CANCEL request When sent by call's initiator session-terminate with reason decline 486 Busy Here response When sent by the invite user transport-info INFO request Ringing notification Both Jingle and SIP have the ringing notification. It's generated as a response code 180 Ringing by a SIP entity when the INVITE is sent to the device. In SIP world a 183 Session Progress response code is also generated in some cases. Both 180 and 183 codes are translated as session-info Jingle stanza with ringing sub element. MongooseIM generates only 180 Ringing response code the INVITE request, if the recipient's online. If the recipient is online, MongooseIM generates the 180 Ringing response code to the INVITE request. Recipient unavailable When MongooseIM receives a SIP INVITE request addressed to an offline user, it replies with a 480 Temporarily Unavailable code. The same code is expected from the SIP Proxy when MongooseIM sends the INVITE request. Other error codes When an error response to the INVITE request is from the range 400 to 699 but not 486 , MongooseIM will send a Jingle session-terminate stanza to the call's initiator. The stanza has reason general-error with the SIP error code in the sip-error sub element. Non-standard Jingle stanzas used by jingle.js The following non-standard Jingle stanzas were integrated with https://github.com/softwarehutpl/jingle.js source-remove source-add source-update When MongooseIM observes the above Jingle stanzas, it will translate them to a SIP in-dialog INVITE request. In the SDP content of the request, there will be a custom attribute a=jingle-action . The value of the custom attribute is one of the three presented above. Similarly when MongooseIM gets a SIP in-dialog INVITE request, it will check if there is a custom attribute and use it as the action attribute of the Jingle stanza sent to the user. If there is no such attribute, the action will be set to regular Jingle transport-info . Non-stadard Jingle existing-session-initiate stanza MongooseIM allows a user to ask for an unanswered session-initiate request. This may be useful in web applications when there is a need to handle the call in a new browser window. In order to get the session-initiate , which was not answered yet, the user can send a get Jingle stanza to self with action set to existing-session-initiate . As a result, MongooseIM will resend the original session-initiate request to the device which sent the query. Prerequisites By default, MongooseIM is built without SIP support. In order to build the server with SIP support, please use tools/configure script before the release generation. You may either pick only certain drivers (with SIP included) or simply use with-all option. Examples: tools/configure with-mysql with-jingle-sip tools/configure with-all without-odbc tools/configure with-all MongooseIM packages are built with Jingle/SIP support. Options proxy_host (default: \"localhost\") name or IP address of the SIP Proxy to which MongooseIM will send SIP messages proxy_port (default: 5600) port of the SIP Proxy listen_port (default: 5600) the port on which MongooseIM will listen for incomming SIP messages local_host (default: \"localhost\") value used to create SIP URIs (including VIA headers) sdp_origin (default: \"127.0.0.1\") value of the c= SDP attribute The simplest configuration is the following: {mod_jingle_sip, []} With this configuration MongooseIM will try sending SIP messages to a SIP proxy listening on localhost and port 5060. Use cases covered by tests Currently to test the functionality we use a SIP Proxy mock written in Erlang. The following scenarios are covered by our tests in big_tests/tests/jingle_SUITE.erl All the sequence diagrams where generated with textart.io/sequence . The source code is embedded in the markdown file below every diagram inside a comment <!--- ---> 1. Establishing a session with another XMPP user With the mod_jingle_sip enabled, all Jingle IQ set stanzas listed above are intercepted, translated to SIP packets and sent to a SIP Proxy. This means that the current implementation will also translate stanzas addressed to a user in the same domain. This allows the SIP entity to control how the call between XMPP users is established. Below there are sequence diagrams showing the communication between XMPP users, MongooseIM and SIP Proxy as in our tests. It's possible that the SIP Proxy or other SIP entity decides that the call needs to be forked and delivered to the user's phone number instead of generating a corresponding call back to MongooseIM. 1.1 Signaling session-initiate to other XMPP user via SIP Proxy +-------+ +-------------+ +-----------+ +-------+ | UserA | | MongooseIM | | SIPProxy | | UserB | +-------+ +-------------+ +-----------+ +-------+ | | | | | session-initiate to UserB | | | |--------------------------------->| | | | -------------------------\\ | | | |-| Jingle stanza | | | | | | action:session-initate | | | | | | sid: 123 | | | | | |------------------------| | SIP INVITE | | | |------------------->| | | | -------------\\ | | | |-| from:UserA | | | | | | to:UserB | | | | | | sid: 123 | | | | | |------------| | create new call | | | |---------------- | | | | | | | | |<--------------- | | | | ------------------------\\ | | | |-| SDP content can be | | | | | | changed for instance | | | | | | to inject a transport | | | | SIP INVITE | | canidate | | | |<-------------------| |-----------------------| | | | -------------\\ | | | | | from:UserA |-| | | | | to:UserB | | | | --------------------\\ | | sid:456 | | | | | yes, new SID: 456 |-| |------------| | | | |-------------------| | | | | | | | | | session-initiate to UserB | | |------------------------------------------------->| | | | | 1.2 Signaling session-accept to other XMPP user via SIP Proxy When the other user accepts the call invite sent by the first, the following sequence is executed. This is a continuation of the previous example +-------+ +-------------+ +-----------+ +-------+ | UserA | | MongooseIM | | SIPProxy | | UserB | +-------+ +-------------+ +-----------+ +-------+ | | | | | | | session-accpet to UserA | | |<--------------------------------------------------| | | | ------------------------\\ | | | | | Jingle stanza |-| | | | | action:session-accept | | | | | | sid: 456 | | | | 200 OK | |-----------------------| | | |-------------------->| | | | --------------\\ | | | |-| from: UserA | | | | | | to: UserB | | | | | | sid: 456 | | | | | |-------------| | find corresponding call | | | |------------------------ | | | | | | | | |<----------------------- | | | | | | | 200 OK | | | |<--------------------| | | | --------------\\ | | | | | from: UserA |-| | | | | to: UserB | | | | | | sid: 123 | | | | session-accept from UserB | |-------------| | | |<---------------------------------| | | | | | | 1.3 Terminating a call Any Jingle session (accepted or not) can be terminated by sending a Jingle stanza with action session-terminate and a reason. In the SIP world it's more complex. See the following examples for more information. 1.3.1 Terminating an accepted call The easiest scenario is when the call was accepted as in 1.2 . In this case one of the users sends a session-terminate Jingle action with a reason success . This is translated to a SIP BYE request with to and from headers set appropriately - from is the user who wants to terminate the call and to is the user on the other end of the session. The BYE request is sent to the SIP Proxy and then to the other user in a similar way to session acceptance. 1.3.2 Terminating an unanswered call by initiator To terminate the call before it's accepted, the initiator sends a Jingle session-terminate stanza with a reason decline . Then MongooseIM translates this to a SIP CANCEL request which is sent to the SIP Proxy. 1.3.3 Rejecting the call When the invitee wants to terminate the call, on the XMPP level this is also a Jingle session-terminate stanza with a reason decline . MongooseIM translates this to SIP 486 Busy Here Response (because this is a response to the invite request). 2. Establishing a session with a SIP user Establishing a session with a SIP user (or a SIP entity) works the same as in the previous section. The only difference is that the SIP Proxy will not call MongooseIM back (as it may happen for call to other XMPP user). Instead the SIP message sent by MongooseIM to SIP Proxy will be delivered directly to the SIP user's device.","title":"mod_jingle_sip"},{"location":"modules/mod_jingle_sip/#module-description","text":"This module enables Jingle to SIP and SIP to Jingle translation. When this module is enabled, MongooseIM will intercept any Jingle IQ set stanza with action: session-initiate session-terminate session-accept transport-info and translate it to SIP messages with appropriate SDP content based on the details in the Jingle stanza. The translation back from SIP to Jingle is done for the following SIP requests: INVITE re-INVITE - INVITE message sent for an accepted session CANCEL BYE INFO and following responses to the INVITE request: 200 when the call invite was accepted 180 and 183 to indicate that the invitation was sent to the device 486 when the call's recipient rejects it from 400 to 600 - other error codes indicating session termination","title":"Module Description"},{"location":"modules/mod_jingle_sip/#jingle-to-sip-translation","text":"The table below summarises the bilateral translation for standard Jingle and SIP messages: Jingle action SIP message comment session-initiate INVITE request session-accept 200 OK response session-terminate with reason success BYE request Only for accepted session session-terminate with reason decline CANCEL request When sent by call's initiator session-terminate with reason decline 486 Busy Here response When sent by the invite user transport-info INFO request","title":"Jingle to SIP translation"},{"location":"modules/mod_jingle_sip/#ringing-notification","text":"Both Jingle and SIP have the ringing notification. It's generated as a response code 180 Ringing by a SIP entity when the INVITE is sent to the device. In SIP world a 183 Session Progress response code is also generated in some cases. Both 180 and 183 codes are translated as session-info Jingle stanza with ringing sub element. MongooseIM generates only 180 Ringing response code the INVITE request, if the recipient's online. If the recipient is online, MongooseIM generates the 180 Ringing response code to the INVITE request.","title":"Ringing notification"},{"location":"modules/mod_jingle_sip/#recipient-unavailable","text":"When MongooseIM receives a SIP INVITE request addressed to an offline user, it replies with a 480 Temporarily Unavailable code. The same code is expected from the SIP Proxy when MongooseIM sends the INVITE request.","title":"Recipient unavailable"},{"location":"modules/mod_jingle_sip/#other-error-codes","text":"When an error response to the INVITE request is from the range 400 to 699 but not 486 , MongooseIM will send a Jingle session-terminate stanza to the call's initiator. The stanza has reason general-error with the SIP error code in the sip-error sub element.","title":"Other error codes"},{"location":"modules/mod_jingle_sip/#non-standard-jingle-stanzas-used-by-jinglejs","text":"The following non-standard Jingle stanzas were integrated with https://github.com/softwarehutpl/jingle.js source-remove source-add source-update When MongooseIM observes the above Jingle stanzas, it will translate them to a SIP in-dialog INVITE request. In the SDP content of the request, there will be a custom attribute a=jingle-action . The value of the custom attribute is one of the three presented above. Similarly when MongooseIM gets a SIP in-dialog INVITE request, it will check if there is a custom attribute and use it as the action attribute of the Jingle stanza sent to the user. If there is no such attribute, the action will be set to regular Jingle transport-info .","title":"Non-standard Jingle stanzas used by jingle.js"},{"location":"modules/mod_jingle_sip/#non-stadard-jingle-existing-session-initiate-stanza","text":"MongooseIM allows a user to ask for an unanswered session-initiate request. This may be useful in web applications when there is a need to handle the call in a new browser window. In order to get the session-initiate , which was not answered yet, the user can send a get Jingle stanza to self with action set to existing-session-initiate . As a result, MongooseIM will resend the original session-initiate request to the device which sent the query.","title":"Non-stadard Jingle existing-session-initiate stanza"},{"location":"modules/mod_jingle_sip/#prerequisites","text":"By default, MongooseIM is built without SIP support. In order to build the server with SIP support, please use tools/configure script before the release generation. You may either pick only certain drivers (with SIP included) or simply use with-all option. Examples: tools/configure with-mysql with-jingle-sip tools/configure with-all without-odbc tools/configure with-all MongooseIM packages are built with Jingle/SIP support.","title":"Prerequisites"},{"location":"modules/mod_jingle_sip/#options","text":"proxy_host (default: \"localhost\") name or IP address of the SIP Proxy to which MongooseIM will send SIP messages proxy_port (default: 5600) port of the SIP Proxy listen_port (default: 5600) the port on which MongooseIM will listen for incomming SIP messages local_host (default: \"localhost\") value used to create SIP URIs (including VIA headers) sdp_origin (default: \"127.0.0.1\") value of the c= SDP attribute The simplest configuration is the following: {mod_jingle_sip, []} With this configuration MongooseIM will try sending SIP messages to a SIP proxy listening on localhost and port 5060.","title":"Options"},{"location":"modules/mod_jingle_sip/#use-cases-covered-by-tests","text":"Currently to test the functionality we use a SIP Proxy mock written in Erlang. The following scenarios are covered by our tests in big_tests/tests/jingle_SUITE.erl All the sequence diagrams where generated with textart.io/sequence . The source code is embedded in the markdown file below every diagram inside a comment <!--- --->","title":"Use cases covered by tests"},{"location":"modules/mod_jingle_sip/#1-establishing-a-session-with-another-xmpp-user","text":"With the mod_jingle_sip enabled, all Jingle IQ set stanzas listed above are intercepted, translated to SIP packets and sent to a SIP Proxy. This means that the current implementation will also translate stanzas addressed to a user in the same domain. This allows the SIP entity to control how the call between XMPP users is established. Below there are sequence diagrams showing the communication between XMPP users, MongooseIM and SIP Proxy as in our tests. It's possible that the SIP Proxy or other SIP entity decides that the call needs to be forked and delivered to the user's phone number instead of generating a corresponding call back to MongooseIM.","title":"1. Establishing a session with another XMPP user"},{"location":"modules/mod_jingle_sip/#11-signaling-session-initiate-to-other-xmpp-user-via-sip-proxy","text":"+-------+ +-------------+ +-----------+ +-------+ | UserA | | MongooseIM | | SIPProxy | | UserB | +-------+ +-------------+ +-----------+ +-------+ | | | | | session-initiate to UserB | | | |--------------------------------->| | | | -------------------------\\ | | | |-| Jingle stanza | | | | | | action:session-initate | | | | | | sid: 123 | | | | | |------------------------| | SIP INVITE | | | |------------------->| | | | -------------\\ | | | |-| from:UserA | | | | | | to:UserB | | | | | | sid: 123 | | | | | |------------| | create new call | | | |---------------- | | | | | | | | |<--------------- | | | | ------------------------\\ | | | |-| SDP content can be | | | | | | changed for instance | | | | | | to inject a transport | | | | SIP INVITE | | canidate | | | |<-------------------| |-----------------------| | | | -------------\\ | | | | | from:UserA |-| | | | | to:UserB | | | | --------------------\\ | | sid:456 | | | | | yes, new SID: 456 |-| |------------| | | | |-------------------| | | | | | | | | | session-initiate to UserB | | |------------------------------------------------->| | | | |","title":"1.1 Signaling session-initiate to other XMPP user via SIP Proxy"},{"location":"modules/mod_jingle_sip/#12-signaling-session-accept-to-other-xmpp-user-via-sip-proxy","text":"When the other user accepts the call invite sent by the first, the following sequence is executed. This is a continuation of the previous example +-------+ +-------------+ +-----------+ +-------+ | UserA | | MongooseIM | | SIPProxy | | UserB | +-------+ +-------------+ +-----------+ +-------+ | | | | | | | session-accpet to UserA | | |<--------------------------------------------------| | | | ------------------------\\ | | | | | Jingle stanza |-| | | | | action:session-accept | | | | | | sid: 456 | | | | 200 OK | |-----------------------| | | |-------------------->| | | | --------------\\ | | | |-| from: UserA | | | | | | to: UserB | | | | | | sid: 456 | | | | | |-------------| | find corresponding call | | | |------------------------ | | | | | | | | |<----------------------- | | | | | | | 200 OK | | | |<--------------------| | | | --------------\\ | | | | | from: UserA |-| | | | | to: UserB | | | | | | sid: 123 | | | | session-accept from UserB | |-------------| | | |<---------------------------------| | | | | | |","title":"1.2 Signaling session-accept to other XMPP user via SIP Proxy"},{"location":"modules/mod_jingle_sip/#13-terminating-a-call","text":"Any Jingle session (accepted or not) can be terminated by sending a Jingle stanza with action session-terminate and a reason. In the SIP world it's more complex. See the following examples for more information.","title":"1.3 Terminating a call"},{"location":"modules/mod_jingle_sip/#131-terminating-an-accepted-call","text":"The easiest scenario is when the call was accepted as in 1.2 . In this case one of the users sends a session-terminate Jingle action with a reason success . This is translated to a SIP BYE request with to and from headers set appropriately - from is the user who wants to terminate the call and to is the user on the other end of the session. The BYE request is sent to the SIP Proxy and then to the other user in a similar way to session acceptance.","title":"1.3.1 Terminating an accepted call"},{"location":"modules/mod_jingle_sip/#132-terminating-an-unanswered-call-by-initiator","text":"To terminate the call before it's accepted, the initiator sends a Jingle session-terminate stanza with a reason decline . Then MongooseIM translates this to a SIP CANCEL request which is sent to the SIP Proxy.","title":"1.3.2 Terminating an unanswered call by initiator"},{"location":"modules/mod_jingle_sip/#133-rejecting-the-call","text":"When the invitee wants to terminate the call, on the XMPP level this is also a Jingle session-terminate stanza with a reason decline . MongooseIM translates this to SIP 486 Busy Here Response (because this is a response to the invite request).","title":"1.3.3 Rejecting the call"},{"location":"modules/mod_jingle_sip/#2-establishing-a-session-with-a-sip-user","text":"Establishing a session with a SIP user (or a SIP entity) works the same as in the previous section. The only difference is that the SIP Proxy will not call MongooseIM back (as it may happen for call to other XMPP user). Instead the SIP message sent by MongooseIM to SIP Proxy will be delivered directly to the SIP user's device.","title":"2. Establishing a session with a SIP user"},{"location":"modules/mod_keystore/","text":"Module Description mod_keystore serves as storage for crypto keys - it doesn't implement any XMPP-level protocol. The module can store transient RAM-only keys generated on module startup, stored in memory only, distributed to all cluster members and existing for only as long as the cluster is alive, as well as predefined and pre-shared keys which can be read from a file. RAM-only keys provide better security since they are never written to persistent storage, at the cost of loss in case of a cluster-global failure or restart. As of now mod_auth_token is the only module dependent on mod_keystore . It's crucial to understand the distinction between single-tenant and multi-tenant hosting scenarios. In a multi-tenant server mod_keystore must be configured separately for each virtual XMPP domain to avoid sharing keys between domains! Options ram_key_size : size to use when generating RAM-only keys (designated by type ram ) keys : list of specifiers of keys which will be provided by the module at runtime Each key specifier is a pair of {KeyName, KeyType} , where: KeyName : any Erlang term. For simplicity's sake atoms are advised. Names have to be unique in the context of one virtual domain. KeyType : one of ram or {file, \"path/to/file\"} . The file is read and its contents are provided as the key (whitespace is trimmed). API The module public API is hook-based: ejabberd_hooks:run_fold(get_key, Domain, [], [{KeyName, Domain}]). An example of usage can be found in mod_auth_token:get_key_for_user/2 Example Configuration Simple configuration - single tenant (i.e. server hosting just one XMPP domain): {mod_keystore, [{keys, [{access_secret, ram}, {access_psk, {file, \"priv/access_psk\"}}, {provision_psk, {file, \"priv/provision_psk\"}}]}]} Multi-tenant setup ( mod_keystore configured differently for each virtual XMPP domain): {host_config, \"first.com\", [ {modules, [ {mod_keystore, [ {keys, [{access_secret, ram}, {access_psk, {file, \"priv/first_access_psk\"}}, {provision_psk, {file, \"priv/first_provision_psk\"}}]} ]} ]} ]}. {host_config, \"second.com\", [ {modules, [ {mod_keystore, [ {keys, [{access_secret, ram}, {access_psk, {file, \"priv/second_access_psk\"}}, {provision_psk, {file, \"priv/second_provision_psk\"}}]} ]} ]} ]}.","title":"mod_keystore"},{"location":"modules/mod_keystore/#module-description","text":"mod_keystore serves as storage for crypto keys - it doesn't implement any XMPP-level protocol. The module can store transient RAM-only keys generated on module startup, stored in memory only, distributed to all cluster members and existing for only as long as the cluster is alive, as well as predefined and pre-shared keys which can be read from a file. RAM-only keys provide better security since they are never written to persistent storage, at the cost of loss in case of a cluster-global failure or restart. As of now mod_auth_token is the only module dependent on mod_keystore . It's crucial to understand the distinction between single-tenant and multi-tenant hosting scenarios. In a multi-tenant server mod_keystore must be configured separately for each virtual XMPP domain to avoid sharing keys between domains!","title":"Module Description"},{"location":"modules/mod_keystore/#options","text":"ram_key_size : size to use when generating RAM-only keys (designated by type ram ) keys : list of specifiers of keys which will be provided by the module at runtime Each key specifier is a pair of {KeyName, KeyType} , where: KeyName : any Erlang term. For simplicity's sake atoms are advised. Names have to be unique in the context of one virtual domain. KeyType : one of ram or {file, \"path/to/file\"} . The file is read and its contents are provided as the key (whitespace is trimmed).","title":"Options"},{"location":"modules/mod_keystore/#api","text":"The module public API is hook-based: ejabberd_hooks:run_fold(get_key, Domain, [], [{KeyName, Domain}]). An example of usage can be found in mod_auth_token:get_key_for_user/2","title":"API"},{"location":"modules/mod_keystore/#example-configuration","text":"Simple configuration - single tenant (i.e. server hosting just one XMPP domain): {mod_keystore, [{keys, [{access_secret, ram}, {access_psk, {file, \"priv/access_psk\"}}, {provision_psk, {file, \"priv/provision_psk\"}}]}]} Multi-tenant setup ( mod_keystore configured differently for each virtual XMPP domain): {host_config, \"first.com\", [ {modules, [ {mod_keystore, [ {keys, [{access_secret, ram}, {access_psk, {file, \"priv/first_access_psk\"}}, {provision_psk, {file, \"priv/first_provision_psk\"}}]} ]} ]} ]}. {host_config, \"second.com\", [ {modules, [ {mod_keystore, [ {keys, [{access_secret, ram}, {access_psk, {file, \"priv/second_access_psk\"}}, {provision_psk, {file, \"priv/second_provision_psk\"}}]} ]} ]} ]}.","title":"Example Configuration"},{"location":"modules/mod_last/","text":"Module Description Implements XEP-0012: Last Activity . Use with caution, as it was observed that a user disconnect spike might result in overloading the database with \"last activity\" writes. Options iqdisc (default: one_queue ) backend (atom, default: mnesia ): Storage backend. Currently mnesia , rdbms and riak are supported. Example Configuration {mod_last, []} Metrics If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Backend action Description (when it gets incremented) get_last A timestamp is fetched from DB. set_last_info A timestamp is stored in DB.","title":"mod_last"},{"location":"modules/mod_last/#module-description","text":"Implements XEP-0012: Last Activity . Use with caution, as it was observed that a user disconnect spike might result in overloading the database with \"last activity\" writes.","title":"Module Description"},{"location":"modules/mod_last/#options","text":"iqdisc (default: one_queue ) backend (atom, default: mnesia ): Storage backend. Currently mnesia , rdbms and riak are supported.","title":"Options"},{"location":"modules/mod_last/#example-configuration","text":"{mod_last, []}","title":"Example Configuration"},{"location":"modules/mod_last/#metrics","text":"If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Backend action Description (when it gets incremented) get_last A timestamp is fetched from DB. set_last_info A timestamp is stored in DB.","title":"Metrics"},{"location":"modules/mod_mam/","text":"Module Description This module implements XEP-0313 (Message Archive Management) . It enables a service to store all user messages for one-to-one chats as well as group chats (MUC, MultiUser Chat). It uses XEP-0059: Result Set Management for paging. It is a highly customizable module, that requires some skill and knowledge to operate properly and efficiently. MongooseIM is compatible with MAM 0.4-0.6. Version 0.3 is deprecated and won't be supported by the next release. Configure MAM with different storage backends: RDBMS (databases like MySQL, PostgreSQL, MS SQL Server) Riak KV (NOSQL) Cassandra (NOSQL) ElasticSearch (NOSQL) mod_mam_meta is a meta-module that ensures all relevant mod_mam_* modules are loaded and properly configured. Full Text Search This module allows message filtering by their text body (if enabled, see Common backend options ). This means that an XMPP client, while requesting messages from the archive may not only specify standard form fields ( with , start , end ), but also full-text-search (of type text-single ). If this happens, the client will receive only messages that contain words specified in the request. The exact behaviour, like whether word ordering matters, may depend on the storage backend in use. For now rdbms backend has very limited support for this feature, while cassandra does not support it at all. riak and elasticsearch backends, on the other hand, should provide you with the best results when it comes to text filtering. mod_mam_rdbms_arch returns all messages that contain all search words, order of words does not matter. Messages are sorted by timestamp (not by relevance). Note on full text search with ElasticSearch backend When using ElasticSearch MAM backend, the value provided in full-text-search form field will be passed to ElasticSearch as Simple Search Query . If you're using our official ElasticSearch mappings from priv/elasticsearch then the query analyzer is set to english . Also note that the default separator for the search query is AND (which roughly means that ElasticSearch will search for messages containing all the terms provided in the query string). Options backend (atom, default: rdbms ) - Database backend to use. rdbms , riak , cassandra and elasticsearch are supported. no_stanzaid_element (boolean, default: false ) - Do not add a <stanza-id/> element from MAM v0.6. is_archivable_message (module, default: mod_mam_utils ) - Name of a module implementing is_archivable_message/3 callback that determines if the message should be archived. Warning : if you are using MUC Light, make sure this option is set to the MUC Light domain. archive_chat_markers (boolean, default: false ) - If set to true, XEP-0333 chat markers will be archived. See more details here pm (list | false , default: [] ) - Override options for archivization of one-to-one messages. If the value of this option is false , one-to-one message archive is disabled. muc (list | false , default: false ) - Override options for archivization of group chat messages. If the value of this option is false , group chat message archive is disabled. extra_lookup_params (atom, default: undefined ) - a module implementing mam_iq behaviour. If this option has value other then undefined, function extra_lookup_params/2 from this module will be called when building MAM lookup parameters. This can be used to extend currently supported MAM query fields by a custom field or fields. This field(s) can be added to lookup params later passed to MAM backend. backend , no_stanzaid_element and is_archivable_message will be applied to both pm and muc (if they are enabled), unless overriden explicitly (see example below). PM-specific options archive_groupchats (boolean, default: true ) - When enabled, MAM will store groupchat messages in recipients' individual archives. USE WITH CAUTION! May increase archive size significantly. Disabling this option for existing installation will neither remove such messages from MAM storage, nor will filter out them from search results. MongooseIM will print a warning on startup if pm MAM is enabled without archive_groupchats being explicitly set to a specific value. In one of the future MongooseIM releases this option will default to false (as it's more common use case and less DB-consuming) and the warning message will be removed. MUC-specific options host (string, default: \"conference.@HOST@\" ) - MUC host that will be archived if MUC archiving is enabled. Example The example below presents how to override common option for muc module specifically. {mod_mam_meta, [ {backend, rdbms}, {async_writer, true}, %% this option enables async writer for RDBMS backend {muc, [ {async_writer, false} %% disable async writer for MUC archive only ]} ]} RDBMS backend options These options will only have effect when the rdbms backend is used: cache_users (boolean, default: true ) - Enables Archive ID to integer mappings cache. rdbms_message_format (atom, default: internal ) - When set to simple , stores messages in XML and full JIDs. When set to internal , stores messages and JIDs in internal format. Warning : Archive MUST be empty to change this option. async_writer (boolean, default: true ) - Enables an asynchronous writer that is faster than the synchronous one but harder to debug. The async writers store batches of messages with a certain delay (see flush_interval ), so the results of the lookup operations executed right after message routing may be incomplete until the configured time passes. flush_interval (integer, default: 2000 ) How often (in milliseconds) the buffered messages are flushed to a DB. max_batch_size (integer, default, 30 ) Max size of the batch insert query for an async writer. If the buffer is full, messages are flushed to a database immediately and the flush timer is reset. Common backend options user_prefs_store (atom, default: false ) - Leaving this option as false will prevent users from setting their archiving preferences. It will also increase performance. Other possible values are: rdbms (RDBMS backend only) - User archiving preferences saved in RDBMS. Slow and not recommended, but might be used for simplicity (keeping everything in RDBMS). cassandra (Cassandra backend only) - User archiving preferences are saved in Cassandra. mnesia (recommended) - User archiving preferences saved in Mnesia and accessed without transactions. Recommended in most deployments, could be overloaded with lots of users updating their preferences at once. There's a small risk of an inconsistent (in a rather harmless way) state of the preferences table. full_text_search (boolean, default: true ) - Enables full text search in message archive (see Full Text Search paragraph). Please note that the full text search is currently only implemented for rdbms and riak backends. Also, full text search works only for messages archived while this option is enabled. is_archivable_message/3 callback is_archivable_message option has to name a module exporting is_archivable_message/3 function conforming to the spec: -spec is_archivable_message(Mod :: module(), Dir :: incoming | outgoing, Packet :: exml:element()) -> boolean(). Servers SHOULD NOT archive messages that do not have a <body/> child tag. Servers SHOULD NOT archive delayed messages. By default, all messages that hold meaningful content, rather than state changes such as Chat State Notifications, are archived. Archiving chat markers Archiving chat markers can be enabled by setting archive_chat_markers option to true . However it only works if is_archivable_message callback module is set to mod_mam_utils or isn't set at all. When performing full text search chat markers are treated as if they had empty message body. Riak backend The Riak KV backend for MAM stores messages in weekly buckets so it's easier to remove old buckets. Archive querying is done using Riak KV 2.0 search mechanism called Yokozuna. Your instance of Riak KV must be configured with Yokozuna enabled. This backend works with Riak KV 2.0 and above, but we recommend version 2.1.1. Cassandra backend Please consult Outgoing connections page to learn how to properly configure Cassandra connection pool. By default, mod_mam Cassandra backend requires global pool with default tag: {outgoing_pools, [ {cassandra, global, default, [], []}. ]}. ElasticSearch backend First, make sure that your ElasticSearch cluster has expected indexes and mappings in place. Please consult Outgoing connections page to learn how to properly configure ElasticSearch connection pool. Example configuration {mod_mam_meta, [ {backend, rdbms}, {no_stanzaid_element, true}, {pm, [{user_prefs_store, rdbms}]}, {muc, [ {host, \"muc.example.com\"}, {rdbms_message_format, simple}, {async_writer, false}, {user_prefs_store, mnesia} ]} ]}. Metrics If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Name Type Description (when it gets incremented) [Host, modMamArchiveRemoved] spiral User's entire archive is removed. [Host, modMamArchived] spiral A message is stored in user's archive. [Host, modMamDropped] spiral A message couldn't be enqueued due to an overloaded async worker. [Host, modMamDropped2] spiral A message couldn't be stored in the DB (and got dropped). [Host, modMamDroppedIQ] spiral MAM IQ has been dropped due to: high query frequency/invalid syntax or type. [Host, modMamFlushed] spiral Message was stored in a DB asynchronously. [Host, modMamForwarded] spiral A message is sent to a client as a part of a MAM query result. [Host, modMamLookups] spiral A MAM lookup is performed. [Host, modMamSinglePurges] spiral A single purge request is processed by MAM. [Host, modMamMultiplePurges] spiral A bulk purge request is processed by MAM. [Host, modMamPrefsGets] spiral Archiving preferences have been requested by a client. [Host, modMamPrefsSets] spiral Archiving preferences have been updated by a client. [Host, modMucMamArchiveRemoved] spiral Room's entire archive is removed. [Host, modMucMamArchived] spiral A message is stored in room's archive. [Host, modMucMamForwarded] spiral A message is sent to a client as a part of a MAM query result from MUC room. [Host, modMucMamLookups] spiral A MAM lookup in MUC room is performed. [Host, modMucMamSinglePurges] spiral A single purge request for MUC room is processed by MAM. [Host, modMucMamMultiplePurges] spiral A bulk purge request for MUC room is processed by MAM. [Host, modMucMamPrefsGets] spiral MUC archiving preferences have been requested by a client. [Host, modMucMamPrefsSets] spiral MUC archiving preferences have been updated by a client. [Host, mod_mam_rdbms_async_pool_writer, per_message_flush_time] histogram Average time per message insert measured in an async MAM worker. [Host, mod_mam_rdbms_async_pool_writer, flush_time] histogram Average time per flush of all buffered messages measured in an async MAM worker. [Host, mod_mam_muc_rdbms_async_pool_writer, per_message_flush_time] histogram Average time per message insert measured in an async MUC MAM worker. [Host, mod_mam_muc_rdbms_async_pool_writer, flush_time] histogram Average time per flush of all buffered messages measured in an async MUC MAM worker. Backend action Description (when it gets incremented) lookup A lookup in an archive. archive One message is saved in an archive.","title":"mod_mam"},{"location":"modules/mod_mam/#module-description","text":"This module implements XEP-0313 (Message Archive Management) . It enables a service to store all user messages for one-to-one chats as well as group chats (MUC, MultiUser Chat). It uses XEP-0059: Result Set Management for paging. It is a highly customizable module, that requires some skill and knowledge to operate properly and efficiently. MongooseIM is compatible with MAM 0.4-0.6. Version 0.3 is deprecated and won't be supported by the next release. Configure MAM with different storage backends: RDBMS (databases like MySQL, PostgreSQL, MS SQL Server) Riak KV (NOSQL) Cassandra (NOSQL) ElasticSearch (NOSQL) mod_mam_meta is a meta-module that ensures all relevant mod_mam_* modules are loaded and properly configured.","title":"Module Description"},{"location":"modules/mod_mam/#full-text-search","text":"This module allows message filtering by their text body (if enabled, see Common backend options ). This means that an XMPP client, while requesting messages from the archive may not only specify standard form fields ( with , start , end ), but also full-text-search (of type text-single ). If this happens, the client will receive only messages that contain words specified in the request. The exact behaviour, like whether word ordering matters, may depend on the storage backend in use. For now rdbms backend has very limited support for this feature, while cassandra does not support it at all. riak and elasticsearch backends, on the other hand, should provide you with the best results when it comes to text filtering. mod_mam_rdbms_arch returns all messages that contain all search words, order of words does not matter. Messages are sorted by timestamp (not by relevance).","title":"Full Text Search"},{"location":"modules/mod_mam/#note-on-full-text-search-with-elasticsearch-backend","text":"When using ElasticSearch MAM backend, the value provided in full-text-search form field will be passed to ElasticSearch as Simple Search Query . If you're using our official ElasticSearch mappings from priv/elasticsearch then the query analyzer is set to english . Also note that the default separator for the search query is AND (which roughly means that ElasticSearch will search for messages containing all the terms provided in the query string).","title":"Note on full text search with ElasticSearch backend"},{"location":"modules/mod_mam/#options","text":"backend (atom, default: rdbms ) - Database backend to use. rdbms , riak , cassandra and elasticsearch are supported. no_stanzaid_element (boolean, default: false ) - Do not add a <stanza-id/> element from MAM v0.6. is_archivable_message (module, default: mod_mam_utils ) - Name of a module implementing is_archivable_message/3 callback that determines if the message should be archived. Warning : if you are using MUC Light, make sure this option is set to the MUC Light domain. archive_chat_markers (boolean, default: false ) - If set to true, XEP-0333 chat markers will be archived. See more details here pm (list | false , default: [] ) - Override options for archivization of one-to-one messages. If the value of this option is false , one-to-one message archive is disabled. muc (list | false , default: false ) - Override options for archivization of group chat messages. If the value of this option is false , group chat message archive is disabled. extra_lookup_params (atom, default: undefined ) - a module implementing mam_iq behaviour. If this option has value other then undefined, function extra_lookup_params/2 from this module will be called when building MAM lookup parameters. This can be used to extend currently supported MAM query fields by a custom field or fields. This field(s) can be added to lookup params later passed to MAM backend. backend , no_stanzaid_element and is_archivable_message will be applied to both pm and muc (if they are enabled), unless overriden explicitly (see example below).","title":"Options"},{"location":"modules/mod_mam/#pm-specific-options","text":"archive_groupchats (boolean, default: true ) - When enabled, MAM will store groupchat messages in recipients' individual archives. USE WITH CAUTION! May increase archive size significantly. Disabling this option for existing installation will neither remove such messages from MAM storage, nor will filter out them from search results. MongooseIM will print a warning on startup if pm MAM is enabled without archive_groupchats being explicitly set to a specific value. In one of the future MongooseIM releases this option will default to false (as it's more common use case and less DB-consuming) and the warning message will be removed.","title":"PM-specific options"},{"location":"modules/mod_mam/#muc-specific-options","text":"host (string, default: \"conference.@HOST@\" ) - MUC host that will be archived if MUC archiving is enabled.","title":"MUC-specific options"},{"location":"modules/mod_mam/#example","text":"The example below presents how to override common option for muc module specifically. {mod_mam_meta, [ {backend, rdbms}, {async_writer, true}, %% this option enables async writer for RDBMS backend {muc, [ {async_writer, false} %% disable async writer for MUC archive only ]} ]}","title":"Example"},{"location":"modules/mod_mam/#rdbms-backend-options","text":"These options will only have effect when the rdbms backend is used: cache_users (boolean, default: true ) - Enables Archive ID to integer mappings cache. rdbms_message_format (atom, default: internal ) - When set to simple , stores messages in XML and full JIDs. When set to internal , stores messages and JIDs in internal format. Warning : Archive MUST be empty to change this option. async_writer (boolean, default: true ) - Enables an asynchronous writer that is faster than the synchronous one but harder to debug. The async writers store batches of messages with a certain delay (see flush_interval ), so the results of the lookup operations executed right after message routing may be incomplete until the configured time passes. flush_interval (integer, default: 2000 ) How often (in milliseconds) the buffered messages are flushed to a DB. max_batch_size (integer, default, 30 ) Max size of the batch insert query for an async writer. If the buffer is full, messages are flushed to a database immediately and the flush timer is reset.","title":"RDBMS backend options"},{"location":"modules/mod_mam/#common-backend-options","text":"user_prefs_store (atom, default: false ) - Leaving this option as false will prevent users from setting their archiving preferences. It will also increase performance. Other possible values are: rdbms (RDBMS backend only) - User archiving preferences saved in RDBMS. Slow and not recommended, but might be used for simplicity (keeping everything in RDBMS). cassandra (Cassandra backend only) - User archiving preferences are saved in Cassandra. mnesia (recommended) - User archiving preferences saved in Mnesia and accessed without transactions. Recommended in most deployments, could be overloaded with lots of users updating their preferences at once. There's a small risk of an inconsistent (in a rather harmless way) state of the preferences table. full_text_search (boolean, default: true ) - Enables full text search in message archive (see Full Text Search paragraph). Please note that the full text search is currently only implemented for rdbms and riak backends. Also, full text search works only for messages archived while this option is enabled.","title":"Common backend options"},{"location":"modules/mod_mam/#is_archivable_message3-callback","text":"is_archivable_message option has to name a module exporting is_archivable_message/3 function conforming to the spec: -spec is_archivable_message(Mod :: module(), Dir :: incoming | outgoing, Packet :: exml:element()) -> boolean(). Servers SHOULD NOT archive messages that do not have a <body/> child tag. Servers SHOULD NOT archive delayed messages. By default, all messages that hold meaningful content, rather than state changes such as Chat State Notifications, are archived.","title":"is_archivable_message/3 callback"},{"location":"modules/mod_mam/#archiving-chat-markers","text":"Archiving chat markers can be enabled by setting archive_chat_markers option to true . However it only works if is_archivable_message callback module is set to mod_mam_utils or isn't set at all. When performing full text search chat markers are treated as if they had empty message body.","title":"Archiving chat markers"},{"location":"modules/mod_mam/#riak-backend","text":"The Riak KV backend for MAM stores messages in weekly buckets so it's easier to remove old buckets. Archive querying is done using Riak KV 2.0 search mechanism called Yokozuna. Your instance of Riak KV must be configured with Yokozuna enabled. This backend works with Riak KV 2.0 and above, but we recommend version 2.1.1.","title":"Riak backend"},{"location":"modules/mod_mam/#cassandra-backend","text":"Please consult Outgoing connections page to learn how to properly configure Cassandra connection pool. By default, mod_mam Cassandra backend requires global pool with default tag: {outgoing_pools, [ {cassandra, global, default, [], []}. ]}.","title":"Cassandra backend"},{"location":"modules/mod_mam/#elasticsearch-backend","text":"First, make sure that your ElasticSearch cluster has expected indexes and mappings in place. Please consult Outgoing connections page to learn how to properly configure ElasticSearch connection pool.","title":"ElasticSearch backend"},{"location":"modules/mod_mam/#example-configuration","text":"{mod_mam_meta, [ {backend, rdbms}, {no_stanzaid_element, true}, {pm, [{user_prefs_store, rdbms}]}, {muc, [ {host, \"muc.example.com\"}, {rdbms_message_format, simple}, {async_writer, false}, {user_prefs_store, mnesia} ]} ]}.","title":"Example configuration"},{"location":"modules/mod_mam/#metrics","text":"If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Name Type Description (when it gets incremented) [Host, modMamArchiveRemoved] spiral User's entire archive is removed. [Host, modMamArchived] spiral A message is stored in user's archive. [Host, modMamDropped] spiral A message couldn't be enqueued due to an overloaded async worker. [Host, modMamDropped2] spiral A message couldn't be stored in the DB (and got dropped). [Host, modMamDroppedIQ] spiral MAM IQ has been dropped due to: high query frequency/invalid syntax or type. [Host, modMamFlushed] spiral Message was stored in a DB asynchronously. [Host, modMamForwarded] spiral A message is sent to a client as a part of a MAM query result. [Host, modMamLookups] spiral A MAM lookup is performed. [Host, modMamSinglePurges] spiral A single purge request is processed by MAM. [Host, modMamMultiplePurges] spiral A bulk purge request is processed by MAM. [Host, modMamPrefsGets] spiral Archiving preferences have been requested by a client. [Host, modMamPrefsSets] spiral Archiving preferences have been updated by a client. [Host, modMucMamArchiveRemoved] spiral Room's entire archive is removed. [Host, modMucMamArchived] spiral A message is stored in room's archive. [Host, modMucMamForwarded] spiral A message is sent to a client as a part of a MAM query result from MUC room. [Host, modMucMamLookups] spiral A MAM lookup in MUC room is performed. [Host, modMucMamSinglePurges] spiral A single purge request for MUC room is processed by MAM. [Host, modMucMamMultiplePurges] spiral A bulk purge request for MUC room is processed by MAM. [Host, modMucMamPrefsGets] spiral MUC archiving preferences have been requested by a client. [Host, modMucMamPrefsSets] spiral MUC archiving preferences have been updated by a client. [Host, mod_mam_rdbms_async_pool_writer, per_message_flush_time] histogram Average time per message insert measured in an async MAM worker. [Host, mod_mam_rdbms_async_pool_writer, flush_time] histogram Average time per flush of all buffered messages measured in an async MAM worker. [Host, mod_mam_muc_rdbms_async_pool_writer, per_message_flush_time] histogram Average time per message insert measured in an async MUC MAM worker. [Host, mod_mam_muc_rdbms_async_pool_writer, flush_time] histogram Average time per flush of all buffered messages measured in an async MUC MAM worker. Backend action Description (when it gets incremented) lookup A lookup in an archive. archive One message is saved in an archive.","title":"Metrics"},{"location":"modules/mod_muc/","text":"Module Description This module implements XEP-0045: Multi-User Chat (MUC). It's a common XMPP group chat solution. This extension consists of two Erlang modules: mod_muc and mod_muc_room , the latter being the room code itself. Note that only mod_muc needs to be enabled in the configuration file. Also mod_muc_log is a logging submodule. Options host (string, default: \"conference.@HOST@\" ): Subdomain for MUC service to reside under. @HOST@ is replaced with each served domain. backend (atom, default: mnesia ): Storage backend. Currently only mnesia is supported. access (atom, default: all ): Access Rule to determine who is allowed to use the MUC service. access_create (atom, default: all ): Who is allowed to create rooms. access_admin (atom, default: none ): Who is the administrator in all rooms. access_persistent (atom, default: all ): Who is allowed to make the rooms persistent. In order to change this parameter, the user must not only match the Access Rule but also be the owner of the room. history_size (non-negative integer, default: 20): Room message history to be kept in RAM. After node restart, the history is lost. room_shaper (atom, default: none ): Limits per-room data throughput with traffic shaper. max_room_id (atom or positive integer, default: infinite ): Maximum room username length (in JID). max_room_name (atom or positive integer, default: infinite ): Maximum room name length. max_room_desc (atom or positive integer, default: infinite ): Maximum room description length. min_message_interval (non-negative integer, default: 0): Minimal interval (in seconds) between messages processed by the room. min_presence_interval (non-negative integer, default: 0): Minimal interval (in seconds) between presences processed by the room. max_users (positive integer, default: 200): Absolute maximum user count per room on the node. max_users_admin_threshold (positive integer, default: 5): When the server checks if a new user can join a room and they are an admin, max_users_admin_threshold is added to max_users during occupant limit check. user_message_shaper (atom, default: none ): Shaper for user messages processed by a room (global for the room). user_presence_shaper (atom, default: none ): Shaper for user presences processed by a room (global for the room). max_user_conferences (non-negative, default: 10): Specifies the number of rooms that a user can occupy simultaneously. http_auth_pool (atom, default: none ): If an external HTTP service is chosen to check passwords for password-protected rooms, this option specifies the HTTP pool name to use (see External HTTP Authentication below). load_permanent_rooms_at_startup (boolean, default: false) - Load all rooms at startup (can be unsafe when there are many rooms, that's why disabled). hibernate_timeout (timeout, default: 90000 ): Timeout (in milliseconds) defining the inactivity period after which the room's process should be hibernated. hibernated_room_check_interval (timeout, default: infinity ): Interval defining how often the hibernated rooms will be checked (a timer is global for a node). hibernated_room_timeout (timeout, default: inifitniy ): A time after which a hibernated room is stopped (deeply hibernated). See MUC performance optimisation . default_room_options (list of key-value tuples, default: [] ): List of room configuration options to be overridden in the initial state. title (binary, default: <<>> ): Room title, short free text. description (binary, default: <<>> ): Room description, long free text. allow_change_subj (boolean, default: true ): Allow all occupants to change the room subject. allow_query_users (boolean, default: true ): Allow occupants to send IQ queries to other occupants. allow_private_messages (boolean, default: true ): Allow private messaging between occupants. allow_visitor_status (boolean, default: true ): Allow occupants to use text statuses in presences. When disabled, text is removed by the room before broadcasting. allow_visitor_nickchange (boolean, default: true ): Allow occupants to change nicknames. public (boolean, default: true ): Room is included in the list available via Service Discovery. public_list (boolean, default: true ): Member list can be fetched by non-members. persistent (boolean, default: false ): Room will be stored in DB and survive even when the last occupant leaves or the node is restarted. moderated (boolean, default: true ): Only occupants with a \"voice\" can send group chat messages. members_by_default (boolean, default: true ): All new occupants are members by default, unless they have a different affiliation assigned. members_only (boolean, default: false ): Only users with a member affiliation can join the room. allow_user_invites (boolean, default: false ): Allow ordinary members to send mediated invitations. allow_multiple_sessions (boolean, default: false ): Allow multiple user session to use the same nick. password_protected (boolean, default: false ): Room is protected with a password. password (binary, default: <<>> ): Room password is required upon joining. This option has no effect when password_protected is false . anonymous (boolean, default: true ): Room is anonymous, meaning occupants can't see each others real JIDs, except for the room moderators. max_users (positive integer, default: 200): Maximum user count per room. Admins and the room owner are not affected. logging (boolean, default: false ): Enables logging of room events (messages, presences) to a file on the disk. Uses mod_muc_log . maygetmemberlist (list of atoms, default: [] ): A list of roles and/or privileges that enable retrieving the room's member list. affiliations (list of {{<<\"user\">>, <<\"server\">>, <<\"resource\">>}, affiliation} tuples, default: [] ): A default list of affiliations set for every new room. subject (binary, default: <<>> ): A default subject for new room. subject_author (binary, default: <<>> ): A nick name of the default subject's author. Example Configuration {mod_muc, [ {host, \"muc.example.com\"}, {access, muc}, {access_create, muc_create} ]}, Performance optimisations Each room is represented by an Erlang process with its own state and can consume memory even if it's not used. In large installations with many rooms, this might cause performance issues. To address that problem MongooseIM has 2 levels of MUC rooms memory optimisations. Room's process hibernation By default the room's process is hibernated by the Erlang VM 90 seconds after the last activity. This timeout can be modified by hibernate_timeout option. Room deep hibernation MongooseIM introduces an addtional option of deep hibernation for unused rooms. This optimisation works only for persistent rooms as only these can be restored on demand. The improvement works as follows: 1. All room processes are traversed at a chosen hibernated_room_check_interval . 1. If a hibernated_room_timeout is exceeded, a \"stop\" signal is sent to a unused room. 1. The room's process is stopped only if there are no online users or if the only one is its owner. If the owner is online, a presence of a type unavailable is sent to it indicating that the room's process is being terminated. The room's process can be recreated on demand, for example when a presence sent to it, or the owner wants to add more users to the room. External HTTP Authentication MUC rooms can be protected by a password that is set by the room owner. Note that MongooseIM supports another custom solution, where each attempt to enter or create a room requires the password to be checked by an external HTTP service. To enable this option, you need to: Configure an HTTP connection pool . Set the name of the connection pool as the value of the http_auth_pool option of mod_muc . Enable the password_protected default room option (without setting the password itself). Whenever a user tries to enter or create a room, the server will receive a GET request to the check_password path. It should return a 200 response with a JSON object {\"code\": Code, \"msg\": Message} in the response body. If the server returns something else, an error presence will be sent back to the client. Code is the status code: 0 indicates a successful authentication, any other value means the authentication failed. Message is a string containing the message to be sent back to the XMPP client indicating the reason for a failed authentication. When authentication succeeds it is ignored and can contain anything ( eg. the string \"OK\" ). Example: {outgoing_pools, [{http, global, my_auth_pool, [{strategy, available_worker}], [{server, \"http://my_server:8000\"}]} ] }. {modules, [ (...) {mod_muc, [ {host, \"muc.example.com\"}, {access, muc}, {access_create, muc_create}, {http_auth_pool, my_auth_pool}, {default_room_options, [{password_protected, true}]} ]}, (...) ]}. Metrics If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Name Type Description (when it gets incremented) [global, mod_muc, deep_hibernations] spiral A room process is stopped (applies only to persistent rooms). [global, mod_muc, process_recreations] spiral A room process is recreated from a persisted state. [global, mod_muc, hibernations] spiral A room process becomes hibernated (garbage collected and put in wait state). [global, mod_muc, hibernated_rooms] value How many rooms are in hibernated state. Does not include rooms in \"deep hibernation\". [global, mod_muc, online_rooms] value How many rooms have running processes (includes rooms in a hibernated state).","title":"mod_muc"},{"location":"modules/mod_muc/#module-description","text":"This module implements XEP-0045: Multi-User Chat (MUC). It's a common XMPP group chat solution. This extension consists of two Erlang modules: mod_muc and mod_muc_room , the latter being the room code itself. Note that only mod_muc needs to be enabled in the configuration file. Also mod_muc_log is a logging submodule.","title":"Module Description"},{"location":"modules/mod_muc/#options","text":"host (string, default: \"conference.@HOST@\" ): Subdomain for MUC service to reside under. @HOST@ is replaced with each served domain. backend (atom, default: mnesia ): Storage backend. Currently only mnesia is supported. access (atom, default: all ): Access Rule to determine who is allowed to use the MUC service. access_create (atom, default: all ): Who is allowed to create rooms. access_admin (atom, default: none ): Who is the administrator in all rooms. access_persistent (atom, default: all ): Who is allowed to make the rooms persistent. In order to change this parameter, the user must not only match the Access Rule but also be the owner of the room. history_size (non-negative integer, default: 20): Room message history to be kept in RAM. After node restart, the history is lost. room_shaper (atom, default: none ): Limits per-room data throughput with traffic shaper. max_room_id (atom or positive integer, default: infinite ): Maximum room username length (in JID). max_room_name (atom or positive integer, default: infinite ): Maximum room name length. max_room_desc (atom or positive integer, default: infinite ): Maximum room description length. min_message_interval (non-negative integer, default: 0): Minimal interval (in seconds) between messages processed by the room. min_presence_interval (non-negative integer, default: 0): Minimal interval (in seconds) between presences processed by the room. max_users (positive integer, default: 200): Absolute maximum user count per room on the node. max_users_admin_threshold (positive integer, default: 5): When the server checks if a new user can join a room and they are an admin, max_users_admin_threshold is added to max_users during occupant limit check. user_message_shaper (atom, default: none ): Shaper for user messages processed by a room (global for the room). user_presence_shaper (atom, default: none ): Shaper for user presences processed by a room (global for the room). max_user_conferences (non-negative, default: 10): Specifies the number of rooms that a user can occupy simultaneously. http_auth_pool (atom, default: none ): If an external HTTP service is chosen to check passwords for password-protected rooms, this option specifies the HTTP pool name to use (see External HTTP Authentication below). load_permanent_rooms_at_startup (boolean, default: false) - Load all rooms at startup (can be unsafe when there are many rooms, that's why disabled). hibernate_timeout (timeout, default: 90000 ): Timeout (in milliseconds) defining the inactivity period after which the room's process should be hibernated. hibernated_room_check_interval (timeout, default: infinity ): Interval defining how often the hibernated rooms will be checked (a timer is global for a node). hibernated_room_timeout (timeout, default: inifitniy ): A time after which a hibernated room is stopped (deeply hibernated). See MUC performance optimisation . default_room_options (list of key-value tuples, default: [] ): List of room configuration options to be overridden in the initial state. title (binary, default: <<>> ): Room title, short free text. description (binary, default: <<>> ): Room description, long free text. allow_change_subj (boolean, default: true ): Allow all occupants to change the room subject. allow_query_users (boolean, default: true ): Allow occupants to send IQ queries to other occupants. allow_private_messages (boolean, default: true ): Allow private messaging between occupants. allow_visitor_status (boolean, default: true ): Allow occupants to use text statuses in presences. When disabled, text is removed by the room before broadcasting. allow_visitor_nickchange (boolean, default: true ): Allow occupants to change nicknames. public (boolean, default: true ): Room is included in the list available via Service Discovery. public_list (boolean, default: true ): Member list can be fetched by non-members. persistent (boolean, default: false ): Room will be stored in DB and survive even when the last occupant leaves or the node is restarted. moderated (boolean, default: true ): Only occupants with a \"voice\" can send group chat messages. members_by_default (boolean, default: true ): All new occupants are members by default, unless they have a different affiliation assigned. members_only (boolean, default: false ): Only users with a member affiliation can join the room. allow_user_invites (boolean, default: false ): Allow ordinary members to send mediated invitations. allow_multiple_sessions (boolean, default: false ): Allow multiple user session to use the same nick. password_protected (boolean, default: false ): Room is protected with a password. password (binary, default: <<>> ): Room password is required upon joining. This option has no effect when password_protected is false . anonymous (boolean, default: true ): Room is anonymous, meaning occupants can't see each others real JIDs, except for the room moderators. max_users (positive integer, default: 200): Maximum user count per room. Admins and the room owner are not affected. logging (boolean, default: false ): Enables logging of room events (messages, presences) to a file on the disk. Uses mod_muc_log . maygetmemberlist (list of atoms, default: [] ): A list of roles and/or privileges that enable retrieving the room's member list. affiliations (list of {{<<\"user\">>, <<\"server\">>, <<\"resource\">>}, affiliation} tuples, default: [] ): A default list of affiliations set for every new room. subject (binary, default: <<>> ): A default subject for new room. subject_author (binary, default: <<>> ): A nick name of the default subject's author.","title":"Options"},{"location":"modules/mod_muc/#example-configuration","text":"{mod_muc, [ {host, \"muc.example.com\"}, {access, muc}, {access_create, muc_create} ]},","title":"Example Configuration"},{"location":"modules/mod_muc/#performance-optimisations","text":"Each room is represented by an Erlang process with its own state and can consume memory even if it's not used. In large installations with many rooms, this might cause performance issues. To address that problem MongooseIM has 2 levels of MUC rooms memory optimisations.","title":"Performance optimisations"},{"location":"modules/mod_muc/#rooms-process-hibernation","text":"By default the room's process is hibernated by the Erlang VM 90 seconds after the last activity. This timeout can be modified by hibernate_timeout option.","title":"Room's process hibernation"},{"location":"modules/mod_muc/#room-deep-hibernation","text":"MongooseIM introduces an addtional option of deep hibernation for unused rooms. This optimisation works only for persistent rooms as only these can be restored on demand. The improvement works as follows: 1. All room processes are traversed at a chosen hibernated_room_check_interval . 1. If a hibernated_room_timeout is exceeded, a \"stop\" signal is sent to a unused room. 1. The room's process is stopped only if there are no online users or if the only one is its owner. If the owner is online, a presence of a type unavailable is sent to it indicating that the room's process is being terminated. The room's process can be recreated on demand, for example when a presence sent to it, or the owner wants to add more users to the room.","title":"Room deep hibernation"},{"location":"modules/mod_muc/#external-http-authentication","text":"MUC rooms can be protected by a password that is set by the room owner. Note that MongooseIM supports another custom solution, where each attempt to enter or create a room requires the password to be checked by an external HTTP service. To enable this option, you need to: Configure an HTTP connection pool . Set the name of the connection pool as the value of the http_auth_pool option of mod_muc . Enable the password_protected default room option (without setting the password itself). Whenever a user tries to enter or create a room, the server will receive a GET request to the check_password path. It should return a 200 response with a JSON object {\"code\": Code, \"msg\": Message} in the response body. If the server returns something else, an error presence will be sent back to the client. Code is the status code: 0 indicates a successful authentication, any other value means the authentication failed. Message is a string containing the message to be sent back to the XMPP client indicating the reason for a failed authentication. When authentication succeeds it is ignored and can contain anything ( eg. the string \"OK\" ). Example: {outgoing_pools, [{http, global, my_auth_pool, [{strategy, available_worker}], [{server, \"http://my_server:8000\"}]} ] }. {modules, [ (...) {mod_muc, [ {host, \"muc.example.com\"}, {access, muc}, {access_create, muc_create}, {http_auth_pool, my_auth_pool}, {default_room_options, [{password_protected, true}]} ]}, (...) ]}.","title":"External HTTP Authentication"},{"location":"modules/mod_muc/#metrics","text":"If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Name Type Description (when it gets incremented) [global, mod_muc, deep_hibernations] spiral A room process is stopped (applies only to persistent rooms). [global, mod_muc, process_recreations] spiral A room process is recreated from a persisted state. [global, mod_muc, hibernations] spiral A room process becomes hibernated (garbage collected and put in wait state). [global, mod_muc, hibernated_rooms] value How many rooms are in hibernated state. Does not include rooms in \"deep hibernation\". [global, mod_muc, online_rooms] value How many rooms have running processes (includes rooms in a hibernated state).","title":"Metrics"},{"location":"modules/mod_muc_commands/","text":"MongooseIM's multi-user chat commands set Purpose This is a set of commands, providing actions related to multi-user chat features. Configuration This module contains command definitions which are loaded when the module is activated. There are no options to be provided, therefore the following entry in the config file is sufficient: {mod_muc_commands, []} Commands This file consists of commands definitions . Following commands (along with functions necessary for them to run) are defined: + create_muc_room Creates a MUC room. Args: - host (binary) - name (binary) - room name - owner (binary) - the XMPP entity that would normally request an instant MUC room - nick (binary) + kick_user_from_room Kick a user from a MUC room (on behalf of a moderator). Args: - host (binary) - name (binary) - nick (binary) + invite_to_muc_room Sends a MUC room invite (direct) from one user to another. Args: - host (binary) - name (binary) - sender (binary) - recipient (binary) - reason (binary) + send_message_to_room Sends a message to a MUC room from a given room. Args: - host (binary) - name (binary) - from (binary) - body (binary) Running commands Commands must be registered and then run using the module mongoose_commands .","title":"mod_muc_commands"},{"location":"modules/mod_muc_commands/#mongooseims-multi-user-chat-commands-set","text":"","title":"MongooseIM's multi-user chat commands set"},{"location":"modules/mod_muc_commands/#purpose","text":"This is a set of commands, providing actions related to multi-user chat features.","title":"Purpose"},{"location":"modules/mod_muc_commands/#configuration","text":"This module contains command definitions which are loaded when the module is activated. There are no options to be provided, therefore the following entry in the config file is sufficient: {mod_muc_commands, []}","title":"Configuration"},{"location":"modules/mod_muc_commands/#commands","text":"This file consists of commands definitions . Following commands (along with functions necessary for them to run) are defined: + create_muc_room Creates a MUC room. Args: - host (binary) - name (binary) - room name - owner (binary) - the XMPP entity that would normally request an instant MUC room - nick (binary) + kick_user_from_room Kick a user from a MUC room (on behalf of a moderator). Args: - host (binary) - name (binary) - nick (binary) + invite_to_muc_room Sends a MUC room invite (direct) from one user to another. Args: - host (binary) - name (binary) - sender (binary) - recipient (binary) - reason (binary) + send_message_to_room Sends a message to a MUC room from a given room. Args: - host (binary) - name (binary) - from (binary) - body (binary)","title":"Commands"},{"location":"modules/mod_muc_commands/#running-commands","text":"Commands must be registered and then run using the module mongoose_commands .","title":"Running commands"},{"location":"modules/mod_muc_light/","text":"Module Description This module implements Multi-User Chat Light . It's an experimental XMPP group chat solution. This extension consists of several modules but only mod_muc_light needs to be enabled in the config file. Options host (string, default: \"muclight.@HOST@\" ) - Domain for the MUC Light service to reside under. @HOST@ is replaced with each served domain. backend (atom, default: mnesia ) - Database backend to use. mnesia and rdbms are supported. equal_occupants (boolean, default: false ) - When enabled, MUC Light rooms won't have owners. It means that every occupant will be a member , even the room creator. Warning: This option does not implicitly set all_can_invite to true . If that option is set to false , nobody will be able to join the room after the initial creation request. legacy_mode (boolean, default: false ) - Enables XEP-0045 compatibility mode. It allows using a subset of classic MUC stanzas with some MUC Light functions limited. rooms_per_user (positive integer or infinity , default: infinity ) - Specifies a cap on a number of rooms a user can occupy. Warning: Setting such a limit may trigger expensive DB queries for every occupant addition. blocking (boolean, default: true ) - Blocking feature enabled/disabled. all_can_configure (boolean, default: false ) - When enabled, all room occupants can change all configuration options. If disabled, everyone can still the change room subject. all_can_invite (boolean, default: false ) - When enabled, all room occupants can add new occupants to the room. Occupants added by members become members as well. max_occupants (positive integer or infinity , default: infinity ) - Specifies a cap on the occupant count per room. rooms_per_page (positive integer or infinity , default: 10) - Specifies maximal number of rooms returned for a single Disco request. rooms_in_rosters (boolean, default: false ) - When enabled, rooms the user occupies are included in their roster. config_schema (list; see below, default: [\"roomname\", \"subject\"] ) - A list of fields allowed in the room configuration. The field type may be specified but the default is \"binary\", i.e. effectively a string. WARNING! Lack of the roomname field will cause room names in Disco results and Roster items be set to the room username. default_config (list, default: [{\"roomname, \"Untitled\"}, {\"subject\", \"\"}] ) - Custom default room configuration; must be a subset of config schema. It's a list of KV tuples with string keys and values of appriopriate type. String values will be converted to binary automatically. Config schema Allowed config_schema list items are (may be mixed): Just the field name: \"field\" - will be expanded to \"field\" of a type binary Field name and a type: {\"field\", integer} Field name, an atom and a type: {\"field\", field, float} - useful only for debugging or unusual applications Example of such list: [\"roomname\", {\"subject\", binary}, {\"priority\", priority, integer}] Valid config field types are: binary (i.e. any valid XML CDATA) integer float Example Configuration {mod_muc_light, [ {host, \"muclight.example.com\"}, {equal_occupants, true}, {legacy_mode, true}, {rooms_per_user, 10}, {blocking, false}, {all_can_configure, true}, {all_can_invite, true}, {max_occupants, 50}, {rooms_per_page, 5}, {rooms_in_rosters, true}, {config_schema, [\"roomname\", {\"display-lines\", integer}]}, {default_config, [{\"roomname\", \"The Room\"}, {\"display-lines\", 30}]} ]}, Metrics If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Backend action Description (when it gets incremented) create_room A new room is stored in a DB. destroy_room Room data is removed from a DB. room_exists A room existence is checked. get_user_rooms A list of rooms the user is a participant of is retrieved from a DB. remove_user All MUC Light related user data is removed from a DB. get_config A room config is retrieved from a DB. set_config A room config is updated in a DB. get_blocking Blocking data is fetched from a DB. set_blocking Blocking data is updated in a DB. get_aff_users An affiliated users list is fetched from a DB. modify_aff_users Affiliations in a room are updated in a DB.","title":"mod_muc_light"},{"location":"modules/mod_muc_light/#module-description","text":"This module implements Multi-User Chat Light . It's an experimental XMPP group chat solution. This extension consists of several modules but only mod_muc_light needs to be enabled in the config file.","title":"Module Description"},{"location":"modules/mod_muc_light/#options","text":"host (string, default: \"muclight.@HOST@\" ) - Domain for the MUC Light service to reside under. @HOST@ is replaced with each served domain. backend (atom, default: mnesia ) - Database backend to use. mnesia and rdbms are supported. equal_occupants (boolean, default: false ) - When enabled, MUC Light rooms won't have owners. It means that every occupant will be a member , even the room creator. Warning: This option does not implicitly set all_can_invite to true . If that option is set to false , nobody will be able to join the room after the initial creation request. legacy_mode (boolean, default: false ) - Enables XEP-0045 compatibility mode. It allows using a subset of classic MUC stanzas with some MUC Light functions limited. rooms_per_user (positive integer or infinity , default: infinity ) - Specifies a cap on a number of rooms a user can occupy. Warning: Setting such a limit may trigger expensive DB queries for every occupant addition. blocking (boolean, default: true ) - Blocking feature enabled/disabled. all_can_configure (boolean, default: false ) - When enabled, all room occupants can change all configuration options. If disabled, everyone can still the change room subject. all_can_invite (boolean, default: false ) - When enabled, all room occupants can add new occupants to the room. Occupants added by members become members as well. max_occupants (positive integer or infinity , default: infinity ) - Specifies a cap on the occupant count per room. rooms_per_page (positive integer or infinity , default: 10) - Specifies maximal number of rooms returned for a single Disco request. rooms_in_rosters (boolean, default: false ) - When enabled, rooms the user occupies are included in their roster. config_schema (list; see below, default: [\"roomname\", \"subject\"] ) - A list of fields allowed in the room configuration. The field type may be specified but the default is \"binary\", i.e. effectively a string. WARNING! Lack of the roomname field will cause room names in Disco results and Roster items be set to the room username. default_config (list, default: [{\"roomname, \"Untitled\"}, {\"subject\", \"\"}] ) - Custom default room configuration; must be a subset of config schema. It's a list of KV tuples with string keys and values of appriopriate type. String values will be converted to binary automatically.","title":"Options"},{"location":"modules/mod_muc_light/#config-schema","text":"Allowed config_schema list items are (may be mixed): Just the field name: \"field\" - will be expanded to \"field\" of a type binary Field name and a type: {\"field\", integer} Field name, an atom and a type: {\"field\", field, float} - useful only for debugging or unusual applications Example of such list: [\"roomname\", {\"subject\", binary}, {\"priority\", priority, integer}] Valid config field types are: binary (i.e. any valid XML CDATA) integer float","title":"Config schema"},{"location":"modules/mod_muc_light/#example-configuration","text":"{mod_muc_light, [ {host, \"muclight.example.com\"}, {equal_occupants, true}, {legacy_mode, true}, {rooms_per_user, 10}, {blocking, false}, {all_can_configure, true}, {all_can_invite, true}, {max_occupants, 50}, {rooms_per_page, 5}, {rooms_in_rosters, true}, {config_schema, [\"roomname\", {\"display-lines\", integer}]}, {default_config, [{\"roomname\", \"The Room\"}, {\"display-lines\", 30}]} ]},","title":"Example Configuration"},{"location":"modules/mod_muc_light/#metrics","text":"If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Backend action Description (when it gets incremented) create_room A new room is stored in a DB. destroy_room Room data is removed from a DB. room_exists A room existence is checked. get_user_rooms A list of rooms the user is a participant of is retrieved from a DB. remove_user All MUC Light related user data is removed from a DB. get_config A room config is retrieved from a DB. set_config A room config is updated in a DB. get_blocking Blocking data is fetched from a DB. set_blocking Blocking data is updated in a DB. get_aff_users An affiliated users list is fetched from a DB. modify_aff_users Affiliations in a room are updated in a DB.","title":"Metrics"},{"location":"modules/mod_muc_light_commands/","text":"MongooseIM's multi-user chat light commands set Purpose This is a set of commands, providing actions related to multi-user chat light features. These commands are used by REST API modules. Configuration This module contains command definitions which are loaded when the module is activated. There are no options to be provided, therefore the following entry in the config file is sufficient: {mod_muc_light_commands, []} Commands This file consists of commands definitions . Following commands (along with functions necessary for them to run) are defined: + create_muc_light_room Create a MUC Light room with unique username part in JID. Args: - domain (binary) - name (binary) - owner (binary) - subject (binary) + create_identifiable_muc_light_room Creates a MUC Light room with user-provided username part in JID. Args: - domain (binary) - id (binary) - name (binary) - owner (binary) - subject (binary) + invite_to_room Invites to a MUC Light room. Args: - domain (binary) - name (binary) - sender (binary) - recipient (binary) + send_message_to_muc_light_room Sends a message to a MUC Light room. Args: - domain (binary) - name (binary) - from (binary) - body (binary) Running commands Commands must be registered and then run using the module mongoose_commands .","title":"mod_muc_light_commands"},{"location":"modules/mod_muc_light_commands/#mongooseims-multi-user-chat-light-commands-set","text":"","title":"MongooseIM's multi-user chat light commands set"},{"location":"modules/mod_muc_light_commands/#purpose","text":"This is a set of commands, providing actions related to multi-user chat light features. These commands are used by REST API modules.","title":"Purpose"},{"location":"modules/mod_muc_light_commands/#configuration","text":"This module contains command definitions which are loaded when the module is activated. There are no options to be provided, therefore the following entry in the config file is sufficient: {mod_muc_light_commands, []}","title":"Configuration"},{"location":"modules/mod_muc_light_commands/#commands","text":"This file consists of commands definitions . Following commands (along with functions necessary for them to run) are defined: + create_muc_light_room Create a MUC Light room with unique username part in JID. Args: - domain (binary) - name (binary) - owner (binary) - subject (binary) + create_identifiable_muc_light_room Creates a MUC Light room with user-provided username part in JID. Args: - domain (binary) - id (binary) - name (binary) - owner (binary) - subject (binary) + invite_to_room Invites to a MUC Light room. Args: - domain (binary) - name (binary) - sender (binary) - recipient (binary) + send_message_to_muc_light_room Sends a message to a MUC Light room. Args: - domain (binary) - name (binary) - from (binary) - body (binary)","title":"Commands"},{"location":"modules/mod_muc_light_commands/#running-commands","text":"Commands must be registered and then run using the module mongoose_commands .","title":"Running commands"},{"location":"modules/mod_muc_log/","text":"Module Description A logging submodule for mod_muc . Is must be explicitly configured to work. It writes room-related information (configuration) and events (messages, presences) to files on the disk. Options outdir (string, default: \"www/muc\" ): Filesystem directory where the files are stored. access_log (atom, default: muc_admin ): ACL that defines who can enable/disable logging for specific rooms. dirtype (atom, default: subdirs ): Specifies the log directory structure. subdirs : Module will use the following directory structure [Logs root]/[dirname]/YYYY/MM/ with file names being DD.[extension] . plain : Module will use the following directory structure [Logs root]/[dirname]/ with file names being YYYY-MM-DD.[extension] . dirname (atom, default: room_jid ): Specifies directory name created for each room. room_jid : Uses the room bare JID. room_name : Uses the room name from its configuration. file_format (atom, default: html ): html : The output is a fancy-formatted HTML page. plaintext : Just a text file, better suited for processing than HTML. css_file (binary or atom, default: false ): false : Uses default styles for HTML logs. <<\"path to custom CSS file\">> : Links custom CSS inside HTML logs. Please note it won't be copied to the logs directory but the given path will be linked in HTML files instead. timezone (atom, default: local ): local : Uses the local server timezone in dates written into the logs. universal : Uses GMT in dates written into the logs. top_link (default: `{\"/\", \"Home\"}): Allows setting a custom link at the top of the HTML log file. First tuple element is the link target and the second one is the text to be displayed. You can put any HTML instead of just plain text. spam_prevention (boolean, default: true ): When enabled, MongooseIM will enforce rel=\"nofollow\" attribute in links sent by user and written to MUC logs. Example Configuration {mod_muc_log, [ {outdir, \"/tmp/muclogs\"}, {access_log, muc} ]},","title":"mod_muc_log"},{"location":"modules/mod_muc_log/#module-description","text":"A logging submodule for mod_muc . Is must be explicitly configured to work. It writes room-related information (configuration) and events (messages, presences) to files on the disk.","title":"Module Description"},{"location":"modules/mod_muc_log/#options","text":"outdir (string, default: \"www/muc\" ): Filesystem directory where the files are stored. access_log (atom, default: muc_admin ): ACL that defines who can enable/disable logging for specific rooms. dirtype (atom, default: subdirs ): Specifies the log directory structure. subdirs : Module will use the following directory structure [Logs root]/[dirname]/YYYY/MM/ with file names being DD.[extension] . plain : Module will use the following directory structure [Logs root]/[dirname]/ with file names being YYYY-MM-DD.[extension] . dirname (atom, default: room_jid ): Specifies directory name created for each room. room_jid : Uses the room bare JID. room_name : Uses the room name from its configuration. file_format (atom, default: html ): html : The output is a fancy-formatted HTML page. plaintext : Just a text file, better suited for processing than HTML. css_file (binary or atom, default: false ): false : Uses default styles for HTML logs. <<\"path to custom CSS file\">> : Links custom CSS inside HTML logs. Please note it won't be copied to the logs directory but the given path will be linked in HTML files instead. timezone (atom, default: local ): local : Uses the local server timezone in dates written into the logs. universal : Uses GMT in dates written into the logs. top_link (default: `{\"/\", \"Home\"}): Allows setting a custom link at the top of the HTML log file. First tuple element is the link target and the second one is the text to be displayed. You can put any HTML instead of just plain text. spam_prevention (boolean, default: true ): When enabled, MongooseIM will enforce rel=\"nofollow\" attribute in links sent by user and written to MUC logs.","title":"Options"},{"location":"modules/mod_muc_log/#example-configuration","text":"{mod_muc_log, [ {outdir, \"/tmp/muclogs\"}, {access_log, muc} ]},","title":"Example Configuration"},{"location":"modules/mod_offline/","text":"Module Description This module implements an offline messages storage compliant with XEP-0160: Best Practices for Handling Offline Messages . It stores one-to-one messages only when the recipient has no online resources. It is not well suited for applications supporting multiple user devices, because anything saved in the DB can be retrieved only once, so the message history is not synchronised between devices. Although mod_offline may be sufficient in some cases, it is preferable to use mod_mam . Options access_max_user_messages (atom, default: max_user_offline_messages ): Access Rule to use for limiting the storage size per user. backend (atom, default: mnesia ): Storage backend. Currently mnesia , rdbms and riak are supported. Example Configuration {mod_offline, [{access_max_user_messages, max_user_offline_messages}]}, Metrics If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Backend action Description (when it gets incremented) pop_messages histogram write_messages histogram","title":"mod_offline"},{"location":"modules/mod_offline/#module-description","text":"This module implements an offline messages storage compliant with XEP-0160: Best Practices for Handling Offline Messages . It stores one-to-one messages only when the recipient has no online resources. It is not well suited for applications supporting multiple user devices, because anything saved in the DB can be retrieved only once, so the message history is not synchronised between devices. Although mod_offline may be sufficient in some cases, it is preferable to use mod_mam .","title":"Module Description"},{"location":"modules/mod_offline/#options","text":"access_max_user_messages (atom, default: max_user_offline_messages ): Access Rule to use for limiting the storage size per user. backend (atom, default: mnesia ): Storage backend. Currently mnesia , rdbms and riak are supported.","title":"Options"},{"location":"modules/mod_offline/#example-configuration","text":"{mod_offline, [{access_max_user_messages, max_user_offline_messages}]},","title":"Example Configuration"},{"location":"modules/mod_offline/#metrics","text":"If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Backend action Description (when it gets incremented) pop_messages histogram write_messages histogram","title":"Metrics"},{"location":"modules/mod_offline_stub/","text":"Module Description RFC 6121 requires a <service-unavailable/> stanza error to be sent to a user messaging an unavailable recipient if the message is not stored for delayed delivery (i.e. as an \"offline message\"). If the recipient exists (i.e. auth module returns true from is_user_exists ), mod_mam stores the message, but is still returned. This is not compliant with the RFC. This module prevents returning . Please note that mod_offline_stub is not tightly coupled with mod_mam . It can be used as a standalone extension, if the specific application requires it. Options None. Example Configuration {mod_offline_stub, []},","title":"mod_offline_stub"},{"location":"modules/mod_offline_stub/#module-description","text":"RFC 6121 requires a <service-unavailable/> stanza error to be sent to a user messaging an unavailable recipient if the message is not stored for delayed delivery (i.e. as an \"offline message\"). If the recipient exists (i.e. auth module returns true from is_user_exists ), mod_mam stores the message, but is still returned. This is not compliant with the RFC. This module prevents returning . Please note that mod_offline_stub is not tightly coupled with mod_mam . It can be used as a standalone extension, if the specific application requires it.","title":"Module Description"},{"location":"modules/mod_offline_stub/#options","text":"None.","title":"Options"},{"location":"modules/mod_offline_stub/#example-configuration","text":"{mod_offline_stub, []},","title":"Example Configuration"},{"location":"modules/mod_ping/","text":"Module Description This module implements XMPP Ping functionality as described in XEP-0199: XMPP Ping . Options send_pings (boolean, default false ): If set to true, the server will send ping iqs to the client if they are not active for a ping_interval . ping_interval (seconds, default 60 ): Defines the client inactivity timeout after which the server will send a ping request if the above option is set to true . timeout_action ( none | kill , default none ): Defines if the client connection should be closed if it doesn't reply to a ping request in less than ping_req_timeout . ping_req_timeout (seconds, default 32 ) Defines how long the server waits for the client to reply to the ping request. iqdisc (default: no_queue ) Example Configuration {mod_ping, [{send_pings, true}]},","title":"mod_ping"},{"location":"modules/mod_ping/#module-description","text":"This module implements XMPP Ping functionality as described in XEP-0199: XMPP Ping .","title":"Module Description"},{"location":"modules/mod_ping/#options","text":"send_pings (boolean, default false ): If set to true, the server will send ping iqs to the client if they are not active for a ping_interval . ping_interval (seconds, default 60 ): Defines the client inactivity timeout after which the server will send a ping request if the above option is set to true . timeout_action ( none | kill , default none ): Defines if the client connection should be closed if it doesn't reply to a ping request in less than ping_req_timeout . ping_req_timeout (seconds, default 32 ) Defines how long the server waits for the client to reply to the ping request. iqdisc (default: no_queue )","title":"Options"},{"location":"modules/mod_ping/#example-configuration","text":"{mod_ping, [{send_pings, true}]},","title":"Example Configuration"},{"location":"modules/mod_privacy/","text":"Module Description This module implements XEP-0016: Privacy Lists . This extension allows user to block IQs, messages, presences, or all, based on JIDs, subscription, and roster groups. Options backend (atom, default: mnesia ): Storage backend. Currently supported are mnesia , rdbms and riak . Example Configuration {mod_privacy, []}, Metrics If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Backend action Description (when it gets incremented) get_privacy_list A privacy list is retrieved from a DB. get_list_names Names of user's privacy lists are fetched from a DB. get_default_list A default privacy list for a user is fetched from a DB. set_default_list A default list's name for a user is set in a DB. forget_default_list A default list's name for a user is removed from a DB. remove_privacy_list A privacy list is deleted from a DB. replace_privacy_list A privacy list is updated (replaced) in a DB.","title":"mod_privacy"},{"location":"modules/mod_privacy/#module-description","text":"This module implements XEP-0016: Privacy Lists . This extension allows user to block IQs, messages, presences, or all, based on JIDs, subscription, and roster groups.","title":"Module Description"},{"location":"modules/mod_privacy/#options","text":"backend (atom, default: mnesia ): Storage backend. Currently supported are mnesia , rdbms and riak .","title":"Options"},{"location":"modules/mod_privacy/#example-configuration","text":"{mod_privacy, []},","title":"Example Configuration"},{"location":"modules/mod_privacy/#metrics","text":"If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Backend action Description (when it gets incremented) get_privacy_list A privacy list is retrieved from a DB. get_list_names Names of user's privacy lists are fetched from a DB. get_default_list A default privacy list for a user is fetched from a DB. set_default_list A default list's name for a user is set in a DB. forget_default_list A default list's name for a user is removed from a DB. remove_privacy_list A privacy list is deleted from a DB. replace_privacy_list A privacy list is updated (replaced) in a DB.","title":"Metrics"},{"location":"modules/mod_private/","text":"Module Description This module implements XEP-0049: Private XML Storage , allowing users to store custom XML data in the server's database. Used e.g. for storing roster groups separator. Options iqdisc (default: one_queue ) backend (atom, default: mnesia ): Storage backend. Currently mnesia , rdbms , riak and mysql are supported . mysql uses MySQL-specific queries so in some cases it is more efficient than generic rdbms . CAUTION: Riak KV backend doesn't support transactions (rollbacks), so please avoid inserting more than one value in a single set request, otherwise you may end up with partially saved data. Backend returns the first error. Example Configuration {mod_private, []} Metrics If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Backend operation Description (when it gets incremented) multi_get_data XML data is fetched from a DB. multi_set_data XML data is stored in a DB.","title":"mod_private"},{"location":"modules/mod_private/#module-description","text":"This module implements XEP-0049: Private XML Storage , allowing users to store custom XML data in the server's database. Used e.g. for storing roster groups separator.","title":"Module Description"},{"location":"modules/mod_private/#options","text":"iqdisc (default: one_queue ) backend (atom, default: mnesia ): Storage backend. Currently mnesia , rdbms , riak and mysql are supported . mysql uses MySQL-specific queries so in some cases it is more efficient than generic rdbms . CAUTION: Riak KV backend doesn't support transactions (rollbacks), so please avoid inserting more than one value in a single set request, otherwise you may end up with partially saved data. Backend returns the first error.","title":"Options"},{"location":"modules/mod_private/#example-configuration","text":"{mod_private, []}","title":"Example Configuration"},{"location":"modules/mod_private/#metrics","text":"If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Backend operation Description (when it gets incremented) multi_get_data XML data is fetched from a DB. multi_set_data XML data is stored in a DB.","title":"Metrics"},{"location":"modules/mod_pubsub/","text":"What is PubSub? PubSub is a design pattern which mostly promotes a loose coupling between two kinds of entities - publishers and subscribers. Like their names suggest, in the pubsub world we have publishers who fire events, and subscribers who wish to be notified about those events when publishers push data. There might be several subscribers, several publishers, and even several channels (or nodes) where the events are sent. Module Description This module implements XEP-0060 (Publish-Subscribe) . Due to the complexity of the protocol, the PubSub engine makes successive calls to the nodetree and node plugins in order to check the validity of requests, perform the corresponding action and return a result or appropriate error. Such an architecture makes it much easier to write custom pubsub plugins and add new storage backends. It's all about tailoring PubSub to your needs! Options iqdisc (default: one_queue ) host (string, default: \"pubsub.@HOST@\" ): Subdomain for Pubsub service to reside under. @HOST@ is replaced with each served domain. backend (atom, default: mnesia ) - Database backend to use. mnesia and rdbms are supported currently. access_create (atom, default: all ): Who is allowed to create pubsub nodes. max_items_node (integer, default: 10 ): Define the maximum number of items that can be stored in a node. max_subscriptions_node (integer, default: undefined - no limitation): The maximum number of subscriptions managed by a node. nodetree (binary, default: <<\"tree\">> ): Specifies the storage and organisation of the pubsub nodes. See the section below. ignore_pep_from_offline (boolean, default: true ): specify whether or not we should get last published PEP items from users in our roster which are offline when we connect. The default option is true hence we will get only the last items from the online contacts. last_item_cache (atom, default false ): If enabled, PubSub will cache the last published items in the nodes. It may increase PubSub performance but at a price of an increased memory usage. Valid values are mnesia , rdbms and false . plugins ([Plugin, ...], default: [<<\"flat\">>] ): List of enabled pubsub plugins. pep_mapping ([{Key, Value}, ...]): This permits creating a Key-Value list to define a custom node plugin on a given PEP namespace. E.g. pair {\"urn:xmpp:microblog:0\", \"mb\"} will use module node_mb instead of node_pep when the specified namespace is used. default_node_config ([{Key, Value}, ...]): Overrides the default node configuration, regradless of the node plugin. Node configuration still uses the default configuration defined by the node plugin, and overrides any items by the value defined in this configurable list. item_publisher (boolean, default: false ): When enabled, a JID of the publisher will be saved in the item metadata. This effectively makes them an owner of this item. sync_broadcast (boolean, default: false ): If false, routing of notifications to subscribers is done in a separate Erlang process. As a consequence, some notifications may arrive to the subscribers in the wrong order (however, the two events would have to be published at the exact same time). Cache Backend Caching is disabled by default. You may enable it by specifying the backend it should use. It is not coupled with the main DB backend, so it is possible to store the cached data in mnesia , while the actual PubSub information is kept in RDBMS (and vice versa!). Example Configuration {mod_pubsub, [{access_createnode, pubsub_createnode}, {ignore_pep_from_offline, false}, {backend, rdbms}, {last_item_cache, mnesia}, {max_items_node, 1000}, {plugins, [<<\"flat\">>, <<\"pep\">>]} ]}, Nodetrees Called on get , create and delete node. Only one nodetree can be used per host and is shared by all node plugins. <<\"tree\">> Stores nodes in a tree structure. Every node name must be formatted like a UNIX path (e.g. /top/middle/leaf ). When a node is created, its direct ancestor must already exist, so in order to create /top/middle/leaf , /top/middle is needed. A user may create any top-level node. A user may create a subnode of a node, only if they own it or it was created by the service. <<\"dag\">> Provides experimental support for XEP-0248 (PubSub Collection Nodes) . In this case you should also add the <<\"dag\">> node plugin as default, for example: {plugins, [<<\"dag\">>,<<\"flat\">>,<<\"hometree\">>,<<\"pep\">>]} Plugins They handle affiliations, subscriptions and items and also provide default node con\ufb01guration and features. PubSub clients can define which plugin to use when creating a node by adding type='plugin-name' attribute to the create stanza element. If such an attribute is not specified, the default plugin will be the first on the plugin list. <<\"flat\">> No node hierarchy. It handles the standard PubSub case. <<\"hometree\">> Uses the exact same features as the flat plugin but additionally organises nodes in a tree. Basically it follows a scheme similar to the filesystem's structure. Every user can create nodes in their own home root: e.g /home/user . Each node can contain items and/or sub-nodes. <<\"pep\">> Implementation of XEP-0060 (Personal Eventing Protocol) . In this case, items are not persisted but kept in an in-memory cache. When the pep plugin is enabled, a user can have their own node (exposed as their bare jid) with a common namespace. Requires module mod_caps to be enabled. <<\"dag\">> Implementation of XEP-0248 (PubSub Collection Nodes) . Every node takes a place in a collection and becomes either a collection node (and have only sub-nodes) or a leaf node (contains only items). <<\"push\">> Special node type that may be used as a target node for XEP-0357 (Push Notifications) capable services (e.g. mod_event_pusher_push ). For each published notification, a hook push_notification is run. You may enable as many modules that support this hook (all module with mod_push_service_* name prefix) as you like (see for example mod_push_service_mongoosepush ). This node type requires publish-options with at least device_id and service fields supplied. Metrics If you'd like to learn more about metrics in MongooseIM, please visit the MongooseIM metrics page. Overall PubSub action metrics For every PubSub action, like node creation, subscription, publication the following metrics are available: count - a spiral metric showing the number of given action invocations errors - a spiral metric counting the errors for a given action time - a histogram metric showing the time it took to finish the action in case of success Below there is a table describing all metrics related to PubSub actions Name Description (when it gets incremented) [HOST, pubsub, get, affiliations, TYPE] When node's affiliations are read [HOST, pubsub, get, configure, TYPE] When node's configuration is read [HOST, pubsub, get, default, TYPE] When node's defaults are read [HOST, pubsub, get, items, TYPE] When node's items are read [HOST, pubsub, get, options, TYPE] When node's options are read [HOST, pubsub, get, subscriptions, TYPE] When node's subscriptions are read [HOST, pubsub, set, affiliations, TYPE] When node's subscriptions are set [HOST, pubsub, set, configure, TYPE] When node's configuration is set [HOST, pubsub, set, create, TYPE] When node is created [HOST, pubsub, set, delete, TYPE] When node is deleted [HOST, pubsub, set, options, TYPE] When node's options are set [HOST, pubsub, set, publish, TYPE] When an item is published [HOST, pubsub, set, purge, TYPE] When node's items are purged [HOST, pubsub, set, retract, TYPE] When node's items are retracted [HOST, pubsub, set, subscribe, TYPE] When a subscriber subscribes to a node [HOST, pubsub, set, subscriptions, TYPE] When a subscription is set (for instance accepted) [HOST, pubsub, set, unsubscribe, TYPE] When a subscriber unsubscribes Where: HOST is the XMPP host for which mod_pubsub is running. Can be set to global if all metrics are set to be global. TYPE is one of the following count , errors , time (described above the table) Backend operations The are also more detailed metrics measuring execution time of backend operations. Metrics for these actions may be found under mod_pubsub_db subkey. Backend action Description (when it gets incremented) get_state User's state for a specific node is fetched. get_states Node's states are fetched. get_states_by_lus Nodes' states for user + domain are fetched. get_states_by_bare Nodes' states for bare JID are fetched. get_states_by_full Nodes' states for full JID are fetched. get_own_nodes_states State data for user's nodes is fetched. create_node A node's owner is set. del_node All data related to a node is removed. get_items Node's items are fetched. get_item A specific item from a node is fetched. add_item An item is upserted into a node. set_item An item is updated in a node. del_item An item is deleted from a node. del_items Specified items are deleted from a node. set_node A node is upserted. find_node_by_id A node is fetched by its ID. find_nodes_by_key Nodes are fetched by key. find_node_by_name A node is fetched by its name. del_node A node is deleted. get_subnodes Subnodes of a node are fetched. get_subnodes_tree Full tree of subnodes of a node is fetched. get_parentnodes_tree All parents of a node are fetched.","title":"mod_pubsub"},{"location":"modules/mod_pubsub/#what-is-pubsub","text":"PubSub is a design pattern which mostly promotes a loose coupling between two kinds of entities - publishers and subscribers. Like their names suggest, in the pubsub world we have publishers who fire events, and subscribers who wish to be notified about those events when publishers push data. There might be several subscribers, several publishers, and even several channels (or nodes) where the events are sent.","title":"What is PubSub?"},{"location":"modules/mod_pubsub/#module-description","text":"This module implements XEP-0060 (Publish-Subscribe) . Due to the complexity of the protocol, the PubSub engine makes successive calls to the nodetree and node plugins in order to check the validity of requests, perform the corresponding action and return a result or appropriate error. Such an architecture makes it much easier to write custom pubsub plugins and add new storage backends. It's all about tailoring PubSub to your needs!","title":"Module Description"},{"location":"modules/mod_pubsub/#options","text":"iqdisc (default: one_queue ) host (string, default: \"pubsub.@HOST@\" ): Subdomain for Pubsub service to reside under. @HOST@ is replaced with each served domain. backend (atom, default: mnesia ) - Database backend to use. mnesia and rdbms are supported currently. access_create (atom, default: all ): Who is allowed to create pubsub nodes. max_items_node (integer, default: 10 ): Define the maximum number of items that can be stored in a node. max_subscriptions_node (integer, default: undefined - no limitation): The maximum number of subscriptions managed by a node. nodetree (binary, default: <<\"tree\">> ): Specifies the storage and organisation of the pubsub nodes. See the section below. ignore_pep_from_offline (boolean, default: true ): specify whether or not we should get last published PEP items from users in our roster which are offline when we connect. The default option is true hence we will get only the last items from the online contacts. last_item_cache (atom, default false ): If enabled, PubSub will cache the last published items in the nodes. It may increase PubSub performance but at a price of an increased memory usage. Valid values are mnesia , rdbms and false . plugins ([Plugin, ...], default: [<<\"flat\">>] ): List of enabled pubsub plugins. pep_mapping ([{Key, Value}, ...]): This permits creating a Key-Value list to define a custom node plugin on a given PEP namespace. E.g. pair {\"urn:xmpp:microblog:0\", \"mb\"} will use module node_mb instead of node_pep when the specified namespace is used. default_node_config ([{Key, Value}, ...]): Overrides the default node configuration, regradless of the node plugin. Node configuration still uses the default configuration defined by the node plugin, and overrides any items by the value defined in this configurable list. item_publisher (boolean, default: false ): When enabled, a JID of the publisher will be saved in the item metadata. This effectively makes them an owner of this item. sync_broadcast (boolean, default: false ): If false, routing of notifications to subscribers is done in a separate Erlang process. As a consequence, some notifications may arrive to the subscribers in the wrong order (however, the two events would have to be published at the exact same time).","title":"Options"},{"location":"modules/mod_pubsub/#cache-backend","text":"Caching is disabled by default. You may enable it by specifying the backend it should use. It is not coupled with the main DB backend, so it is possible to store the cached data in mnesia , while the actual PubSub information is kept in RDBMS (and vice versa!).","title":"Cache Backend"},{"location":"modules/mod_pubsub/#example-configuration","text":"{mod_pubsub, [{access_createnode, pubsub_createnode}, {ignore_pep_from_offline, false}, {backend, rdbms}, {last_item_cache, mnesia}, {max_items_node, 1000}, {plugins, [<<\"flat\">>, <<\"pep\">>]} ]},","title":"Example Configuration"},{"location":"modules/mod_pubsub/#nodetrees","text":"Called on get , create and delete node. Only one nodetree can be used per host and is shared by all node plugins.","title":"Nodetrees"},{"location":"modules/mod_pubsub/#tree","text":"Stores nodes in a tree structure. Every node name must be formatted like a UNIX path (e.g. /top/middle/leaf ). When a node is created, its direct ancestor must already exist, so in order to create /top/middle/leaf , /top/middle is needed. A user may create any top-level node. A user may create a subnode of a node, only if they own it or it was created by the service.","title":"&lt;&lt;\"tree\"&gt;&gt;"},{"location":"modules/mod_pubsub/#dag","text":"Provides experimental support for XEP-0248 (PubSub Collection Nodes) . In this case you should also add the <<\"dag\">> node plugin as default, for example: {plugins, [<<\"dag\">>,<<\"flat\">>,<<\"hometree\">>,<<\"pep\">>]}","title":"&lt;&lt;\"dag\"&gt;&gt;"},{"location":"modules/mod_pubsub/#plugins","text":"They handle affiliations, subscriptions and items and also provide default node con\ufb01guration and features. PubSub clients can define which plugin to use when creating a node by adding type='plugin-name' attribute to the create stanza element. If such an attribute is not specified, the default plugin will be the first on the plugin list.","title":"Plugins"},{"location":"modules/mod_pubsub/#flat","text":"No node hierarchy. It handles the standard PubSub case.","title":"&lt;&lt;\"flat\"&gt;&gt;"},{"location":"modules/mod_pubsub/#hometree","text":"Uses the exact same features as the flat plugin but additionally organises nodes in a tree. Basically it follows a scheme similar to the filesystem's structure. Every user can create nodes in their own home root: e.g /home/user . Each node can contain items and/or sub-nodes.","title":"&lt;&lt;\"hometree\"&gt;&gt;"},{"location":"modules/mod_pubsub/#pep","text":"Implementation of XEP-0060 (Personal Eventing Protocol) . In this case, items are not persisted but kept in an in-memory cache. When the pep plugin is enabled, a user can have their own node (exposed as their bare jid) with a common namespace. Requires module mod_caps to be enabled.","title":"&lt;&lt;\"pep\"&gt;&gt;"},{"location":"modules/mod_pubsub/#dag_1","text":"Implementation of XEP-0248 (PubSub Collection Nodes) . Every node takes a place in a collection and becomes either a collection node (and have only sub-nodes) or a leaf node (contains only items).","title":"&lt;&lt;\"dag\"&gt;&gt;"},{"location":"modules/mod_pubsub/#push","text":"Special node type that may be used as a target node for XEP-0357 (Push Notifications) capable services (e.g. mod_event_pusher_push ). For each published notification, a hook push_notification is run. You may enable as many modules that support this hook (all module with mod_push_service_* name prefix) as you like (see for example mod_push_service_mongoosepush ). This node type requires publish-options with at least device_id and service fields supplied.","title":"&lt;&lt;\"push\"&gt;&gt;"},{"location":"modules/mod_pubsub/#metrics","text":"If you'd like to learn more about metrics in MongooseIM, please visit the MongooseIM metrics page.","title":"Metrics"},{"location":"modules/mod_pubsub/#overall-pubsub-action-metrics","text":"For every PubSub action, like node creation, subscription, publication the following metrics are available: count - a spiral metric showing the number of given action invocations errors - a spiral metric counting the errors for a given action time - a histogram metric showing the time it took to finish the action in case of success Below there is a table describing all metrics related to PubSub actions Name Description (when it gets incremented) [HOST, pubsub, get, affiliations, TYPE] When node's affiliations are read [HOST, pubsub, get, configure, TYPE] When node's configuration is read [HOST, pubsub, get, default, TYPE] When node's defaults are read [HOST, pubsub, get, items, TYPE] When node's items are read [HOST, pubsub, get, options, TYPE] When node's options are read [HOST, pubsub, get, subscriptions, TYPE] When node's subscriptions are read [HOST, pubsub, set, affiliations, TYPE] When node's subscriptions are set [HOST, pubsub, set, configure, TYPE] When node's configuration is set [HOST, pubsub, set, create, TYPE] When node is created [HOST, pubsub, set, delete, TYPE] When node is deleted [HOST, pubsub, set, options, TYPE] When node's options are set [HOST, pubsub, set, publish, TYPE] When an item is published [HOST, pubsub, set, purge, TYPE] When node's items are purged [HOST, pubsub, set, retract, TYPE] When node's items are retracted [HOST, pubsub, set, subscribe, TYPE] When a subscriber subscribes to a node [HOST, pubsub, set, subscriptions, TYPE] When a subscription is set (for instance accepted) [HOST, pubsub, set, unsubscribe, TYPE] When a subscriber unsubscribes Where: HOST is the XMPP host for which mod_pubsub is running. Can be set to global if all metrics are set to be global. TYPE is one of the following count , errors , time (described above the table)","title":"Overall PubSub action metrics"},{"location":"modules/mod_pubsub/#backend-operations","text":"The are also more detailed metrics measuring execution time of backend operations. Metrics for these actions may be found under mod_pubsub_db subkey. Backend action Description (when it gets incremented) get_state User's state for a specific node is fetched. get_states Node's states are fetched. get_states_by_lus Nodes' states for user + domain are fetched. get_states_by_bare Nodes' states for bare JID are fetched. get_states_by_full Nodes' states for full JID are fetched. get_own_nodes_states State data for user's nodes is fetched. create_node A node's owner is set. del_node All data related to a node is removed. get_items Node's items are fetched. get_item A specific item from a node is fetched. add_item An item is upserted into a node. set_item An item is updated in a node. del_item An item is deleted from a node. del_items Specified items are deleted from a node. set_node A node is upserted. find_node_by_id A node is fetched by its ID. find_nodes_by_key Nodes are fetched by key. find_node_by_name A node is fetched by its name. del_node A node is deleted. get_subnodes Subnodes of a node are fetched. get_subnodes_tree Full tree of subnodes of a node is fetched. get_parentnodes_tree All parents of a node are fetched.","title":"Backend operations"},{"location":"modules/mod_push_service_mongoosepush/","text":"Module Description This module handles the push_notification hook generated by mod_pubsub with an active push node. Each push_notification hook is converted as a REST API call to the MongoosePush service. The following publish-options that are added to the hook are directly passed to MongoosePush : mode - if not supplied, prod value will be used click_action - optional. See click_action in the FCM documentation or category in the APNS documentation. topic - null if not supplied service - has to be specified and the value must be valid and supported by the MongoosePush push service provider. E.g. fcm , apns . device_id - has to be specified and the value must be valid device token received from push notification service provider specified in service option In addition to those publish-options you may also specify a silent option, which, when set to true will result in \"silent\" notification. Silent notifications send only data payload to push notifications service provider with all fields specified in the notification without any modification and/or filtering. Prerequisites This module uses a connection pool via mongoose_http_client . It must be defined in outgoing_pools setting . Options pool_name (atom, required) - name of the pool to use (as defined in outgoing_pools ) api_version (string, default: v2 ) - REST API version to be used. max_http_connections (integer, default: 100) - the maximum amount of concurrent http connections Example configuration {outgoing_pools, {http, global, mongoose_push_http, [], [{server, \"https://localhost:8443\"}] } ]}. {mod_push_service_mongoosepush, [ {pool_name, mongoose_push_http} {api_version, \"v2\"} ]}.","title":"mod_push_service_mongoosepush"},{"location":"modules/mod_push_service_mongoosepush/#module-description","text":"This module handles the push_notification hook generated by mod_pubsub with an active push node. Each push_notification hook is converted as a REST API call to the MongoosePush service. The following publish-options that are added to the hook are directly passed to MongoosePush : mode - if not supplied, prod value will be used click_action - optional. See click_action in the FCM documentation or category in the APNS documentation. topic - null if not supplied service - has to be specified and the value must be valid and supported by the MongoosePush push service provider. E.g. fcm , apns . device_id - has to be specified and the value must be valid device token received from push notification service provider specified in service option In addition to those publish-options you may also specify a silent option, which, when set to true will result in \"silent\" notification. Silent notifications send only data payload to push notifications service provider with all fields specified in the notification without any modification and/or filtering.","title":"Module Description"},{"location":"modules/mod_push_service_mongoosepush/#prerequisites","text":"This module uses a connection pool via mongoose_http_client . It must be defined in outgoing_pools setting .","title":"Prerequisites"},{"location":"modules/mod_push_service_mongoosepush/#options","text":"pool_name (atom, required) - name of the pool to use (as defined in outgoing_pools ) api_version (string, default: v2 ) - REST API version to be used. max_http_connections (integer, default: 100) - the maximum amount of concurrent http connections","title":"Options"},{"location":"modules/mod_push_service_mongoosepush/#example-configuration","text":"{outgoing_pools, {http, global, mongoose_push_http, [], [{server, \"https://localhost:8443\"}] } ]}. {mod_push_service_mongoosepush, [ {pool_name, mongoose_push_http} {api_version, \"v2\"} ]}.","title":"Example configuration"},{"location":"modules/mod_register/","text":"Module Description This module implements XEP-0077: In-Band Registration , allowing users to register accounts on the server via XMPP. Use of this module on Internet-facing servers is not recommended . Options iqdisc (default: one_queue ) access (atom, default: all ): Defines which ACL should be used for checking if a chosen username is allowed for registration. welcome_message ( {Subject :: string(), Body :: string()} , default: {\"\", \"\"} ): Body and subject of a <message> stanza sent to new users. registration_watchers (list of binaries, default: [] ): List of JIDs, which should receive a <message> notification about every successful registration. password_strength (non-negative integer, default: 0): Specifies minimal entropy of allowed password. Entropy is measured with ejabberd_auth:entropy/1 . Recommended minimum is 32. The entropy calculation algorithm is described in a section below. ip_access (list of {deny|allow, StringIP|StringSubnet, default: []`): Access list for specified IPs or networks. Default value allows registration from every IP. Example configuration Allow registrations from localhost: {mod_register, [{allow, \"127.0.0.1\"}]} Deny registration from network 10.20.0.0 with mask 255.255.0.0. {mod_register, [{deny, \"10.20.0.0/16\"}]} Metrics If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Name Type Description (when it gets incremented) [Host, modRegisterCount] spiral A user registers via mod_register module. [Host, modUnregisterCount] spiral A user unregisters via mod_register module. Entropy calculation algorithm Entropy = length(Password) * log(X) / log(2) Where X is initially set to 0 and certain values are added if at least one of these bytes are present: Lower case character: 26 Upper case character: 26 Digit: 9 Printable ASCII (0x21 - 0x7e): 33 Any other value: 128 Note: These values are added only once, no matter how many bytes of specific type are found. Example entropies: kotek : ~23.5 abc123 : ~30.8 L33tSp34k : ~53.4 CamelCase : ~51.3 lowUP1#: : ~45.9 lowUP1#\u2764 : ~78","title":"mod_register"},{"location":"modules/mod_register/#module-description","text":"This module implements XEP-0077: In-Band Registration , allowing users to register accounts on the server via XMPP. Use of this module on Internet-facing servers is not recommended .","title":"Module Description"},{"location":"modules/mod_register/#options","text":"iqdisc (default: one_queue ) access (atom, default: all ): Defines which ACL should be used for checking if a chosen username is allowed for registration. welcome_message ( {Subject :: string(), Body :: string()} , default: {\"\", \"\"} ): Body and subject of a <message> stanza sent to new users. registration_watchers (list of binaries, default: [] ): List of JIDs, which should receive a <message> notification about every successful registration. password_strength (non-negative integer, default: 0): Specifies minimal entropy of allowed password. Entropy is measured with ejabberd_auth:entropy/1 . Recommended minimum is 32. The entropy calculation algorithm is described in a section below. ip_access (list of {deny|allow, StringIP|StringSubnet, default: []`): Access list for specified IPs or networks. Default value allows registration from every IP.","title":"Options"},{"location":"modules/mod_register/#example-configuration","text":"Allow registrations from localhost: {mod_register, [{allow, \"127.0.0.1\"}]} Deny registration from network 10.20.0.0 with mask 255.255.0.0. {mod_register, [{deny, \"10.20.0.0/16\"}]}","title":"Example configuration"},{"location":"modules/mod_register/#metrics","text":"If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Name Type Description (when it gets incremented) [Host, modRegisterCount] spiral A user registers via mod_register module. [Host, modUnregisterCount] spiral A user unregisters via mod_register module.","title":"Metrics"},{"location":"modules/mod_register/#entropy-calculation-algorithm","text":"Entropy = length(Password) * log(X) / log(2) Where X is initially set to 0 and certain values are added if at least one of these bytes are present: Lower case character: 26 Upper case character: 26 Digit: 9 Printable ASCII (0x21 - 0x7e): 33 Any other value: 128 Note: These values are added only once, no matter how many bytes of specific type are found.","title":"Entropy calculation algorithm"},{"location":"modules/mod_register/#example-entropies","text":"kotek : ~23.5 abc123 : ~30.8 L33tSp34k : ~53.4 CamelCase : ~51.3 lowUP1#: : ~45.9 lowUP1#\u2764 : ~78","title":"Example entropies:"},{"location":"modules/mod_revproxy/","text":"Module Description MongooseIM can be used as a reverse proxy thanks to mod_revproxy module. To enable this functionality, add a new entry to the listeners and modules sections in the mongooseim.cfg file. Setting up listener Add the following entry in the listeners section: { {8090, ejabberd_cowboy, [ {num_acceptors, 10}, {max_connections, 1024}, {modules, [ %% Example usage of mod_revproxy, please note that mod_revproxy %% needs to be included in MODULES as well. {\"_\", \"/[...]\", mod_revproxy, [{timeout, 5000}, % time limit for upstream to respond {body_length, 8000000}, % maximum body size (may be infinity) {custom_headers, [{<<\"header\">>,<<\"value\">>}]} % list of extra headers that are send to upstream ]}, ]} ]}, For more details about the listeners configuration please take a look at ejabberd_cowboy section on Listeners config page Configuring routes To define reverse proxy rules, add the following entry to the modules section. {mod_revproxy, [{routes, [{\"www.erlang-solutions.com\", \"/admin\", \"_\", \"https://www.erlang-solutions.com/\"}, {\":var.com\", \"/:var\", \"_\", \"http://localhost:8080/\"}, {\":domain.com\", \"/\", \"_\", \"http://localhost:8080/:domain\"}] }]}, Routes are defined in the options of mod_revproxy module using either {Host, Path, Method, Upstream} or {Host, Path, Upstream} . The latter one is the equivalent of {Host, Path, \"_\", Upstream} . \"_\" can be used as a wildcard for Host , Path and Method and it matches on everything. Upstreams can be defined either by host (just http(s)://host:port ) or URI. The difference between them is that the host upstreams are concatenated by the whole request path while the URI upstreams are concatenated only by the remainder that follows the matched Path . This behaviour is similar to the nginx's proxy_pass rules. Moreover, bindings may be used to match certain parts of host and/or path. They will be overlaid with appropriate parts of the upstream URI. Example configuration For example, for the shown example configuration, requests for: Host: www.erlang-solutions.com /admin/resources/case-studies will be rewritten to https://www.erlang-solutions.com/resources/case-studies (rule 1) Host: domain.com /domain/index.html will be rewritten to http://localhost:8080/index.html (rule 2, since binding :var matches in both host and path) Host: abc.com /def will be rewritten to http://localhost:8080/abc/def (rule 3)","title":"mod_revproxy"},{"location":"modules/mod_revproxy/#module-description","text":"MongooseIM can be used as a reverse proxy thanks to mod_revproxy module. To enable this functionality, add a new entry to the listeners and modules sections in the mongooseim.cfg file.","title":"Module Description"},{"location":"modules/mod_revproxy/#setting-up-listener","text":"Add the following entry in the listeners section: { {8090, ejabberd_cowboy, [ {num_acceptors, 10}, {max_connections, 1024}, {modules, [ %% Example usage of mod_revproxy, please note that mod_revproxy %% needs to be included in MODULES as well. {\"_\", \"/[...]\", mod_revproxy, [{timeout, 5000}, % time limit for upstream to respond {body_length, 8000000}, % maximum body size (may be infinity) {custom_headers, [{<<\"header\">>,<<\"value\">>}]} % list of extra headers that are send to upstream ]}, ]} ]}, For more details about the listeners configuration please take a look at ejabberd_cowboy section on Listeners config page","title":"Setting up listener"},{"location":"modules/mod_revproxy/#configuring-routes","text":"To define reverse proxy rules, add the following entry to the modules section. {mod_revproxy, [{routes, [{\"www.erlang-solutions.com\", \"/admin\", \"_\", \"https://www.erlang-solutions.com/\"}, {\":var.com\", \"/:var\", \"_\", \"http://localhost:8080/\"}, {\":domain.com\", \"/\", \"_\", \"http://localhost:8080/:domain\"}] }]}, Routes are defined in the options of mod_revproxy module using either {Host, Path, Method, Upstream} or {Host, Path, Upstream} . The latter one is the equivalent of {Host, Path, \"_\", Upstream} . \"_\" can be used as a wildcard for Host , Path and Method and it matches on everything. Upstreams can be defined either by host (just http(s)://host:port ) or URI. The difference between them is that the host upstreams are concatenated by the whole request path while the URI upstreams are concatenated only by the remainder that follows the matched Path . This behaviour is similar to the nginx's proxy_pass rules. Moreover, bindings may be used to match certain parts of host and/or path. They will be overlaid with appropriate parts of the upstream URI.","title":"Configuring routes"},{"location":"modules/mod_revproxy/#example-configuration","text":"For example, for the shown example configuration, requests for: Host: www.erlang-solutions.com /admin/resources/case-studies will be rewritten to https://www.erlang-solutions.com/resources/case-studies (rule 1) Host: domain.com /domain/index.html will be rewritten to http://localhost:8080/index.html (rule 2, since binding :var matches in both host and path) Host: abc.com /def will be rewritten to http://localhost:8080/abc/def (rule 3)","title":"Example configuration"},{"location":"modules/mod_roster/","text":"Module Description The module implements roster support, specified in RFC 6121 . Includes support for XEP-0237: Roster Versioning . It can sometimes become quite a heavyweight feature, so there is an option to disable it. Options iqdisc (default: one_queue ) versioning (boolean, default: false ): Turn on/off support for Roster Versioning. store_current_id (boolean, default: false ): Stores the last roster hash in DB (used in Roster Versioning). Improves performance but should be disabled, when shared rosters are used. backend (atom, default: mnesia ): Storage backend. Currently mnesia , rdbms and riak are supported. Example configuration {mod_roster, [ {versioning, true}, {store_current_id, true} ]} Metrics If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Backend action Description (when it gets incremented) read_roster_version Version of a user's roster is retrieved. write_roster_version Vversion of a user's roster is stored. get_roster A user's roster is fetched. get_roster_entry A specific roster entry is fetched. get_roster_entry_t A specific roster entry is fetched inside a transaction. get_subscription_lists A subscription list of a user is retrieved. roster_subscribe_t A subscription status between users is updated inside a transaction. update_roster_t A roster entry is updated in a transaction. del_roster_t A roster entry is removed inside a transaction.","title":"mod_roster"},{"location":"modules/mod_roster/#module-description","text":"The module implements roster support, specified in RFC 6121 . Includes support for XEP-0237: Roster Versioning . It can sometimes become quite a heavyweight feature, so there is an option to disable it.","title":"Module Description"},{"location":"modules/mod_roster/#options","text":"iqdisc (default: one_queue ) versioning (boolean, default: false ): Turn on/off support for Roster Versioning. store_current_id (boolean, default: false ): Stores the last roster hash in DB (used in Roster Versioning). Improves performance but should be disabled, when shared rosters are used. backend (atom, default: mnesia ): Storage backend. Currently mnesia , rdbms and riak are supported.","title":"Options"},{"location":"modules/mod_roster/#example-configuration","text":"{mod_roster, [ {versioning, true}, {store_current_id, true} ]}","title":"Example configuration"},{"location":"modules/mod_roster/#metrics","text":"If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Backend action Description (when it gets incremented) read_roster_version Version of a user's roster is retrieved. write_roster_version Vversion of a user's roster is stored. get_roster A user's roster is fetched. get_roster_entry A specific roster entry is fetched. get_roster_entry_t A specific roster entry is fetched inside a transaction. get_subscription_lists A subscription list of a user is retrieved. roster_subscribe_t A subscription status between users is updated inside a transaction. update_roster_t A roster entry is updated in a transaction. del_roster_t A roster entry is removed inside a transaction.","title":"Metrics"},{"location":"modules/mod_shared_roster_ldap/","text":"Module Description This module, when enabled, will inject roster entries fetched from LDAP. It might get quite complicated to configure it properly, so fasten your seatbelts and prepare for a ride. When a default value for an option is defined with \"top-level/XXX\", it means that the default value is equal to a top-level parameter in mongooseim.cfg of the same name. If it is not defined, XXX becomes the default value. Options: general ldap_pool_tag , ldap_base , ldap_deref : these options are the same as for the LDAP authentication module . Options: attributes ldap_groupattr (string, default: \"cn\" ): Provides a group name. ldap_groupdesc (string, default: value of ldap_groupattr ): Provides a group description. ldap_userdesc (string, default: \"cn\" ): Provides a human-readable user name. ldap_useruid (string, default: \"cn\" ): Provides a username. ldap_memberattr (string, default: \"memberUid\" ): Holds group members' IDs. ldap_memberattr_format (string, default: \"%u\" ): Simple LDAP expression for extracting a user ID. ldap_memberattr_format_re (string, default: \"\" ): Allows extracting the user ID with a regular expression. Options: parameters ldap_auth_check (boolean, default: true ): Enables checking if a shared roster entry actually exists in the XMPP database. ldap_user_cache_validity (integer, default: top-level/300): Specifies in seconds how long are the roster entries kept in the cache. ldap_group_cache_validity (integer, default: top-level/300): Specifies in seconds how long is the user's membership in a group kept in the cache . ldap_user_cache_size (integer, default: top-level/1000): Specifies how many shared roster items are kept in the cache. ldap_group_cache_size (integer, default: top-level/1000): Specifies how many roster group entries are kept in cache. Options: LDAP filters ldap_rfilter (string, default: top-level/ \"\" ): Used to find names of all shared roster groups. ldap_gfilter (string, default: top-level/ \"\" ): Used for retrieving the human-readable name and the members of a group. ldap_ufilter (string, default: top-level/ \"\" ): Used for retrieving the human-readable name of the roster entries. ldap_filter (string, default: top-level/ \"\" ): Filter AND-ed with previous filters. Example Configuration {mod_shared_roster_ldap, [ {ldap_base, \"ou=Users,dc=ejd,dc=com\"}, {ldap_groupattr, \"ou\"}, {ldap_memberattr, \"cn\"},{ldap_userdesc, \"cn\"}, {ldap_filter, \"(objectClass=inetOrgPerson)\"}, {ldap_rfilter, \"(objectClass=inetOrgPerson)\"}, {ldap_group_cache_validity, 1}, {ldap_user_cache_validity, 1}]}","title":"mod_shared_roster_ldap"},{"location":"modules/mod_shared_roster_ldap/#module-description","text":"This module, when enabled, will inject roster entries fetched from LDAP. It might get quite complicated to configure it properly, so fasten your seatbelts and prepare for a ride. When a default value for an option is defined with \"top-level/XXX\", it means that the default value is equal to a top-level parameter in mongooseim.cfg of the same name. If it is not defined, XXX becomes the default value.","title":"Module Description"},{"location":"modules/mod_shared_roster_ldap/#options-general","text":"ldap_pool_tag , ldap_base , ldap_deref : these options are the same as for the LDAP authentication module .","title":"Options: general"},{"location":"modules/mod_shared_roster_ldap/#options-attributes","text":"ldap_groupattr (string, default: \"cn\" ): Provides a group name. ldap_groupdesc (string, default: value of ldap_groupattr ): Provides a group description. ldap_userdesc (string, default: \"cn\" ): Provides a human-readable user name. ldap_useruid (string, default: \"cn\" ): Provides a username. ldap_memberattr (string, default: \"memberUid\" ): Holds group members' IDs. ldap_memberattr_format (string, default: \"%u\" ): Simple LDAP expression for extracting a user ID. ldap_memberattr_format_re (string, default: \"\" ): Allows extracting the user ID with a regular expression.","title":"Options: attributes"},{"location":"modules/mod_shared_roster_ldap/#options-parameters","text":"ldap_auth_check (boolean, default: true ): Enables checking if a shared roster entry actually exists in the XMPP database. ldap_user_cache_validity (integer, default: top-level/300): Specifies in seconds how long are the roster entries kept in the cache. ldap_group_cache_validity (integer, default: top-level/300): Specifies in seconds how long is the user's membership in a group kept in the cache . ldap_user_cache_size (integer, default: top-level/1000): Specifies how many shared roster items are kept in the cache. ldap_group_cache_size (integer, default: top-level/1000): Specifies how many roster group entries are kept in cache.","title":"Options: parameters"},{"location":"modules/mod_shared_roster_ldap/#options-ldap-filters","text":"ldap_rfilter (string, default: top-level/ \"\" ): Used to find names of all shared roster groups. ldap_gfilter (string, default: top-level/ \"\" ): Used for retrieving the human-readable name and the members of a group. ldap_ufilter (string, default: top-level/ \"\" ): Used for retrieving the human-readable name of the roster entries. ldap_filter (string, default: top-level/ \"\" ): Filter AND-ed with previous filters.","title":"Options: LDAP filters"},{"location":"modules/mod_shared_roster_ldap/#example-configuration","text":"{mod_shared_roster_ldap, [ {ldap_base, \"ou=Users,dc=ejd,dc=com\"}, {ldap_groupattr, \"ou\"}, {ldap_memberattr, \"cn\"},{ldap_userdesc, \"cn\"}, {ldap_filter, \"(objectClass=inetOrgPerson)\"}, {ldap_rfilter, \"(objectClass=inetOrgPerson)\"}, {ldap_group_cache_validity, 1}, {ldap_user_cache_validity, 1}]}","title":"Example Configuration"},{"location":"modules/mod_sic/","text":"Module Description This module implements XEP-0279: Server IP Check . It allows clients to ask the server, what is the client IP and port from the server's perspective. Options iqdisc (default: one_queue ) Example Configuration {mod_sic, []}","title":"mod_sic"},{"location":"modules/mod_sic/#module-description","text":"This module implements XEP-0279: Server IP Check . It allows clients to ask the server, what is the client IP and port from the server's perspective.","title":"Module Description"},{"location":"modules/mod_sic/#options","text":"iqdisc (default: one_queue )","title":"Options"},{"location":"modules/mod_sic/#example-configuration","text":"{mod_sic, []}","title":"Example Configuration"},{"location":"modules/mod_stream_management/","text":"Module Description Enables XEP-0198: Stream Management . Most of the logic regarding session resumption and acknowledgement is implemented in ejabberd_c2s , while the management of the session tables and configuration is implemented in mod_stream_management . Options buffer_max (default: 100): Buffer size for messages yet to be acknowledged. ack_freq (default: 1): Frequency of ack requests sent from the server to the client, e.g. 1 means a request after each stanza, 3 means a request after each 3 stanzas. resume_timeout (default: 600): Timeout for the session resumption. Sessions will be removed after the specified number of seconds. stale_h : enable keeping old server's <h> values after the resumption timed out. Defaults to [{enabled, false}] . When enabled, parameters for the garbage collection of these tables should be provided, for example as [{enabled, true}, {stale_h_repeat_after, 1800}, {stale_h_geriatric, 3600}] \u2014 1800 for stale_h_repeat_after and 3600 for stale_h_geriatric are the defaults. stale_h_repeat_after : How often the garbage collection will run in the background to clean this table. Defaults to 1800 seconds (half an hour). stale_h_geriatric : The maximum lifespan of a record in memory. After this, they will be chased for cleanup. Defaults to 3600 seconds (one hour). Example Configuration {mod_stream_management, [{buffer_max, 30}, {ack_freq, 1}, {resume_timeout, 600} {stale_h, [{enabled, true}, {stale_h_repeat_after, 1800}, {stale_h_geriatric, 3600}]} ]}, Implementation details In ejabberd_c2s The record #smgc_state{} in the ejabberd_c2s gen_fsm server keeps fields like: stream_mgmt = false, %% whether SM is enabled, used in pattern matching inside `ejabberd_c2s` stream_mgmt_in = 0, %% amount of msgs on the server and not acked by the user (server's <h>) stream_mgmt_id, %% the mod_stream_management:smid() unique identifier stream_mgmt_out_acked = 0, %% messages delivered to the user, and acked by the user (user's <h>) stream_mgmt_buffer = [], %% buffered stanzas not yet acked by the user stream_mgmt_buffer_size = 0, %% amount of messages buffered for the user stream_mgmt_buffer_max = ?STREAM_MGMT_CACHE_MAX, %% server's capacity for buffering stream_mgmt_ack_freq = ?STREAM_MGMT_ACK_FREQ, %% how often the server requests acks stream_mgmt_resume_timeout = ?STREAM_MGMT_RESUME_TIMEOUT, %% resumption timeout stream_mgmt_resume_tref, %% a ref() to pattern-match a given timeout stream_mgmt_resumed_from, %% a ejabberd_sm:sid() to keep identifiying the old session stream_mgmt_constraint_check_tref, %% another ref() for a timeout, this time for buffer_full check In mod_stream_management This module is just a \"starter\", to provide the configuration values to new client connections. It also provides a basic session table API and adds a new stream feature. At a bare minimum, this module keeps the config values in its gen_mod records, and keeps a mnesia table defined as follows: -record(sm_session, {smid :: smid(), sid :: ejabberd_sm:sid() }). where smid is a unique identifier \u2014 in this case a random binary, and sid is an opaque session identifier from ejabberd_sm , which is needed to find the previous session we want to resume from. This module implements hooks that run on connection removals and session cleanups, in order to clean records from a dying session; and it also implements registration callbacks, used in ejabberd_c2s when a session is registered for resumption. XEP version 1.6 requires the server to attempt giving the user the value of the server's <h> when a session timed out and cannot be resumed anymore. To be compliant with it, there's a second optional table: -record(stream_mgmt_stale_h, {smid :: smid(), h :: non_neg_integer(), stamp :: non_neg_integer() }). This table is created, together with a gen_server responsible for cleaning up the tables, when stale_h is set to true with the proper garbage collection configuration. Then, when removing a record from the sm_session table (which happens when the state of the previous session is also dropped), a new record is added to this new table with the smid and h values of the dropped session, together with a timestamp. Next, when a new session attempting resumption queries mod_stream_management for the data behind a smid , mod_stream_management can answer with one of the following: {sid, ejabberd_sm:sid()} | {stale_h, non_neg_integer()} | {error, smid_not_found}. And ejabberd_c2s will pattern-match and act accordingly.","title":"mod_stream_management"},{"location":"modules/mod_stream_management/#module-description","text":"Enables XEP-0198: Stream Management . Most of the logic regarding session resumption and acknowledgement is implemented in ejabberd_c2s , while the management of the session tables and configuration is implemented in mod_stream_management .","title":"Module Description"},{"location":"modules/mod_stream_management/#options","text":"buffer_max (default: 100): Buffer size for messages yet to be acknowledged. ack_freq (default: 1): Frequency of ack requests sent from the server to the client, e.g. 1 means a request after each stanza, 3 means a request after each 3 stanzas. resume_timeout (default: 600): Timeout for the session resumption. Sessions will be removed after the specified number of seconds. stale_h : enable keeping old server's <h> values after the resumption timed out. Defaults to [{enabled, false}] . When enabled, parameters for the garbage collection of these tables should be provided, for example as [{enabled, true}, {stale_h_repeat_after, 1800}, {stale_h_geriatric, 3600}] \u2014 1800 for stale_h_repeat_after and 3600 for stale_h_geriatric are the defaults. stale_h_repeat_after : How often the garbage collection will run in the background to clean this table. Defaults to 1800 seconds (half an hour). stale_h_geriatric : The maximum lifespan of a record in memory. After this, they will be chased for cleanup. Defaults to 3600 seconds (one hour).","title":"Options"},{"location":"modules/mod_stream_management/#example-configuration","text":"{mod_stream_management, [{buffer_max, 30}, {ack_freq, 1}, {resume_timeout, 600} {stale_h, [{enabled, true}, {stale_h_repeat_after, 1800}, {stale_h_geriatric, 3600}]} ]},","title":"Example Configuration"},{"location":"modules/mod_stream_management/#implementation-details","text":"","title":"Implementation details"},{"location":"modules/mod_stream_management/#in-ejabberd_c2s","text":"The record #smgc_state{} in the ejabberd_c2s gen_fsm server keeps fields like: stream_mgmt = false, %% whether SM is enabled, used in pattern matching inside `ejabberd_c2s` stream_mgmt_in = 0, %% amount of msgs on the server and not acked by the user (server's <h>) stream_mgmt_id, %% the mod_stream_management:smid() unique identifier stream_mgmt_out_acked = 0, %% messages delivered to the user, and acked by the user (user's <h>) stream_mgmt_buffer = [], %% buffered stanzas not yet acked by the user stream_mgmt_buffer_size = 0, %% amount of messages buffered for the user stream_mgmt_buffer_max = ?STREAM_MGMT_CACHE_MAX, %% server's capacity for buffering stream_mgmt_ack_freq = ?STREAM_MGMT_ACK_FREQ, %% how often the server requests acks stream_mgmt_resume_timeout = ?STREAM_MGMT_RESUME_TIMEOUT, %% resumption timeout stream_mgmt_resume_tref, %% a ref() to pattern-match a given timeout stream_mgmt_resumed_from, %% a ejabberd_sm:sid() to keep identifiying the old session stream_mgmt_constraint_check_tref, %% another ref() for a timeout, this time for buffer_full check","title":"In ejabberd_c2s"},{"location":"modules/mod_stream_management/#in-mod_stream_management","text":"This module is just a \"starter\", to provide the configuration values to new client connections. It also provides a basic session table API and adds a new stream feature. At a bare minimum, this module keeps the config values in its gen_mod records, and keeps a mnesia table defined as follows: -record(sm_session, {smid :: smid(), sid :: ejabberd_sm:sid() }). where smid is a unique identifier \u2014 in this case a random binary, and sid is an opaque session identifier from ejabberd_sm , which is needed to find the previous session we want to resume from. This module implements hooks that run on connection removals and session cleanups, in order to clean records from a dying session; and it also implements registration callbacks, used in ejabberd_c2s when a session is registered for resumption. XEP version 1.6 requires the server to attempt giving the user the value of the server's <h> when a session timed out and cannot be resumed anymore. To be compliant with it, there's a second optional table: -record(stream_mgmt_stale_h, {smid :: smid(), h :: non_neg_integer(), stamp :: non_neg_integer() }). This table is created, together with a gen_server responsible for cleaning up the tables, when stale_h is set to true with the proper garbage collection configuration. Then, when removing a record from the sm_session table (which happens when the state of the previous session is also dropped), a new record is added to this new table with the smid and h values of the dropped session, together with a timestamp. Next, when a new session attempting resumption queries mod_stream_management for the data behind a smid , mod_stream_management can answer with one of the following: {sid, ejabberd_sm:sid()} | {stale_h, non_neg_integer()} | {error, smid_not_found}. And ejabberd_c2s will pattern-match and act accordingly.","title":"In mod_stream_management"},{"location":"modules/mod_time/","text":"Module Description This module enables support for communicating the local time of an entity. It reports time in UTC according to the entity as well as the offset from UTC. Protocol is described under XEP-0202: Entity Time . Options iqdisc (default: one_queue ) Example Configuration {mod_time, []},","title":"mod_time"},{"location":"modules/mod_time/#module-description","text":"This module enables support for communicating the local time of an entity. It reports time in UTC according to the entity as well as the offset from UTC. Protocol is described under XEP-0202: Entity Time .","title":"Module Description"},{"location":"modules/mod_time/#options","text":"iqdisc (default: one_queue )","title":"Options"},{"location":"modules/mod_time/#example-configuration","text":"{mod_time, []},","title":"Example Configuration"},{"location":"modules/mod_vcard/","text":"Module Description This module provides support for vCards, as specified in XEP-0054: vcard-temp and XEP-0055: Jabber Search . Options iqdisc (default: one_queue ) host (string, default: \"vjud.@HOST@\" ): Domain of the vCard User Directory, used for searching. @HOST@ is replaced with the domain(s) supported by the cluster. search (boolean, default: true ): Enables/disables the domain set in the previous option. false makes searching for users impossible. backend (atom, default: mnesia ): vCard storage backend. Valid values are ldap , rdbms , riak and mnesia . Warning: LDAP backend is read-only. matches ( inifnity or positive integer, default: 30): Maxmimum search results to be returned to the user. LDAP-specific options ldap_pool_tag , ldap_base , ldap_uids , ldap_filter , ldap_deref : These options are the same as for the LDAP authentication module . ldap_vcard_map (list of {VCardField, LDAPPattern, LDAPField} , default: see description): Mappings between VCard and LDAP fields. For the default setting, please see [MongooseIM root]/src/mod_vcard_ldap.erl , line 74. ldap_search_fields (list of {SearchField, LDAPField} , default: see description): Mappings between the human-readable search fields and LDAP fields. For the default setting, please see [MongooseIM root]/src/mod_vcard_ldap.erl , line 96. ldap_search_reported (list of {SearchField, VCardField} , default: see description): Mappings between the human-readable search fields and VCard fields. For the default setting, please see [MongooseIM root]/src/mod_vcard_ldap.erl , line 109. ldap_search_operator ( or | and , default: and ): A default operator used for search query items. ldap_binary_search_fields (list of binaries, default: [] ): A list of search fields, which values should be Base64-encoded by MongooseIM before sending to LDAP. Example Configuration {mod_vcard, [ {allow_return_all, true}, {search_all_hosts, true}, {matches, 1}, {search, true}, {host, \"directory.example.com\"} ]} Metrics If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Backend action Description (when it gets incremented) set_vcard A vCard is set in a DB. get_vcard A specific vCard is retrieved from a DB. search A vCard search is performed.","title":"mod_vcard"},{"location":"modules/mod_vcard/#module-description","text":"This module provides support for vCards, as specified in XEP-0054: vcard-temp and XEP-0055: Jabber Search .","title":"Module Description"},{"location":"modules/mod_vcard/#options","text":"iqdisc (default: one_queue ) host (string, default: \"vjud.@HOST@\" ): Domain of the vCard User Directory, used for searching. @HOST@ is replaced with the domain(s) supported by the cluster. search (boolean, default: true ): Enables/disables the domain set in the previous option. false makes searching for users impossible. backend (atom, default: mnesia ): vCard storage backend. Valid values are ldap , rdbms , riak and mnesia . Warning: LDAP backend is read-only. matches ( inifnity or positive integer, default: 30): Maxmimum search results to be returned to the user.","title":"Options"},{"location":"modules/mod_vcard/#ldap-specific-options","text":"ldap_pool_tag , ldap_base , ldap_uids , ldap_filter , ldap_deref : These options are the same as for the LDAP authentication module . ldap_vcard_map (list of {VCardField, LDAPPattern, LDAPField} , default: see description): Mappings between VCard and LDAP fields. For the default setting, please see [MongooseIM root]/src/mod_vcard_ldap.erl , line 74. ldap_search_fields (list of {SearchField, LDAPField} , default: see description): Mappings between the human-readable search fields and LDAP fields. For the default setting, please see [MongooseIM root]/src/mod_vcard_ldap.erl , line 96. ldap_search_reported (list of {SearchField, VCardField} , default: see description): Mappings between the human-readable search fields and VCard fields. For the default setting, please see [MongooseIM root]/src/mod_vcard_ldap.erl , line 109. ldap_search_operator ( or | and , default: and ): A default operator used for search query items. ldap_binary_search_fields (list of binaries, default: [] ): A list of search fields, which values should be Base64-encoded by MongooseIM before sending to LDAP.","title":"LDAP-specific options"},{"location":"modules/mod_vcard/#example-configuration","text":"{mod_vcard, [ {allow_return_all, true}, {search_all_hosts, true}, {matches, 1}, {search, true}, {host, \"directory.example.com\"} ]}","title":"Example Configuration"},{"location":"modules/mod_vcard/#metrics","text":"If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Backend action Description (when it gets incremented) set_vcard A vCard is set in a DB. get_vcard A specific vCard is retrieved from a DB. search A vCard search is performed.","title":"Metrics"},{"location":"modules/mod_version/","text":"Module description This module provides the functionality specified in XEP-0092: Software Version . Options iqdisc (default: one_queue ) os_info (boolean, default: false ): Determines wheter information about the operating system will be included. Example configuration {mod_version, [{os_info, true}]}","title":"mod_version"},{"location":"modules/mod_version/#module-description","text":"This module provides the functionality specified in XEP-0092: Software Version .","title":"Module description"},{"location":"modules/mod_version/#options","text":"iqdisc (default: one_queue ) os_info (boolean, default: false ): Determines wheter information about the operating system will be included.","title":"Options"},{"location":"modules/mod_version/#example-configuration","text":"{mod_version, [{os_info, true}]}","title":"Example configuration"},{"location":"open-extensions/muc_light/","text":"1. Introduction Classic Multi-User chat, as described in XEP-0045, adds an IRC-like functionality to XMPP. It distinguishes between the affiliation list and the occupant list, where the latter is based on presences routed to the room from the client resource. While perfectly sufficient for desktop applications and relatively stable network connection, it does not exactly meet the challenges the mobile world it is facing. Modern mobile applications do not rely on presence information, as it can frequently change. The expected user experience not only differs from the IRC model, but also uses only a small subset of XEP-0045 features. The service described in this specification attempts to provide a complete solution for all common use cases of mobile groupchats. 2. Requirements Here are some high-level features required from a new variant of MUC The service allows any user to create a room for group communication. Users cannot join rooms on their own. They have to be added by the room owner or (if configured by service administrator) any other occupant. Only the owner can remove other occupants from the room. Every occupant can leave the room. A user may block the attempts of being added to the specific room or by specific user. The message sent in the room is always broadcasted to every occupant. The full occupant list is always available to all occupants. The occupant is always visible on the list, even if they do not have any resources online. Occupants can only have two affiliations: owner and member. There MUST be at most one owner in the room (the service can choose to treat all users equally). If the room becomes empty, it is destroyed. Occupants cannot hide behind nicks. Their real bare JID is always visible to everyone No exchange of any <presence/> stanza inside the room. The user MUST be able to retrieve the list of rooms they occupy. The owner can modify the room configuration at any time; members may also be allowed to set configuration. All occupants can get the full room configuration at any time. Room history is available only in Message Archive Management. 3. Entity Use Cases 3.1 Discovering a MUC Light Service An entity often discovers a MUC service by sending a Service Discovery items (\"disco#items\") request to its own server. Entity Queries the Server for Associated Services <iq from='hag66@shakespeare.lit/pda' id='h7ns81g' to='shakespeare.lit' type='get'> <query xmlns='http://jabber.org/protocol/disco#items'/> </iq> The server then returns the services that are associated with it. Server Returns a Disco Items Result <iq from='shakespeare.lit' id='h7ns81g' to='hag66@shakespeare.lit/pda' type='result'> <query xmlns='http://jabber.org/protocol/disco#items'> <item jid='muclight.shakespeare.lit' name='MUC Light Service'/> </query> </iq> 3.2 Discovering the Features Supported by a MUC Light Service An entity may wish to discover if a service implements the Multi-User Chat protocol; in order to do so, it sends a service discovery information (\"disco#info\") query to the MUC service's JID. Entity Queries Chat Service for MUC Light Support via Disco <iq from='hag66@shakespeare.lit/pda' id='lx09df27' to='muclight.shakespeare.lit' type='get'> <query xmlns='http://jabber.org/protocol/disco#info'/> </iq> The service MUST return its identity and the features it supports. Service Returns a Disco Info Result <iq from='muclight.shakespeare.lit' id='lx09df27' to='hag66@shakespeare.lit/pda' type='result'> <query xmlns='http://jabber.org/protocol/disco#info'> <identity category='conference' name='Shakespearean Chat Service' type='text'/> <feature var='urn:xmpp:muclight:0'/> </query> </iq> 3.3 Discovering Occupied Rooms The service discovery items (\"disco#items\") protocol enables an entity to query a service for a list of associated items, which in the case of a chat service would consist of the specific chat rooms the entity occupies. Entity Queries Chat Service for Rooms <iq from='hag66@shakespeare.lit/pda' id='zb8q41f4' to='muclight.shakespeare.lit' type='get'> <query xmlns='http://jabber.org/protocol/disco#items'/> </iq> The service MUST return a full list of the rooms the entity occupies. The server SHOULD include room name and version in each item. Service Returns a Disco Items Result <iq from='muclight.shakespeare.lit' id='zb8q41f4' to='hag66@shakespeare.lit/pda' type='result'> <query xmlns='http://jabber.org/protocol/disco#items'> <item jid='heath@muclight.shakespeare.lit' name='A Lonely Heath' version='1'/> <item jid='coven@muclight.shakespeare.lit' name='A Dark Cave' version='2'/> <item jid='forres@muclight.shakespeare.lit' name='The Palace' version='3'/> <item jid='inverness@muclight.shakespeare.lit' name='Macbeth&apos;s Castle' version='4'/> </query> </iq> If the full list of rooms is large (see XEP-0030 for details), the service MAY return only a partial list of rooms. If it does, it MUST include a <set/> element qualified by the 'http://jabber.org/protocol/rsm' namespace (as defined in Result Set Management (XEP-0059) [1]) to indicate that the list is not the full result set. Service Returns a Limited List of Disco Items Result <iq from='muclight.shakespeare.lit' id='hx51v49s' to='hag66@shakespeare.lit/pda' type='result'> <query xmlns='http://jabber.org/protocol/disco#items'> <item jid='alls-well-that-ends-well@muclight.shakespeare.lit' name='Everybody dies' version='1'/> <item jid='as-you-like-it@muclight.shakespeare.lit' name='As you like it' version='2'/> <item jid='cleopatra@muclight.shakespeare.lit' name='Cleo fans' version='3'/> <item jid='comedy-of-errors@muclight.shakespeare.lit' name='404 Comedy not found' version='4'/> <item jid='coriolanus@muclight.shakespeare.lit' name='What is Coriolanus?' version='5'/> <item jid='cymbeline@muclight.shakespeare.lit' name='Music room' version='6'/> <item jid='hamlet@muclight.shakespeare.lit' name='To chat or not to chat?' version='7'/> <item jid='henry-the-fourth-one@muclight.shakespeare.lit' name='Royal Room 1' version='8'/> <item jid='henry-the-fourth-two@muclight.shakespeare.lit' name='Royal Room 2' version='9'/> <item jid='henry-the-fifth@muclight.shakespeare.lit' name='Royal Room Prime' version='10'/> <set xmlns='http://jabber.org/protocol/rsm'> <first index='0'>alls-well-that-ends-well@muclight.shakespeare.lit</first> <last>henry-the-fifth@muclight.shakespeare.lit</last> <count>37</count> </set> </query> </iq> 4. Occupant Use Cases 4.1 Sending a message to a room Every occupant in the room MAY broadcast messages to other occupants. In order to do so, the client MUST send a groupchat message to the room bare JID. The room automatically assumes that occupants' nicks are equal to their bare JIDs. MUC light is designed for applications where it is not important to hide behind nicknames. On the contrary - it is up to the client to replace pure JIDs with user-friendly names like phone numbers or full names if necessary. The room MUST route all messages of the 'groupchat' type. Client sends a message to the room <message from='hag66@shakespeare.lit/pda' id='msg111' to='coven@muclight.shakespeare.lit' type='groupchat'> <body>Harpier cries: 'tis time, 'tis time.</body> </message> Server broadcasts a groupchat message <message id='msg111' type='groupchat' from='coven@muclight.shakespeare.lit/hag66@shakespeare.lit' to='crone1@shakespeare.lit'> <body>Harpier cries: 'tis time, 'tis time.</body> </message> <message id='msg111' type='groupchat' from='coven@muclight.shakespeare.lit/hag66@shakespeare.lit' to='crone2@shakespeare.lit'> <body>Harpier cries: 'tis time, 'tis time.</body> </message> Note the message is sent to all the room occupants including the original sender. <message id='msg111' type='groupchat' from='coven@muclight.shakespeare.lit/hag66@shakespeare.lit' to='hag66@shakespeare.lit'> <body>Harpier cries: 'tis time, 'tis time.</body> </message> 4.2 Changing a room subject The service MAY allow room occupants to set the room subject by changing the \"subject\" configuration field. A standard configuration stanza is used in this case. Subject change is announced like an ordinary configuration change. Client sends a message to the room <iq from='hag66@shakespeare.lit/pda' id='subject1' to='coven@muclight.shakespeare.lit' type='set'> <query xmlns='urn:xmpp:muclight:0#configuration'> <subject>To be or not to be?</subject> </query> </iq> <message from='coven@muclight.shakespeare.lit' to='crone1@shakespeare.lit' type='groupchat' id='newsubject'> <x xmlns='urn:xmpp:muclight:0#configuration'> <prev-version>asdfghj000</prev-version> <version>asdfghj</version> <subject>To be or not to be?</subject> </x> <body /> </message> <message from='coven@muclight.shakespeare.lit' to='hag66@shakespeare.lit' type='groupchat' id='newsubject'> <x xmlns='urn:xmpp:muclight:0#configuration'> <prev-version>asdfghj000</prev-version> <version>asdfghj</version> <subject>To be or not to be?</subject> </x> <body /> </message> <iq to='hag66@shakespeare.lit/pda' id='subject1' from='coven@muclight.shakespeare.lit' type='result' /> 4.3 Requesting room information Room occupants may request room information (configuration and/or occupants list) by an information version. It is up to the service to define the version string, the only requirement for it, is to be unique per room. Please note there are no separate versions for configuration and occupant list alone. If the server side version does not match the one provided by the client (or if the client does not provide one, i.e. the 'version' element is empty), the service MUST respond with a current version string and full configuration and/or occupant list. If the version strings match, server MUST reply with an empty result. Only room occupants can get room information. Matching versions <iq from='crone1@shakespeare.lit/desktop' id='config0' to='coven@muclight.shakespeare.lit' type='get'> <query xmlns='urn:xmpp:muclight:0#configuration'> <version>abcdefg</version> </query> </iq> <iq from='coven@muclight.shakespeare.lit' id='config0' to='crone1@shakespeare.lit/desktop' type='result' /> 4.3.1 Getting the room configuration Client gets configuration from the server <iq from='crone1@shakespeare.lit/desktop' id='getconfig1' to='coven@muclight.shakespeare.lit' type='get'> <query xmlns='urn:xmpp:muclight:0#configuration'> <version>abcdefg</version> </query> </iq> <iq from='coven@muclight.shakespeare.lit' id='getconfig1' to='crone1@shakespeare.lit/desktop' type='result'> <query xmlns='urn:xmpp:muclight:0#configuration'> <version>123456</version> <roomname>A Dark Cave</roomname> </query> </iq> 4.3.2 Requesting a user list Client requests a user list <iq from='crone1@shakespeare.lit/desktop' id='getmembers' to='coven@muclight.shakespeare.lit' type='get'> <query xmlns='urn:xmpp:muclight:0#affiliations'> <version>abcdefg</version> </query> </iq> <iq from='coven@muclight.shakespeare.lit' id='getmembers' to='crone1@shakespeare.lit/desktop' type='result'> <query xmlns='urn:xmpp:muclight:0#affiliations'> <version>123456</version> <user affiliation='owner'>user1@shakespeare.lit</user> <user affiliation='member'>user2@shakespeare.lit</user> <user affiliation='member'>user3@shakespeare.lit</user> </query> </iq> 4.3.3 Requesting full room information Room occupants may request both lists (configuration + occupants) with a single request. Client requests room information <iq from='crone1@shakespeare.lit/desktop' id='getinfo1' to='coven@muclight.shakespeare.lit' type='get'> <query xmlns='urn:xmpp:muclight:0#info'> <version>abcdefg</version> </query> </iq> <iq from='coven@muclight.shakespeare.lit' id='getinfo1' to='crone1@shakespeare.lit/desktop' type='result'> <query xmlns='urn:xmpp:muclight:0#info'> <version>123456</version> <configuration> <roomname>A Dark Cave</roomname> </configuration> <occupants> <user affiliation='owner'>user1@shakespeare.lit</user> <user affiliation='member'>user2@shakespeare.lit</user> <user affiliation='member'>user3@shakespeare.lit</user> </occupants> </query> </iq> 4.4 Leaving the room Every occupant is allowed to leave the room at any time. It is done by modifying their own affiliation. Occupant leaves the room <iq from='crone1@shakespeare.lit/desktop' id='leave1' to='coven@muclight.shakespeare.lit' type='set'> <query xmlns='urn:xmpp:muclight:0#affiliations'> <user affiliation='none'>crone1@shakespeare.lit</user> </query> </iq> <message from='coven@muclight.shakespeare.lit' to='crone1@shakespeare.lit' type='groupchat' id='leave1'> <x xmlns='urn:xmpp:muclight:0#affiliations'> <user affiliation='none'>crone1@shakespeare.lit</user> </x> <body /> </message> <message from='coven@muclight.shakespeare.lit' to='hag77@shakespeare.lit' type='groupchat' id='leave1'> <x xmlns='urn:xmpp:muclight:0#affiliations'> <prev-version>1111111</prev-version> <version>aaaaaaa</version> <user affiliation='none'>crone1@shakespeare.lit</user> </x> <body /> </message> <message from='coven@muclight.shakespeare.lit' to='hag88@shakespeare.lit' type='groupchat' id='leave1'> <x xmlns='urn:xmpp:muclight:0#affiliations'> <prev-version>1111111</prev-version> <version>aaaaaaa</version> <user affiliation='none'>crone1@shakespeare.lit</user> </x> <body /> </message> <iq to='crone1@shakespeare.lit/desktop' id='leave1' from='coven@muclight.shakespeare.lit' type='result' /> 4.5 Blocking functionality A user MAY choose to automatically deny being added to the room. All stanzas must be directed to MUC Light service. User MAY send more than one item in a single request and mix both 'user' and 'room' elements. If the occupant tries to add another user to the room, and this user has set a blocking policy, the server MUST ignore the attempt. No error is returned, this user is simply skipped when processing affiliation change query. Service denies adding blocking user <iq from='crone2@shakespeare.lit/desktop' id='blocked1' to='coven@muclight.shakespeare.lit' type='set'> <query xmlns='urn:xmpp:muclight:0#affiliations'> <user affiliation='member'>crone1@shakespeare.lit</user> <user affiliation='member'>crone3@shakespeare.lit</user> </query> </iq> <message from='coven@muclight.shakespeare.lit' to='crone2@shakespeare.lit' type='groupchat' id='blockedadd1'> <x xmlns='urn:xmpp:muclight:0#affiliations'> <user affiliation='member'>crone3@shakespeare.lit</user> </x> <body /> </message> <message from='coven@muclight.shakespeare.lit' to='hag88@@shakespeare.lit' type='groupchat' id='blockedadd1'> <x xmlns='urn:xmpp:muclight:0#affiliations'> <user affiliation='member'>crone3@shakespeare.lit</user> </x> <body /> </message> <iq to='crone2@shakespeare.lit/desktop' id='blocked1' from='coven@muclight.shakespeare.lit' type='result' /> 4.5.1 Requesting a blocking list In order to get the current blocking list in the MUC Light service, the client sends an empty IQ get query with a proper namespace. The list includes only items with a 'deny' action, since the 'allow' behaviour is default for MUC Light and is only used for the list modification. User retrieves a blocking list <iq from='crone1@shakespeare.lit/desktop' id='getblock1' to='muclight.shakespeare.lit' type='get'> <query xmlns='urn:xmpp:muclight:0#blocking'> </query> </iq> <iq type='result' id='getblock1' to='crone1@shakespeare.lit/desktop' from='muclight.shakespeare.lit'> <query xmlns='urn:xmpp:muclight:0#blocking'> <room action='deny'>coven@muclight.shakespeare.lit</room> <user action='deny'>hag77@shakespeare.lit</user> </query> </iq> 4.5.2 Blocking a room In order to block a room, a query must contain at least one 'room' item with a 'deny' action and a room bare JID in the content. User blocks a room <iq from='crone1@shakespeare.lit/desktop' id='block1' to='muclight.shakespeare.lit' type='set'> <query xmlns='urn:xmpp:muclight:0#blocking'> <room action='deny'>coven@muclight.shakespeare.lit</room> <room action='deny'>chapel@shakespeare.lit</room> </query> </iq> <iq type='result' id='block1' to='crone1@shakespeare.lit/desktop' from='muclight.shakespeare.lit' /> 4.5.3 Blocking a user In order to block a user, a query must contain at least one 'user' item with a 'deny' action and a user bare JID in the content. User blocks another user <iq from='crone1@shakespeare.lit/desktop' id='block2' to='muclight.shakespeare.lit' type='set'> <query xmlns='urn:xmpp:muclight:0#blocking'> <user action='deny'>hag66@shakespeare.lit</user> <user action='deny'>hag77@shakespeare.lit</user> </query> </iq> <iq type='result' id='block2' to='crone1@shakespeare.lit/desktop' from='muclight.shakespeare.lit' /> 4.5.4 Unblocking In order to cancel a blocking, a query must contain at least one 'room' or 'user' item with an 'allow' action and an appriopriate bare JID in the content. Unblocking a JID that is not blocked does not trigger any error. The server MUST return an empty IQ result in such case. User cancels blocking <iq from='crone1@shakespeare.lit/desktop' id='unblock1' to='muclight.shakespeare.lit' type='set'> <query xmlns='urn:xmpp:muclight:0#blocking'> <room action='allow'>coven@muclight.shakespeare.lit</room> <user action='allow'>hag66@shakespeare.lit</user> </query> </iq> <iq type='result' id='unblock1' to='crone1@shakespeare.lit/desktop' from='muclight.shakespeare.lit' /> 5. Owner Use Cases 5.1 Creating a new room A room is created by submitting a dedicated stanza. The client application should pick a random room node name, since a human-readable room name is in configuration. For rules that apply to the configuration options, please see \"Setting room configuration\" chapter. The client MAY include initial configuration and occupant list (the list MUST NOT include the creator). The server MAY allow sending an incomplete configuration form. In such case the server MUST use the default values for missing fields. The server MAY enforce a minimal occupant list length. The service MAY either give the creator the 'owner' or 'member' status. In the latter case all users are equal. Upon room creation success, the service MUST reply with an empty IQ result. The following rules (similar to the ones relevant to the affiliation change request) apply to the occupant list: 'none' affiliation cannot be used. All user bare JIDs must be unique At most one owner can be chosen. If none is chosen, the room creator will become \"just\" a 'member'. After the room is created (but before receiving IQ result), new occupants (including the creator) receive <message/> from the room with their affiliations (the stanza MUST include only recipient's affiliation) and the initial room version. <prev-version/> element MUST NOT be included. Client requests room creation <iq from='crone1@shakespeare.lit/desktop' id='create1' to='coven@muclight.shakespeare.lit' type='set'> <query xmlns='urn:xmpp:muclight:0#create'> <configuration> <roomname>A Dark Cave</roomname> </configuration> <occupants> <user affiliation='member'>user1@shakespeare.lit</user> <user affiliation='member'>user2@shakespeare.lit</user> </occupants> </query> </iq> <message from='coven@muclight.shakespeare.lit' to='crone1@shakespeare.lit' type='groupchat' id='createnotif'> <x xmlns='urn:xmpp:muclight:0#affiliations'> <version>aaaaaaa</version> <user affiliation='owner'>crone1@shakespeare.lit</user> </x> <body /> </message> <message from='coven@muclight.shakespeare.lit' to='user1@shakespeare.lit' type='groupchat' id='createnotif'> <x xmlns='urn:xmpp:muclight:0#affiliations'> <version>aaaaaaa</version> <user affiliation='member'>user1@shakespeare.lit</user> </x> <body /> </message> <message from='coven@muclight.shakespeare.lit' to='user2@shakespeare.lit' type='groupchat' id='createnotif'> <x xmlns='urn:xmpp:muclight:0#affiliations'> <version>aaaaaaa</version> <user affiliation='member'>user2@shakespeare.lit</user> </x> <body /> </message> <iq to='crone1@shakespeare.lit/desktop' id='create1' from='coven@muclight.shakespeare.lit' type='result' /> 5.1.1 Requesting a new room with a unique name If a client would like to avoid a room JID conflict, it MAY request creating a new room with a server-side generated name, that is verfied to be unique. In order to do so, the client MUST send a creation request to service JID, not room bare JID. The IQ result will originate from the new room bare JID The messages with affiliation change notifications MUST have the same ID as IQ set and result. Client requests room creation <iq from='crone1@shakespeare.lit/desktop' id='createrandom' to='muclight.shakespeare.lit' type='set'> <query xmlns='urn:xmpp:muclight:0#create'> <configuration> <roomname>Random Cave</roomname> </configuration> </query> </iq> <message from='randomcave@muclight.shakespeare.lit' to='crone1@shakespeare.lit' type='groupchat' id='createrandom'> <x xmlns='urn:xmpp:muclight:0#affiliations'> <version>aaaaaaa</version> <user affiliation='owner'>crone1@shakespeare.lit</user> </x> <body /> </message> <iq to='crone1@shakespeare.lit/desktop' id='createrandom' from='muclight.shakespeare.lit' type='result' /> 5.1.2 Room already exists If the chosen room name already exists, the service MUST return a 'conflict' error. Client requests room creation with existing name <iq from='crone1@shakespeare.lit/desktop' id='conflict1' to='castle@muclight.shakespeare.lit' type='set'> <query xmlns='urn:xmpp:muclight:0#create'> <configuration> <roomname>A Dark Cave</roomname> </configuration> </query> </iq> <iq to='crone1@shakespeare.lit/desktop' id='conflict1' from='castle@muclight.shakespeare.lit' type='error'> <error type='cancel'> <conflict xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/> </error> </iq> 5.2 Destroying a room A room is automatically destroyed when its occupant list becomes empty or the room owner explicitly sends an IQ with a room destroy request. Before sending an IQ result, every occupant is notified that its affiliation has changed to 'none'. These notifications include an <x/> element qualified with a \"urn:xmpp:muclight:0#destroy\" namespace. Only the room owner is allowed to destroy it. Room destruction notification SHOULD NOT contain version (or \"prev-version\" information). Client requests room destruction <iq from='crone1@shakespeare.lit/desktop' id='destroy1' to='coven@muclight.shakespeare.lit' type='set'> <query xmlns='urn:xmpp:muclight:0#destroy' /> </iq> <message from='coven@muclight.shakespeare.lit' to='crone1@shakespeare.lit' type='groupchat' id='destroynotif'> <x xmlns='urn:xmpp:muclight:0#affiliations'> <user affiliation='none'>crone1@shakespeare.lit</user> </x> <x xmlns='urn:xmpp:muclight:0#destroy' /> <body /> </message> <message from='coven@muclight.shakespeare.lit' to='hag77@shakespeare.lit' type='groupchat' id='destroynotif'> <x xmlns='urn:xmpp:muclight:0#affiliations'> <user affiliation='none'>hag77@shakespeare.lit</user> </x> <x xmlns='urn:xmpp:muclight:0#destroy' /> <body /> </message> <message from='coven@muclight.shakespeare.lit' to='hag88@shakespeare.lit' type='groupchat' id='destroynotif'> <x xmlns='urn:xmpp:muclight:0#affiliations'> <user affiliation='none'>hag88@shakespeare.lit</user> </x> <x xmlns='urn:xmpp:muclight:0#destroy' /> <body /> </message> <iq to='crone1@shakespeare.lit/desktop' id='create1' from='coven@muclight.shakespeare.lit' type='result' /> 5.3 Setting room configuration Only room owners can modify the room configuration but the service MAY allow members to change it too. All room occupants MUST be notified about a configuration change and both the new and old room version string ( <version /> and <prev-version /> respectively). \"version\" and \"prev-version\" configuration field names are NOT ALLOWED - they are reserved for room versioning. The service MAY allow the client to set the configuration fields with any name but it is NOT RECOMMENDED. The Data Forms are not used for the configuration. Instead, the config fields are encoded in XML elements with names equal to the key and content equal to the value. Client configuration request to the server <iq from='crone1@shakespeare.lit/desktop' id='conf2' to='coven@muclight.shakespeare.lit' type='set'> <query xmlns='urn:xmpp:muclight:0#configuration'> <roomname>A Darker Cave</roomname> </query> </iq> <message from='coven@muclight.shakespeare.lit' to='crone1@shakespeare.lit' type='groupchat' id='configchange'> <x xmlns='urn:xmpp:muclight:0#configuration'> <prev-version>zaqwsx</prev-version> <version>zxcvbnm</version> <roomname>A Darker Cave</roomname> </x> <body /> </message> <message from='coven@muclight.shakespeare.lit' to='hag66@shakespeare.lit' type='groupchat' id='configchange'> <x xmlns='urn:xmpp:muclight:0#configuration'> <prev-version>zaqwsx</prev-version> <version>zxcvbnm</version> <roomname>A Darker Cave</roomname> </x> <body /> </message> <iq to='crone1@shakespeare.lit/desktop' id='conf2' from='coven@muclight.shakespeare.lit' type='result' /> The server SHOULD accept incomplete (i.e. delta) configuration forms. In such case, values of the missing fields SHOULD be preserved. 5.4 Changing the occupant list The occupant list is modified by a direct affiliation change. Following rules apply: There are only 3 affiliations. owner - can do everything in the room member - can send messages to the room and if the service allows it, can also change configuration or change others' affiliations none - not in the room; it's a keyword for marking a user for removal from a room Every occupant can change its own affiliation to none in order to leave the room. The only way to join the room is being added by other occupant. The owner can change affiliations at will. If the owner leaves, the server MAY use any strategy to choose a new one. The room can have at most one owner. Giving someone else the 'owner' status effectively causes the current one to lose it. The owner can choose a new owner when leaving by including both 'none' and 'owner' items in affiliation change request. Every user JID can be used in the request at most once. A single request MAY change multiple affiliations. All changes must be meaningful, e.g. setting member's affiliation to 'member' is considered a bad request. Server MAY allow members to add new members but they still cannot make anyone an 'owner' or remove other users from the room. On success the server will reply with a result IQ with all the changed items. BEFORE returning the IQ result, the service MUST route a message with the affiliation change to all relevant users. Newcomers, i.e. users that were not occupants before the change, SHOULD receive only their own affiliation and SHOULD NOT receive a <prev-version /> element. The notifications must include both the new and old room version ( <version /> and <prev-version /> respectively) string (except for the ones directed to users that have been removed from the room). The notifications contain a list of items. The item list may be different from the list in the IQ set, because some of the changes may require additional operations, e.g. choosing new owner when the old one leaves. Users, that are still in the room after the change, will receive the full change list. Users, that have been removed from the room with the request, will get only one item: themselves with affiliation 'none'. Affiliations change request Let's consider a room coven with following members: crone1 - owner hag77 - member hag88 - member hag66 is not in the room yet. User crone1 wants to add hag66 to the room, kick hag88 out and make hag77 the room owner. <iq from='crone1@shakespeare.lit/desktop' id='member1' to='coven@muclight.shakespeare.lit' type='set'> <query xmlns='urn:xmpp:muclight:0#affiliations'> <user affiliation='member'>hag66@shakespeare.lit</user> <user affiliation='owner'>hag77@shakespeare.lit</user> <user affiliation='none'>hag88@shakespeare.lit</user> </query> </iq> Now each user will receive an update. As you can see, affiliations have changed accordingly to crone1 request. However, this request implies one more update. Since hag77 has been promoted to a new owner, crone1 is automatically degraded to member . <message from='coven@muclight.shakespeare.lit' to='crone1@shakespeare.lit' type='groupchat' id='memberchange'> <x xmlns='urn:xmpp:muclight:0#affiliations'> <prev-version>njiokm</prev-version> <version>qwerty</version> <user affiliation='member'>crone1@shakespeare.lit</user> <user affiliation='member'>hag66@shakespeare.lit</user> <user affiliation='owner'>hag77@shakespeare.lit</user> <user affiliation='none'>hag88@shakespeare.lit</user> </x> <body></body> </message> Because hag66 was not a member of this room before, they only receive their own affiliation and no prev-version element. <message from='coven@muclight.shakespeare.lit' to='hag66@shakespeare.lit' type='groupchat' id='memberchange'> <x xmlns='urn:xmpp:muclight:0#affiliations'> <version>qwerty</version> <user affiliation='member'>hag66@shakespeare.lit</user> </x> <body></body> </message> hag77 receives an ordinary update, just like crone1 . <message from='coven@muclight.shakespeare.lit' to='hag77@shakespeare.lit' type='groupchat' id='memberchange'> <x xmlns='urn:xmpp:muclight:0#affiliations'> <prev-version>njiokm</prev-version> <version>qwerty</version> <user affiliation='member'>crone1@shakespeare.lit</user> <user affiliation='member'>hag66@shakespeare.lit</user> <user affiliation='owner'>hag77@shakespeare.lit</user> <user affiliation='none'>hag88@shakespeare.lit</user> </x> <body></body> </message> hag88 has been kicked out of the room and therefore gets only their own affiliation change of type 'none'. <message from='coven@muclight.shakespeare.lit' to='hag88@shakespeare.lit' type='groupchat' id='memberchange'> <x xmlns='urn:xmpp:muclight:0#affiliations'> <user affiliation='none'>hag88@shakespeare.lit</user> </x> <body></body> </message> crone1 gets the result IQ after the change. <iq to='crone1@shakespeare.lit/desktop' id='member1' from='coven@muclight.shakespeare.lit' type='result' /> 6. Interactions with RFCs and other XEPs 6.1 User rosters The service MAY add user's rooms to its roster. It allows the client to skip the separate Disco request to the service. Roster items with rooms MUST belong to the group \"urn:xmpp:muclight:0\" (MUC Light namespace) and include the <version/> element. Their subscription type MUST be 'to'. Entity requests the roster and receives a reply that includes a room item <iq type='get' id='roster1' to='shakespeare.lit'> <query xmlns='jabber:iq:roster'/> </iq> <iq id='roster1' to='hag66@shakespeare.lit/tablet' type='result'> <query xmlns='jabber:iq:roster' ver='ver7'> <item jid='hag77@shakespeare.lit' subscription='both'/> <item jid='hag88@shakespeare.lit' subscription='both'/> <item jid='coven@muclight.shakespeare.lit' name='The Coven' subscription='to'> <group>urn:xmpp:muclight:0</group> <version>1234345</version> </item> </query> </iq> 6.2 XEP-0313 Message Archive Management This section defines the rules for archiving MUC Light events and messages. Stanzas described in the subsections below MUST be archived by the server. The stanzas not included here MUST NOT be archived. The <message/> element inside <forwarded/> MUST include a \"from\" attribute and MUST NOT include a \"to\" attribute. \"id\" SHOULD be archived as well. In case of regular groupchat messages, the \"from\" attribute MUST consist of a room full JID with a sender bare JID in the resource part. As for room notification, e.g. create event, \"from\" MUST be equal to room bare JID. Examples below use MAM v0.4 protocol. The archive can be fetched only from a specific room, the client MUST NOT query MUC Light service directly. 6.2.1 Groupchat message from occupant Message from a user MUST be archived with all child elements. Occupant queries MAM and receives regular groupchat message <iq type='set' id='mamget1' to='coven@muclight.shakespeare.lit'> <query xmlns='urn:xmpp:mam:1' queryid='f27' /> </iq> <message id='aeb213' to='hag66@shakespeare.lit/pda'> <result xmlns='urn:xmpp:mam:1' queryid='f27' id='28482-98726-73623'> <forwarded xmlns='urn:xmpp:forward:0'> <delay xmlns='urn:xmpp:delay' stamp='2010-07-10T23:08:25Z'/> <message from=\"coven@muclight.shakespeare.lit/hag77@shakespeare.lit\" id=\"msgid11\"> <body>Welcome!</body> <x xmlns=\"elixir:ingredient\">bat-wing</x> </message> </forwarded> </result> </message> <iq type='result' id='mamget1' from='coven@muclight.shakespeare.lit'/> 6.2.2 Affiliation change Every archived affiliation change notification MUST include the <version/> element and MUST NOT contain the <prev-version/> element. Occupant queries MAM and receives an affiliation change notification <iq type='set' id='mamget2' to='muclight.shakespeare.lit'> <query xmlns='urn:xmpp:mam:1' queryid='f37' /> </iq> <message id='aef2133' to='hag66@shakespeare.lit/pda'> <result xmlns='urn:xmpp:mam:1' queryid='f37' id='21482-98726-71623'> <forwarded xmlns='urn:xmpp:forward:0'> <delay xmlns='urn:xmpp:delay' stamp='2013-07-10T21:08:25Z'/> <message from=\"coven@muclight.shakespeare.lit\" id=\"notifid11\"> <x xmlns='urn:xmpp:muclight:0#affiliations'> <version>b9uf13h98f13</version> <user affiliation='owner'>hag66@shakespeare.lit</user> <user affiliation='member'>user1@shakespeare.lit</user> <user affiliation='member'>user2@shakespeare.lit</user> </x> </message> </forwarded> </result> </message> <iq type='result' id='mamget12'/> 6.2.3 Room creation Room creation is archived as an affiliation change that includes ALL initial occupants (including the room creator). 7. General Error Cases 7.1 Client sends an unauthorized stanza to a room If a client sends a stanza to the room, that it does not occupy, the service MUST reply with the 'item-not-found' error. Unauthorized IQ <iq from='crone1@shakespeare.lit/desktop' id='member1' to='coven@muclight.shakespeare.lit' type='set'> <query xmlns='urn:xmpp:muclight:0#affiliations'> <user affiliation='member'>hag66@shakespeare.lit</user> </query> </iq> <iq to='crone1@shakespeare.lit/desktop' id='member1' from='coven@muclight.shakespeare.lit' type='error'> <error type='cancel'> <item-not-found xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/> </error> </iq> Unauthorized message <message from='hag66@shakespeare.lit/pda' id='unauth2' to='coven@muclight.shakespeare.lit' type='groupchat'> <body>Harpier cries: 'tis time, 'tis time.</body> </message> <message to='hag66@shakespeare.lit/pda' id='unauth2' from='coven@muclight.shakespeare.lit' type='error'> <error type='cancel'> <item-not-found xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/> </error> </message> 7.2 Client sends a <presence/> stanza to the service The service MUST ignore all <presence/> stanzas sent by the client. 7.3 Client sends an invalid stanza to the service If service receives an invalid stanza it MUST reply with a 'bad-request' error. Invalid IQ <iq from='crone1@shakespeare.lit/desktop' id='bad1' to='coven@muclight.shakespeare.lit' type='set'> <query xmlns='urn:xmpp:muclight:0#affiliations'> <item role='participant'>hag66@shakespeare.lit</item> </query> </iq> <iq to='crone1@shakespeare.lit/desktop' id='bad1' from='coven@muclight.shakespeare.lit' type='error'> <error type='modify'> <bad-request xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/> </error> </iq> Invalid message <message from='hag66@shakespeare.lit/pda' id='bad2' to='coven@muclight.shakespeare.lit' type='chat'> <body>Harpier cries: 'tis time, 'tis time.</body> </message> <message to='hag66@shakespeare.lit/pda' id='bad2' from='coven@muclight.shakespeare.lit' type='error'> <error type='modify'> <bad-request xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/> </error> </message> 7.4 Request sender has insufficient privileges If the request sender does not have sufficient privileges (but is a room occupant), the service MUST reply with a 'not-allowed' error. It occurs in the following cases: A member tries to change the configuration but the service is not configured to allow it. It does not apply to the subject change, although it has to be performed by sending <message/> with <subject/> , not configuration <iq/> . A member tries to change anyone's affiliation to 'none' or 'owner'. A member tries to change someone's affiliation to 'member' but the service is not configured to allow it. Prohibited IQ <iq from='minion@shakespeare.lit/desktop' id='privileges1' to='coven@muclight.shakespeare.lit' type='set'> <query xmlns='urn:xmpp:muclight:0#affiliations'> <user role='owner'>minion@shakespeare.lit</user> </query> </iq> <iq to='minion@shakespeare.lit/desktop' id='privileges1' from='coven@muclight.shakespeare.lit' type='error'> <error type='cancel'> <not-allowed xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/> </error> </iq> 8. Implementation Notes 8.1 XEP-0045 mappings Some client-side developers might choose to use existing XEP-0045 Multi-User Chat implementations to interface with the new MUC Light. There may be various reasons to do so: using a familiar protocol, avoiding additional implementation, quick prototyping etc. This section provides suggestions of mappings between XEP-0045 stanzas and the new ones described in this document. Operations not described here SHOULD remain unmodified. 8.1.1 Discovering the Features Supported by a MUC Service A Disco result MAY either include a new <feature/> element with an \"http://jabber.org/protocol/muc\" namespace next to MUC Light one, or completely replace it, which is the RECOMMENDED behaviour. Returning a MUC namespace in Disco <iq from='hag66@shakespeare.lit/pda' id='lx09df27' to='muclight.shakespeare.lit' type='get'> <query xmlns='http://jabber.org/protocol/disco#info'/> </iq> <iq from='muclight.shakespeare.lit' id='lx09df27' to='hag66@shakespeare.lit/pda' type='result'> <query xmlns='http://jabber.org/protocol/disco#info'> <identity category='conference' name='Shakespearean Chat Service' type='text'/> <feature var='http://jabber.org/protocol/muc'/> </query> </iq> 8.1.2 Discovering Occupied Rooms The room list MUST NOT include room versions. Service Returns Disco Items Result <iq from='muclight.shakespeare.lit' id='zb8q41f4' to='hag66@shakespeare.lit/pda' type='result'> <query xmlns='http://jabber.org/protocol/disco#items'> <item jid='heath@muclight.shakespeare.lit' name='A Lonely Heath'/> <item jid='coven@muclight.shakespeare.lit' name='A Dark Cave'/> <item jid='forres@muclight.shakespeare.lit' name='The Palace'/> <item jid='inverness@muclight.shakespeare.lit' name='Macbeth&apos;s Castle'/> </query> </iq> 8.1.3 Changing a room subject Instead of distributing the configuration change notifications, the room MUST route <message/> with a <subject/> like a classic MUC would. The client MUST send a classic message <subject/> as well. The room SHOULD save a new subject in the room configuration. New subject is routed as an ordinary message <message from='hag66@shakespeare.lit/pda' id='compsubject' to='coven@muclight.shakespeare.lit' type='groupchat'> <subject>To be or not to be?</subject> </message> <message from='coven@muclight.shakespeare.lit' to='crone1@shakespeare.lit' type='groupchat' id='compsubject'> <subject>To be or not to be?</subject> </message> <message from='coven@muclight.shakespeare.lit' to='hag66@shakespeare.lit' type='groupchat' id='compsubject'> <subject>To be or not to be?</subject> </message> 8.1.4 Getting a room configuration Room configuration is encoded in a Data Form, that simulates the XEP-0045 config form. Getting the room configuration does not benefit from room versioning. Requesting room configuration <iq from='crone1@shakespeare.lit/desktop' id='comp-config' to='coven@muclight.shakespeare.lit' type='get'> <query xmlns='http://jabber.org/protocol/muc#owner'/> </iq> <iq from='coven@muclight.shakespeare.lit' id='comp-config' to='crone1@shakespeare.lit/desktop' type='result'> <query xmlns='http://jabber.org/protocol/muc#owner'> <x xmlns='jabber:x:data' type='form'> <title>Configuration for \"coven\" Room</title> <field type='hidden' var='FORM_TYPE'> <value>http://jabber.org/protocol/muc#roomconfig</value> </field> <field label='Natural-Language Room Name' type='text-single' var='muc#roomconfig_roomname'> <value>A Dark Cave</value> </field> <field label='Room subject' type='text-single' var='muc#roomconfig_subject'> <value>To be or not to be?</value> </field> </x> </query> </iq> 8.1.5 Requesting a user list A user list is retrieved with an affiliation IQ get. Requesting affiliation list <iq from='crone1@shakespeare.lit/desktop' id='comp-getaff' to='coven@muclight.shakespeare.lit' type='get'> <query xmlns='http://jabber.org/protocol/muc#admin'> <item affiliation='owner'/> <item affiliation='member'/> </query> </iq> <iq from='coven@muclight.shakespeare.lit' id='comp-getaff' to='crone1@shakespeare.lit/desktop' type='result'> <query xmlns='http://jabber.org/protocol/muc#admin'> <item affiliation='owner' jid='crone1@shakespeare.lit' nick='crone1@shakespeare.lit' role='moderator'/> <item affiliation='member' jid='hag66@shakespeare.lit' nick='hag66@shakespeare.lit' role='participant'/> </query> </iq> 8.1.6 Requesting room information There is no XEP-0045 equivalent for getting full room information. 8.1.7 Leaving the room Leaving the room is performed by setting the own affiliation to 'none'. The service uses <presence/> to notify all occupants (and former occupant) about the change. <presence/> to the leaving occupant MUST be of the type \"unavailable\" and MUST include a status code 321 (i.e. user leaving due to affiliation change). Leaving the room <iq from='crone1@shakespeare.lit/desktop' id='comp-leave' to='coven@muclight.shakespeare.lit' type='set'> <query xmlns='http://jabber.org/protocol/muc#admin'> <item affiliation='none' jid='crone1@shakespeare.lit'/> </query> </iq> <presence from='coven@muclight.shakespeare.lit/crone1@shakespeare.lit' to='crone1@shakespeare.lit' type='unavailable'> <x xmlns='http://jabber.org/protocol/muc#user'> <item affiliation='none' jid='crone1@shakespeare.lit/pda' role='none'/> <status code='321'/> </x> </presence> <presence from='coven@muclight.shakespeare.lit/crone1@shakespeare.lit' to='hag66@shakespeare.lit/desktop'> <x xmlns='http://jabber.org/protocol/muc#user'> <item affiliation='none' jid='crone1@shakespeare.lit/pda' role='none'/> <status code='321'/> </x> </presence> <iq from='coven@muclight.shakespeare.lit' id='comp-leave' to='crone1@shakespeare.lit/desktop' type='result'/> 8.1.8 Blocking functionality The blocking functionality uses a small subset of the Privacy Lists protocol. Stanzas MUST be addressed to the sender's bare JID (the to attribute may be skipped). The privacy list name MUST be equal to \"urn:xmpp:muclight:0\". Obviously, this method won't work properly in XMPP Server Federation, because privacy stanzas are handled by sender's server and the MUC Light Blocking functionality is handled by a MUC Light service server. As opposed to XEP-0016, it is allowed to send \"delta\" privacy lists. 8.1.8.1 Request blocking list Retrieving blocking list <iq from='crone1@shakespeare.lit/desktop' type='get' id='comp-getlist'> <query xmlns='jabber:iq:privacy'> <list name='urn:xmpp:muclight:0'/> </query> </iq> <iq type='result' id='comp-getlist' to='crone1@shakespeare.lit/desktop'> <query xmlns='jabber:iq:privacy'> <list name='urn:xmpp:muclight:0'> <item type='jid' value='coven@muclight.shakespeare.lit' action='deny' order='1'/> <item type='jid' value='muclight.shakespeare.lit/hag66@shakespeare.lit' action='deny' order='1'/> </list> </query> </iq> 8.1.8.2 Blocking a room In order to block a room, the client MUST deny a room bare JID in privacy list. Blocking a room <iq from='crone1@shakespeare.lit/desktop' type='set' id='comp-blockroom'> <query xmlns='jabber:iq:privacy'> <list name='urn:xmpp:muclight:0'> <item type='jid' value='coven@muclight.shakespeare.lit' action='deny' order='1'/> </list> </query> </iq> <iq type='result' id='comp-blockroom' to='crone1@shakespeare.lit/desktop' /> 8.1.8.3 Blocking a user In order to block a room, the client MUST deny a service JID with user's bare JID in the resource. Blocking a user <iq from='crone1@shakespeare.lit/desktop' type='set' id='comp-blockuser'> <query xmlns='jabber:iq:privacy'> <list name='urn:xmpp:muclight:0'> <item type='jid' value='muclight.shakespeare.lit/hag66@shakespeare.lit' action='deny' order='1'/> </list> </query> </iq> <iq type='result' id='comp-blockuser' to='crone1@shakespeare.lit/desktop' /> 8.1.8.4 Unblocking Unblocking <iq from='crone1@shakespeare.lit/desktop' type='get' id='comp-getlist'> <query xmlns='jabber:iq:privacy'> <list name='urn:xmpp:muclight:0'> <item type='jid' value='coven@muclight.shakespeare.lit' action='allow' order='1'/> <item type='jid' value='muclight.shakespeare.lit/hag66@shakespeare.lit' action='allow' order='1'/> </list> </query> </iq> <iq type='result' id='comp-getlist' to='crone1@shakespeare.lit/desktop' /> 8.1.9 Creating a room The room is created in a standard XEP-0045 way. Client MUST use a nick equal to their own bare JID. Compatibility mode MUST NOT support a unique room name generation. Creating a room <presence from='crone1@shakespeare.lit/desktop' to='coven@muclight.shakespeare.lit/crone1@shakespeare.lit'> <x xmlns='http://jabber.org/protocol/muc'/> </presence> <presence from='coven@chat.shakespeare.lit/crone1@shakespeare.lit' to='crone1@shakespeare.lit/desktop'> <x xmlns='http://jabber.org/protocol/muc#user'> <item affiliation='owner' role='moderator'/> <status code='110'/> <status code='201'/> </x> </presence> 8.1.9.1 Room already exists If the client attempts to create a room that is already used, it will receive an error <presence/> informing that registration is required (like in the case of members-only rooms in XEP-0045). Creating a room <presence from='coven@muclight.shakespeare.lit/crone1@shakespeare.lit' to='crone1@shakespeare.lit/desktop' type='error'> <x xmlns='http://jabber.org/protocol/muc'/> <error by='coven@muclight.shakespeare.lit' type='auth'> <registration-required xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/> </error> </presence> 8.1.10 Destroying the room A classic XEP-0045 method is used but the service SHOULD NOT forward reason and alternate venue JID. Destroying the room <iq from='crone1@shakespeare.lit/desktop' id='begone' to='heath@muclight.shakespeare.lit' type='set'> <query xmlns='http://jabber.org/protocol/muc#owner'> <destroy jid='coven@muclight.shakespare.lit'> <reason>Some reason.</reason> </destroy> </query> </iq> <presence from='heath@chat.shakespeare.lit/crone1@shakespeare.lit' to='crone1@shakespeare.lit/desktop' type='unavailable'> <x xmlns='http://jabber.org/protocol/muc#user'> <item affiliation='none' role='none'/> <destroy /> </x> </presence> <presence from='heath@chat.shakespeare.lit/wiccarocks@shakespeare.lit' to='wiccarocks@shakespeare.lit/laptop' type='unavailable'> <x xmlns='http://jabber.org/protocol/muc#user'> <item affiliation='none' role='none'/> <destroy /> </x> </presence> <presence from='heath@chat.shakespeare.lit/hag66@shakespeare.lit' to='hag66@shakespeare.lit/pda' type='unavailable'> <x xmlns='http://jabber.org/protocol/muc#user'> <item affiliation='none' role='none'/> <destroy /> </x> </presence> <iq from='heath@chat.shakespeare.lit' id='begone' to='crone1@shakespeare.lit/desktop' type='result'/> 8.1.11 Setting room configuration Room occupants can use a standard XEP-0045 configuration modification method. The service MUST broadcast only the notification about the configuration change with a status code 104, so every occupant can retrieve the new room configuration in a separate request. The client is allowed to send a config delta in a form. Setting room configuration <iq to='coven@muclight.shakespeare.lit' id='comp-setconfig' from='crone1@shakespeare.lit/desktop' type='set'> <query xmlns='http://jabber.org/protocol/muc#owner'> <x xmlns='jabber:x:data' type='form'> <field type='hidden' var='FORM_TYPE'> <value>http://jabber.org/protocol/muc#roomconfig</value> </field> <field label='Natural-Language Room Name' type='text-single' var='muc#roomconfig_roomname'> <value>A Darker Cave</value> </field> <field label='Room subject' type='text-single' var='muc#roomconfig_subject'> <value>To be!</value> </field> </x> </query> </iq> <message from='coven@muclight.shakespeare.lit' id='comp-confchange' to='crone1@shakespeare.lit/desktop' type='groupchat'> <x xmlns='http://jabber.org/protocol/muc#user'> <status code='104'/> </x> </message> <message from='coven@muclight.shakespeare.lit' id='comp-confchange' to='crone2@shakespeare.lit/desktop' type='groupchat'> <x xmlns='http://jabber.org/protocol/muc#user'> <status code='104'/> </x> </message> <iq from='coven@muclight.shakespeare.lit' id='comp-setconfig' to='crone1@shakespeare.lit/desktop' type='result'/> 8.1.12 Changing occupant list The service MUST send an affiliation change notification to all participants. Leaving users MUST NOT receive any information except for their own \"none\" affiliation. New users MUST receive an invitation message. Changing occupant list <iq from='crone1@shakespeare.lit/desktop' id='comp-setaff' to='coven@muclight.shakespeare.lit' type='set'> <query xmlns='http://jabber.org/protocol/muc#admin'> <item affiliation='none' jid='hag66@shakespeare.lit'/> <item affiliation='member' jid='hecate@shakespeare.lit'/> </query> </iq> <presence from='coven@chat.shakespeare.lit/hag66@shakespeare.lit' to='hag66@shakespeare.lit' type='unavailable'> <x xmlns='http://jabber.org/protocol/muc#user'> <item affiliation='none' jid='hag66@shakespeare.lit' role='none'/> <status code='321'/> </x> </presence> <message from='coven@muclight.shakespeare.lit' id='comp-invite0' to='hecate@shakespeare.lit'> <x xmlns='http://jabber.org/protocol/muc#user'> <invite from='crone1@shakespeare.lit'/> </x> </message> <presence from='coven@chat.shakespeare.lit/hag66@shakespeare.lit' to='crone1@shakespeare.lit' type='unavailable'> <x xmlns='http://jabber.org/protocol/muc#user'> <item affiliation='none' jid='hag66@shakespeare.lit' role='none'/> <status code='321'/> </x> </presence> <presence from='coven@chat.shakespeare.lit/hecate@shakespeare.lit' to='crone1@shakespeare.lit'> <x xmlns='http://jabber.org/protocol/muc#user'> <item affiliation='member' jid='hecate@shakespeare.lit' role='participant' nick='hecate@shakespeare.lit'/> </x> </presence> <iq from='coven@muclight.shakespeare.lit' id='comp-setaff' to='crone1@shakespeare.lit/desktop' type='result'/> 8.2 Service limits and configuration The MUC Light service may be abused by a malicious users, e.g. due to replicating a single message for every room occupant. The list below contains suggested configurable limits that SHOULD be implemented. The service features that might vary depending on a specific application are included as well. Maximum number of rooms the user occupies. Blocking feature enabled/disabled. XEP-0045 compatibility mode enabled/disabled. Room creator's initial affiliation: owner/member. Room configuration may be changed by owner/occupants. New members can be invited by owner/occupants. Maximal room size.","title":"MUC light"},{"location":"open-extensions/muc_light/#1-introduction","text":"Classic Multi-User chat, as described in XEP-0045, adds an IRC-like functionality to XMPP. It distinguishes between the affiliation list and the occupant list, where the latter is based on presences routed to the room from the client resource. While perfectly sufficient for desktop applications and relatively stable network connection, it does not exactly meet the challenges the mobile world it is facing. Modern mobile applications do not rely on presence information, as it can frequently change. The expected user experience not only differs from the IRC model, but also uses only a small subset of XEP-0045 features. The service described in this specification attempts to provide a complete solution for all common use cases of mobile groupchats.","title":"1. Introduction"},{"location":"open-extensions/muc_light/#2-requirements","text":"Here are some high-level features required from a new variant of MUC The service allows any user to create a room for group communication. Users cannot join rooms on their own. They have to be added by the room owner or (if configured by service administrator) any other occupant. Only the owner can remove other occupants from the room. Every occupant can leave the room. A user may block the attempts of being added to the specific room or by specific user. The message sent in the room is always broadcasted to every occupant. The full occupant list is always available to all occupants. The occupant is always visible on the list, even if they do not have any resources online. Occupants can only have two affiliations: owner and member. There MUST be at most one owner in the room (the service can choose to treat all users equally). If the room becomes empty, it is destroyed. Occupants cannot hide behind nicks. Their real bare JID is always visible to everyone No exchange of any <presence/> stanza inside the room. The user MUST be able to retrieve the list of rooms they occupy. The owner can modify the room configuration at any time; members may also be allowed to set configuration. All occupants can get the full room configuration at any time. Room history is available only in Message Archive Management.","title":"2. Requirements"},{"location":"open-extensions/muc_light/#3-entity-use-cases","text":"","title":"3. Entity Use Cases"},{"location":"open-extensions/muc_light/#31-discovering-a-muc-light-service","text":"An entity often discovers a MUC service by sending a Service Discovery items (\"disco#items\") request to its own server. Entity Queries the Server for Associated Services <iq from='hag66@shakespeare.lit/pda' id='h7ns81g' to='shakespeare.lit' type='get'> <query xmlns='http://jabber.org/protocol/disco#items'/> </iq> The server then returns the services that are associated with it. Server Returns a Disco Items Result <iq from='shakespeare.lit' id='h7ns81g' to='hag66@shakespeare.lit/pda' type='result'> <query xmlns='http://jabber.org/protocol/disco#items'> <item jid='muclight.shakespeare.lit' name='MUC Light Service'/> </query> </iq>","title":"3.1 Discovering a MUC Light Service"},{"location":"open-extensions/muc_light/#32-discovering-the-features-supported-by-a-muc-light-service","text":"An entity may wish to discover if a service implements the Multi-User Chat protocol; in order to do so, it sends a service discovery information (\"disco#info\") query to the MUC service's JID. Entity Queries Chat Service for MUC Light Support via Disco <iq from='hag66@shakespeare.lit/pda' id='lx09df27' to='muclight.shakespeare.lit' type='get'> <query xmlns='http://jabber.org/protocol/disco#info'/> </iq> The service MUST return its identity and the features it supports. Service Returns a Disco Info Result <iq from='muclight.shakespeare.lit' id='lx09df27' to='hag66@shakespeare.lit/pda' type='result'> <query xmlns='http://jabber.org/protocol/disco#info'> <identity category='conference' name='Shakespearean Chat Service' type='text'/> <feature var='urn:xmpp:muclight:0'/> </query> </iq>","title":"3.2 Discovering the Features Supported by a MUC Light Service"},{"location":"open-extensions/muc_light/#33-discovering-occupied-rooms","text":"The service discovery items (\"disco#items\") protocol enables an entity to query a service for a list of associated items, which in the case of a chat service would consist of the specific chat rooms the entity occupies. Entity Queries Chat Service for Rooms <iq from='hag66@shakespeare.lit/pda' id='zb8q41f4' to='muclight.shakespeare.lit' type='get'> <query xmlns='http://jabber.org/protocol/disco#items'/> </iq> The service MUST return a full list of the rooms the entity occupies. The server SHOULD include room name and version in each item. Service Returns a Disco Items Result <iq from='muclight.shakespeare.lit' id='zb8q41f4' to='hag66@shakespeare.lit/pda' type='result'> <query xmlns='http://jabber.org/protocol/disco#items'> <item jid='heath@muclight.shakespeare.lit' name='A Lonely Heath' version='1'/> <item jid='coven@muclight.shakespeare.lit' name='A Dark Cave' version='2'/> <item jid='forres@muclight.shakespeare.lit' name='The Palace' version='3'/> <item jid='inverness@muclight.shakespeare.lit' name='Macbeth&apos;s Castle' version='4'/> </query> </iq> If the full list of rooms is large (see XEP-0030 for details), the service MAY return only a partial list of rooms. If it does, it MUST include a <set/> element qualified by the 'http://jabber.org/protocol/rsm' namespace (as defined in Result Set Management (XEP-0059) [1]) to indicate that the list is not the full result set. Service Returns a Limited List of Disco Items Result <iq from='muclight.shakespeare.lit' id='hx51v49s' to='hag66@shakespeare.lit/pda' type='result'> <query xmlns='http://jabber.org/protocol/disco#items'> <item jid='alls-well-that-ends-well@muclight.shakespeare.lit' name='Everybody dies' version='1'/> <item jid='as-you-like-it@muclight.shakespeare.lit' name='As you like it' version='2'/> <item jid='cleopatra@muclight.shakespeare.lit' name='Cleo fans' version='3'/> <item jid='comedy-of-errors@muclight.shakespeare.lit' name='404 Comedy not found' version='4'/> <item jid='coriolanus@muclight.shakespeare.lit' name='What is Coriolanus?' version='5'/> <item jid='cymbeline@muclight.shakespeare.lit' name='Music room' version='6'/> <item jid='hamlet@muclight.shakespeare.lit' name='To chat or not to chat?' version='7'/> <item jid='henry-the-fourth-one@muclight.shakespeare.lit' name='Royal Room 1' version='8'/> <item jid='henry-the-fourth-two@muclight.shakespeare.lit' name='Royal Room 2' version='9'/> <item jid='henry-the-fifth@muclight.shakespeare.lit' name='Royal Room Prime' version='10'/> <set xmlns='http://jabber.org/protocol/rsm'> <first index='0'>alls-well-that-ends-well@muclight.shakespeare.lit</first> <last>henry-the-fifth@muclight.shakespeare.lit</last> <count>37</count> </set> </query> </iq>","title":"3.3 Discovering Occupied Rooms"},{"location":"open-extensions/muc_light/#4-occupant-use-cases","text":"","title":"4. Occupant Use Cases"},{"location":"open-extensions/muc_light/#41-sending-a-message-to-a-room","text":"Every occupant in the room MAY broadcast messages to other occupants. In order to do so, the client MUST send a groupchat message to the room bare JID. The room automatically assumes that occupants' nicks are equal to their bare JIDs. MUC light is designed for applications where it is not important to hide behind nicknames. On the contrary - it is up to the client to replace pure JIDs with user-friendly names like phone numbers or full names if necessary. The room MUST route all messages of the 'groupchat' type. Client sends a message to the room <message from='hag66@shakespeare.lit/pda' id='msg111' to='coven@muclight.shakespeare.lit' type='groupchat'> <body>Harpier cries: 'tis time, 'tis time.</body> </message> Server broadcasts a groupchat message <message id='msg111' type='groupchat' from='coven@muclight.shakespeare.lit/hag66@shakespeare.lit' to='crone1@shakespeare.lit'> <body>Harpier cries: 'tis time, 'tis time.</body> </message> <message id='msg111' type='groupchat' from='coven@muclight.shakespeare.lit/hag66@shakespeare.lit' to='crone2@shakespeare.lit'> <body>Harpier cries: 'tis time, 'tis time.</body> </message> Note the message is sent to all the room occupants including the original sender. <message id='msg111' type='groupchat' from='coven@muclight.shakespeare.lit/hag66@shakespeare.lit' to='hag66@shakespeare.lit'> <body>Harpier cries: 'tis time, 'tis time.</body> </message>","title":"4.1 Sending a message to a room"},{"location":"open-extensions/muc_light/#42-changing-a-room-subject","text":"The service MAY allow room occupants to set the room subject by changing the \"subject\" configuration field. A standard configuration stanza is used in this case. Subject change is announced like an ordinary configuration change. Client sends a message to the room <iq from='hag66@shakespeare.lit/pda' id='subject1' to='coven@muclight.shakespeare.lit' type='set'> <query xmlns='urn:xmpp:muclight:0#configuration'> <subject>To be or not to be?</subject> </query> </iq> <message from='coven@muclight.shakespeare.lit' to='crone1@shakespeare.lit' type='groupchat' id='newsubject'> <x xmlns='urn:xmpp:muclight:0#configuration'> <prev-version>asdfghj000</prev-version> <version>asdfghj</version> <subject>To be or not to be?</subject> </x> <body /> </message> <message from='coven@muclight.shakespeare.lit' to='hag66@shakespeare.lit' type='groupchat' id='newsubject'> <x xmlns='urn:xmpp:muclight:0#configuration'> <prev-version>asdfghj000</prev-version> <version>asdfghj</version> <subject>To be or not to be?</subject> </x> <body /> </message> <iq to='hag66@shakespeare.lit/pda' id='subject1' from='coven@muclight.shakespeare.lit' type='result' />","title":"4.2 Changing a room subject"},{"location":"open-extensions/muc_light/#43-requesting-room-information","text":"Room occupants may request room information (configuration and/or occupants list) by an information version. It is up to the service to define the version string, the only requirement for it, is to be unique per room. Please note there are no separate versions for configuration and occupant list alone. If the server side version does not match the one provided by the client (or if the client does not provide one, i.e. the 'version' element is empty), the service MUST respond with a current version string and full configuration and/or occupant list. If the version strings match, server MUST reply with an empty result. Only room occupants can get room information. Matching versions <iq from='crone1@shakespeare.lit/desktop' id='config0' to='coven@muclight.shakespeare.lit' type='get'> <query xmlns='urn:xmpp:muclight:0#configuration'> <version>abcdefg</version> </query> </iq> <iq from='coven@muclight.shakespeare.lit' id='config0' to='crone1@shakespeare.lit/desktop' type='result' />","title":"4.3 Requesting room information"},{"location":"open-extensions/muc_light/#431-getting-the-room-configuration","text":"Client gets configuration from the server <iq from='crone1@shakespeare.lit/desktop' id='getconfig1' to='coven@muclight.shakespeare.lit' type='get'> <query xmlns='urn:xmpp:muclight:0#configuration'> <version>abcdefg</version> </query> </iq> <iq from='coven@muclight.shakespeare.lit' id='getconfig1' to='crone1@shakespeare.lit/desktop' type='result'> <query xmlns='urn:xmpp:muclight:0#configuration'> <version>123456</version> <roomname>A Dark Cave</roomname> </query> </iq>","title":"4.3.1 Getting the room configuration"},{"location":"open-extensions/muc_light/#432-requesting-a-user-list","text":"Client requests a user list <iq from='crone1@shakespeare.lit/desktop' id='getmembers' to='coven@muclight.shakespeare.lit' type='get'> <query xmlns='urn:xmpp:muclight:0#affiliations'> <version>abcdefg</version> </query> </iq> <iq from='coven@muclight.shakespeare.lit' id='getmembers' to='crone1@shakespeare.lit/desktop' type='result'> <query xmlns='urn:xmpp:muclight:0#affiliations'> <version>123456</version> <user affiliation='owner'>user1@shakespeare.lit</user> <user affiliation='member'>user2@shakespeare.lit</user> <user affiliation='member'>user3@shakespeare.lit</user> </query> </iq>","title":"4.3.2 Requesting a user list"},{"location":"open-extensions/muc_light/#433-requesting-full-room-information","text":"Room occupants may request both lists (configuration + occupants) with a single request. Client requests room information <iq from='crone1@shakespeare.lit/desktop' id='getinfo1' to='coven@muclight.shakespeare.lit' type='get'> <query xmlns='urn:xmpp:muclight:0#info'> <version>abcdefg</version> </query> </iq> <iq from='coven@muclight.shakespeare.lit' id='getinfo1' to='crone1@shakespeare.lit/desktop' type='result'> <query xmlns='urn:xmpp:muclight:0#info'> <version>123456</version> <configuration> <roomname>A Dark Cave</roomname> </configuration> <occupants> <user affiliation='owner'>user1@shakespeare.lit</user> <user affiliation='member'>user2@shakespeare.lit</user> <user affiliation='member'>user3@shakespeare.lit</user> </occupants> </query> </iq>","title":"4.3.3 Requesting full room information"},{"location":"open-extensions/muc_light/#44-leaving-the-room","text":"Every occupant is allowed to leave the room at any time. It is done by modifying their own affiliation. Occupant leaves the room <iq from='crone1@shakespeare.lit/desktop' id='leave1' to='coven@muclight.shakespeare.lit' type='set'> <query xmlns='urn:xmpp:muclight:0#affiliations'> <user affiliation='none'>crone1@shakespeare.lit</user> </query> </iq> <message from='coven@muclight.shakespeare.lit' to='crone1@shakespeare.lit' type='groupchat' id='leave1'> <x xmlns='urn:xmpp:muclight:0#affiliations'> <user affiliation='none'>crone1@shakespeare.lit</user> </x> <body /> </message> <message from='coven@muclight.shakespeare.lit' to='hag77@shakespeare.lit' type='groupchat' id='leave1'> <x xmlns='urn:xmpp:muclight:0#affiliations'> <prev-version>1111111</prev-version> <version>aaaaaaa</version> <user affiliation='none'>crone1@shakespeare.lit</user> </x> <body /> </message> <message from='coven@muclight.shakespeare.lit' to='hag88@shakespeare.lit' type='groupchat' id='leave1'> <x xmlns='urn:xmpp:muclight:0#affiliations'> <prev-version>1111111</prev-version> <version>aaaaaaa</version> <user affiliation='none'>crone1@shakespeare.lit</user> </x> <body /> </message> <iq to='crone1@shakespeare.lit/desktop' id='leave1' from='coven@muclight.shakespeare.lit' type='result' />","title":"4.4 Leaving the room"},{"location":"open-extensions/muc_light/#45-blocking-functionality","text":"A user MAY choose to automatically deny being added to the room. All stanzas must be directed to MUC Light service. User MAY send more than one item in a single request and mix both 'user' and 'room' elements. If the occupant tries to add another user to the room, and this user has set a blocking policy, the server MUST ignore the attempt. No error is returned, this user is simply skipped when processing affiliation change query. Service denies adding blocking user <iq from='crone2@shakespeare.lit/desktop' id='blocked1' to='coven@muclight.shakespeare.lit' type='set'> <query xmlns='urn:xmpp:muclight:0#affiliations'> <user affiliation='member'>crone1@shakespeare.lit</user> <user affiliation='member'>crone3@shakespeare.lit</user> </query> </iq> <message from='coven@muclight.shakespeare.lit' to='crone2@shakespeare.lit' type='groupchat' id='blockedadd1'> <x xmlns='urn:xmpp:muclight:0#affiliations'> <user affiliation='member'>crone3@shakespeare.lit</user> </x> <body /> </message> <message from='coven@muclight.shakespeare.lit' to='hag88@@shakespeare.lit' type='groupchat' id='blockedadd1'> <x xmlns='urn:xmpp:muclight:0#affiliations'> <user affiliation='member'>crone3@shakespeare.lit</user> </x> <body /> </message> <iq to='crone2@shakespeare.lit/desktop' id='blocked1' from='coven@muclight.shakespeare.lit' type='result' />","title":"4.5 Blocking functionality"},{"location":"open-extensions/muc_light/#451-requesting-a-blocking-list","text":"In order to get the current blocking list in the MUC Light service, the client sends an empty IQ get query with a proper namespace. The list includes only items with a 'deny' action, since the 'allow' behaviour is default for MUC Light and is only used for the list modification. User retrieves a blocking list <iq from='crone1@shakespeare.lit/desktop' id='getblock1' to='muclight.shakespeare.lit' type='get'> <query xmlns='urn:xmpp:muclight:0#blocking'> </query> </iq> <iq type='result' id='getblock1' to='crone1@shakespeare.lit/desktop' from='muclight.shakespeare.lit'> <query xmlns='urn:xmpp:muclight:0#blocking'> <room action='deny'>coven@muclight.shakespeare.lit</room> <user action='deny'>hag77@shakespeare.lit</user> </query> </iq>","title":"4.5.1 Requesting a blocking list"},{"location":"open-extensions/muc_light/#452-blocking-a-room","text":"In order to block a room, a query must contain at least one 'room' item with a 'deny' action and a room bare JID in the content. User blocks a room <iq from='crone1@shakespeare.lit/desktop' id='block1' to='muclight.shakespeare.lit' type='set'> <query xmlns='urn:xmpp:muclight:0#blocking'> <room action='deny'>coven@muclight.shakespeare.lit</room> <room action='deny'>chapel@shakespeare.lit</room> </query> </iq> <iq type='result' id='block1' to='crone1@shakespeare.lit/desktop' from='muclight.shakespeare.lit' />","title":"4.5.2 Blocking a room"},{"location":"open-extensions/muc_light/#453-blocking-a-user","text":"In order to block a user, a query must contain at least one 'user' item with a 'deny' action and a user bare JID in the content. User blocks another user <iq from='crone1@shakespeare.lit/desktop' id='block2' to='muclight.shakespeare.lit' type='set'> <query xmlns='urn:xmpp:muclight:0#blocking'> <user action='deny'>hag66@shakespeare.lit</user> <user action='deny'>hag77@shakespeare.lit</user> </query> </iq> <iq type='result' id='block2' to='crone1@shakespeare.lit/desktop' from='muclight.shakespeare.lit' />","title":"4.5.3 Blocking a user"},{"location":"open-extensions/muc_light/#454-unblocking","text":"In order to cancel a blocking, a query must contain at least one 'room' or 'user' item with an 'allow' action and an appriopriate bare JID in the content. Unblocking a JID that is not blocked does not trigger any error. The server MUST return an empty IQ result in such case. User cancels blocking <iq from='crone1@shakespeare.lit/desktop' id='unblock1' to='muclight.shakespeare.lit' type='set'> <query xmlns='urn:xmpp:muclight:0#blocking'> <room action='allow'>coven@muclight.shakespeare.lit</room> <user action='allow'>hag66@shakespeare.lit</user> </query> </iq> <iq type='result' id='unblock1' to='crone1@shakespeare.lit/desktop' from='muclight.shakespeare.lit' />","title":"4.5.4 Unblocking"},{"location":"open-extensions/muc_light/#5-owner-use-cases","text":"","title":"5. Owner Use Cases"},{"location":"open-extensions/muc_light/#51-creating-a-new-room","text":"A room is created by submitting a dedicated stanza. The client application should pick a random room node name, since a human-readable room name is in configuration. For rules that apply to the configuration options, please see \"Setting room configuration\" chapter. The client MAY include initial configuration and occupant list (the list MUST NOT include the creator). The server MAY allow sending an incomplete configuration form. In such case the server MUST use the default values for missing fields. The server MAY enforce a minimal occupant list length. The service MAY either give the creator the 'owner' or 'member' status. In the latter case all users are equal. Upon room creation success, the service MUST reply with an empty IQ result. The following rules (similar to the ones relevant to the affiliation change request) apply to the occupant list: 'none' affiliation cannot be used. All user bare JIDs must be unique At most one owner can be chosen. If none is chosen, the room creator will become \"just\" a 'member'. After the room is created (but before receiving IQ result), new occupants (including the creator) receive <message/> from the room with their affiliations (the stanza MUST include only recipient's affiliation) and the initial room version. <prev-version/> element MUST NOT be included. Client requests room creation <iq from='crone1@shakespeare.lit/desktop' id='create1' to='coven@muclight.shakespeare.lit' type='set'> <query xmlns='urn:xmpp:muclight:0#create'> <configuration> <roomname>A Dark Cave</roomname> </configuration> <occupants> <user affiliation='member'>user1@shakespeare.lit</user> <user affiliation='member'>user2@shakespeare.lit</user> </occupants> </query> </iq> <message from='coven@muclight.shakespeare.lit' to='crone1@shakespeare.lit' type='groupchat' id='createnotif'> <x xmlns='urn:xmpp:muclight:0#affiliations'> <version>aaaaaaa</version> <user affiliation='owner'>crone1@shakespeare.lit</user> </x> <body /> </message> <message from='coven@muclight.shakespeare.lit' to='user1@shakespeare.lit' type='groupchat' id='createnotif'> <x xmlns='urn:xmpp:muclight:0#affiliations'> <version>aaaaaaa</version> <user affiliation='member'>user1@shakespeare.lit</user> </x> <body /> </message> <message from='coven@muclight.shakespeare.lit' to='user2@shakespeare.lit' type='groupchat' id='createnotif'> <x xmlns='urn:xmpp:muclight:0#affiliations'> <version>aaaaaaa</version> <user affiliation='member'>user2@shakespeare.lit</user> </x> <body /> </message> <iq to='crone1@shakespeare.lit/desktop' id='create1' from='coven@muclight.shakespeare.lit' type='result' />","title":"5.1 Creating a new room"},{"location":"open-extensions/muc_light/#511-requesting-a-new-room-with-a-unique-name","text":"If a client would like to avoid a room JID conflict, it MAY request creating a new room with a server-side generated name, that is verfied to be unique. In order to do so, the client MUST send a creation request to service JID, not room bare JID. The IQ result will originate from the new room bare JID The messages with affiliation change notifications MUST have the same ID as IQ set and result. Client requests room creation <iq from='crone1@shakespeare.lit/desktop' id='createrandom' to='muclight.shakespeare.lit' type='set'> <query xmlns='urn:xmpp:muclight:0#create'> <configuration> <roomname>Random Cave</roomname> </configuration> </query> </iq> <message from='randomcave@muclight.shakespeare.lit' to='crone1@shakespeare.lit' type='groupchat' id='createrandom'> <x xmlns='urn:xmpp:muclight:0#affiliations'> <version>aaaaaaa</version> <user affiliation='owner'>crone1@shakespeare.lit</user> </x> <body /> </message> <iq to='crone1@shakespeare.lit/desktop' id='createrandom' from='muclight.shakespeare.lit' type='result' />","title":"5.1.1 Requesting a new room with a unique name"},{"location":"open-extensions/muc_light/#512-room-already-exists","text":"If the chosen room name already exists, the service MUST return a 'conflict' error. Client requests room creation with existing name <iq from='crone1@shakespeare.lit/desktop' id='conflict1' to='castle@muclight.shakespeare.lit' type='set'> <query xmlns='urn:xmpp:muclight:0#create'> <configuration> <roomname>A Dark Cave</roomname> </configuration> </query> </iq> <iq to='crone1@shakespeare.lit/desktop' id='conflict1' from='castle@muclight.shakespeare.lit' type='error'> <error type='cancel'> <conflict xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/> </error> </iq>","title":"5.1.2 Room already exists"},{"location":"open-extensions/muc_light/#52-destroying-a-room","text":"A room is automatically destroyed when its occupant list becomes empty or the room owner explicitly sends an IQ with a room destroy request. Before sending an IQ result, every occupant is notified that its affiliation has changed to 'none'. These notifications include an <x/> element qualified with a \"urn:xmpp:muclight:0#destroy\" namespace. Only the room owner is allowed to destroy it. Room destruction notification SHOULD NOT contain version (or \"prev-version\" information). Client requests room destruction <iq from='crone1@shakespeare.lit/desktop' id='destroy1' to='coven@muclight.shakespeare.lit' type='set'> <query xmlns='urn:xmpp:muclight:0#destroy' /> </iq> <message from='coven@muclight.shakespeare.lit' to='crone1@shakespeare.lit' type='groupchat' id='destroynotif'> <x xmlns='urn:xmpp:muclight:0#affiliations'> <user affiliation='none'>crone1@shakespeare.lit</user> </x> <x xmlns='urn:xmpp:muclight:0#destroy' /> <body /> </message> <message from='coven@muclight.shakespeare.lit' to='hag77@shakespeare.lit' type='groupchat' id='destroynotif'> <x xmlns='urn:xmpp:muclight:0#affiliations'> <user affiliation='none'>hag77@shakespeare.lit</user> </x> <x xmlns='urn:xmpp:muclight:0#destroy' /> <body /> </message> <message from='coven@muclight.shakespeare.lit' to='hag88@shakespeare.lit' type='groupchat' id='destroynotif'> <x xmlns='urn:xmpp:muclight:0#affiliations'> <user affiliation='none'>hag88@shakespeare.lit</user> </x> <x xmlns='urn:xmpp:muclight:0#destroy' /> <body /> </message> <iq to='crone1@shakespeare.lit/desktop' id='create1' from='coven@muclight.shakespeare.lit' type='result' />","title":"5.2 Destroying a room"},{"location":"open-extensions/muc_light/#53-setting-room-configuration","text":"Only room owners can modify the room configuration but the service MAY allow members to change it too. All room occupants MUST be notified about a configuration change and both the new and old room version string ( <version /> and <prev-version /> respectively). \"version\" and \"prev-version\" configuration field names are NOT ALLOWED - they are reserved for room versioning. The service MAY allow the client to set the configuration fields with any name but it is NOT RECOMMENDED. The Data Forms are not used for the configuration. Instead, the config fields are encoded in XML elements with names equal to the key and content equal to the value. Client configuration request to the server <iq from='crone1@shakespeare.lit/desktop' id='conf2' to='coven@muclight.shakespeare.lit' type='set'> <query xmlns='urn:xmpp:muclight:0#configuration'> <roomname>A Darker Cave</roomname> </query> </iq> <message from='coven@muclight.shakespeare.lit' to='crone1@shakespeare.lit' type='groupchat' id='configchange'> <x xmlns='urn:xmpp:muclight:0#configuration'> <prev-version>zaqwsx</prev-version> <version>zxcvbnm</version> <roomname>A Darker Cave</roomname> </x> <body /> </message> <message from='coven@muclight.shakespeare.lit' to='hag66@shakespeare.lit' type='groupchat' id='configchange'> <x xmlns='urn:xmpp:muclight:0#configuration'> <prev-version>zaqwsx</prev-version> <version>zxcvbnm</version> <roomname>A Darker Cave</roomname> </x> <body /> </message> <iq to='crone1@shakespeare.lit/desktop' id='conf2' from='coven@muclight.shakespeare.lit' type='result' /> The server SHOULD accept incomplete (i.e. delta) configuration forms. In such case, values of the missing fields SHOULD be preserved.","title":"5.3 Setting room configuration"},{"location":"open-extensions/muc_light/#54-changing-the-occupant-list","text":"The occupant list is modified by a direct affiliation change. Following rules apply: There are only 3 affiliations. owner - can do everything in the room member - can send messages to the room and if the service allows it, can also change configuration or change others' affiliations none - not in the room; it's a keyword for marking a user for removal from a room Every occupant can change its own affiliation to none in order to leave the room. The only way to join the room is being added by other occupant. The owner can change affiliations at will. If the owner leaves, the server MAY use any strategy to choose a new one. The room can have at most one owner. Giving someone else the 'owner' status effectively causes the current one to lose it. The owner can choose a new owner when leaving by including both 'none' and 'owner' items in affiliation change request. Every user JID can be used in the request at most once. A single request MAY change multiple affiliations. All changes must be meaningful, e.g. setting member's affiliation to 'member' is considered a bad request. Server MAY allow members to add new members but they still cannot make anyone an 'owner' or remove other users from the room. On success the server will reply with a result IQ with all the changed items. BEFORE returning the IQ result, the service MUST route a message with the affiliation change to all relevant users. Newcomers, i.e. users that were not occupants before the change, SHOULD receive only their own affiliation and SHOULD NOT receive a <prev-version /> element. The notifications must include both the new and old room version ( <version /> and <prev-version /> respectively) string (except for the ones directed to users that have been removed from the room). The notifications contain a list of items. The item list may be different from the list in the IQ set, because some of the changes may require additional operations, e.g. choosing new owner when the old one leaves. Users, that are still in the room after the change, will receive the full change list. Users, that have been removed from the room with the request, will get only one item: themselves with affiliation 'none'. Affiliations change request Let's consider a room coven with following members: crone1 - owner hag77 - member hag88 - member hag66 is not in the room yet. User crone1 wants to add hag66 to the room, kick hag88 out and make hag77 the room owner. <iq from='crone1@shakespeare.lit/desktop' id='member1' to='coven@muclight.shakespeare.lit' type='set'> <query xmlns='urn:xmpp:muclight:0#affiliations'> <user affiliation='member'>hag66@shakespeare.lit</user> <user affiliation='owner'>hag77@shakespeare.lit</user> <user affiliation='none'>hag88@shakespeare.lit</user> </query> </iq> Now each user will receive an update. As you can see, affiliations have changed accordingly to crone1 request. However, this request implies one more update. Since hag77 has been promoted to a new owner, crone1 is automatically degraded to member . <message from='coven@muclight.shakespeare.lit' to='crone1@shakespeare.lit' type='groupchat' id='memberchange'> <x xmlns='urn:xmpp:muclight:0#affiliations'> <prev-version>njiokm</prev-version> <version>qwerty</version> <user affiliation='member'>crone1@shakespeare.lit</user> <user affiliation='member'>hag66@shakespeare.lit</user> <user affiliation='owner'>hag77@shakespeare.lit</user> <user affiliation='none'>hag88@shakespeare.lit</user> </x> <body></body> </message> Because hag66 was not a member of this room before, they only receive their own affiliation and no prev-version element. <message from='coven@muclight.shakespeare.lit' to='hag66@shakespeare.lit' type='groupchat' id='memberchange'> <x xmlns='urn:xmpp:muclight:0#affiliations'> <version>qwerty</version> <user affiliation='member'>hag66@shakespeare.lit</user> </x> <body></body> </message> hag77 receives an ordinary update, just like crone1 . <message from='coven@muclight.shakespeare.lit' to='hag77@shakespeare.lit' type='groupchat' id='memberchange'> <x xmlns='urn:xmpp:muclight:0#affiliations'> <prev-version>njiokm</prev-version> <version>qwerty</version> <user affiliation='member'>crone1@shakespeare.lit</user> <user affiliation='member'>hag66@shakespeare.lit</user> <user affiliation='owner'>hag77@shakespeare.lit</user> <user affiliation='none'>hag88@shakespeare.lit</user> </x> <body></body> </message> hag88 has been kicked out of the room and therefore gets only their own affiliation change of type 'none'. <message from='coven@muclight.shakespeare.lit' to='hag88@shakespeare.lit' type='groupchat' id='memberchange'> <x xmlns='urn:xmpp:muclight:0#affiliations'> <user affiliation='none'>hag88@shakespeare.lit</user> </x> <body></body> </message> crone1 gets the result IQ after the change. <iq to='crone1@shakespeare.lit/desktop' id='member1' from='coven@muclight.shakespeare.lit' type='result' />","title":"5.4 Changing the occupant list"},{"location":"open-extensions/muc_light/#6-interactions-with-rfcs-and-other-xeps","text":"","title":"6. Interactions with RFCs and other XEPs"},{"location":"open-extensions/muc_light/#61-user-rosters","text":"The service MAY add user's rooms to its roster. It allows the client to skip the separate Disco request to the service. Roster items with rooms MUST belong to the group \"urn:xmpp:muclight:0\" (MUC Light namespace) and include the <version/> element. Their subscription type MUST be 'to'. Entity requests the roster and receives a reply that includes a room item <iq type='get' id='roster1' to='shakespeare.lit'> <query xmlns='jabber:iq:roster'/> </iq> <iq id='roster1' to='hag66@shakespeare.lit/tablet' type='result'> <query xmlns='jabber:iq:roster' ver='ver7'> <item jid='hag77@shakespeare.lit' subscription='both'/> <item jid='hag88@shakespeare.lit' subscription='both'/> <item jid='coven@muclight.shakespeare.lit' name='The Coven' subscription='to'> <group>urn:xmpp:muclight:0</group> <version>1234345</version> </item> </query> </iq>","title":"6.1 User rosters"},{"location":"open-extensions/muc_light/#62-xep-0313-message-archive-management","text":"This section defines the rules for archiving MUC Light events and messages. Stanzas described in the subsections below MUST be archived by the server. The stanzas not included here MUST NOT be archived. The <message/> element inside <forwarded/> MUST include a \"from\" attribute and MUST NOT include a \"to\" attribute. \"id\" SHOULD be archived as well. In case of regular groupchat messages, the \"from\" attribute MUST consist of a room full JID with a sender bare JID in the resource part. As for room notification, e.g. create event, \"from\" MUST be equal to room bare JID. Examples below use MAM v0.4 protocol. The archive can be fetched only from a specific room, the client MUST NOT query MUC Light service directly.","title":"6.2 XEP-0313 Message Archive Management"},{"location":"open-extensions/muc_light/#621-groupchat-message-from-occupant","text":"Message from a user MUST be archived with all child elements. Occupant queries MAM and receives regular groupchat message <iq type='set' id='mamget1' to='coven@muclight.shakespeare.lit'> <query xmlns='urn:xmpp:mam:1' queryid='f27' /> </iq> <message id='aeb213' to='hag66@shakespeare.lit/pda'> <result xmlns='urn:xmpp:mam:1' queryid='f27' id='28482-98726-73623'> <forwarded xmlns='urn:xmpp:forward:0'> <delay xmlns='urn:xmpp:delay' stamp='2010-07-10T23:08:25Z'/> <message from=\"coven@muclight.shakespeare.lit/hag77@shakespeare.lit\" id=\"msgid11\"> <body>Welcome!</body> <x xmlns=\"elixir:ingredient\">bat-wing</x> </message> </forwarded> </result> </message> <iq type='result' id='mamget1' from='coven@muclight.shakespeare.lit'/>","title":"6.2.1 Groupchat message from occupant"},{"location":"open-extensions/muc_light/#622-affiliation-change","text":"Every archived affiliation change notification MUST include the <version/> element and MUST NOT contain the <prev-version/> element. Occupant queries MAM and receives an affiliation change notification <iq type='set' id='mamget2' to='muclight.shakespeare.lit'> <query xmlns='urn:xmpp:mam:1' queryid='f37' /> </iq> <message id='aef2133' to='hag66@shakespeare.lit/pda'> <result xmlns='urn:xmpp:mam:1' queryid='f37' id='21482-98726-71623'> <forwarded xmlns='urn:xmpp:forward:0'> <delay xmlns='urn:xmpp:delay' stamp='2013-07-10T21:08:25Z'/> <message from=\"coven@muclight.shakespeare.lit\" id=\"notifid11\"> <x xmlns='urn:xmpp:muclight:0#affiliations'> <version>b9uf13h98f13</version> <user affiliation='owner'>hag66@shakespeare.lit</user> <user affiliation='member'>user1@shakespeare.lit</user> <user affiliation='member'>user2@shakespeare.lit</user> </x> </message> </forwarded> </result> </message> <iq type='result' id='mamget12'/>","title":"6.2.2 Affiliation change"},{"location":"open-extensions/muc_light/#623-room-creation","text":"Room creation is archived as an affiliation change that includes ALL initial occupants (including the room creator).","title":"6.2.3 Room creation"},{"location":"open-extensions/muc_light/#7-general-error-cases","text":"","title":"7. General Error Cases"},{"location":"open-extensions/muc_light/#71-client-sends-an-unauthorized-stanza-to-a-room","text":"If a client sends a stanza to the room, that it does not occupy, the service MUST reply with the 'item-not-found' error. Unauthorized IQ <iq from='crone1@shakespeare.lit/desktop' id='member1' to='coven@muclight.shakespeare.lit' type='set'> <query xmlns='urn:xmpp:muclight:0#affiliations'> <user affiliation='member'>hag66@shakespeare.lit</user> </query> </iq> <iq to='crone1@shakespeare.lit/desktop' id='member1' from='coven@muclight.shakespeare.lit' type='error'> <error type='cancel'> <item-not-found xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/> </error> </iq> Unauthorized message <message from='hag66@shakespeare.lit/pda' id='unauth2' to='coven@muclight.shakespeare.lit' type='groupchat'> <body>Harpier cries: 'tis time, 'tis time.</body> </message> <message to='hag66@shakespeare.lit/pda' id='unauth2' from='coven@muclight.shakespeare.lit' type='error'> <error type='cancel'> <item-not-found xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/> </error> </message>","title":"7.1 Client sends an unauthorized stanza to a room"},{"location":"open-extensions/muc_light/#72-client-sends-a-presence-stanza-to-the-service","text":"The service MUST ignore all <presence/> stanzas sent by the client.","title":"7.2 Client sends a &lt;presence/&gt; stanza to the service"},{"location":"open-extensions/muc_light/#73-client-sends-an-invalid-stanza-to-the-service","text":"If service receives an invalid stanza it MUST reply with a 'bad-request' error. Invalid IQ <iq from='crone1@shakespeare.lit/desktop' id='bad1' to='coven@muclight.shakespeare.lit' type='set'> <query xmlns='urn:xmpp:muclight:0#affiliations'> <item role='participant'>hag66@shakespeare.lit</item> </query> </iq> <iq to='crone1@shakespeare.lit/desktop' id='bad1' from='coven@muclight.shakespeare.lit' type='error'> <error type='modify'> <bad-request xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/> </error> </iq> Invalid message <message from='hag66@shakespeare.lit/pda' id='bad2' to='coven@muclight.shakespeare.lit' type='chat'> <body>Harpier cries: 'tis time, 'tis time.</body> </message> <message to='hag66@shakespeare.lit/pda' id='bad2' from='coven@muclight.shakespeare.lit' type='error'> <error type='modify'> <bad-request xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/> </error> </message>","title":"7.3 Client sends an invalid stanza to the service"},{"location":"open-extensions/muc_light/#74-request-sender-has-insufficient-privileges","text":"If the request sender does not have sufficient privileges (but is a room occupant), the service MUST reply with a 'not-allowed' error. It occurs in the following cases: A member tries to change the configuration but the service is not configured to allow it. It does not apply to the subject change, although it has to be performed by sending <message/> with <subject/> , not configuration <iq/> . A member tries to change anyone's affiliation to 'none' or 'owner'. A member tries to change someone's affiliation to 'member' but the service is not configured to allow it. Prohibited IQ <iq from='minion@shakespeare.lit/desktop' id='privileges1' to='coven@muclight.shakespeare.lit' type='set'> <query xmlns='urn:xmpp:muclight:0#affiliations'> <user role='owner'>minion@shakespeare.lit</user> </query> </iq> <iq to='minion@shakespeare.lit/desktop' id='privileges1' from='coven@muclight.shakespeare.lit' type='error'> <error type='cancel'> <not-allowed xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/> </error> </iq>","title":"7.4 Request sender has insufficient privileges"},{"location":"open-extensions/muc_light/#8-implementation-notes","text":"","title":"8. Implementation Notes"},{"location":"open-extensions/muc_light/#81-xep-0045-mappings","text":"Some client-side developers might choose to use existing XEP-0045 Multi-User Chat implementations to interface with the new MUC Light. There may be various reasons to do so: using a familiar protocol, avoiding additional implementation, quick prototyping etc. This section provides suggestions of mappings between XEP-0045 stanzas and the new ones described in this document. Operations not described here SHOULD remain unmodified.","title":"8.1 XEP-0045 mappings"},{"location":"open-extensions/muc_light/#811-discovering-the-features-supported-by-a-muc-service","text":"A Disco result MAY either include a new <feature/> element with an \"http://jabber.org/protocol/muc\" namespace next to MUC Light one, or completely replace it, which is the RECOMMENDED behaviour. Returning a MUC namespace in Disco <iq from='hag66@shakespeare.lit/pda' id='lx09df27' to='muclight.shakespeare.lit' type='get'> <query xmlns='http://jabber.org/protocol/disco#info'/> </iq> <iq from='muclight.shakespeare.lit' id='lx09df27' to='hag66@shakespeare.lit/pda' type='result'> <query xmlns='http://jabber.org/protocol/disco#info'> <identity category='conference' name='Shakespearean Chat Service' type='text'/> <feature var='http://jabber.org/protocol/muc'/> </query> </iq>","title":"8.1.1 Discovering the Features Supported by a MUC Service"},{"location":"open-extensions/muc_light/#812-discovering-occupied-rooms","text":"The room list MUST NOT include room versions. Service Returns Disco Items Result <iq from='muclight.shakespeare.lit' id='zb8q41f4' to='hag66@shakespeare.lit/pda' type='result'> <query xmlns='http://jabber.org/protocol/disco#items'> <item jid='heath@muclight.shakespeare.lit' name='A Lonely Heath'/> <item jid='coven@muclight.shakespeare.lit' name='A Dark Cave'/> <item jid='forres@muclight.shakespeare.lit' name='The Palace'/> <item jid='inverness@muclight.shakespeare.lit' name='Macbeth&apos;s Castle'/> </query> </iq>","title":"8.1.2 Discovering Occupied Rooms"},{"location":"open-extensions/muc_light/#813-changing-a-room-subject","text":"Instead of distributing the configuration change notifications, the room MUST route <message/> with a <subject/> like a classic MUC would. The client MUST send a classic message <subject/> as well. The room SHOULD save a new subject in the room configuration. New subject is routed as an ordinary message <message from='hag66@shakespeare.lit/pda' id='compsubject' to='coven@muclight.shakespeare.lit' type='groupchat'> <subject>To be or not to be?</subject> </message> <message from='coven@muclight.shakespeare.lit' to='crone1@shakespeare.lit' type='groupchat' id='compsubject'> <subject>To be or not to be?</subject> </message> <message from='coven@muclight.shakespeare.lit' to='hag66@shakespeare.lit' type='groupchat' id='compsubject'> <subject>To be or not to be?</subject> </message>","title":"8.1.3 Changing a room subject"},{"location":"open-extensions/muc_light/#814-getting-a-room-configuration","text":"Room configuration is encoded in a Data Form, that simulates the XEP-0045 config form. Getting the room configuration does not benefit from room versioning. Requesting room configuration <iq from='crone1@shakespeare.lit/desktop' id='comp-config' to='coven@muclight.shakespeare.lit' type='get'> <query xmlns='http://jabber.org/protocol/muc#owner'/> </iq> <iq from='coven@muclight.shakespeare.lit' id='comp-config' to='crone1@shakespeare.lit/desktop' type='result'> <query xmlns='http://jabber.org/protocol/muc#owner'> <x xmlns='jabber:x:data' type='form'> <title>Configuration for \"coven\" Room</title> <field type='hidden' var='FORM_TYPE'> <value>http://jabber.org/protocol/muc#roomconfig</value> </field> <field label='Natural-Language Room Name' type='text-single' var='muc#roomconfig_roomname'> <value>A Dark Cave</value> </field> <field label='Room subject' type='text-single' var='muc#roomconfig_subject'> <value>To be or not to be?</value> </field> </x> </query> </iq>","title":"8.1.4 Getting a room configuration"},{"location":"open-extensions/muc_light/#815-requesting-a-user-list","text":"A user list is retrieved with an affiliation IQ get. Requesting affiliation list <iq from='crone1@shakespeare.lit/desktop' id='comp-getaff' to='coven@muclight.shakespeare.lit' type='get'> <query xmlns='http://jabber.org/protocol/muc#admin'> <item affiliation='owner'/> <item affiliation='member'/> </query> </iq> <iq from='coven@muclight.shakespeare.lit' id='comp-getaff' to='crone1@shakespeare.lit/desktop' type='result'> <query xmlns='http://jabber.org/protocol/muc#admin'> <item affiliation='owner' jid='crone1@shakespeare.lit' nick='crone1@shakespeare.lit' role='moderator'/> <item affiliation='member' jid='hag66@shakespeare.lit' nick='hag66@shakespeare.lit' role='participant'/> </query> </iq>","title":"8.1.5 Requesting a user list"},{"location":"open-extensions/muc_light/#816-requesting-room-information","text":"There is no XEP-0045 equivalent for getting full room information.","title":"8.1.6 Requesting room information"},{"location":"open-extensions/muc_light/#817-leaving-the-room","text":"Leaving the room is performed by setting the own affiliation to 'none'. The service uses <presence/> to notify all occupants (and former occupant) about the change. <presence/> to the leaving occupant MUST be of the type \"unavailable\" and MUST include a status code 321 (i.e. user leaving due to affiliation change). Leaving the room <iq from='crone1@shakespeare.lit/desktop' id='comp-leave' to='coven@muclight.shakespeare.lit' type='set'> <query xmlns='http://jabber.org/protocol/muc#admin'> <item affiliation='none' jid='crone1@shakespeare.lit'/> </query> </iq> <presence from='coven@muclight.shakespeare.lit/crone1@shakespeare.lit' to='crone1@shakespeare.lit' type='unavailable'> <x xmlns='http://jabber.org/protocol/muc#user'> <item affiliation='none' jid='crone1@shakespeare.lit/pda' role='none'/> <status code='321'/> </x> </presence> <presence from='coven@muclight.shakespeare.lit/crone1@shakespeare.lit' to='hag66@shakespeare.lit/desktop'> <x xmlns='http://jabber.org/protocol/muc#user'> <item affiliation='none' jid='crone1@shakespeare.lit/pda' role='none'/> <status code='321'/> </x> </presence> <iq from='coven@muclight.shakespeare.lit' id='comp-leave' to='crone1@shakespeare.lit/desktop' type='result'/>","title":"8.1.7 Leaving the room"},{"location":"open-extensions/muc_light/#818-blocking-functionality","text":"The blocking functionality uses a small subset of the Privacy Lists protocol. Stanzas MUST be addressed to the sender's bare JID (the to attribute may be skipped). The privacy list name MUST be equal to \"urn:xmpp:muclight:0\". Obviously, this method won't work properly in XMPP Server Federation, because privacy stanzas are handled by sender's server and the MUC Light Blocking functionality is handled by a MUC Light service server. As opposed to XEP-0016, it is allowed to send \"delta\" privacy lists.","title":"8.1.8 Blocking functionality"},{"location":"open-extensions/muc_light/#8181-request-blocking-list","text":"Retrieving blocking list <iq from='crone1@shakespeare.lit/desktop' type='get' id='comp-getlist'> <query xmlns='jabber:iq:privacy'> <list name='urn:xmpp:muclight:0'/> </query> </iq> <iq type='result' id='comp-getlist' to='crone1@shakespeare.lit/desktop'> <query xmlns='jabber:iq:privacy'> <list name='urn:xmpp:muclight:0'> <item type='jid' value='coven@muclight.shakespeare.lit' action='deny' order='1'/> <item type='jid' value='muclight.shakespeare.lit/hag66@shakespeare.lit' action='deny' order='1'/> </list> </query> </iq>","title":"8.1.8.1 Request blocking list"},{"location":"open-extensions/muc_light/#8182-blocking-a-room","text":"In order to block a room, the client MUST deny a room bare JID in privacy list. Blocking a room <iq from='crone1@shakespeare.lit/desktop' type='set' id='comp-blockroom'> <query xmlns='jabber:iq:privacy'> <list name='urn:xmpp:muclight:0'> <item type='jid' value='coven@muclight.shakespeare.lit' action='deny' order='1'/> </list> </query> </iq> <iq type='result' id='comp-blockroom' to='crone1@shakespeare.lit/desktop' />","title":"8.1.8.2 Blocking a room"},{"location":"open-extensions/muc_light/#8183-blocking-a-user","text":"In order to block a room, the client MUST deny a service JID with user's bare JID in the resource. Blocking a user <iq from='crone1@shakespeare.lit/desktop' type='set' id='comp-blockuser'> <query xmlns='jabber:iq:privacy'> <list name='urn:xmpp:muclight:0'> <item type='jid' value='muclight.shakespeare.lit/hag66@shakespeare.lit' action='deny' order='1'/> </list> </query> </iq> <iq type='result' id='comp-blockuser' to='crone1@shakespeare.lit/desktop' />","title":"8.1.8.3 Blocking a user"},{"location":"open-extensions/muc_light/#8184-unblocking","text":"Unblocking <iq from='crone1@shakespeare.lit/desktop' type='get' id='comp-getlist'> <query xmlns='jabber:iq:privacy'> <list name='urn:xmpp:muclight:0'> <item type='jid' value='coven@muclight.shakespeare.lit' action='allow' order='1'/> <item type='jid' value='muclight.shakespeare.lit/hag66@shakespeare.lit' action='allow' order='1'/> </list> </query> </iq> <iq type='result' id='comp-getlist' to='crone1@shakespeare.lit/desktop' />","title":"8.1.8.4 Unblocking"},{"location":"open-extensions/muc_light/#819-creating-a-room","text":"The room is created in a standard XEP-0045 way. Client MUST use a nick equal to their own bare JID. Compatibility mode MUST NOT support a unique room name generation. Creating a room <presence from='crone1@shakespeare.lit/desktop' to='coven@muclight.shakespeare.lit/crone1@shakespeare.lit'> <x xmlns='http://jabber.org/protocol/muc'/> </presence> <presence from='coven@chat.shakespeare.lit/crone1@shakespeare.lit' to='crone1@shakespeare.lit/desktop'> <x xmlns='http://jabber.org/protocol/muc#user'> <item affiliation='owner' role='moderator'/> <status code='110'/> <status code='201'/> </x> </presence>","title":"8.1.9 Creating a room"},{"location":"open-extensions/muc_light/#8191-room-already-exists","text":"If the client attempts to create a room that is already used, it will receive an error <presence/> informing that registration is required (like in the case of members-only rooms in XEP-0045). Creating a room <presence from='coven@muclight.shakespeare.lit/crone1@shakespeare.lit' to='crone1@shakespeare.lit/desktop' type='error'> <x xmlns='http://jabber.org/protocol/muc'/> <error by='coven@muclight.shakespeare.lit' type='auth'> <registration-required xmlns='urn:ietf:params:xml:ns:xmpp-stanzas'/> </error> </presence>","title":"8.1.9.1 Room already exists"},{"location":"open-extensions/muc_light/#8110-destroying-the-room","text":"A classic XEP-0045 method is used but the service SHOULD NOT forward reason and alternate venue JID. Destroying the room <iq from='crone1@shakespeare.lit/desktop' id='begone' to='heath@muclight.shakespeare.lit' type='set'> <query xmlns='http://jabber.org/protocol/muc#owner'> <destroy jid='coven@muclight.shakespare.lit'> <reason>Some reason.</reason> </destroy> </query> </iq> <presence from='heath@chat.shakespeare.lit/crone1@shakespeare.lit' to='crone1@shakespeare.lit/desktop' type='unavailable'> <x xmlns='http://jabber.org/protocol/muc#user'> <item affiliation='none' role='none'/> <destroy /> </x> </presence> <presence from='heath@chat.shakespeare.lit/wiccarocks@shakespeare.lit' to='wiccarocks@shakespeare.lit/laptop' type='unavailable'> <x xmlns='http://jabber.org/protocol/muc#user'> <item affiliation='none' role='none'/> <destroy /> </x> </presence> <presence from='heath@chat.shakespeare.lit/hag66@shakespeare.lit' to='hag66@shakespeare.lit/pda' type='unavailable'> <x xmlns='http://jabber.org/protocol/muc#user'> <item affiliation='none' role='none'/> <destroy /> </x> </presence> <iq from='heath@chat.shakespeare.lit' id='begone' to='crone1@shakespeare.lit/desktop' type='result'/>","title":"8.1.10 Destroying the room"},{"location":"open-extensions/muc_light/#8111-setting-room-configuration","text":"Room occupants can use a standard XEP-0045 configuration modification method. The service MUST broadcast only the notification about the configuration change with a status code 104, so every occupant can retrieve the new room configuration in a separate request. The client is allowed to send a config delta in a form. Setting room configuration <iq to='coven@muclight.shakespeare.lit' id='comp-setconfig' from='crone1@shakespeare.lit/desktop' type='set'> <query xmlns='http://jabber.org/protocol/muc#owner'> <x xmlns='jabber:x:data' type='form'> <field type='hidden' var='FORM_TYPE'> <value>http://jabber.org/protocol/muc#roomconfig</value> </field> <field label='Natural-Language Room Name' type='text-single' var='muc#roomconfig_roomname'> <value>A Darker Cave</value> </field> <field label='Room subject' type='text-single' var='muc#roomconfig_subject'> <value>To be!</value> </field> </x> </query> </iq> <message from='coven@muclight.shakespeare.lit' id='comp-confchange' to='crone1@shakespeare.lit/desktop' type='groupchat'> <x xmlns='http://jabber.org/protocol/muc#user'> <status code='104'/> </x> </message> <message from='coven@muclight.shakespeare.lit' id='comp-confchange' to='crone2@shakespeare.lit/desktop' type='groupchat'> <x xmlns='http://jabber.org/protocol/muc#user'> <status code='104'/> </x> </message> <iq from='coven@muclight.shakespeare.lit' id='comp-setconfig' to='crone1@shakespeare.lit/desktop' type='result'/>","title":"8.1.11 Setting room configuration"},{"location":"open-extensions/muc_light/#8112-changing-occupant-list","text":"The service MUST send an affiliation change notification to all participants. Leaving users MUST NOT receive any information except for their own \"none\" affiliation. New users MUST receive an invitation message. Changing occupant list <iq from='crone1@shakespeare.lit/desktop' id='comp-setaff' to='coven@muclight.shakespeare.lit' type='set'> <query xmlns='http://jabber.org/protocol/muc#admin'> <item affiliation='none' jid='hag66@shakespeare.lit'/> <item affiliation='member' jid='hecate@shakespeare.lit'/> </query> </iq> <presence from='coven@chat.shakespeare.lit/hag66@shakespeare.lit' to='hag66@shakespeare.lit' type='unavailable'> <x xmlns='http://jabber.org/protocol/muc#user'> <item affiliation='none' jid='hag66@shakespeare.lit' role='none'/> <status code='321'/> </x> </presence> <message from='coven@muclight.shakespeare.lit' id='comp-invite0' to='hecate@shakespeare.lit'> <x xmlns='http://jabber.org/protocol/muc#user'> <invite from='crone1@shakespeare.lit'/> </x> </message> <presence from='coven@chat.shakespeare.lit/hag66@shakespeare.lit' to='crone1@shakespeare.lit' type='unavailable'> <x xmlns='http://jabber.org/protocol/muc#user'> <item affiliation='none' jid='hag66@shakespeare.lit' role='none'/> <status code='321'/> </x> </presence> <presence from='coven@chat.shakespeare.lit/hecate@shakespeare.lit' to='crone1@shakespeare.lit'> <x xmlns='http://jabber.org/protocol/muc#user'> <item affiliation='member' jid='hecate@shakespeare.lit' role='participant' nick='hecate@shakespeare.lit'/> </x> </presence> <iq from='coven@muclight.shakespeare.lit' id='comp-setaff' to='crone1@shakespeare.lit/desktop' type='result'/>","title":"8.1.12 Changing occupant list"},{"location":"open-extensions/muc_light/#82-service-limits-and-configuration","text":"The MUC Light service may be abused by a malicious users, e.g. due to replicating a single message for every room occupant. The list below contains suggested configurable limits that SHOULD be implemented. The service features that might vary depending on a specific application are included as well. Maximum number of rooms the user occupies. Blocking feature enabled/disabled. XEP-0045 compatibility mode enabled/disabled. Room creator's initial affiliation: owner/member. Room configuration may be changed by owner/occupants. New members can be invited by owner/occupants. Maximal room size.","title":"8.2 Service limits and configuration"},{"location":"open-extensions/token-reconnection/","text":"Introduction Automatic reconnection after spurious disconnection is a must-have feature in modern IM applications. One way of providing this feature is storing the user login information on the disk. Here you need to balance two values - security and convienience for the end-user. To put it simply: storing passowords in plaintext is inherently insecure while protecting the XMPP password with a master-password is damages the user experience. With a token-based authentication mechanism, the user has to provide login information only once, for the initial connection to the XMPP server, and can later rely on the application's automatic use of tokens for subsequent reconnections. Reconnecting to the XMPP server, usually means that the client has to go through the same long process of SASL challenge-response exchange which may cause noticable lags, especially while using SCRAM-based mechanisms. Providing a token to the XMPP server is secure and doesn't require multiple challenge-response roundtrips, therefore might significantly speed up reconnection times. Requirements This extension requires the client application to authenticate to the XMPP server using a regular XMPP authentication mechanism like SCRAM-SHA-1 at least once. After that, the following authentications may be done using X-OAUTH SASL mechanism with a token obtained from the server. To enable the feature, modules mod_auth_token and mod_keystore have to be enabled on the server. For more details regarding the configuration see mod_auth_token documentation and mod_keystore . Token types Token Type Description Access token These are short lived tokens whose grants aren't tracked by the server (i.e. there's no need to store anything in a database). Access tokens can be used as a payload for the X-OAUTH authentication mechanism and grant access to the system. Access tokens can't be revoked. An access token is valid only until its expiry date is reached. Refresh token These are longer lived tokens which are tracked by the server, and therefore require persistent storage. Refresh tokens can be used as a payload for the X-OAUTH authentication mechanism and grant access to the system, as well as result in a new set of tokens being returned upon successful authentication. Refresh tokens can be revoked. A refresh token is valid until it has expired, unless it has been revoked. On revocation, it immediately becomes invalid. As the server stores information about granted tokens, it can also persistently mark them as revoked. While only two token types have been described above, implementations might use other token types for specific purposes. For example, a particular token type could limit the access privileges of a user logged into the system or denote an affiliation with a Multi User Chat room. None of such capability grants are a subject of this specification though. Use cases Obtaining a token After authenticating with some other mechanism like SCRAM-SHA-1, a client may request a token from the server by sending the following iq get to its own bare JID: Client requests tokens <iq type='get' to='alice@wonderland.com' id='123'> <query xmlns='erlang-solutions.com:xmpp:token-auth:0'/> </iq> Server responds with a tokens <iq from=\"alice@wonderland.com\" type=\"result\" to=\"alice@wonderland.com/resource\" id=\"123\"> <items xmlns=\"erlang-solutions.com:xmpp:token-auth:0\"> <access_token>YWNjZXNzAGFsaWNlQHdvbmRlcmxhbmQuY29tL01pY2hhbC1QaW90cm93c2tpcy1NYWNCb29rLVBybwA2MzYyMTg4Mzc2NAA4M2QwNzNiZjBkOGJlYzVjZmNkODgyY2ZlMzkyZWM5NGIzZjA4ODNlNDI4ZjQzYjc5MGYxOWViM2I2ZWJlNDc0ODc3MDkxZTIyN2RhOGMwYTk2ZTc5ODBhNjM5NjE1Zjk=</access_token> <refresh_token>cmVmcmVzaABhbGljZUB3b25kZXJsYW5kLmNvbS9NaWNoYWwtUGlvdHJvd3NraXMtTWFjQm9vay1Qcm8ANjM2MjMwMDYxODQAMQAwZGQxOGJjODhkMGQ0N2MzNTBkYzAwYjcxZjMyZDVmOWIwOTljMmI1ODU5MmNhN2QxZGFmNWFkNGM0NDQ2ZGU2MWYxYzdhNTJjNDUyMGI5YmIxNGIxNTMwMTE4YTM1NTc=</refresh_token> </items> </iq> Authentication with an access token Client authenticates with an access token <auth xmlns=\"urn:ietf:params:xml:ns:xmpp-sasl\" mechanism=\"X-OAUTH\"> YWNjZXNzAGFsaWNlQHdvbmRlcmxhbmQuY29tL01pY2hhbC1QaW90cm93c2tpcy1NYWNCb29rLVBybwA2MzYyMTg4Mzc2NAA4M2QwNzNiZjBkOGJlYzVjZmNkODgyY2ZlMzkyZWM5NGIzZjA4ODNlNDI4ZjQzYjc5MGYxOWViM2I2ZWJlNDc0ODc3MDkxZTIyN2RhOGMwYTk2ZTc5ODBhNjM5NjE1Zjk= </auth> Server responds with a success <success xmlns=\"urn:ietf:params:xml:ns:xmpp-sasl\"/> Authentication with a refresh token In this situation server will respond with a new refresh token which SHOULD be used in future authentication. Client authenticates with a refresh token <auth xmlns=\"urn:ietf:params:xml:ns:xmpp-sasl\" mechanism=\"X-OAUTH\"> cmVmcmVzaABhbGljZUB3b25kZXJsYW5kLmNvbS9NaWNoYWwtUGlvdHJvd3NraXMtTWFjQm9vay1Qcm8ANjM2MjMwMDYxODQAMQAwZGQxOGJjODhkMGQ0N2MzNTBkYzAwYjcxZjMyZDVmOWIwOTljMmI1ODU5MmNhN2QxZGFmNWFkNGM0NDQ2ZGU2MWYxYzdhNTJjNDUyMGI5YmIxNGIxNTMwMTE4YTM1NTc= </auth> Server responds with a success and a new refresh token <success xmlns=\"urn:ietf:params:xml:ns:xmpp-sasl\"> cmVmcmVzaABhbGljZUB3b25kZXJsYW5kLmNvbS9NaWNoYWwtUGlvdHJvd3NraXMtTWFjQm9vay1Qcm8ANjM2MjMwMDYxODQAMgAwZGQxOGJjODhkMGQ0N2MzNTBkYzAwYjcxZjMyZDVmOWIwOTljMmI1ODU5MmNhN2QxZGFmNWFkNGM0NDQ2ZGU2MWYxYzdhNTJjNDUyMGI5YmIxNGIxNTMwMTE4YTM1NTc= </success> Token format All tokens are exchanged as Base64 encoded binary data. Serialization format of the token before encoding with Base64 is dependent on its type. Common parts in every token are BARE_JID and EXPIRES_AT . EXPIRES_AT is a timestamp saying when a given token will expire. \\0 stands for the ASCII null character (i.e. byte 0). Text in single quotes ('example') is literal. ALL_CAPS denote parameters. Access token format BASE64_encode ('access', \\0, BARE_JID, \\0, EXPIRES_AT, \\0, DATA) Example (please note the line break was added only for readability): 'access' \\0 Q8@wonderland.com \\0 64875466454 \\0 0acd0a66d06934791d046060cf9f1ad3c2abb3274cc7e7d7b2bc7e2ac4453ed774b6c6813b40ebec2bbc3774d59d4087 Refresh token format BASE64_encode ('refresh', \\0, BARE_JID, \\0, EXPIRES_AT, \\0, SEQUENCE_NO, \\0, DATA) Example (please note the line break was added only for readability): 'refresh' \\0 qp@wonderland.com \\0 64875466457 \\0 6 \\0 8f57cb019cd6dc6e7779be165b9558611baf71ee4a40d03e77b78b069f482f96c9d23b1ac1ef69f64c1a1db3d36a96ad","title":"Token-based reconnection"},{"location":"open-extensions/token-reconnection/#introduction","text":"Automatic reconnection after spurious disconnection is a must-have feature in modern IM applications. One way of providing this feature is storing the user login information on the disk. Here you need to balance two values - security and convienience for the end-user. To put it simply: storing passowords in plaintext is inherently insecure while protecting the XMPP password with a master-password is damages the user experience. With a token-based authentication mechanism, the user has to provide login information only once, for the initial connection to the XMPP server, and can later rely on the application's automatic use of tokens for subsequent reconnections. Reconnecting to the XMPP server, usually means that the client has to go through the same long process of SASL challenge-response exchange which may cause noticable lags, especially while using SCRAM-based mechanisms. Providing a token to the XMPP server is secure and doesn't require multiple challenge-response roundtrips, therefore might significantly speed up reconnection times.","title":"Introduction"},{"location":"open-extensions/token-reconnection/#requirements","text":"This extension requires the client application to authenticate to the XMPP server using a regular XMPP authentication mechanism like SCRAM-SHA-1 at least once. After that, the following authentications may be done using X-OAUTH SASL mechanism with a token obtained from the server. To enable the feature, modules mod_auth_token and mod_keystore have to be enabled on the server. For more details regarding the configuration see mod_auth_token documentation and mod_keystore .","title":"Requirements"},{"location":"open-extensions/token-reconnection/#token-types","text":"Token Type Description Access token These are short lived tokens whose grants aren't tracked by the server (i.e. there's no need to store anything in a database). Access tokens can be used as a payload for the X-OAUTH authentication mechanism and grant access to the system. Access tokens can't be revoked. An access token is valid only until its expiry date is reached. Refresh token These are longer lived tokens which are tracked by the server, and therefore require persistent storage. Refresh tokens can be used as a payload for the X-OAUTH authentication mechanism and grant access to the system, as well as result in a new set of tokens being returned upon successful authentication. Refresh tokens can be revoked. A refresh token is valid until it has expired, unless it has been revoked. On revocation, it immediately becomes invalid. As the server stores information about granted tokens, it can also persistently mark them as revoked. While only two token types have been described above, implementations might use other token types for specific purposes. For example, a particular token type could limit the access privileges of a user logged into the system or denote an affiliation with a Multi User Chat room. None of such capability grants are a subject of this specification though.","title":"Token types"},{"location":"open-extensions/token-reconnection/#use-cases","text":"","title":"Use cases"},{"location":"open-extensions/token-reconnection/#obtaining-a-token","text":"After authenticating with some other mechanism like SCRAM-SHA-1, a client may request a token from the server by sending the following iq get to its own bare JID: Client requests tokens <iq type='get' to='alice@wonderland.com' id='123'> <query xmlns='erlang-solutions.com:xmpp:token-auth:0'/> </iq> Server responds with a tokens <iq from=\"alice@wonderland.com\" type=\"result\" to=\"alice@wonderland.com/resource\" id=\"123\"> <items xmlns=\"erlang-solutions.com:xmpp:token-auth:0\"> <access_token>YWNjZXNzAGFsaWNlQHdvbmRlcmxhbmQuY29tL01pY2hhbC1QaW90cm93c2tpcy1NYWNCb29rLVBybwA2MzYyMTg4Mzc2NAA4M2QwNzNiZjBkOGJlYzVjZmNkODgyY2ZlMzkyZWM5NGIzZjA4ODNlNDI4ZjQzYjc5MGYxOWViM2I2ZWJlNDc0ODc3MDkxZTIyN2RhOGMwYTk2ZTc5ODBhNjM5NjE1Zjk=</access_token> <refresh_token>cmVmcmVzaABhbGljZUB3b25kZXJsYW5kLmNvbS9NaWNoYWwtUGlvdHJvd3NraXMtTWFjQm9vay1Qcm8ANjM2MjMwMDYxODQAMQAwZGQxOGJjODhkMGQ0N2MzNTBkYzAwYjcxZjMyZDVmOWIwOTljMmI1ODU5MmNhN2QxZGFmNWFkNGM0NDQ2ZGU2MWYxYzdhNTJjNDUyMGI5YmIxNGIxNTMwMTE4YTM1NTc=</refresh_token> </items> </iq>","title":"Obtaining a token"},{"location":"open-extensions/token-reconnection/#authentication-with-an-access-token","text":"Client authenticates with an access token <auth xmlns=\"urn:ietf:params:xml:ns:xmpp-sasl\" mechanism=\"X-OAUTH\"> YWNjZXNzAGFsaWNlQHdvbmRlcmxhbmQuY29tL01pY2hhbC1QaW90cm93c2tpcy1NYWNCb29rLVBybwA2MzYyMTg4Mzc2NAA4M2QwNzNiZjBkOGJlYzVjZmNkODgyY2ZlMzkyZWM5NGIzZjA4ODNlNDI4ZjQzYjc5MGYxOWViM2I2ZWJlNDc0ODc3MDkxZTIyN2RhOGMwYTk2ZTc5ODBhNjM5NjE1Zjk= </auth> Server responds with a success <success xmlns=\"urn:ietf:params:xml:ns:xmpp-sasl\"/>","title":"Authentication with an access token"},{"location":"open-extensions/token-reconnection/#authentication-with-a-refresh-token","text":"In this situation server will respond with a new refresh token which SHOULD be used in future authentication. Client authenticates with a refresh token <auth xmlns=\"urn:ietf:params:xml:ns:xmpp-sasl\" mechanism=\"X-OAUTH\"> cmVmcmVzaABhbGljZUB3b25kZXJsYW5kLmNvbS9NaWNoYWwtUGlvdHJvd3NraXMtTWFjQm9vay1Qcm8ANjM2MjMwMDYxODQAMQAwZGQxOGJjODhkMGQ0N2MzNTBkYzAwYjcxZjMyZDVmOWIwOTljMmI1ODU5MmNhN2QxZGFmNWFkNGM0NDQ2ZGU2MWYxYzdhNTJjNDUyMGI5YmIxNGIxNTMwMTE4YTM1NTc= </auth> Server responds with a success and a new refresh token <success xmlns=\"urn:ietf:params:xml:ns:xmpp-sasl\"> cmVmcmVzaABhbGljZUB3b25kZXJsYW5kLmNvbS9NaWNoYWwtUGlvdHJvd3NraXMtTWFjQm9vay1Qcm8ANjM2MjMwMDYxODQAMgAwZGQxOGJjODhkMGQ0N2MzNTBkYzAwYjcxZjMyZDVmOWIwOTljMmI1ODU5MmNhN2QxZGFmNWFkNGM0NDQ2ZGU2MWYxYzdhNTJjNDUyMGI5YmIxNGIxNTMwMTE4YTM1NTc= </success>","title":"Authentication with a refresh token"},{"location":"open-extensions/token-reconnection/#token-format","text":"All tokens are exchanged as Base64 encoded binary data. Serialization format of the token before encoding with Base64 is dependent on its type. Common parts in every token are BARE_JID and EXPIRES_AT . EXPIRES_AT is a timestamp saying when a given token will expire. \\0 stands for the ASCII null character (i.e. byte 0). Text in single quotes ('example') is literal. ALL_CAPS denote parameters.","title":"Token format"},{"location":"open-extensions/token-reconnection/#access-token-format","text":"BASE64_encode ('access', \\0, BARE_JID, \\0, EXPIRES_AT, \\0, DATA) Example (please note the line break was added only for readability): 'access' \\0 Q8@wonderland.com \\0 64875466454 \\0 0acd0a66d06934791d046060cf9f1ad3c2abb3274cc7e7d7b2bc7e2ac4453ed774b6c6813b40ebec2bbc3774d59d4087","title":"Access token format"},{"location":"open-extensions/token-reconnection/#refresh-token-format","text":"BASE64_encode ('refresh', \\0, BARE_JID, \\0, EXPIRES_AT, \\0, SEQUENCE_NO, \\0, DATA) Example (please note the line break was added only for readability): 'refresh' \\0 qp@wonderland.com \\0 64875466457 \\0 6 \\0 8f57cb019cd6dc6e7779be165b9558611baf71ee4a40d03e77b78b069f482f96c9d23b1ac1ef69f64c1a1db3d36a96ad","title":"Refresh token format"},{"location":"operation-and-maintenance/Cluster-configuration-and-node-management/","text":"Environment configuration File descriptors To handle large traffic, some of the system variables need to be tuned. Number one on that list is the maximum number of file descriptors which often is set to 1024. Each MongooseIM connection consumes ~1 file descriptor, so the default value will not suffice for larger installations - when it is exceeded, emfile errors will appear in logs. To check the current limit execute: ulimit -n . To list all limits execute: ulimit -a . In the example below we set limits for a mongooseim user. To increase the limit the following entries should be added in /etc/security/limits.conf : mongooseim soft nofile 1000000 mongooseim hard nofile 1000000 If you are using Ubuntu , all /etc/pam.d/common-session* files should include session required pam_limits.so . vm.args file This file contains erlang options used when starting the VM. It is located in REL_ROOT/etc/vm.args where REL_ROOT is the path to a MonoogseIM release (ie. _build/prod/rel/mongooseim if you build MongooseIM from source). When using an SSL/TLS connection we advise to increase ERL_MAX_PORTS to 350000 . This value specifies how many ports (files, drivers, sockets etc) can be used by Erlang VM. Be cautious - it preallocates some structures inside the VM and will have impact on the memory usage. We suggest 350000 for 100 k users when using an SSL/TLS connection or 250000 in other cases. To check how memory consumption changes depending on ERL_MAX_PORTS , use the following command: env ERL_MAX_PORTS=[given value] erl -noinput -eval 'io:format(\"~p~n\",[erlang:memory(system)]).' -s erlang halt Another change you need to make when building a MongooseIM cluster is setting the -sname . To do it, just set the -sname option in vm.args with node's hostname, which must be resolvable on other nodes in the cluster. Port range To connect to other nodes, a freshly started node uses a port from the range inet_dist_listen_min to inet_dist_listen_max . To enable this, add the following line to the vm.args file: -kernel inet_dist_listen_min 50000 inet_dist_listen_max 50010 Make sure that the range you set provides enough ports for all the nodes in the cluster. Remember to keep an epmd port open (port 4369) if any firewall restrictions are required. Epmd keeps track of which erlang node is using which ports on the local machine. Connecting nodes Checklist: working directory rel/mongooseim (root of a MongooseIM release or installation) the same cookie across all nodes ( vm.args -setcookie parameter) each node should be able to ping other nodes using its sname (ex. net_adm:ping('mongoose@localhost') ) Initial node There is no action required on the initial node. Just start MongooseIM using mongooseim start or mongooseim live . New node - joining cluster mongooseimctl start mongooseimctl started #waits until MongooseIM starts mongooseimctl join_cluster ClusterMember ClusterMember is the name of a running node set in vm.args file, for example mongooseim@localhost . This node has to be part of the cluster we'd like to join. First MongooseIM will display a warning and a question if the operation should proceed: Warning. This will drop all current connections and will discard all persistent data from Mnesia. Do you want to continue? (yes/no) If you type yes MongooseIM will start joining the cluster. Successful output may look like the following: You have successfully joined the node mongooseim2@localhost to the cluster with node member mongooseim@localhost In order to skip the question you can add option -f which will perform the action without displaying the warning and waiting for the confirmation. Leaving cluster To leave a running node from the cluster, call: mongooseimctl leave_cluster It only makes sense to use it if the node is the part of a cluster, e.g join_cluster was called from that node before. Similarly to join_cluster a warning and a question will be displayed unless the option -f is added to the command. The successful output from the above command may look like the following: You have successfully left the node mongooseim2@localhost from the cluster . Removing a node from the cluster To remove another node from the cluster, call the following command from one of the cluster members: mongooseimctl remove_from_cluster RemoteNodeName where RemoteNodeName is a name of the node that we'd like to remove from our cluster. This command could be useful when the node is dead and not responding and we'd like to remove it remotely. The successful output from the above command may look like the following: The node mongooseim2@localhost has been removed from the cluster Cluster status You can use the following commands on any of the running nodes to examine the cluster or to see if a newly added node is properly clustered: mongooseimctl mnesia info | grep \"running db nodes\" This command shows all running nodes. A healthy cluster should contain all nodes here. For example: running db nodes = [mongooseim@node1, mongooseim@node2] To see stopped or misbehaving nodes following command can be useful: mongooseimctl mnesia info | grep \"stopped db nodes\" This command shows which nodes are considered stopped. This does not necessarily indicate that they are down but might be a symptom of a communication problem. Load Balancing Elastic Load Balancer (ELB) When using ELB please be advised that some warm-up time may be needed before the load balancer works efficiently for a big load. Software load balancer A good example of load balancing on the application layer are HAProxy and Nginx. DNS-based load balancing Load balancing can be performed on a DNS level. A DNS response can have a number of IP addresses that can be returned to the client side in a random order. On the AWS stack this type of balancing is provided by Route53. The description of their service can be found at: http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/WeightedResourceRecordSets.html Other The approaches described above can be mixed - we can use DNS load balancing to pick a software load balancer which will select one of the nodes.","title":"Cluster configuration and node management"},{"location":"operation-and-maintenance/Cluster-configuration-and-node-management/#environment-configuration","text":"","title":"Environment configuration"},{"location":"operation-and-maintenance/Cluster-configuration-and-node-management/#file-descriptors","text":"To handle large traffic, some of the system variables need to be tuned. Number one on that list is the maximum number of file descriptors which often is set to 1024. Each MongooseIM connection consumes ~1 file descriptor, so the default value will not suffice for larger installations - when it is exceeded, emfile errors will appear in logs. To check the current limit execute: ulimit -n . To list all limits execute: ulimit -a . In the example below we set limits for a mongooseim user. To increase the limit the following entries should be added in /etc/security/limits.conf : mongooseim soft nofile 1000000 mongooseim hard nofile 1000000 If you are using Ubuntu , all /etc/pam.d/common-session* files should include session required pam_limits.so .","title":"File descriptors"},{"location":"operation-and-maintenance/Cluster-configuration-and-node-management/#vmargs-file","text":"This file contains erlang options used when starting the VM. It is located in REL_ROOT/etc/vm.args where REL_ROOT is the path to a MonoogseIM release (ie. _build/prod/rel/mongooseim if you build MongooseIM from source). When using an SSL/TLS connection we advise to increase ERL_MAX_PORTS to 350000 . This value specifies how many ports (files, drivers, sockets etc) can be used by Erlang VM. Be cautious - it preallocates some structures inside the VM and will have impact on the memory usage. We suggest 350000 for 100 k users when using an SSL/TLS connection or 250000 in other cases. To check how memory consumption changes depending on ERL_MAX_PORTS , use the following command: env ERL_MAX_PORTS=[given value] erl -noinput -eval 'io:format(\"~p~n\",[erlang:memory(system)]).' -s erlang halt Another change you need to make when building a MongooseIM cluster is setting the -sname . To do it, just set the -sname option in vm.args with node's hostname, which must be resolvable on other nodes in the cluster.","title":"vm.args file"},{"location":"operation-and-maintenance/Cluster-configuration-and-node-management/#port-range","text":"To connect to other nodes, a freshly started node uses a port from the range inet_dist_listen_min to inet_dist_listen_max . To enable this, add the following line to the vm.args file: -kernel inet_dist_listen_min 50000 inet_dist_listen_max 50010 Make sure that the range you set provides enough ports for all the nodes in the cluster. Remember to keep an epmd port open (port 4369) if any firewall restrictions are required. Epmd keeps track of which erlang node is using which ports on the local machine.","title":"Port range"},{"location":"operation-and-maintenance/Cluster-configuration-and-node-management/#connecting-nodes","text":"Checklist: working directory rel/mongooseim (root of a MongooseIM release or installation) the same cookie across all nodes ( vm.args -setcookie parameter) each node should be able to ping other nodes using its sname (ex. net_adm:ping('mongoose@localhost') )","title":"Connecting nodes"},{"location":"operation-and-maintenance/Cluster-configuration-and-node-management/#initial-node","text":"There is no action required on the initial node. Just start MongooseIM using mongooseim start or mongooseim live .","title":"Initial node"},{"location":"operation-and-maintenance/Cluster-configuration-and-node-management/#new-node-joining-cluster","text":"mongooseimctl start mongooseimctl started #waits until MongooseIM starts mongooseimctl join_cluster ClusterMember ClusterMember is the name of a running node set in vm.args file, for example mongooseim@localhost . This node has to be part of the cluster we'd like to join. First MongooseIM will display a warning and a question if the operation should proceed: Warning. This will drop all current connections and will discard all persistent data from Mnesia. Do you want to continue? (yes/no) If you type yes MongooseIM will start joining the cluster. Successful output may look like the following: You have successfully joined the node mongooseim2@localhost to the cluster with node member mongooseim@localhost In order to skip the question you can add option -f which will perform the action without displaying the warning and waiting for the confirmation.","title":"New node - joining cluster"},{"location":"operation-and-maintenance/Cluster-configuration-and-node-management/#leaving-cluster","text":"To leave a running node from the cluster, call: mongooseimctl leave_cluster It only makes sense to use it if the node is the part of a cluster, e.g join_cluster was called from that node before. Similarly to join_cluster a warning and a question will be displayed unless the option -f is added to the command. The successful output from the above command may look like the following: You have successfully left the node mongooseim2@localhost from the cluster .","title":"Leaving cluster"},{"location":"operation-and-maintenance/Cluster-configuration-and-node-management/#removing-a-node-from-the-cluster","text":"To remove another node from the cluster, call the following command from one of the cluster members: mongooseimctl remove_from_cluster RemoteNodeName where RemoteNodeName is a name of the node that we'd like to remove from our cluster. This command could be useful when the node is dead and not responding and we'd like to remove it remotely. The successful output from the above command may look like the following: The node mongooseim2@localhost has been removed from the cluster","title":"Removing a node from the cluster"},{"location":"operation-and-maintenance/Cluster-configuration-and-node-management/#cluster-status","text":"You can use the following commands on any of the running nodes to examine the cluster or to see if a newly added node is properly clustered: mongooseimctl mnesia info | grep \"running db nodes\" This command shows all running nodes. A healthy cluster should contain all nodes here. For example: running db nodes = [mongooseim@node1, mongooseim@node2] To see stopped or misbehaving nodes following command can be useful: mongooseimctl mnesia info | grep \"stopped db nodes\" This command shows which nodes are considered stopped. This does not necessarily indicate that they are down but might be a symptom of a communication problem.","title":"Cluster status"},{"location":"operation-and-maintenance/Cluster-configuration-and-node-management/#load-balancing","text":"","title":"Load Balancing"},{"location":"operation-and-maintenance/Cluster-configuration-and-node-management/#elastic-load-balancer-elb","text":"When using ELB please be advised that some warm-up time may be needed before the load balancer works efficiently for a big load.","title":"Elastic Load Balancer (ELB)"},{"location":"operation-and-maintenance/Cluster-configuration-and-node-management/#software-load-balancer","text":"A good example of load balancing on the application layer are HAProxy and Nginx.","title":"Software load balancer"},{"location":"operation-and-maintenance/Cluster-configuration-and-node-management/#dns-based-load-balancing","text":"Load balancing can be performed on a DNS level. A DNS response can have a number of IP addresses that can be returned to the client side in a random order. On the AWS stack this type of balancing is provided by Route53. The description of their service can be found at: http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/WeightedResourceRecordSets.html","title":"DNS-based load balancing"},{"location":"operation-and-maintenance/Cluster-configuration-and-node-management/#other","text":"The approaches described above can be mixed - we can use DNS load balancing to pick a software load balancer which will select one of the nodes.","title":"Other"},{"location":"operation-and-maintenance/Cluster-management-considerations/","text":"This applies to bare metal, virtualization, hypervisor, containers and other technologies. Single-node MongooseIM With a single-node MongooseIM, one can set up a vertically scalable system, that is a function of the server resources. MongooseIM can scale from hundreds to tens of thousands of concurrent users. Note that in a single-node MongooseIM, there is no load distribution, and no fallback or failover in case of failure. This architecture is suitable for low-scale deployments, such as testing and development environments on embedded devices, personal computers, or servers. Dual-node MongooseIM With a dual-node MongooseIM, one can set up a vertically scalable system, that is a function of the servers' resources. We recommend that servers with the same power are used. Both nodes can handle different sets of services, given that these non-MongooseIM services consume roughly the same resources on both servers. In this setup, MongooseIM can scale up to hundred of thousands of concurrent users. In a dual-node MongooseIM, there is a 50-50 load distribution - there is a possible fallback or failover in case of a node failure. Please keep in mind that to avoid degrading the service the remaining node should be able to handle the full load when necessary. This setup is applicable to low to mid-scale deployments used f.e. for functional and load testing. We recommend using real dedicated servers, although MongooseIM could run in a cluster mode with low-power machines, such as embedded devices. This setup provides better fault tolerance and robustness than the single-node but it's not recommended for production environments. The minimum recommended production setup is 3 nodes. Multi-node MongooseIM With a multi-node MongooseIM, one can set up a system that is highly scalable both vertically and horizontally and that is still a function of the servers' resources. We recommend that servers with the same power are used. We also recommend that all the nodes handle the same set of services. In this setup, MongooseIM can scale up to tens of millions of concurrent users. In a multi-node MongooseIM, with n nodes, there is a 1/n load distribution - there is a possible fallback or failover in case of a node failure. To avoid degrading the service the remaining nodes should be able to handle 1/(n-1) load when necessary. This setup fits mid and large-scale deployments, such as production environments. We recommend using real dedicated, powerful servers. Multi-datacenter MongooseIM With a multi-datacenter MongooseIM, one can set up a system that is highly scalable both vertically and horizontally. The MongooseIM clusters are simply distributed across continents for local, low-lag client connections, and the clusters are interconnected via high-speed links. In this setup, MongooseIM can scale up to hundreds of millions of concurrent users. This applies to large and very large-scale deployments. Contact us. Summary table Setup : reflects the number of nodes in your cluster. Purpose : is the goal and use of this cluster. Low-end : number of concurent users on low-power machines, such as laptops, embedded devides, entry-level cloud or bare metal. High-end : number of concurent users on powerful machines, with lots of memory, multi-core CPU, whether they or cloud or bare metal. Setup Purpose Low-end High-end Single-node Functional testing, development 100 to 10k 100k to 500k Dual-node Low-end system, load testing 1k to 100k 1M to 3M Multi-node High-end production system 10k to 1M 2M to 10M Multi-datacenter Very large scale production system 100k to 10M 10M to 100M Important notes Scalability highly depends on variables such as: machine's power, such as memory, CPU, I/O the type of concurrent users: most iOS apps are not connected in the background, they use APNS to push info to the device web clients use websockets, with fallback on BOSH (HTTP long-polling) client-side and backend-side REST API how much archiving is needed and the latency for storage and querying, which depends a lot on storage backend architecture message throughput: one-to-one MUC MUC light PubSub Presences HTTP notifications (with queuing systems such as RabbitMQ or Kafka) latency of messaging, both real-time and archived messages","title":"Cluster management considerations"},{"location":"operation-and-maintenance/Cluster-management-considerations/#single-node-mongooseim","text":"With a single-node MongooseIM, one can set up a vertically scalable system, that is a function of the server resources. MongooseIM can scale from hundreds to tens of thousands of concurrent users. Note that in a single-node MongooseIM, there is no load distribution, and no fallback or failover in case of failure. This architecture is suitable for low-scale deployments, such as testing and development environments on embedded devices, personal computers, or servers.","title":"Single-node MongooseIM"},{"location":"operation-and-maintenance/Cluster-management-considerations/#dual-node-mongooseim","text":"With a dual-node MongooseIM, one can set up a vertically scalable system, that is a function of the servers' resources. We recommend that servers with the same power are used. Both nodes can handle different sets of services, given that these non-MongooseIM services consume roughly the same resources on both servers. In this setup, MongooseIM can scale up to hundred of thousands of concurrent users. In a dual-node MongooseIM, there is a 50-50 load distribution - there is a possible fallback or failover in case of a node failure. Please keep in mind that to avoid degrading the service the remaining node should be able to handle the full load when necessary. This setup is applicable to low to mid-scale deployments used f.e. for functional and load testing. We recommend using real dedicated servers, although MongooseIM could run in a cluster mode with low-power machines, such as embedded devices. This setup provides better fault tolerance and robustness than the single-node but it's not recommended for production environments. The minimum recommended production setup is 3 nodes.","title":"Dual-node MongooseIM"},{"location":"operation-and-maintenance/Cluster-management-considerations/#multi-node-mongooseim","text":"With a multi-node MongooseIM, one can set up a system that is highly scalable both vertically and horizontally and that is still a function of the servers' resources. We recommend that servers with the same power are used. We also recommend that all the nodes handle the same set of services. In this setup, MongooseIM can scale up to tens of millions of concurrent users. In a multi-node MongooseIM, with n nodes, there is a 1/n load distribution - there is a possible fallback or failover in case of a node failure. To avoid degrading the service the remaining nodes should be able to handle 1/(n-1) load when necessary. This setup fits mid and large-scale deployments, such as production environments. We recommend using real dedicated, powerful servers.","title":"Multi-node MongooseIM"},{"location":"operation-and-maintenance/Cluster-management-considerations/#multi-datacenter-mongooseim","text":"With a multi-datacenter MongooseIM, one can set up a system that is highly scalable both vertically and horizontally. The MongooseIM clusters are simply distributed across continents for local, low-lag client connections, and the clusters are interconnected via high-speed links. In this setup, MongooseIM can scale up to hundreds of millions of concurrent users. This applies to large and very large-scale deployments. Contact us.","title":"Multi-datacenter MongooseIM"},{"location":"operation-and-maintenance/Cluster-management-considerations/#summary-table","text":"Setup : reflects the number of nodes in your cluster. Purpose : is the goal and use of this cluster. Low-end : number of concurent users on low-power machines, such as laptops, embedded devides, entry-level cloud or bare metal. High-end : number of concurent users on powerful machines, with lots of memory, multi-core CPU, whether they or cloud or bare metal. Setup Purpose Low-end High-end Single-node Functional testing, development 100 to 10k 100k to 500k Dual-node Low-end system, load testing 1k to 100k 1M to 3M Multi-node High-end production system 10k to 1M 2M to 10M Multi-datacenter Very large scale production system 100k to 10M 10M to 100M","title":"Summary table"},{"location":"operation-and-maintenance/Cluster-management-considerations/#important-notes","text":"Scalability highly depends on variables such as: machine's power, such as memory, CPU, I/O the type of concurrent users: most iOS apps are not connected in the background, they use APNS to push info to the device web clients use websockets, with fallback on BOSH (HTTP long-polling) client-side and backend-side REST API how much archiving is needed and the latency for storage and querying, which depends a lot on storage backend architecture message throughput: one-to-one MUC MUC light PubSub Presences HTTP notifications (with queuing systems such as RabbitMQ or Kafka) latency of messaging, both real-time and archived messages","title":"Important notes"},{"location":"operation-and-maintenance/Logging-%26-monitoring/","text":"Logs We strongly recommend storing logs in one centralized place when working in a clustered environment. MongooseIM uses Lager - the logging framework. Its backend can be easily replaced; the syslog backend is included by default in MongooseIM. Using syslog To activate the syslog backend you have to edit rel/files/app.config and uncomment the line: %% use below line to add syslog backend for Lager % {lager_syslog_backend, [ \"mongooseim\", local0, info]}, Remember to provide a parameter list to make your lager syslog backend running: The first parameter is a string to tag all the syslog messages with. The default is mongooseim . The second one is the facility to log to (see the syslog documentation). The last parameter is the lager level at which the backend accepts messages. In our case it's info . Depending on the system platform you use, remember also to add the appropriate line in the syslog config file: local0.info /var/log/mongooseim.log Now all the logs of level info will be passed to the /var/log/mongooseim.log file. Example log (e.g tail -f /var/log/mongooseim.log ): Apr 1 12:36:49 User.local mongooseim[6068]: [info] <0.7.0> Application mnesia started on node mongooseim@localhost Further / multiserver integration For more advanced processing and analysis of logs, including gathering logs from multiple machines, you can use one of the many available systems (e.g. logstash/elasticsearch/kibana, graylog, splunk), which collect data from the syslog and are beyond the scope of this documentation. Monitoring WombatOAM WombatOAM is an operations and maintenance framework for Erlang based systems. Its Web Dashboard displays this data in an aggregated manner. Additionally, WombatOAM provides interfaces to feed the data to other OAM tools such as Graphite, Nagios or Zabbix. For more information see: WombatOAM . graphite-collectd To monitor MongooseIM during load testing, we recommend the following open source applications: Grafana is used for data presentation. Graphite is a server used for metrics storage. collectd is a daemon running on the monitored nodes capturing data related to CPU and Memory usage, IO etc. Plug-in Exometer reporters MongooseIM uses a fork of Exometer library for collecting metrics. Exometer has many plug-in reporters that can send metrics to external services. We maintain exometer_report_graphite and exometer_report_statsd for Graphite and StatsD respectively. It is possible to enable them in MoongooseIM via the app.config file. The file sits next to the mongooseim.cfg file in the rel/files and _REL_DIR_/etc directories. Below you can find a sample configuration. It shows setting up a reporter connecting to graphite running on localhost. You can see an additional option not listed in the Exometer docs - mongooseim_report_interval , which sets the metrics' resolution, i.e. how often Exometer gathers and sends metrics through reporters. By default, the resolution is set to 60 seconds. ... {exometer_core, [ {mongooseim_report_interval, 60000}, %% 60 seconds {report, [ {reporters, [ {exometer_report_graphite, [ {prefix, \"mongooseim\"}, {connect_timeout, 5000}, {host, \"127.0.0.1\"}, {port, 2003}, {api_key, \"\"} ]} ]} ]} ]} ... Run Graphite & Grafana in Docker - quick start The following commands will download the latest version of kamon/grafana_graphite docker image that contains both Grafana and Graphite, and start them while mounting local directory ./docker-grafana-graphite-master/data for metrics persistance: $ curl -SL https://github.com/kamon-io/docker-grafana-graphite/archive/master.tar.gz | tar -xzf - $ make -C docker-grafana-graphite-master up Go to http://localhost to view Grafana dashboard that's already set up to use metrics from Graphite. Add metrics to Grafana dashboard We recommend the following metrics as a baseling for tracking your MongooseIM installation. For time-based metrics, you can choose to display multiple calculated values for a reporting period - we recommend tracking at least max , median and mean . Session count: <prefix>.global.totalSessionCount.value XMPP messages received: <prefix>.<domain>.xmppMessageReceived.one XMPP messages sent: <prefix>.<domain>.xmppMessageSent.one Successful logins: <prefix>.<domain>.sessionSuccessfulLogins.one Logouts: <prefix>.<domain>.sessionLogouts.one Authorization time: <prefix>.<domain>.backends.auth.authorize.<value-type> RDBMS \"simple\" query time: <prefix>.<domain>.backends.mongoose_rdbms.query.<value-type> RDBMS prepared query time: <prefix>.<domain>.backends.mongoose_rdbms.execute.<value-type> MAM lookups: <prefix>.<domain>.mam_lookup_messages.one MAM archivization time: <prefix>.<domain>.backends.mod_mam.archive.<value-type> MAM lookup time: <prefix>.<domain>.backends.mod_mam.lookup.<value-type> MAM private messages flush time: <prefix>.<domain>.mod_mam_rdbms_async_pool_writer.flush_time.<value-type> MAM MUC messages flush time: <prefix>.<domain>.mod_mam_muc_rdbms_async_pool_writer.flush_time.<value-type> Note that RDBMS metrics are only relevant if MongooseIM is configured with an RDBMS backend , MAM metrics when mod_mam is enabled and MAM flush times when MAM is configured with an RDBMS backend with async_writer option (default). Example graph in Grafana This screenshot shows a graph plotting the RDBMS simple query time metric mentioned above. The graph is plotted for three nodes with each node having a different prefix: mongoose.node1 , mongoose.node2 and mongoose.node3 . The queries take metrics for all nodes and all domains ( ** is a wildcard for multiple parts of the metric name) and group them per-node and per-value-type (respectively 1 st and -1 st part of the metric's name). Parts of the names are indexed from 0 . Time-based metrics in MongooseIM are given in microseconds , so to display human-readable values in graph's legend, the Y-axis unit has to be edited on the Axes tab.","title":"Logging & monitoring"},{"location":"operation-and-maintenance/Logging-%26-monitoring/#logs","text":"We strongly recommend storing logs in one centralized place when working in a clustered environment. MongooseIM uses Lager - the logging framework. Its backend can be easily replaced; the syslog backend is included by default in MongooseIM.","title":"Logs"},{"location":"operation-and-maintenance/Logging-%26-monitoring/#using-syslog","text":"To activate the syslog backend you have to edit rel/files/app.config and uncomment the line: %% use below line to add syslog backend for Lager % {lager_syslog_backend, [ \"mongooseim\", local0, info]}, Remember to provide a parameter list to make your lager syslog backend running: The first parameter is a string to tag all the syslog messages with. The default is mongooseim . The second one is the facility to log to (see the syslog documentation). The last parameter is the lager level at which the backend accepts messages. In our case it's info . Depending on the system platform you use, remember also to add the appropriate line in the syslog config file: local0.info /var/log/mongooseim.log Now all the logs of level info will be passed to the /var/log/mongooseim.log file. Example log (e.g tail -f /var/log/mongooseim.log ): Apr 1 12:36:49 User.local mongooseim[6068]: [info] <0.7.0> Application mnesia started on node mongooseim@localhost","title":"Using syslog"},{"location":"operation-and-maintenance/Logging-%26-monitoring/#further-multiserver-integration","text":"For more advanced processing and analysis of logs, including gathering logs from multiple machines, you can use one of the many available systems (e.g. logstash/elasticsearch/kibana, graylog, splunk), which collect data from the syslog and are beyond the scope of this documentation.","title":"Further / multiserver integration"},{"location":"operation-and-maintenance/Logging-%26-monitoring/#monitoring","text":"","title":"Monitoring"},{"location":"operation-and-maintenance/Logging-%26-monitoring/#wombatoam","text":"WombatOAM is an operations and maintenance framework for Erlang based systems. Its Web Dashboard displays this data in an aggregated manner. Additionally, WombatOAM provides interfaces to feed the data to other OAM tools such as Graphite, Nagios or Zabbix. For more information see: WombatOAM .","title":"WombatOAM"},{"location":"operation-and-maintenance/Logging-%26-monitoring/#graphite-collectd","text":"To monitor MongooseIM during load testing, we recommend the following open source applications: Grafana is used for data presentation. Graphite is a server used for metrics storage. collectd is a daemon running on the monitored nodes capturing data related to CPU and Memory usage, IO etc.","title":"graphite-collectd"},{"location":"operation-and-maintenance/Logging-%26-monitoring/#plug-in-exometer-reporters","text":"MongooseIM uses a fork of Exometer library for collecting metrics. Exometer has many plug-in reporters that can send metrics to external services. We maintain exometer_report_graphite and exometer_report_statsd for Graphite and StatsD respectively. It is possible to enable them in MoongooseIM via the app.config file. The file sits next to the mongooseim.cfg file in the rel/files and _REL_DIR_/etc directories. Below you can find a sample configuration. It shows setting up a reporter connecting to graphite running on localhost. You can see an additional option not listed in the Exometer docs - mongooseim_report_interval , which sets the metrics' resolution, i.e. how often Exometer gathers and sends metrics through reporters. By default, the resolution is set to 60 seconds. ... {exometer_core, [ {mongooseim_report_interval, 60000}, %% 60 seconds {report, [ {reporters, [ {exometer_report_graphite, [ {prefix, \"mongooseim\"}, {connect_timeout, 5000}, {host, \"127.0.0.1\"}, {port, 2003}, {api_key, \"\"} ]} ]} ]} ]} ...","title":"Plug-in Exometer reporters"},{"location":"operation-and-maintenance/Logging-%26-monitoring/#run-graphite-grafana-in-docker-quick-start","text":"The following commands will download the latest version of kamon/grafana_graphite docker image that contains both Grafana and Graphite, and start them while mounting local directory ./docker-grafana-graphite-master/data for metrics persistance: $ curl -SL https://github.com/kamon-io/docker-grafana-graphite/archive/master.tar.gz | tar -xzf - $ make -C docker-grafana-graphite-master up Go to http://localhost to view Grafana dashboard that's already set up to use metrics from Graphite.","title":"Run Graphite &amp; Grafana in Docker - quick start"},{"location":"operation-and-maintenance/Logging-%26-monitoring/#add-metrics-to-grafana-dashboard","text":"We recommend the following metrics as a baseling for tracking your MongooseIM installation. For time-based metrics, you can choose to display multiple calculated values for a reporting period - we recommend tracking at least max , median and mean . Session count: <prefix>.global.totalSessionCount.value XMPP messages received: <prefix>.<domain>.xmppMessageReceived.one XMPP messages sent: <prefix>.<domain>.xmppMessageSent.one Successful logins: <prefix>.<domain>.sessionSuccessfulLogins.one Logouts: <prefix>.<domain>.sessionLogouts.one Authorization time: <prefix>.<domain>.backends.auth.authorize.<value-type> RDBMS \"simple\" query time: <prefix>.<domain>.backends.mongoose_rdbms.query.<value-type> RDBMS prepared query time: <prefix>.<domain>.backends.mongoose_rdbms.execute.<value-type> MAM lookups: <prefix>.<domain>.mam_lookup_messages.one MAM archivization time: <prefix>.<domain>.backends.mod_mam.archive.<value-type> MAM lookup time: <prefix>.<domain>.backends.mod_mam.lookup.<value-type> MAM private messages flush time: <prefix>.<domain>.mod_mam_rdbms_async_pool_writer.flush_time.<value-type> MAM MUC messages flush time: <prefix>.<domain>.mod_mam_muc_rdbms_async_pool_writer.flush_time.<value-type> Note that RDBMS metrics are only relevant if MongooseIM is configured with an RDBMS backend , MAM metrics when mod_mam is enabled and MAM flush times when MAM is configured with an RDBMS backend with async_writer option (default).","title":"Add metrics to Grafana dashboard"},{"location":"operation-and-maintenance/Logging-%26-monitoring/#example-graph-in-grafana","text":"This screenshot shows a graph plotting the RDBMS simple query time metric mentioned above. The graph is plotted for three nodes with each node having a different prefix: mongoose.node1 , mongoose.node2 and mongoose.node3 . The queries take metrics for all nodes and all domains ( ** is a wildcard for multiple parts of the metric name) and group them per-node and per-value-type (respectively 1 st and -1 st part of the metric's name). Parts of the names are indexed from 0 . Time-based metrics in MongooseIM are given in microseconds , so to display human-readable values in graph's legend, the Y-axis unit has to be edited on the Axes tab.","title":"Example graph in Grafana"},{"location":"operation-and-maintenance/Mongoose-metrics/","text":"MongooseIM metrics MongooseIM by default collects many metrics showing the user behaviour and general system statistics. They are managed by exometer . MongooseIM uses ESL's fork of this project . All metrics are divided into the following groups: Per host metrics: Gathered separately for every XMPP host supported by the cluster. Warning: If a cluster supports many (thousands or more) domains, performance issues might occur. To avoid this, use global equivalents of the metrics with all_metrics_are_global config option. Hook metrics. They are created for every hook and incremented on every call to it. Global metrics: Metrics common for all XMPP hosts. Data metrics. These are misc. metrics related to data transfers (e.g. sent and received stanza size statistics). VM metrics. Basic Erlang VM statistics. Backend metrics: Histograms with timings of calls to various backends. Metrics types spiral This kind of metric provides 2 values: total event count (e.g. stanzas processed) and a value in 60s window ( one value). Dividing one value by 60 provides an average per-second value over last minute. Example: [{total, 1000}, {one, 20}] value A simple value. It is actually a one-element proplist: [{value, N}] . Example: [{value, 256}] gauge It is similiar to a value type but consists of two properties: value ms_since_reset - Time in milliseconds elapsed from the last metric update. Example: [{value, 12}, {ms_since_reset, 91761}] proplist A metric which is a nonstandard proplist. You can find the lists of keys in metrics descriptions. Example: [{total,295941736}, {processes_used,263766824}, {atom_used,640435}, {binary,1513152}, {ets,3942592}, {system,32182072}] histogram A histogram collects values over a sliding window of 60s and exposes the following stats: n - A number of samples. mean - An arithmetic mean. min max median 50 , 75 , 90 , 95 , 99 , 999 - 50th, 75th, 90th, 95th, 99th and 99.9th percentile Per host metrics Hook metrics There are more hook metrics than what is listed in this table, because they are automatically created for every new hook. As a result it makes more sense to maintain a list of the most relevant or useful items, rather than keeping this table fully in sync with the code. Name Type Description (when it gets incremented) [Host, anonymous_purge_hook] spiral An anonymous user disconnects. [Host, c2s_unauthenticated_iq] spiral An IQ sent from a user to a server without authentication. [Host, disco_info] spiral An information about the server has been requested via Disco protocol. [Host, disco_local_features] spiral A list of server features is gathered. [Host, disco_local_identity] spiral A list of server identities is gathered. [Host, disco_local_items] spiral A list of server's items (e.g. services) is gathered. [Host, disco_sm_features] spiral A list of user's features is gathered. [Host, disco_sm_identity] spiral A list of user's identities is gathered. [Host, disco_sm_items] spiral A list of user's items is gathered. [Host, mam_lookup_messages] spiral An archive lookup is performed. [Host, offline_message_hook] spiral A message was sent to an offline user. (Except for \"error\", \"headline\" and \"groupchat\" message types.) [Host, offline_groupchat_message_hook] spiral A groupchat message was sent to an offline user. [Host, privacy_updated_list] spiral User's privacy list is updated. [Host, resend_offline_messages_hook] spiral A list of offline messages is gathered for delivery to a user's new connection. [Host, roster_get_subscription_lists] spiral Presence subscription lists (based on which presence updates are broadcasted) are gathered. [Host, roster_in_subscription] spiral A presence with subscription update is processed. [Host, roster_out_subscription] spiral A presence with subscription update is received from a client. [Host, sm_broadcast] spiral A stanza is broadcasted to all of user's resources. [Host, unset_presence_hook] spiral A user disconnects or sends an unavailable presence. Presences & rosters Name Type Description (when it gets incremented) [Host, modPresenceSubscriptions] spiral Presence subscription is processed. [Host, modPresenceUnsubscriptions] spiral Presence unsubscription is processed. [Host, modRosterGets] spiral User's roster is fetched. [Host, modRosterPush] spiral A roster update is pushed to a single session. [Host, modRosterSets] spiral User's roster is updated. Privacy lists Name Type Description (when it gets incremented) [Host, modPrivacyGets] spiral IQ privacy get is processed. [Host, modPrivacyPush] spiral Privacy list update is sent to a single session. [Host, modPrivacySets] spiral IQ privacy set is processed. [Host, modPrivacySetsActive] spiral Active privacy list is changed. [Host, modPrivacySetsDefault] spiral Default privacy list is changed. [Host, modPrivacyStanzaAll] spiral A packet is checked against the privacy list. [Host, modPrivacyStanzaDenied] spiral Privacy list check resulted in deny . [Host, modPrivacyStanzaBlocked] spiral Privacy list check resulted in block . Other Name Type Description (when it gets incremented) [Host, sessionAuthAnonymous] spiral A client authenticates anonymously. [Host, sessionAuthFails] spiral A client failed to authenticate. [Host, sessionCount] counter Number of active sessions. [Host, sessionLogouts] spiral A client session is closed. [Host, sessionSuccessfulLogins] spiral A client session is opened. [Host, xmppErrorIq] spiral An error IQ is sent to a client. [Host, xmppErrorMessage] spiral An error message is sent to a client. [Host, xmppErrorPresence] spiral An error presence is sent to a client. [Host, xmppErrorTotal] spiral A stanza with error type is routed. [Host, xmppMessageBounced] spiral A service-unavailable error is sent, because the message recipient if offline. [Host, xmppIqSent] spiral An IQ is sent by a client. [Host, xmppMessageSent] spiral A message is sent by a client [Host, xmppPresenceSent] spiral A presence is sent by a client. [Host, xmppStanzaSent] spiral A stanza is sent by a client. [Host, xmppIqReceived] spiral An IQ is sent to a client. [Host, xmppMessageReceived] spiral A message is sent to a client. [Host, xmppPresenceReceived] spiral A presence is sent to a client. [Host, xmppStanzaReceived] spiral A stanza is sent to a client. [Host, xmppStanzaCount] spiral A stanza is sent to a client. [Host, xmppStanzaDropped] spiral A stanza is dropped due to an AMP rule or a filter_packet processing flow. Extension-specific metrics Metrics specific to an extension, e.g. Message Archive Management, are described in respective module documentation pages. Global metrics Name Type Description (when it gets incremented) [global, routingErrors] spiral It is not possible to route a stanza (all routing handlers failed). [global, nodeSessionCount] value A number of sessions connected to a given MongooseIM node. [global, totalSessionCount] value A number of sessions connected to a MongooseIM cluster. [global, uniqueSessionCount] value A number of unique users connected to a MongooseIM cluster (e.g. 3 sessions of the same user will be counted as 1 in this metric). [global, cache, unique_sessions_number] gauge A cached value of uniqueSessionCount . It is automatically updated when a unique session count is calculated. [global, nodeUpTime] value Node uptime. [global, clusterSize] value A number of nodes in a MongooseIM cluster seen by a given MongooseIM node. [global, tcpPortsUsed] value A number of open tcp connections. This should relate to the number of connected sessions and databases, as well as federations and http requests, in order to detect connection leaks. [global, processQueueLengths] probe The number of queued messages in the internal message queue of every erlang process, and the internal queue of every fsm (ejabberd_c2s). This is sampled every 30 seconds asynchronously. It is a good indicator of an overloaded system: if too many messages are queued at the same time, the system is not able to process the data at the rate it was designed for. Data metrics Metric name Type Description [global, data, xmpp, received, xml_stanza_size] histogram A size (in bytes) of a received stanza after decompression and decryption. [global, data, xmpp, sent, xml_stanza_size] histogram A size (in bytes) of a stanza sent to a client socket. [global, data, xmpp, received, compressed_size] histogram A size (in bytes) of a received stanza before decompression. [global, data, xmpp, sent, compressed_size] histogram A size (in bytes) of a stanza after compression. [global, data, xmpp, received, encrypted_size] histogram A size (in bytes) of a received stanza before decryption. [global, data, xmpp, sent, encrypted_size] histogram A size (in bytes) of a stanza after encryption. [global, data, dist] proplist Network stats for an Erlang distributed communication. A proplist with values: recv_oct , recv_cnt , recv_max , send_oct , send_max , send_cnt , send_pend , connections [global, data, rdbms, PoolName] proplist For every RDBMS pool defined, an instance of this metric is available. It is a proplist with values workers , recv_oct , recv_cnt , recv_max , send_oct , send_max , send_cnt , send_pend . VM metrics Metric name Type Description [global, erlang, memory] proplist A proplist with total , processes_used , atom_used , binary , ets and system memory stats. [global, erlang, system_info] proplist A proplist with port_count , port_limit , process_count , process_limit , ets_limit stats. Backend metrics Some extension modules expose histograms with timings of calls made to their backends. Please check the documentation of modules that are enabled in your config file, in order to learn if they provide them. All module backend metrics names use the following convention: [global, backends, Module, BackendAction] and [global, backends, Module, BackendAction, count] . The former is a histogram of operation times. However, the time is not recorded if a backend operation exits with an exception. The latter is a number of calls (spiral metric), incremented for every call (even a failed one). Besides these, following authentication metrics are always available: [Host, backends, auth, authorize] [Host, backends, auth, check_password] [Host, backends, auth, try_register] [Host, backends, auth, does_user_exist] These are total times of respective operations. One operation usually requires only a single call to an auth backend but sometimes with e.g. 3 backends configured, the operation may fail for first 2 backends. In such case, these metrics will be updated with combined time of 2 failed and 1 successful request. Additionaly, RDBMS layer in MongooseIM exposes two more metrics, if RDBMS is configured: [global, backends, mongoose_rdbms, query] - Execution time of a \"simple\"\" (not prepared) query by a DB driver. [global, backends, mongoose_rdbms, execute] - Execution time of a prepared query by a DB driver.","title":"Metrics"},{"location":"operation-and-maintenance/Mongoose-metrics/#mongooseim-metrics","text":"MongooseIM by default collects many metrics showing the user behaviour and general system statistics. They are managed by exometer . MongooseIM uses ESL's fork of this project . All metrics are divided into the following groups: Per host metrics: Gathered separately for every XMPP host supported by the cluster. Warning: If a cluster supports many (thousands or more) domains, performance issues might occur. To avoid this, use global equivalents of the metrics with all_metrics_are_global config option. Hook metrics. They are created for every hook and incremented on every call to it. Global metrics: Metrics common for all XMPP hosts. Data metrics. These are misc. metrics related to data transfers (e.g. sent and received stanza size statistics). VM metrics. Basic Erlang VM statistics. Backend metrics: Histograms with timings of calls to various backends.","title":"MongooseIM metrics"},{"location":"operation-and-maintenance/Mongoose-metrics/#metrics-types","text":"","title":"Metrics types"},{"location":"operation-and-maintenance/Mongoose-metrics/#spiral","text":"This kind of metric provides 2 values: total event count (e.g. stanzas processed) and a value in 60s window ( one value). Dividing one value by 60 provides an average per-second value over last minute. Example: [{total, 1000}, {one, 20}]","title":"spiral"},{"location":"operation-and-maintenance/Mongoose-metrics/#value","text":"A simple value. It is actually a one-element proplist: [{value, N}] . Example: [{value, 256}]","title":"value"},{"location":"operation-and-maintenance/Mongoose-metrics/#gauge","text":"It is similiar to a value type but consists of two properties: value ms_since_reset - Time in milliseconds elapsed from the last metric update. Example: [{value, 12}, {ms_since_reset, 91761}]","title":"gauge"},{"location":"operation-and-maintenance/Mongoose-metrics/#proplist","text":"A metric which is a nonstandard proplist. You can find the lists of keys in metrics descriptions. Example: [{total,295941736}, {processes_used,263766824}, {atom_used,640435}, {binary,1513152}, {ets,3942592}, {system,32182072}]","title":"proplist"},{"location":"operation-and-maintenance/Mongoose-metrics/#histogram","text":"A histogram collects values over a sliding window of 60s and exposes the following stats: n - A number of samples. mean - An arithmetic mean. min max median 50 , 75 , 90 , 95 , 99 , 999 - 50th, 75th, 90th, 95th, 99th and 99.9th percentile","title":"histogram"},{"location":"operation-and-maintenance/Mongoose-metrics/#per-host-metrics","text":"","title":"Per host metrics"},{"location":"operation-and-maintenance/Mongoose-metrics/#hook-metrics","text":"There are more hook metrics than what is listed in this table, because they are automatically created for every new hook. As a result it makes more sense to maintain a list of the most relevant or useful items, rather than keeping this table fully in sync with the code. Name Type Description (when it gets incremented) [Host, anonymous_purge_hook] spiral An anonymous user disconnects. [Host, c2s_unauthenticated_iq] spiral An IQ sent from a user to a server without authentication. [Host, disco_info] spiral An information about the server has been requested via Disco protocol. [Host, disco_local_features] spiral A list of server features is gathered. [Host, disco_local_identity] spiral A list of server identities is gathered. [Host, disco_local_items] spiral A list of server's items (e.g. services) is gathered. [Host, disco_sm_features] spiral A list of user's features is gathered. [Host, disco_sm_identity] spiral A list of user's identities is gathered. [Host, disco_sm_items] spiral A list of user's items is gathered. [Host, mam_lookup_messages] spiral An archive lookup is performed. [Host, offline_message_hook] spiral A message was sent to an offline user. (Except for \"error\", \"headline\" and \"groupchat\" message types.) [Host, offline_groupchat_message_hook] spiral A groupchat message was sent to an offline user. [Host, privacy_updated_list] spiral User's privacy list is updated. [Host, resend_offline_messages_hook] spiral A list of offline messages is gathered for delivery to a user's new connection. [Host, roster_get_subscription_lists] spiral Presence subscription lists (based on which presence updates are broadcasted) are gathered. [Host, roster_in_subscription] spiral A presence with subscription update is processed. [Host, roster_out_subscription] spiral A presence with subscription update is received from a client. [Host, sm_broadcast] spiral A stanza is broadcasted to all of user's resources. [Host, unset_presence_hook] spiral A user disconnects or sends an unavailable presence.","title":"Hook metrics"},{"location":"operation-and-maintenance/Mongoose-metrics/#presences-rosters","text":"Name Type Description (when it gets incremented) [Host, modPresenceSubscriptions] spiral Presence subscription is processed. [Host, modPresenceUnsubscriptions] spiral Presence unsubscription is processed. [Host, modRosterGets] spiral User's roster is fetched. [Host, modRosterPush] spiral A roster update is pushed to a single session. [Host, modRosterSets] spiral User's roster is updated.","title":"Presences &amp; rosters"},{"location":"operation-and-maintenance/Mongoose-metrics/#privacy-lists","text":"Name Type Description (when it gets incremented) [Host, modPrivacyGets] spiral IQ privacy get is processed. [Host, modPrivacyPush] spiral Privacy list update is sent to a single session. [Host, modPrivacySets] spiral IQ privacy set is processed. [Host, modPrivacySetsActive] spiral Active privacy list is changed. [Host, modPrivacySetsDefault] spiral Default privacy list is changed. [Host, modPrivacyStanzaAll] spiral A packet is checked against the privacy list. [Host, modPrivacyStanzaDenied] spiral Privacy list check resulted in deny . [Host, modPrivacyStanzaBlocked] spiral Privacy list check resulted in block .","title":"Privacy lists"},{"location":"operation-and-maintenance/Mongoose-metrics/#other","text":"Name Type Description (when it gets incremented) [Host, sessionAuthAnonymous] spiral A client authenticates anonymously. [Host, sessionAuthFails] spiral A client failed to authenticate. [Host, sessionCount] counter Number of active sessions. [Host, sessionLogouts] spiral A client session is closed. [Host, sessionSuccessfulLogins] spiral A client session is opened. [Host, xmppErrorIq] spiral An error IQ is sent to a client. [Host, xmppErrorMessage] spiral An error message is sent to a client. [Host, xmppErrorPresence] spiral An error presence is sent to a client. [Host, xmppErrorTotal] spiral A stanza with error type is routed. [Host, xmppMessageBounced] spiral A service-unavailable error is sent, because the message recipient if offline. [Host, xmppIqSent] spiral An IQ is sent by a client. [Host, xmppMessageSent] spiral A message is sent by a client [Host, xmppPresenceSent] spiral A presence is sent by a client. [Host, xmppStanzaSent] spiral A stanza is sent by a client. [Host, xmppIqReceived] spiral An IQ is sent to a client. [Host, xmppMessageReceived] spiral A message is sent to a client. [Host, xmppPresenceReceived] spiral A presence is sent to a client. [Host, xmppStanzaReceived] spiral A stanza is sent to a client. [Host, xmppStanzaCount] spiral A stanza is sent to a client. [Host, xmppStanzaDropped] spiral A stanza is dropped due to an AMP rule or a filter_packet processing flow.","title":"Other"},{"location":"operation-and-maintenance/Mongoose-metrics/#extension-specific-metrics","text":"Metrics specific to an extension, e.g. Message Archive Management, are described in respective module documentation pages.","title":"Extension-specific metrics"},{"location":"operation-and-maintenance/Mongoose-metrics/#global-metrics","text":"Name Type Description (when it gets incremented) [global, routingErrors] spiral It is not possible to route a stanza (all routing handlers failed). [global, nodeSessionCount] value A number of sessions connected to a given MongooseIM node. [global, totalSessionCount] value A number of sessions connected to a MongooseIM cluster. [global, uniqueSessionCount] value A number of unique users connected to a MongooseIM cluster (e.g. 3 sessions of the same user will be counted as 1 in this metric). [global, cache, unique_sessions_number] gauge A cached value of uniqueSessionCount . It is automatically updated when a unique session count is calculated. [global, nodeUpTime] value Node uptime. [global, clusterSize] value A number of nodes in a MongooseIM cluster seen by a given MongooseIM node. [global, tcpPortsUsed] value A number of open tcp connections. This should relate to the number of connected sessions and databases, as well as federations and http requests, in order to detect connection leaks. [global, processQueueLengths] probe The number of queued messages in the internal message queue of every erlang process, and the internal queue of every fsm (ejabberd_c2s). This is sampled every 30 seconds asynchronously. It is a good indicator of an overloaded system: if too many messages are queued at the same time, the system is not able to process the data at the rate it was designed for.","title":"Global metrics"},{"location":"operation-and-maintenance/Mongoose-metrics/#data-metrics","text":"Metric name Type Description [global, data, xmpp, received, xml_stanza_size] histogram A size (in bytes) of a received stanza after decompression and decryption. [global, data, xmpp, sent, xml_stanza_size] histogram A size (in bytes) of a stanza sent to a client socket. [global, data, xmpp, received, compressed_size] histogram A size (in bytes) of a received stanza before decompression. [global, data, xmpp, sent, compressed_size] histogram A size (in bytes) of a stanza after compression. [global, data, xmpp, received, encrypted_size] histogram A size (in bytes) of a received stanza before decryption. [global, data, xmpp, sent, encrypted_size] histogram A size (in bytes) of a stanza after encryption. [global, data, dist] proplist Network stats for an Erlang distributed communication. A proplist with values: recv_oct , recv_cnt , recv_max , send_oct , send_max , send_cnt , send_pend , connections [global, data, rdbms, PoolName] proplist For every RDBMS pool defined, an instance of this metric is available. It is a proplist with values workers , recv_oct , recv_cnt , recv_max , send_oct , send_max , send_cnt , send_pend .","title":"Data metrics"},{"location":"operation-and-maintenance/Mongoose-metrics/#vm-metrics","text":"Metric name Type Description [global, erlang, memory] proplist A proplist with total , processes_used , atom_used , binary , ets and system memory stats. [global, erlang, system_info] proplist A proplist with port_count , port_limit , process_count , process_limit , ets_limit stats.","title":"VM metrics"},{"location":"operation-and-maintenance/Mongoose-metrics/#backend-metrics","text":"Some extension modules expose histograms with timings of calls made to their backends. Please check the documentation of modules that are enabled in your config file, in order to learn if they provide them. All module backend metrics names use the following convention: [global, backends, Module, BackendAction] and [global, backends, Module, BackendAction, count] . The former is a histogram of operation times. However, the time is not recorded if a backend operation exits with an exception. The latter is a number of calls (spiral metric), incremented for every call (even a failed one). Besides these, following authentication metrics are always available: [Host, backends, auth, authorize] [Host, backends, auth, check_password] [Host, backends, auth, try_register] [Host, backends, auth, does_user_exist] These are total times of respective operations. One operation usually requires only a single call to an auth backend but sometimes with e.g. 3 backends configured, the operation may fail for first 2 backends. In such case, these metrics will be updated with combined time of 2 failed and 1 successful request. Additionaly, RDBMS layer in MongooseIM exposes two more metrics, if RDBMS is configured: [global, backends, mongoose_rdbms, query] - Execution time of a \"simple\"\" (not prepared) query by a DB driver. [global, backends, mongoose_rdbms, execute] - Execution time of a prepared query by a DB driver.","title":"Backend metrics"},{"location":"operation-and-maintenance/Reloading-configuration-on-a-running-system/","text":"Reloading configuration on a running system mongooseimctl subcommands for configuration reloading are: mongooseimctl reload_local mongooseimctl reload_cluster mongooseimctl reload_cluster_dryrun reload_local is unsafe as it reloads the configuration only on the local node. This might introduce inconsistencies between different nodes in the cluster. It's available as a safety mechanism for the rare case of a cluster-global reload failing. reload_cluster applies the configuration on all nodes in the cluster. The prerequisite is that the same version of a config file must be available on all nodes. All nodes in a cluster must have the same config loaded into memory as well. There is a small exception from this rule, see \"Node-specific options\" below on this page. reload_cluster_dryrun calculates and prints config changes, but does not apply them. Useful for debugging. Non-reloadable options Some options require restarting the server in order to be reloaded. The following options' changes will be ignored when using mongooseimctl tool: * domain_certfile * s2s_ * all_metrics_are_global * rdbms_ Node-specific options Usually all nodes in cluster share the same configuration. But sometimes we want different configs for each node in a cluster. By default in such cases reload_cluster would detect a configuration inconsistency and would not allow configuration updates. To tell reload_cluster to ignore such options, extra information should be provided in mongooseim.cfg . It's called node_specific_options . They are defined on top level of the configuration file using node_specific_options tuple. This tuple should be the same for all configs in a cluster. node_specific_options contains a list of match patterns. If you are familiar with ETS tables or Mnesia tuple matching - it's the same thing. Match patterns are documented in Erlang/OTP docs . The pattern mechanism is also documented in Learn you some Erlang book . Basically, it allows you to put '_' to match every possible host. [h,'_',module_opt,mod_muc_log, outdir] would match [h,<<\"localhost\">>,module_opt,mod_muc_log, outdir] and [h,<<\"any.other.host\">>,module_opt,mod_muc_log, outdir] . Example showing where to put node_specific_options . {hosts, [\"localhost\"]}. {node_specific_options, [ [h,'_',module_opt,mod_muc_log, outdir] ]}. {modules, [....]}. The node_specific_options patterns are matched against flat configuration options. To print your config in a flat form, use the command with a running node mongooseimctl print_flat_config . Example: _build/mim1/rel/mongooseim/bin/mongooseimctl print_flat_config Flat options: {[l,listen],'FLAT'}. {[l,listener,{5280,{0,0,0,0},tcp},ejabberd_cowboy],'FLAT'}. {[l,listener_opt,{5280,{0,0,0,0},tcp},ejabberd_cowboy,num_acceptors],10}. {[l,listener_opt,{5280,{0,0,0,0},tcp},ejabberd_cowboy,transport_options], [{max_connections,1024}]}. ... {[h,<<\"anonymous.localhost\">>,auth_method],anonymous}. {[h,<<\"localhost.bis\">>,modules],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_carboncopy],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_stream_management],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_muc_commands],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_amp],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_offline],'FLAT'}. {[h,<<\"localhost.bis\">>,module_opt,mod_offline,access_max_user_messages], max_user_offline_messages}. ... More information about flat options format Node-specific options for Global Distribution Node-specific options mechanism was designed to allow mod_global_distrib to be configured with different parameters for each node. Real life configuration example: {node_specific_options, [ [h,'_',module_opt,mod_global_distrib,endpoints], [h,'_',module_opt,mod_global_distrib,advertised_endpoints], [h,'_',module_subopt,mod_global_distrib,connections,endpoints], [h,'_',module_subopt,mod_global_distrib,connections,advertised_endpoints], [h,'_',module_subopt,mod_global_distrib,redis,server], [h,'_',module_subopt,mod_global_distrib_bounce,connections,advertised_endpoints], [h,'_',module_subopt,mod_global_distrib_bounce,connections,advertised_endpoints,'_'], [h,'_',module_subopt,mod_global_distrib_bounce,connections,endpoints], [h,'_',module_subopt,mod_global_distrib_bounce,connections,endpoints,'_'], [h,'_',module_subopt,mod_global_distrib_disco,connections,advertised_endpoints], [h,'_',module_subopt,mod_global_distrib_disco,connections,advertised_endpoints,'_'], [h,'_',module_subopt,mod_global_distrib_hosts_refresher,connections,advertised_endpoints], [h,'_',module_subopt,mod_global_distrib_hosts_refresher,connections,advertised_endpoints,'_'], [h,'_',module_subopt,mod_global_distrib_hosts_refresher,connections,endpoints], [h,'_',module_subopt,mod_global_distrib_hosts_refresher,connections,endpoints,'_'], [h,'_',module_subopt,mod_global_distrib_hosts_refresher,redis,server], [h,'_',module_subopt,mod_global_distrib_mapping,connections,advertised_endpoints], [h,'_',module_subopt,mod_global_distrib_mapping,connections,advertised_endpoints,'_'], [h,'_',module_subopt,mod_global_distrib_mapping,connections,endpoints], [h,'_',module_subopt,mod_global_distrib_mapping,connections,endpoints,'_'], [h,'_',module_subopt,mod_global_distrib_mapping,redis,server], [h,'_',module_subopt,mod_global_distrib_receiver,advertised_endpoints], [h,'_',module_subopt,mod_global_distrib_receiver,advertised_endpoints,'_'], [h,'_',module_subopt,mod_global_distrib_receiver,connections,advertised_endpoints], [h,'_',module_subopt,mod_global_distrib_receiver,connections,advertised_endpoints,'_'], [h,'_',module_subopt,mod_global_distrib_receiver,connections,endpoints], [h,'_',module_subopt,mod_global_distrib_receiver,connections,endpoints,'_'], [h,'_',module_subopt,mod_global_distrib_receiver,endpoints], [h,'_',module_subopt,mod_global_distrib_receiver,endpoints,'_'], [h,'_',module_subopt,mod_global_distrib_receiver,redis,server], [h,'_',module_subopt,mod_global_distrib_sender,advertised_endpoints], [h,'_',module_subopt,mod_global_distrib_sender,advertised_endpoints,'_'], [h,'_',module_subopt,mod_global_distrib_sender,connections,advertised_endpoints], [h,'_',module_subopt,mod_global_distrib_sender,connections,advertised_endpoints,'_'], [h,'_',module_subopt,mod_global_distrib_sender,connections,endpoints], [h,'_',module_subopt,mod_global_distrib_sender,connections,endpoints,'_'], [h,'_',module_subopt,mod_global_distrib_sender,endpoints], [h,'_',module_subopt,mod_global_distrib_sender,endpoints,'_'], [h,'_',module_subopt,mod_global_distrib_sender,redis,server] ]}. '_' means that any value can be there. Usually, all modules are configured using just one level of option nesting. module_subopt means that we are interested in a nested option. node_specific_options can be used with any module, not just mod_global_distrib (but usually you want all options to be the same on all nodes!). Any flat option can be used in node_specific_options . Node-specific modules We don't compare options of node-specific modules for configuration consistency check. We also don't check, if all nodes run these modules (it's fine to run them only on some nodes in a cluster). {node_specific_options, [ [h,'_',module,mod_global_distrib] ]}.","title":"Reloading configuration on a running system"},{"location":"operation-and-maintenance/Reloading-configuration-on-a-running-system/#reloading-configuration-on-a-running-system","text":"mongooseimctl subcommands for configuration reloading are: mongooseimctl reload_local mongooseimctl reload_cluster mongooseimctl reload_cluster_dryrun reload_local is unsafe as it reloads the configuration only on the local node. This might introduce inconsistencies between different nodes in the cluster. It's available as a safety mechanism for the rare case of a cluster-global reload failing. reload_cluster applies the configuration on all nodes in the cluster. The prerequisite is that the same version of a config file must be available on all nodes. All nodes in a cluster must have the same config loaded into memory as well. There is a small exception from this rule, see \"Node-specific options\" below on this page. reload_cluster_dryrun calculates and prints config changes, but does not apply them. Useful for debugging.","title":"Reloading configuration on a running system"},{"location":"operation-and-maintenance/Reloading-configuration-on-a-running-system/#non-reloadable-options","text":"Some options require restarting the server in order to be reloaded. The following options' changes will be ignored when using mongooseimctl tool: * domain_certfile * s2s_ * all_metrics_are_global * rdbms_","title":"Non-reloadable options"},{"location":"operation-and-maintenance/Reloading-configuration-on-a-running-system/#node-specific-options","text":"Usually all nodes in cluster share the same configuration. But sometimes we want different configs for each node in a cluster. By default in such cases reload_cluster would detect a configuration inconsistency and would not allow configuration updates. To tell reload_cluster to ignore such options, extra information should be provided in mongooseim.cfg . It's called node_specific_options . They are defined on top level of the configuration file using node_specific_options tuple. This tuple should be the same for all configs in a cluster. node_specific_options contains a list of match patterns. If you are familiar with ETS tables or Mnesia tuple matching - it's the same thing. Match patterns are documented in Erlang/OTP docs . The pattern mechanism is also documented in Learn you some Erlang book . Basically, it allows you to put '_' to match every possible host. [h,'_',module_opt,mod_muc_log, outdir] would match [h,<<\"localhost\">>,module_opt,mod_muc_log, outdir] and [h,<<\"any.other.host\">>,module_opt,mod_muc_log, outdir] . Example showing where to put node_specific_options . {hosts, [\"localhost\"]}. {node_specific_options, [ [h,'_',module_opt,mod_muc_log, outdir] ]}. {modules, [....]}. The node_specific_options patterns are matched against flat configuration options. To print your config in a flat form, use the command with a running node mongooseimctl print_flat_config . Example: _build/mim1/rel/mongooseim/bin/mongooseimctl print_flat_config Flat options: {[l,listen],'FLAT'}. {[l,listener,{5280,{0,0,0,0},tcp},ejabberd_cowboy],'FLAT'}. {[l,listener_opt,{5280,{0,0,0,0},tcp},ejabberd_cowboy,num_acceptors],10}. {[l,listener_opt,{5280,{0,0,0,0},tcp},ejabberd_cowboy,transport_options], [{max_connections,1024}]}. ... {[h,<<\"anonymous.localhost\">>,auth_method],anonymous}. {[h,<<\"localhost.bis\">>,modules],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_carboncopy],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_stream_management],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_muc_commands],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_amp],'FLAT'}. {[h,<<\"localhost.bis\">>,module,mod_offline],'FLAT'}. {[h,<<\"localhost.bis\">>,module_opt,mod_offline,access_max_user_messages], max_user_offline_messages}. ... More information about flat options format","title":"Node-specific options"},{"location":"operation-and-maintenance/Reloading-configuration-on-a-running-system/#node-specific-options-for-global-distribution","text":"Node-specific options mechanism was designed to allow mod_global_distrib to be configured with different parameters for each node. Real life configuration example: {node_specific_options, [ [h,'_',module_opt,mod_global_distrib,endpoints], [h,'_',module_opt,mod_global_distrib,advertised_endpoints], [h,'_',module_subopt,mod_global_distrib,connections,endpoints], [h,'_',module_subopt,mod_global_distrib,connections,advertised_endpoints], [h,'_',module_subopt,mod_global_distrib,redis,server], [h,'_',module_subopt,mod_global_distrib_bounce,connections,advertised_endpoints], [h,'_',module_subopt,mod_global_distrib_bounce,connections,advertised_endpoints,'_'], [h,'_',module_subopt,mod_global_distrib_bounce,connections,endpoints], [h,'_',module_subopt,mod_global_distrib_bounce,connections,endpoints,'_'], [h,'_',module_subopt,mod_global_distrib_disco,connections,advertised_endpoints], [h,'_',module_subopt,mod_global_distrib_disco,connections,advertised_endpoints,'_'], [h,'_',module_subopt,mod_global_distrib_hosts_refresher,connections,advertised_endpoints], [h,'_',module_subopt,mod_global_distrib_hosts_refresher,connections,advertised_endpoints,'_'], [h,'_',module_subopt,mod_global_distrib_hosts_refresher,connections,endpoints], [h,'_',module_subopt,mod_global_distrib_hosts_refresher,connections,endpoints,'_'], [h,'_',module_subopt,mod_global_distrib_hosts_refresher,redis,server], [h,'_',module_subopt,mod_global_distrib_mapping,connections,advertised_endpoints], [h,'_',module_subopt,mod_global_distrib_mapping,connections,advertised_endpoints,'_'], [h,'_',module_subopt,mod_global_distrib_mapping,connections,endpoints], [h,'_',module_subopt,mod_global_distrib_mapping,connections,endpoints,'_'], [h,'_',module_subopt,mod_global_distrib_mapping,redis,server], [h,'_',module_subopt,mod_global_distrib_receiver,advertised_endpoints], [h,'_',module_subopt,mod_global_distrib_receiver,advertised_endpoints,'_'], [h,'_',module_subopt,mod_global_distrib_receiver,connections,advertised_endpoints], [h,'_',module_subopt,mod_global_distrib_receiver,connections,advertised_endpoints,'_'], [h,'_',module_subopt,mod_global_distrib_receiver,connections,endpoints], [h,'_',module_subopt,mod_global_distrib_receiver,connections,endpoints,'_'], [h,'_',module_subopt,mod_global_distrib_receiver,endpoints], [h,'_',module_subopt,mod_global_distrib_receiver,endpoints,'_'], [h,'_',module_subopt,mod_global_distrib_receiver,redis,server], [h,'_',module_subopt,mod_global_distrib_sender,advertised_endpoints], [h,'_',module_subopt,mod_global_distrib_sender,advertised_endpoints,'_'], [h,'_',module_subopt,mod_global_distrib_sender,connections,advertised_endpoints], [h,'_',module_subopt,mod_global_distrib_sender,connections,advertised_endpoints,'_'], [h,'_',module_subopt,mod_global_distrib_sender,connections,endpoints], [h,'_',module_subopt,mod_global_distrib_sender,connections,endpoints,'_'], [h,'_',module_subopt,mod_global_distrib_sender,endpoints], [h,'_',module_subopt,mod_global_distrib_sender,endpoints,'_'], [h,'_',module_subopt,mod_global_distrib_sender,redis,server] ]}. '_' means that any value can be there. Usually, all modules are configured using just one level of option nesting. module_subopt means that we are interested in a nested option. node_specific_options can be used with any module, not just mod_global_distrib (but usually you want all options to be the same on all nodes!). Any flat option can be used in node_specific_options .","title":"Node-specific options for Global Distribution"},{"location":"operation-and-maintenance/Reloading-configuration-on-a-running-system/#node-specific-modules","text":"We don't compare options of node-specific modules for configuration consistency check. We also don't check, if all nodes run these modules (it's fine to run them only on some nodes in a cluster). {node_specific_options, [ [h,'_',module,mod_global_distrib] ]}.","title":"Node-specific modules"},{"location":"operation-and-maintenance/gdpr-considerations/","text":"GDPR considerations This page describes what GDPR implies in terms of server management. Data affected by GDPR commands inbox - All entries in the subject's inbox. If their messages are stored in other users' inbox, they will not be removed. message archive - Same as above for 1-1 messages. In case of group chat messages, they are retrieved as personal data but not removed. offline storage - All messages stored for delivery. roster - All entries in the subject's roster. Other users' rosters are NOT affected, even if they include the subject's JID or other data. vCard - The entire content of the subject's vCard. private XML storage - All items stored by the subject will be removed. publish-subscribe retrieval: all subject's subscriptions and nodes (with their payloads included). removal: subject's subscriptions, push and PEP nodes (with their data included). GDPR CLI commands All CLI commands are accessible via mongooseimctl command, located in bin/ inside MIM release. Personal data retrieval requires service_admin_extra with gdpr group enabled. Creating a GDPR-safe user account mongooseimctl register <domain> <password> This command will create an anonymised JID with a random username part. It ensures that no personal information will be leaked via logs or database entries, which include the user's JID. Example $ mongooseimctl register localhost abc123 User 1567-420657-155810-C1CEC31F5C993258@localhost successfully registered Retrieval of Personal Data mongooseimctl retrieve_personal_data <username> <domain> <filepath for the output as a zip> It retrieves personal data accessible to the server (see \"Technical limitations\" section below). The directory where the zip file will be created must already exist. After the execution is complete, a zip file will appear in the specified folder with personal information in CSV files grouped by type. Example mongooseimctl retrieve_personal_data 1567-420657-155810-C1CEC31F5C993258 localhost /home/mongooseim/gdpr/1567-420657-155810-C1CEC31F5C993258.zip Removal of Personal Data mongooseimctl unregister <username> <domain> It removes the user's account along with all associated personal data accessible to the server (see \"Technical limitations\" section below). Example mongooseimctl unregister 1567-420657-155810-C1CEC31F5C993258 localhost Technical limitations of GDPR retrieval and removal Both GDPR retrieval and removal will process the data available via configured extensions and database(s). If a part of personal information is managed by an extension that is e.g. temporarily disabled, it won't be retrieved/deleted. If any MIM extension you had enabled on production is now disabled or you've switched one of them (or e.g. auth module) to another database, it is possible that some personal data will not be retrieved or removed as expected. In such case, please consider starting a separate MIM instance that is configured to access all places, where personal data may be stored. You may also extract the missing pieces of information on your own, however we won't cover the details of this method in this guide. Please also visit Known issues page to learn about a mod_mam_muc issue that may manifest in some environments.","title":"GDPR considerations"},{"location":"operation-and-maintenance/gdpr-considerations/#gdpr-considerations","text":"This page describes what GDPR implies in terms of server management.","title":"GDPR considerations"},{"location":"operation-and-maintenance/gdpr-considerations/#data-affected-by-gdpr-commands","text":"inbox - All entries in the subject's inbox. If their messages are stored in other users' inbox, they will not be removed. message archive - Same as above for 1-1 messages. In case of group chat messages, they are retrieved as personal data but not removed. offline storage - All messages stored for delivery. roster - All entries in the subject's roster. Other users' rosters are NOT affected, even if they include the subject's JID or other data. vCard - The entire content of the subject's vCard. private XML storage - All items stored by the subject will be removed. publish-subscribe retrieval: all subject's subscriptions and nodes (with their payloads included). removal: subject's subscriptions, push and PEP nodes (with their data included).","title":"Data affected by GDPR commands"},{"location":"operation-and-maintenance/gdpr-considerations/#gdpr-cli-commands","text":"All CLI commands are accessible via mongooseimctl command, located in bin/ inside MIM release. Personal data retrieval requires service_admin_extra with gdpr group enabled.","title":"GDPR CLI commands"},{"location":"operation-and-maintenance/gdpr-considerations/#creating-a-gdpr-safe-user-account","text":"mongooseimctl register <domain> <password> This command will create an anonymised JID with a random username part. It ensures that no personal information will be leaked via logs or database entries, which include the user's JID.","title":"Creating a GDPR-safe user account"},{"location":"operation-and-maintenance/gdpr-considerations/#example","text":"$ mongooseimctl register localhost abc123 User 1567-420657-155810-C1CEC31F5C993258@localhost successfully registered","title":"Example"},{"location":"operation-and-maintenance/gdpr-considerations/#retrieval-of-personal-data","text":"mongooseimctl retrieve_personal_data <username> <domain> <filepath for the output as a zip> It retrieves personal data accessible to the server (see \"Technical limitations\" section below). The directory where the zip file will be created must already exist. After the execution is complete, a zip file will appear in the specified folder with personal information in CSV files grouped by type.","title":"Retrieval of Personal Data"},{"location":"operation-and-maintenance/gdpr-considerations/#example_1","text":"mongooseimctl retrieve_personal_data 1567-420657-155810-C1CEC31F5C993258 localhost /home/mongooseim/gdpr/1567-420657-155810-C1CEC31F5C993258.zip","title":"Example"},{"location":"operation-and-maintenance/gdpr-considerations/#removal-of-personal-data","text":"mongooseimctl unregister <username> <domain> It removes the user's account along with all associated personal data accessible to the server (see \"Technical limitations\" section below).","title":"Removal of Personal Data"},{"location":"operation-and-maintenance/gdpr-considerations/#example_2","text":"mongooseimctl unregister 1567-420657-155810-C1CEC31F5C993258 localhost","title":"Example"},{"location":"operation-and-maintenance/gdpr-considerations/#technical-limitations-of-gdpr-retrieval-and-removal","text":"Both GDPR retrieval and removal will process the data available via configured extensions and database(s). If a part of personal information is managed by an extension that is e.g. temporarily disabled, it won't be retrieved/deleted. If any MIM extension you had enabled on production is now disabled or you've switched one of them (or e.g. auth module) to another database, it is possible that some personal data will not be retrieved or removed as expected. In such case, please consider starting a separate MIM instance that is configured to access all places, where personal data may be stored. You may also extract the missing pieces of information on your own, however we won't cover the details of this method in this guide. Please also visit Known issues page to learn about a mod_mam_muc issue that may manifest in some environments.","title":"Technical limitations of GDPR retrieval and removal"},{"location":"operation-and-maintenance/known-issues/","text":"This document provides a list of all known issues with MongooseIM operation and configuration. You may also find proposed workarounds if any is available. MySQL + TLS + OTP 20.3 MongooseIM will not connect to MySQL over TLS on OTP 20.3 due to the MySQL driver bug . Proposed workarounds Upgrade OTP to 21.2 or higher. Use unencrypted communication with MySQL. MSSQL connectivity via ODBC The ODBC driver currently used by MongooseIM is known to work only with Ubuntu Xenial x64 and FreeTDS 0.91-6.1build1. It does not currently work on Ubuntu Bionic, CentOS 7 and macOS Mojave with the latest FreeTDS version. The team is working on resolving this issue. Please watch for updates in MongooseIM release notes. Proposed workarounds Use Ubuntu Xenial x64 for MongooseIM deployment. This OS version is still maintained. GDPR retrieval for MAM MUC limitation When the personal data retrieval is executed for a user in a specific domain, Message Archive Management for groupchats must be running for this particular domain. This is the case for most configurations but the problem manifests when a MongooseIM operator configures mod_mam_muc / mod_mam_meta to start only for a subset of domains supported by the cluster ( host_config option). In such case, personal data stored by MAM MUC will not be retrieved for this user. Proposed workaround Start a dedicated MongooseIM instance with a slightly different config, which enables Message Archive Management for the user's domain. This instance doesn't have to be clustered with other nodes and doesn't have to be accessible for actual users. After a successful retrieval, this instance may be terminated and deleted if necessary.","title":"Known issues"},{"location":"operation-and-maintenance/known-issues/#mysql-tls-otp-203","text":"MongooseIM will not connect to MySQL over TLS on OTP 20.3 due to the MySQL driver bug .","title":"MySQL + TLS + OTP 20.3"},{"location":"operation-and-maintenance/known-issues/#proposed-workarounds","text":"Upgrade OTP to 21.2 or higher. Use unencrypted communication with MySQL.","title":"Proposed workarounds"},{"location":"operation-and-maintenance/known-issues/#mssql-connectivity-via-odbc","text":"The ODBC driver currently used by MongooseIM is known to work only with Ubuntu Xenial x64 and FreeTDS 0.91-6.1build1. It does not currently work on Ubuntu Bionic, CentOS 7 and macOS Mojave with the latest FreeTDS version. The team is working on resolving this issue. Please watch for updates in MongooseIM release notes.","title":"MSSQL connectivity via ODBC"},{"location":"operation-and-maintenance/known-issues/#proposed-workarounds_1","text":"Use Ubuntu Xenial x64 for MongooseIM deployment. This OS version is still maintained.","title":"Proposed workarounds"},{"location":"operation-and-maintenance/known-issues/#gdpr-retrieval-for-mam-muc-limitation","text":"When the personal data retrieval is executed for a user in a specific domain, Message Archive Management for groupchats must be running for this particular domain. This is the case for most configurations but the problem manifests when a MongooseIM operator configures mod_mam_muc / mod_mam_meta to start only for a subset of domains supported by the cluster ( host_config option). In such case, personal data stored by MAM MUC will not be retrieved for this user.","title":"GDPR retrieval for MAM MUC limitation"},{"location":"operation-and-maintenance/known-issues/#proposed-workaround","text":"Start a dedicated MongooseIM instance with a slightly different config, which enables Message Archive Management for the user's domain. This instance doesn't have to be clustered with other nodes and doesn't have to be accessible for actual users. After a successful retrieval, this instance may be terminated and deleted if necessary.","title":"Proposed workaround"},{"location":"operation-and-maintenance/tls-distribution/","text":"Distribution over TLS It's possible to use TLS for communication between MongooseIM cluster nodes. To enable it, find the directory of your release, below it look for etc/vm.dist.args and, inside the file, the section about the distribution protocol: ## Use TLS for connections between Erlang cluster members. ## Don't forget to override the paths to point to your certificate(s) and key(s)! ## Once a connection is established, Erlang doesn't differentiate between ## a client and a server - the same certs/keys can be used on both sides. #-proto_dist inet_tls #-ssl_dist_opt server_certfile /Users/erszcz/work/esl/mongooseim/_build/mim1/rel/mongooseim/priv/ssl/fake_cert.pem client_certfile /Users/erszcz/work/esl/mongooseim/_build/mim1/rel/mongooseim/priv/ssl/fake_cert.pem # server_keyfile /Users/erszcz/work/esl/mongooseim/_build/mim1/rel/mongooseim/priv/ssl/fake_key.pem client_keyfile /Users/erszcz/work/esl/mongooseim/_build/mim1/rel/mongooseim/priv/ssl/fake_key.pem # server_cacertfile /Users/erszcz/work/esl/mongooseim/_build/mim1/rel/mongooseim/priv/ssl/cacert.pem client_cacertfile /Users/erszcz/work/esl/mongooseim/_build/mim1/rel/mongooseim/priv/ssl/cacert.pem # client_verify verify_peer # server_verify verify_peer # server_fail_if_no_peer_cert true By default, the proto_dist as well as the following options for configuring the cluster member are commented out. Enable them and provide the correct paths to your CA certificate, server certificate and server key. There's a number of caveats to remember about when running Erlang distribution over TLS : TLS-enabled and non-TLS Erlang nodes can't communicate with one another. Remember about it when trying to run erl -[s]name ... and communicating with the server. Establishing a TLS connection will fail if a certificate isn't found in the specified location. You might receive a log message indicating that when nodes try to connect: 2017-03-10 16:16:03.844 [warning] <0.4218.2> global: mongooseim@localhost failed to connect to fed1@localhost If the pointed-at certificate/key/CA-certificate file doesn't exist, it won't be reported before trying to connect. Look for (grep) the log message on all cluster nodes, as the message doesn't have to appear on all nodes if a connection fails. You can switch a cluster from running non-TLS distribution, to TLS distribution by shutting down a node, enabling TLS on it, starting it up again, and repeating the steps for each remaining node. Again, nodes with and without TLS enabled won't be able to communicate with one another. It's possible to fortify an Erlang cluster further than the Mongoose's preconfigured vm.dist.args does. This includes: checking certificate revocation status against a CA's Certificate Revocation List, securing/disabling EPMD (Erlang Port Mapper Daemon), using custom certificate verification functions. For details on these steps please refer to Erlang Distribution over TLS and Erlang (and Elixir) distribution without epmd .","title":"Distribution over TLS"},{"location":"operation-and-maintenance/tls-distribution/#distribution-over-tls","text":"It's possible to use TLS for communication between MongooseIM cluster nodes. To enable it, find the directory of your release, below it look for etc/vm.dist.args and, inside the file, the section about the distribution protocol: ## Use TLS for connections between Erlang cluster members. ## Don't forget to override the paths to point to your certificate(s) and key(s)! ## Once a connection is established, Erlang doesn't differentiate between ## a client and a server - the same certs/keys can be used on both sides. #-proto_dist inet_tls #-ssl_dist_opt server_certfile /Users/erszcz/work/esl/mongooseim/_build/mim1/rel/mongooseim/priv/ssl/fake_cert.pem client_certfile /Users/erszcz/work/esl/mongooseim/_build/mim1/rel/mongooseim/priv/ssl/fake_cert.pem # server_keyfile /Users/erszcz/work/esl/mongooseim/_build/mim1/rel/mongooseim/priv/ssl/fake_key.pem client_keyfile /Users/erszcz/work/esl/mongooseim/_build/mim1/rel/mongooseim/priv/ssl/fake_key.pem # server_cacertfile /Users/erszcz/work/esl/mongooseim/_build/mim1/rel/mongooseim/priv/ssl/cacert.pem client_cacertfile /Users/erszcz/work/esl/mongooseim/_build/mim1/rel/mongooseim/priv/ssl/cacert.pem # client_verify verify_peer # server_verify verify_peer # server_fail_if_no_peer_cert true By default, the proto_dist as well as the following options for configuring the cluster member are commented out. Enable them and provide the correct paths to your CA certificate, server certificate and server key. There's a number of caveats to remember about when running Erlang distribution over TLS : TLS-enabled and non-TLS Erlang nodes can't communicate with one another. Remember about it when trying to run erl -[s]name ... and communicating with the server. Establishing a TLS connection will fail if a certificate isn't found in the specified location. You might receive a log message indicating that when nodes try to connect: 2017-03-10 16:16:03.844 [warning] <0.4218.2> global: mongooseim@localhost failed to connect to fed1@localhost If the pointed-at certificate/key/CA-certificate file doesn't exist, it won't be reported before trying to connect. Look for (grep) the log message on all cluster nodes, as the message doesn't have to appear on all nodes if a connection fails. You can switch a cluster from running non-TLS distribution, to TLS distribution by shutting down a node, enabling TLS on it, starting it up again, and repeating the steps for each remaining node. Again, nodes with and without TLS enabled won't be able to communicate with one another. It's possible to fortify an Erlang cluster further than the Mongoose's preconfigured vm.dist.args does. This includes: checking certificate revocation status against a CA's Certificate Revocation List, securing/disabling EPMD (Erlang Port Mapper Daemon), using custom certificate verification functions. For details on these steps please refer to Erlang Distribution over TLS and Erlang (and Elixir) distribution without epmd .","title":"Distribution over TLS"},{"location":"rest-api/","text":"How to render the swagger.{yml,json} Go to: http://editor.swagger.io/ Then: file > Import File","title":"Index"},{"location":"rest-api/#how-to-render-the-swaggerymljson","text":"Go to: http://editor.swagger.io/ Then: file > Import File","title":"How to render the swagger.{yml,json}"},{"location":"rest-api/Administration-backend/","text":"MongooseIM's REST API for backend administration Configuration Commands used by the REST API are provided by modules: mod_commands - provides general purpose commands: both user-like (f.e. sending a message and retrieving messages from the archive) and administration-like (f.e. create/delete a user and change the password) mod_muc_commands - commands related to Multi-user Chat rooms: create a room, invite users, send a message etc. mod_muc_light_commands - same but for rooms based on the muc-light protocol. To activate those commands, put modules you need into the mongooseim.cfg file: {mod_commands, []}, {mod_muc_commands, []}, {mod_muc_light_commands, []}, You also have to hook mongoose_api_admin module to an HTTP endpoint: { {8088, \"127.0.0.1\"} , ejabberd_cowboy, [ {num_acceptors, 10}, {transport_options, [{max_connections, 1024}]}, {modules, [ {\"localhost\", \"/api\", mongoose_api_admin, []} ]} ]}, OpenAPI specifications Read the beautiful Swagger documentation for more information. $(document).ready(function() { if (window.location.host.match(\"readthedocs\")){ path = window.location.pathname.match(\"(.*)/rest-api/Administration-backend\")[1] url = window.location.protocol + \"//\" + window.location.hostname finalURL = url + path + \"/swagger/index.html\" $('a[href$=\"swagger/index.html\"]').attr('href', finalURL) $('#swagger-ui-iframe').attr('src', finalURL) } })","title":"Administration backend"},{"location":"rest-api/Administration-backend/#mongooseims-rest-api-for-backend-administration","text":"","title":"MongooseIM's REST API for backend administration"},{"location":"rest-api/Administration-backend/#configuration","text":"Commands used by the REST API are provided by modules: mod_commands - provides general purpose commands: both user-like (f.e. sending a message and retrieving messages from the archive) and administration-like (f.e. create/delete a user and change the password) mod_muc_commands - commands related to Multi-user Chat rooms: create a room, invite users, send a message etc. mod_muc_light_commands - same but for rooms based on the muc-light protocol. To activate those commands, put modules you need into the mongooseim.cfg file: {mod_commands, []}, {mod_muc_commands, []}, {mod_muc_light_commands, []}, You also have to hook mongoose_api_admin module to an HTTP endpoint: { {8088, \"127.0.0.1\"} , ejabberd_cowboy, [ {num_acceptors, 10}, {transport_options, [{max_connections, 1024}]}, {modules, [ {\"localhost\", \"/api\", mongoose_api_admin, []} ]} ]},","title":"Configuration"},{"location":"rest-api/Administration-backend/#openapi-specifications","text":"Read the beautiful Swagger documentation for more information. $(document).ready(function() { if (window.location.host.match(\"readthedocs\")){ path = window.location.pathname.match(\"(.*)/rest-api/Administration-backend\")[1] url = window.location.protocol + \"//\" + window.location.hostname finalURL = url + path + \"/swagger/index.html\" $('a[href$=\"swagger/index.html\"]').attr('href', finalURL) $('#swagger-ui-iframe').attr('src', finalURL) } })","title":"OpenAPI specifications"},{"location":"rest-api/Client-frontend/","text":"MongooseIM's REST API for frontend or client In addition to the regular XMPP connection methods such as TCP (with TLS/STARTTLS), WebSockets and BOSH, MongooseIM provides parts of its functionality over a REST API. Assumptions Every request has to be authenticated. Please see the Authentication section for more details. We advise that this API is served over HTTPS. User registration has to be done via other methods (f.e. using the REST API for backend services ). The relevant endpoint has to be configured on the server side. See the configuration section . A list of provided actions is documented with Swagger. See the beatiful specification . Authentication The only possible authentication method for the time being is Basic Authentication . The userid part is user's bare JID and the password is the same as that used to register the user's account. Bare JID To ilustrate what bare JIDs are, let's assume your MongooseIM server's hostname is wonderland.com and the user is alice . In this case the bare JID for her is just: alice@wonderland.com . This value should be used as the userid in the Basic Authentication method for all the REST API calls. Configuration In order to enable the REST API, the following configuration should be added to the listen section in mongooseim.cfg file. { 8089 , ejabberd_cowboy, [ {num_acceptors, 10}, {max_connections, 1024}, {compress, true}, {ssl, [{certfile, \"priv/ssl/fake_cert.pem\"}, {keyfile, \"priv/ssl/fake_key.pem\"}, {password, \"\"}]}, {modules, [ {\"_\", \"/api/messages/[:with]\", mongoose_client_api_messages, []}, {\"_\", \"/api/rooms/:id/messages\", mongoose_client_api_rooms_messages, []}, {\"_\", \"/api/rooms/:id/users/[:user]\", mongoose_client_api_rooms_users, []}, {\"_\", \"/api/rooms/[:id]\", mongoose_client_api_rooms, []} ]} ]} The most important part of the above example is the modules lists where the relevant REST API functionalities are enabled and exposed on the given paths. By default the REST API is exposed on port 8089 but this can be changed to whatever is more convenient. For more details about possible ejabberd_cowboy configuration parameters please see the relevant documentation in the Listener modules . Smack library support REST API can fetch messages for Smack Stanza Properties. For example if we have properties in the stanza like: <message xml:lang='en' to='alice@localhost' id='123' type='chat'> <body xml:lang='en_US'>Hi!</body> <properties xmlns=\"http://www.jivesoftware.com/xmlns/xmpp/properties\" <property> <name>some_number</name> <value type='integer'>123</value> <property> <property> <name>some_string</name> <value type='string'>abc</value> <property> </properties> </message> then in the final json message these properties will be converted to json map without tag names and all types will be taken as string: { \"to\": \"alice@localhost\", \"timestamp\": 1531329049949, \"id\": \"123\", \"from\": \"bob@localhost\", \"body\": \"Hi!\", \"properties\":{ \"some_number\":\"123\", \"some_string\":\"abc\" } } OpenAPI specifications See the beautiful Swagger documentation for more information. $(document).ready(function() { if (window.location.host.match(\"readthedocs\")){ path = window.location.pathname.match(\"(.*)/REST-API/\")[1] url = window.location.protocol + \"//\" + window.location.hostname finalURL = url + path + \"/swagger/index.html?client=true\" $('a[href$=\"swagger/index.html?client=true\"]').attr('href', finalURL) $('#swagger-ui-iframe').attr('src', finalURL) } })","title":"Client/frontend"},{"location":"rest-api/Client-frontend/#mongooseims-rest-api-for-frontend-or-client","text":"In addition to the regular XMPP connection methods such as TCP (with TLS/STARTTLS), WebSockets and BOSH, MongooseIM provides parts of its functionality over a REST API.","title":"MongooseIM's REST API for frontend or client"},{"location":"rest-api/Client-frontend/#assumptions","text":"Every request has to be authenticated. Please see the Authentication section for more details. We advise that this API is served over HTTPS. User registration has to be done via other methods (f.e. using the REST API for backend services ). The relevant endpoint has to be configured on the server side. See the configuration section . A list of provided actions is documented with Swagger. See the beatiful specification .","title":"Assumptions"},{"location":"rest-api/Client-frontend/#authentication","text":"The only possible authentication method for the time being is Basic Authentication . The userid part is user's bare JID and the password is the same as that used to register the user's account.","title":"Authentication"},{"location":"rest-api/Client-frontend/#bare-jid","text":"To ilustrate what bare JIDs are, let's assume your MongooseIM server's hostname is wonderland.com and the user is alice . In this case the bare JID for her is just: alice@wonderland.com . This value should be used as the userid in the Basic Authentication method for all the REST API calls.","title":"Bare JID"},{"location":"rest-api/Client-frontend/#configuration","text":"In order to enable the REST API, the following configuration should be added to the listen section in mongooseim.cfg file. { 8089 , ejabberd_cowboy, [ {num_acceptors, 10}, {max_connections, 1024}, {compress, true}, {ssl, [{certfile, \"priv/ssl/fake_cert.pem\"}, {keyfile, \"priv/ssl/fake_key.pem\"}, {password, \"\"}]}, {modules, [ {\"_\", \"/api/messages/[:with]\", mongoose_client_api_messages, []}, {\"_\", \"/api/rooms/:id/messages\", mongoose_client_api_rooms_messages, []}, {\"_\", \"/api/rooms/:id/users/[:user]\", mongoose_client_api_rooms_users, []}, {\"_\", \"/api/rooms/[:id]\", mongoose_client_api_rooms, []} ]} ]} The most important part of the above example is the modules lists where the relevant REST API functionalities are enabled and exposed on the given paths. By default the REST API is exposed on port 8089 but this can be changed to whatever is more convenient. For more details about possible ejabberd_cowboy configuration parameters please see the relevant documentation in the Listener modules .","title":"Configuration"},{"location":"rest-api/Client-frontend/#smack-library-support","text":"REST API can fetch messages for Smack Stanza Properties. For example if we have properties in the stanza like: <message xml:lang='en' to='alice@localhost' id='123' type='chat'> <body xml:lang='en_US'>Hi!</body> <properties xmlns=\"http://www.jivesoftware.com/xmlns/xmpp/properties\" <property> <name>some_number</name> <value type='integer'>123</value> <property> <property> <name>some_string</name> <value type='string'>abc</value> <property> </properties> </message> then in the final json message these properties will be converted to json map without tag names and all types will be taken as string: { \"to\": \"alice@localhost\", \"timestamp\": 1531329049949, \"id\": \"123\", \"from\": \"bob@localhost\", \"body\": \"Hi!\", \"properties\":{ \"some_number\":\"123\", \"some_string\":\"abc\" } }","title":"Smack library support"},{"location":"rest-api/Client-frontend/#openapi-specifications","text":"See the beautiful Swagger documentation for more information. $(document).ready(function() { if (window.location.host.match(\"readthedocs\")){ path = window.location.pathname.match(\"(.*)/REST-API/\")[1] url = window.location.protocol + \"//\" + window.location.hostname finalURL = url + path + \"/swagger/index.html?client=true\" $('a[href$=\"swagger/index.html?client=true\"]').attr('href', finalURL) $('#swagger-ui-iframe').attr('src', finalURL) } })","title":"OpenAPI specifications"},{"location":"rest-api/Metrics-backend/","text":"Introduction Warning: This API is considered obsolete. Please use WombatOAM for monitoring or one of the exometer reporters and your favourite statistics service. To expose MongooseIM metrics, an adequate endpoint must be included in the Cowboy HTTP listener section. Here's an example: ... { {5288, \"127.0.0.1\"}, ejabberd_cowboy, [ ... {modules, [ {\"localhost\", \"/api\", [{handlers, [mongoose_api_metrics]}]} ]} ]} ... If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page. Security notice An auth mechanism is available only for the new administration API. That's why we recommend to expose this API only using a private interface or a port hidden behind a firewall to limit the access to the API. The above configuration starts the API only on a loopback interface. Response format The responses are composed in a JSON format with a root element containing one or more attributes as response elements. Example response: { \"hosts\": [ \"localhost\" ], \"metrics\": [ \"xmppErrorIq\", \"xmppPresenceReceived\", \"xmppMessageBounced\", (...) ], \"global\": [ \"nodeSessionCount\", \"totalSessionCount\", \"uniqueSessionCount\", (...) ] } Services GET /api/metrics Returns 200 OK and two elements: hosts - A list of XMPP host names available on the server. metrics - A list of per-host metrics. global - A list of global metrics. GET /api/metrics/all Returns 200 OK and an element: metrics - A list of aggregated (sum of all domains) per-host metrics with their values. GET /api/metrics/all/:metric On success returns 200 OK and an element: metric - An aggregated (sum of all domains) per-host metric. Returns 404 Not Found when metric :metric doesn't exist. GET /api/metrics/host/:host On success returns 200 OK and an element: metrics - A list of per-host metrics and their values for host :host . Returns 404 Not Found when host :host doesn't exist. GET /api/metrics/host/:host/:metric On success returns 200 OK and an element: metric - A per-host metric :metric and its value for host :host . Returns 404 Not Found when the pair (host :host , metric :metric ) doesn't exist. GET /api/metrics/global On success returns 200 OK and an element: metrics - A list of all global metrics and their values. GET /api/metrics/global/:metric On success returns 200 OK and an element: metric - A global metric :metric and its value. Returns 404 Not Found when metric :metric doesn't exist. collectd integration The interface is compatible with the collectd curl_json plugin. Data fetched by collectd may be later visualized by tools like Graphite. Here's an example of a collectd configuration entry that will fetch all available metrics for a given host: LoadPlugin curl_json ... <Plugin curl_json> <URL \"http://<MONGOOSEIM HOST>:<MONGOOSEIM HTTP LISTENER PORT>/api/metrics/host/<XMPP HOST>\"> Instance \"mongooseim\" <Key \"metrics/sessionCount/value\"> Type \"absolute\" </Key> <Key \"metrics/*/count\"> Type \"absolute\" </Key> <Key \"metrics/*/one\"> Type \"absolute\" </Key> </URL> </Plugin>","title":"Metrics backend"},{"location":"rest-api/Metrics-backend/#introduction","text":"Warning: This API is considered obsolete. Please use WombatOAM for monitoring or one of the exometer reporters and your favourite statistics service. To expose MongooseIM metrics, an adequate endpoint must be included in the Cowboy HTTP listener section. Here's an example: ... { {5288, \"127.0.0.1\"}, ejabberd_cowboy, [ ... {modules, [ {\"localhost\", \"/api\", [{handlers, [mongoose_api_metrics]}]} ]} ]} ... If you'd like to learn more about metrics in MongooseIM, please visit MongooseIM metrics page.","title":"Introduction"},{"location":"rest-api/Metrics-backend/#security-notice","text":"An auth mechanism is available only for the new administration API. That's why we recommend to expose this API only using a private interface or a port hidden behind a firewall to limit the access to the API. The above configuration starts the API only on a loopback interface.","title":"Security notice"},{"location":"rest-api/Metrics-backend/#response-format","text":"The responses are composed in a JSON format with a root element containing one or more attributes as response elements. Example response: { \"hosts\": [ \"localhost\" ], \"metrics\": [ \"xmppErrorIq\", \"xmppPresenceReceived\", \"xmppMessageBounced\", (...) ], \"global\": [ \"nodeSessionCount\", \"totalSessionCount\", \"uniqueSessionCount\", (...) ] }","title":"Response format"},{"location":"rest-api/Metrics-backend/#services","text":"","title":"Services"},{"location":"rest-api/Metrics-backend/#get-apimetrics","text":"Returns 200 OK and two elements: hosts - A list of XMPP host names available on the server. metrics - A list of per-host metrics. global - A list of global metrics.","title":"GET /api/metrics"},{"location":"rest-api/Metrics-backend/#get-apimetricsall","text":"Returns 200 OK and an element: metrics - A list of aggregated (sum of all domains) per-host metrics with their values.","title":"GET /api/metrics/all"},{"location":"rest-api/Metrics-backend/#get-apimetricsallmetric","text":"On success returns 200 OK and an element: metric - An aggregated (sum of all domains) per-host metric. Returns 404 Not Found when metric :metric doesn't exist.","title":"GET /api/metrics/all/:metric"},{"location":"rest-api/Metrics-backend/#get-apimetricshosthost","text":"On success returns 200 OK and an element: metrics - A list of per-host metrics and their values for host :host . Returns 404 Not Found when host :host doesn't exist.","title":"GET /api/metrics/host/:host"},{"location":"rest-api/Metrics-backend/#get-apimetricshosthostmetric","text":"On success returns 200 OK and an element: metric - A per-host metric :metric and its value for host :host . Returns 404 Not Found when the pair (host :host , metric :metric ) doesn't exist.","title":"GET /api/metrics/host/:host/:metric"},{"location":"rest-api/Metrics-backend/#get-apimetricsglobal","text":"On success returns 200 OK and an element: metrics - A list of all global metrics and their values.","title":"GET /api/metrics/global"},{"location":"rest-api/Metrics-backend/#get-apimetricsglobalmetric","text":"On success returns 200 OK and an element: metric - A global metric :metric and its value. Returns 404 Not Found when metric :metric doesn't exist.","title":"GET /api/metrics/global/:metric"},{"location":"rest-api/Metrics-backend/#collectd-integration","text":"The interface is compatible with the collectd curl_json plugin. Data fetched by collectd may be later visualized by tools like Graphite. Here's an example of a collectd configuration entry that will fetch all available metrics for a given host: LoadPlugin curl_json ... <Plugin curl_json> <URL \"http://<MONGOOSEIM HOST>:<MONGOOSEIM HTTP LISTENER PORT>/api/metrics/host/<XMPP HOST>\"> Instance \"mongooseim\" <Key \"metrics/sessionCount/value\"> Type \"absolute\" </Key> <Key \"metrics/*/count\"> Type \"absolute\" </Key> <Key \"metrics/*/one\"> Type \"absolute\" </Key> </URL> </Plugin>","title":"collectd integration"},{"location":"user-guide/Features-and-supported-standards/","text":"Features and supported standards XMPP Core: RFC 3920 , RFC 6120 XMPP Instant Messaging and Presence: RFC 3921 , RFC 6121 Client connections: over TCP (with TLS/STARTTLS available) as defined in RFC 6120 over WebSockets as defined in RFC 7395 over HTTP(S) long-polling (BOSH) as defined in XEP-0124 and XEP-0206 REST API Server/backend connections: REST API Configurable database backends: Transient: Mnesia Redis Persistent: RDBMS: MySQL, PostgreSQL, generic ODBC NOSQL: Riak KV, Cassandra Integration with third-party services Amazon Simple Notification Service Supported XEPs XEP Number Name Module 0004 Data Forms 0012 Last Activity mod_last 0016 Privacy Lists mod_privacy 0018 Invisible Presence 0022 Message Events mod_offline 0023 Message Expiration mod_offline 0030 Service Discovery mod_disco 0045 Multi-User Chat mod_muc 0049 Private XML Storage mod_private 0050 Ad-Hoc Commands mod_adhoc 0054 vcard-temp mod_vcard 0055 Jabber Search mod_vcard 0059 Result Set Management 0060 Publish-Subscribe mod_pubsub 0068 Field Standardization for Data Forms 0073 Basic IM Protocol Suite 0077 In-Band Registration mod_register 0079 Advanced Message Processing mod_amp (partial support) 0082 XMPP Date and Time Profiles 0085 Chat State Notifications 0086 Error Condition Mappings 0106 JID Escaping 0114 Jabber Component Protocol ejabberd_service 0115 Entity Capabilities mod_caps 0124 Bidirectional-streams Over Synchronous HTTP (BOSH) mod_bosh 0126 Invisibility mod_privacy 0138 Stream Compression 0153 vCard-Based Avatars mod_vcard 0157 Contact Addresses for XMPP Services mod_disco 0160 Best Practices for Handling Offline Messages mod_offline 0163 Personal Eventing Protocol mod_pubsub 0170 Recommended Order of Stream Feature Negotiation 0175 Best Practices for Use of SASL ANONYMOUS 0185 Dialback Key Generation and Validation 0191 Blocking Command mod_blocking 0198 Stream Management mod_stream_management 0199 XMPP Ping mod_ping 0202 Entity Time 0203 Delayed Delivery 0206 XMPP Over BOSH mod_bosh 0237 Roster Versioning mod_roster 0270 XMPP Advanced Server 2010 0279 Server IP Check mod_sic 0280 Message Carbons mod_carboncopy 0313 Message Archive Management mod_mam 0352 Client State Indication mod_csi 0357 Push Notifications mod_event_pusher_push 0363 HTTP File Upload mod_http_upload 0384 OMEMO Encryption (MongooseIM supports PEP, which is required by this extension) 0387 XMPP Compliance Suites 2018 - all suites, Advanced Server level Supported Open Extensions Name Module MUC Light mod_muc_light Token-based reconnection mod_auth_token , mod_keystore Integration with other platform components MongoosePUSH MongooseIM can be integrated with MongoosePush . For more details visit the push notification user guide . MongooseICE You can also connect Mongoose with MongooseICE . To get started, we recommend going through this tutorial .","title":"Features and supported standards"},{"location":"user-guide/Features-and-supported-standards/#features-and-supported-standards","text":"XMPP Core: RFC 3920 , RFC 6120 XMPP Instant Messaging and Presence: RFC 3921 , RFC 6121 Client connections: over TCP (with TLS/STARTTLS available) as defined in RFC 6120 over WebSockets as defined in RFC 7395 over HTTP(S) long-polling (BOSH) as defined in XEP-0124 and XEP-0206 REST API Server/backend connections: REST API Configurable database backends: Transient: Mnesia Redis Persistent: RDBMS: MySQL, PostgreSQL, generic ODBC NOSQL: Riak KV, Cassandra Integration with third-party services Amazon Simple Notification Service","title":"Features and supported standards"},{"location":"user-guide/Features-and-supported-standards/#supported-xeps","text":"XEP Number Name Module 0004 Data Forms 0012 Last Activity mod_last 0016 Privacy Lists mod_privacy 0018 Invisible Presence 0022 Message Events mod_offline 0023 Message Expiration mod_offline 0030 Service Discovery mod_disco 0045 Multi-User Chat mod_muc 0049 Private XML Storage mod_private 0050 Ad-Hoc Commands mod_adhoc 0054 vcard-temp mod_vcard 0055 Jabber Search mod_vcard 0059 Result Set Management 0060 Publish-Subscribe mod_pubsub 0068 Field Standardization for Data Forms 0073 Basic IM Protocol Suite 0077 In-Band Registration mod_register 0079 Advanced Message Processing mod_amp (partial support) 0082 XMPP Date and Time Profiles 0085 Chat State Notifications 0086 Error Condition Mappings 0106 JID Escaping 0114 Jabber Component Protocol ejabberd_service 0115 Entity Capabilities mod_caps 0124 Bidirectional-streams Over Synchronous HTTP (BOSH) mod_bosh 0126 Invisibility mod_privacy 0138 Stream Compression 0153 vCard-Based Avatars mod_vcard 0157 Contact Addresses for XMPP Services mod_disco 0160 Best Practices for Handling Offline Messages mod_offline 0163 Personal Eventing Protocol mod_pubsub 0170 Recommended Order of Stream Feature Negotiation 0175 Best Practices for Use of SASL ANONYMOUS 0185 Dialback Key Generation and Validation 0191 Blocking Command mod_blocking 0198 Stream Management mod_stream_management 0199 XMPP Ping mod_ping 0202 Entity Time 0203 Delayed Delivery 0206 XMPP Over BOSH mod_bosh 0237 Roster Versioning mod_roster 0270 XMPP Advanced Server 2010 0279 Server IP Check mod_sic 0280 Message Carbons mod_carboncopy 0313 Message Archive Management mod_mam 0352 Client State Indication mod_csi 0357 Push Notifications mod_event_pusher_push 0363 HTTP File Upload mod_http_upload 0384 OMEMO Encryption (MongooseIM supports PEP, which is required by this extension) 0387 XMPP Compliance Suites 2018 - all suites, Advanced Server level","title":"Supported XEPs"},{"location":"user-guide/Features-and-supported-standards/#supported-open-extensions","text":"Name Module MUC Light mod_muc_light Token-based reconnection mod_auth_token , mod_keystore","title":"Supported Open Extensions"},{"location":"user-guide/Features-and-supported-standards/#integration-with-other-platform-components","text":"","title":"Integration with other platform components"},{"location":"user-guide/Features-and-supported-standards/#mongoosepush","text":"MongooseIM can be integrated with MongoosePush . For more details visit the push notification user guide .","title":"MongoosePUSH"},{"location":"user-guide/Features-and-supported-standards/#mongooseice","text":"You can also connect Mongoose with MongooseICE . To get started, we recommend going through this tutorial .","title":"MongooseICE"},{"location":"user-guide/Get-to-know-MongooseIM/","text":"Overview MongooseIM is Erlang Solutions' robust, scalable and efficient XMPP server, aimed at large installations. Specifically designed for enterprise purposes, it is fault-tolerant, can utilise the resources of multiple clustered machines, and easily scale when more capacity is required by just adding nodes (new hardware boxes or VMs). It provides support for WebSockets and reimplemented BOSH (HTTP long-polling). Architecture MongooseIM brings configurability, scalability and fault-tolerance to the core feature of XMPP \u2013 routing messages. Its architecture is based on a set of pluggable modules that enable different features, including: Websockets: long-lived connections in the browser BOSH: HTTP long-polling MUC (Multi-User Chat): group chat Rosters: contact list, and subscriptions to users' presences MAM: Message Archive Management Message Carbons: for multi-device, real-time copies of all messages Last activity Metrics Offline messages Privacy settings vCards: user profiles This modular architecture allows high customisability and easy access to the required features. MongooseIM enables authenticating users using external or internal databases (Mnesia, RDBMS, NOSQL), LDAP or external scripts. It also allows connecting anonymous users, when required. For storing persistent data, MongooseIM uses Mnesia (the distributed internal Erlang database) and also MySQL and PostgreSQL (RDBMS databases), and Riak KV (NOSQL). If necessary, MongooseIM can be customised to work with a database chosen by the customer. Basic MongooseIM session storage is handled in Mnesia, but using Redis is also possible. Deployment and management MongooseIM can be deployed for a number of scenarios fitting customer needs. The default installation setup consists of a single MongooseIM node using Mnesia, so it does not require any additional services. This primary system is sufficient for fast deployment and connecting XMPP clients. A more scalable solution would be deploying MongooseIM with an external database for persistent data. Such a setup requires a cluster of MongooseIM nodes, an external database, and a load balancer to manage the traffic from the client applications. If deployed on a 16 GB RAM machine with at least 4 cores, a single MongooseIM node can handle 200-300 thousands of online users. This setup is suitable for systems with up to 10 nodes. If the service requires a cluster of more than 10 nodes, we recommend using Redis instead of Mnesia for session storage. To avoid a single point of failure, a master-slave Redis setup is advisable. MongooseIM allows connecting different clusters as parts of larger systems. This feature is used in geo-localised services handling massive traffic from all over the world. MongooseIM gathers over 40 different XMPP-related metrics, allowing close monitoring of what happens inside the nodes. To manage the users, rosters, messages and general settings, we provide a command-line tool, mongooseimctl . Erlang Solutions also provides WombatOAM , an erlang VM monitoring solution, that enbales ops and devs to better understand what going on in a MongooseIM cluster. For load testing consider Tide , another Erlang Solutions' tool that enables devs and ops to validate their scalability, given the clients scenarios. Client side In order to build client applications, the MoongooseIM team recommends the following libraries: XMPP REST API iOS XMPPframework , Objective-C Jayme , Swift Android Smack , Java Retrofit , Java Web Stanza.io / Strophe.js , JavaScript General knowledge of Erlang and XMPP allows complete control over the system and its components.","title":"ABCs of MongooseIM"},{"location":"user-guide/Get-to-know-MongooseIM/#overview","text":"MongooseIM is Erlang Solutions' robust, scalable and efficient XMPP server, aimed at large installations. Specifically designed for enterprise purposes, it is fault-tolerant, can utilise the resources of multiple clustered machines, and easily scale when more capacity is required by just adding nodes (new hardware boxes or VMs). It provides support for WebSockets and reimplemented BOSH (HTTP long-polling).","title":"Overview"},{"location":"user-guide/Get-to-know-MongooseIM/#architecture","text":"MongooseIM brings configurability, scalability and fault-tolerance to the core feature of XMPP \u2013 routing messages. Its architecture is based on a set of pluggable modules that enable different features, including: Websockets: long-lived connections in the browser BOSH: HTTP long-polling MUC (Multi-User Chat): group chat Rosters: contact list, and subscriptions to users' presences MAM: Message Archive Management Message Carbons: for multi-device, real-time copies of all messages Last activity Metrics Offline messages Privacy settings vCards: user profiles This modular architecture allows high customisability and easy access to the required features. MongooseIM enables authenticating users using external or internal databases (Mnesia, RDBMS, NOSQL), LDAP or external scripts. It also allows connecting anonymous users, when required. For storing persistent data, MongooseIM uses Mnesia (the distributed internal Erlang database) and also MySQL and PostgreSQL (RDBMS databases), and Riak KV (NOSQL). If necessary, MongooseIM can be customised to work with a database chosen by the customer. Basic MongooseIM session storage is handled in Mnesia, but using Redis is also possible.","title":"Architecture"},{"location":"user-guide/Get-to-know-MongooseIM/#deployment-and-management","text":"MongooseIM can be deployed for a number of scenarios fitting customer needs. The default installation setup consists of a single MongooseIM node using Mnesia, so it does not require any additional services. This primary system is sufficient for fast deployment and connecting XMPP clients. A more scalable solution would be deploying MongooseIM with an external database for persistent data. Such a setup requires a cluster of MongooseIM nodes, an external database, and a load balancer to manage the traffic from the client applications. If deployed on a 16 GB RAM machine with at least 4 cores, a single MongooseIM node can handle 200-300 thousands of online users. This setup is suitable for systems with up to 10 nodes. If the service requires a cluster of more than 10 nodes, we recommend using Redis instead of Mnesia for session storage. To avoid a single point of failure, a master-slave Redis setup is advisable. MongooseIM allows connecting different clusters as parts of larger systems. This feature is used in geo-localised services handling massive traffic from all over the world. MongooseIM gathers over 40 different XMPP-related metrics, allowing close monitoring of what happens inside the nodes. To manage the users, rosters, messages and general settings, we provide a command-line tool, mongooseimctl . Erlang Solutions also provides WombatOAM , an erlang VM monitoring solution, that enbales ops and devs to better understand what going on in a MongooseIM cluster. For load testing consider Tide , another Erlang Solutions' tool that enables devs and ops to validate their scalability, given the clients scenarios.","title":"Deployment and management"},{"location":"user-guide/Get-to-know-MongooseIM/#client-side","text":"In order to build client applications, the MoongooseIM team recommends the following libraries: XMPP REST API iOS XMPPframework , Objective-C Jayme , Swift Android Smack , Java Retrofit , Java Web Stanza.io / Strophe.js , JavaScript General knowledge of Erlang and XMPP allows complete control over the system and its components.","title":"Client side"},{"location":"user-guide/Getting-started/","text":"In this short guide we will set MongooseIM up and get users chatting right away. The goal is to get to know MongooseIM, set it up, go through basic operations and validation. Warning: This setup is not intended for production. Note: This procedure has been tested on an Ubuntu 18.04.x LTS. Installation We recommend, you install mongooseIM binaries from a package Erlang Solutions delivers. Alternatively, check out our tutorial on How to build MongooseIM from source code for an introduction to compiling, building and testing MongooseIM. Download a package Go to the downloads section of the Erlang Solutions website, and choose the version of MongooseIM you want. The following sections describe the installation process for different operating systems. Ubuntu and Debian Once the deb file is downloaded, open a terminal window and navigate to the directory containing the package. Use the following command to unpack and install MongooseIM: sudo dpkg -i mongooseim_[version here].deb CentOS An ODBC (RDBMS) driver must be installed on your machine to unpack and install from RPM packages. Enter the following command in a terminal window to install the latest unixODBC driver: sudo yum install unixODBC Once the RPM file is downloaded, open a terminal window and navigate to the directory containing the package. Use the following command to unpack and install MongooseIM: sudo rpm -i mongooseim_[version here].rpm Running MongooseIM Warning: MongooseIM will use its default database - Mnesia, which is faster and simpler to setup, but not intended for production purposes when it comes to persistent data. Note: It is possible at anytime to use external databases. For more information see the end of this guide. The following command will start the MongooseIM server: mongooseimctl start When you change the config file and want to restart the MongooseIM server: mongooseimctl restart Use the following command to stop the MongooseIM server: mongooseimctl stop This takes a few seconds. At any given time, the following command shows the status of a MongooseIM server: mongooseimctl status If the command replies nodedown then MongooseIM is not running. Else it will show its status starting , started , or stopping , and its version. When needed, you can also launch the server in the interactive mode: mongooseimctl live This will allow you to better detect and understand the errors in the configuration. When MongooseIM is properly running, the Erlang shell/console is then shown. Just type Control-C twice to exit, the server will then be shut down. For running MongooseIM in a non-interactive way within a supervision system (e.g. systemd), it is recommended to use the foreground mode: mongooseimctl foreground Typing Control-C will stop the server. You can check server loglevel: mongooseimctl get_loglevel Chat users Registering (creating) users The default XMPP domain served by MongooseIM right after installation is localhost . You can register (create) users with the mongooseimctl utility. This command registers the user user@domain using password password . mongooseimctl register_identified user domain password Examples: mongooseimctl register_identified alice localhost qwerty mongooseimctl register_identified bob localhost 12345678 mongooseimctl register_identified carol localhost abc123 mongooseimctl register_identified dan localhost dan Warning: The password is entered manually in the command line and history is accessible to the command line users. This method is not recommended for production use, you may prefer for example LDAP. You can check that it has correctly been created: mongooseimctl check_account user host Example: mongooseimctl check_account alice localhost mongooseimctl check_account bob localhost mongooseimctl check_account carol localhost mongooseimctl check_account dan localhost Now you can list all registered users in your host: mongooseimctl registered_users host Example: mongooseimctl registered_users localhost If you want delete users in your host: mongooseimctl unregister user host Example: mongooseimctl unregister dan localhost Populate the contact lists (rosters) Fo a given user ( localuser and localserver ), add a contact ( user and server ): mongooseimctl add_rosteritem localuser localserver user server nick group subs Examples: mongooseimctl add_rosteritem alice localhost bob localhost bob friends both mongooseimctl add_rosteritem bob localhost alice localhost alice friends both Note: The subs parameter is the \"subscription\" to a user's presence. Possible values are: none , from , to , or both . A subscription in both direction means each user will receive each other's presence. Verify the contact list: mongooseimctl get_roster user host Examples: mongooseimctl get_roster alice localhost mongooseimctl get_roster bob localhost mongooseimctl get_roster carol localhost Basic MongooseIM configuration You can edit the mongooseim.cfg file: /etc/mongooseim/mongooseim.cfg Warning: We recommend you do not touch the advanced settings at this stage. For each change, edit the configuration file using the right Linux/Unix user. Save (and optionally backup, archive, or version) the configuration file and restart the MongooseIM server. Logging Change your own loglevel in the configuration file: % {loglevel, 3}. {loglevel, 4}. Save and exit your editor, restart MongooseIM and check your loglevel from the command line: mongooseimctl get_loglevel Read the ejabberd.log file: /var/log/mongooseim/ejabberd.log You can use commands such cat , more or less , even head or tail . In order to see live logs: tail -f /var/log/mongooseim/ejabberd.log Type Ctrl+C to exit. MUC (Multi-User Chat) for groupchats Enable MUC, or Multi-User Chat, for groupchats/channels in the mongooseim.cfg file: {mod_muc, [{host, \"muc.@HOST@\"}, {access, muc}, {access_create, muc_create} ]}, Verify with: mongooseimctl print_flat_config | grep muc {[h,<<\"localhost\">>,module,mod_muc_commands],'FLAT'}. {[h,<<\"localhost\">>,module,mod_muc_light_commands],'FLAT'}. {[h,<<\"localhost\">>,module,mod_muc],'FLAT'}. {[h,<<\"localhost\">>,module_opt,mod_muc,host],\"muc.@HOST@\"}. {[h,<<\"localhost\">>,module_opt,mod_muc,access],muc}. {[h,<<\"localhost\">>,module_opt,mod_muc,access_create],muc_create}. Roster versioning For faster contact list downloads at each client/app (re)connection, edit the configuration file: {mod_roster, [ {versioning, true}, {store_current_id, true} ]}, Verify with: mongooseimctl print_flat_config | grep roster [{service_admin_extra,[{submods,[node,accounts,sessions,vcard,gdpr,roster, {[h,<<\"localhost\">>,module,mod_roster],'FLAT'}. {[h,<<\"localhost\">>,module_opt,mod_roster,versioning],true}. {[h,<<\"localhost\">>,module_opt,mod_roster,store_current_id],true}. Review configuration Read and double-check your configuration in a different way, after starting MongooseIM: mongooseimctl print_flat_config If MongooseIM does not start because the configuration file is broken in some way: mongooseimctl live Using an XMPP/Jabber client/app The following steps use the registered users on the MongooseIM server, done above. Users that are registered on your server can now add their accounts in a chat application like Gajim (specifying either the server\u2019s IP address or domain name), and start chatting! Connect Gajim Gajim is available on Ubuntu, CentOS & Windows. Warning: Gajim has an obsolete UX. However, it is still well maintained, and has a console that is extremely useful for debugging and testing/validation purposes at the XMPP protocol level. Launch Gajim. Ignore the window with Plugin updates. Go to Edit -> Accounts. Click Add in the left part of the window and select I already have an account I want to use , click Forward Enter the user , domain and password for the accounts registered previously on the command line Click Forward and then Finish Ignore the TLS/SSL error/warning and continue Close the Account window. Add your three created users: alice , bob , and carol . Check what users are currently connected: mongooseimctl connected_users_info Chat with another person Use alice 's account to send messages directly to bob and use bob 's account to reply directly to alice . From the MongooseIM command line: mongooseimctl send_message_chat from to body Examples: mongooseimctl send_message_chat carol@localhost alice@localhost hello mongooseimctl send_message_chat carol@localhost bob@localhost hi Group chats Use alice 's account to create a groupchat channel on your muc.localhost service, and configure it by making it persistent. Invite bob and carol . From bob 's' and carol 's accounts, accept the invitation and join the channel groupchat. All three users exchange messages. Contact lists Use carol 's account to add alice and bob to her contact list. Use alice 's and bob 's accounts accept those additions. Verify on the MongooseIM server: mongooseimctl get_roster user host Examples: mongooseimctl get_roster alice localhost mongooseimctl get_roster bob localhost mongooseimctl get_roster carol localhost Profile (vCard) Edit alice 's profile (vCard) in Gajim: Modify Account... , then Profile , just set her Name to Alice . Verify on the MongooseIM server: mongooseimctl get_vcard alice localhost FN Summary Now you have the minimum knowledge: you know how to deploy MongooseIM, configure some basic features, check/verify a few useful items, validate it both on the client and server side, and utilize a few good practices. Summary: command line You know mongooseimctl , with commands such as: start , restart , stop , status , live , foreground get_loglevel register_identified , check_account , registered_users , unregister add_rosteritem , get_roster print_flat_config You can even run mongooseimctl without arguments for a list of available commands. Summary: files You know basic entries in files: /etc/mongooseim/mongooseim.cfg /var/log/mongooseim/ejabberd.log Summary: client/app In an app, you know how to: connect chat with another user create/join groupchats manage contact lists (roster) edit profile (vCard) Go further For the next steps, we now encourage you to: Deploy it as a single node, on a publicly accessible server, with a real routable domain name with its certificate Add an RDBMS for persistent data, and LDAP for user directory Enable message history with MAM (Message Archive Management) Enable file exchange with HTTP file upload, with an S3-compatible object storage server Use a mobile app for users to chat","title":"Getting started"},{"location":"user-guide/Getting-started/#installation","text":"We recommend, you install mongooseIM binaries from a package Erlang Solutions delivers. Alternatively, check out our tutorial on How to build MongooseIM from source code for an introduction to compiling, building and testing MongooseIM.","title":"Installation"},{"location":"user-guide/Getting-started/#download-a-package","text":"Go to the downloads section of the Erlang Solutions website, and choose the version of MongooseIM you want. The following sections describe the installation process for different operating systems.","title":"Download a package"},{"location":"user-guide/Getting-started/#ubuntu-and-debian","text":"Once the deb file is downloaded, open a terminal window and navigate to the directory containing the package. Use the following command to unpack and install MongooseIM: sudo dpkg -i mongooseim_[version here].deb","title":"Ubuntu and Debian"},{"location":"user-guide/Getting-started/#centos","text":"An ODBC (RDBMS) driver must be installed on your machine to unpack and install from RPM packages. Enter the following command in a terminal window to install the latest unixODBC driver: sudo yum install unixODBC Once the RPM file is downloaded, open a terminal window and navigate to the directory containing the package. Use the following command to unpack and install MongooseIM: sudo rpm -i mongooseim_[version here].rpm","title":"CentOS"},{"location":"user-guide/Getting-started/#running-mongooseim","text":"Warning: MongooseIM will use its default database - Mnesia, which is faster and simpler to setup, but not intended for production purposes when it comes to persistent data. Note: It is possible at anytime to use external databases. For more information see the end of this guide. The following command will start the MongooseIM server: mongooseimctl start When you change the config file and want to restart the MongooseIM server: mongooseimctl restart Use the following command to stop the MongooseIM server: mongooseimctl stop This takes a few seconds. At any given time, the following command shows the status of a MongooseIM server: mongooseimctl status If the command replies nodedown then MongooseIM is not running. Else it will show its status starting , started , or stopping , and its version. When needed, you can also launch the server in the interactive mode: mongooseimctl live This will allow you to better detect and understand the errors in the configuration. When MongooseIM is properly running, the Erlang shell/console is then shown. Just type Control-C twice to exit, the server will then be shut down. For running MongooseIM in a non-interactive way within a supervision system (e.g. systemd), it is recommended to use the foreground mode: mongooseimctl foreground Typing Control-C will stop the server. You can check server loglevel: mongooseimctl get_loglevel","title":"Running MongooseIM"},{"location":"user-guide/Getting-started/#chat-users","text":"","title":"Chat users"},{"location":"user-guide/Getting-started/#registering-creating-users","text":"The default XMPP domain served by MongooseIM right after installation is localhost . You can register (create) users with the mongooseimctl utility. This command registers the user user@domain using password password . mongooseimctl register_identified user domain password Examples: mongooseimctl register_identified alice localhost qwerty mongooseimctl register_identified bob localhost 12345678 mongooseimctl register_identified carol localhost abc123 mongooseimctl register_identified dan localhost dan Warning: The password is entered manually in the command line and history is accessible to the command line users. This method is not recommended for production use, you may prefer for example LDAP. You can check that it has correctly been created: mongooseimctl check_account user host Example: mongooseimctl check_account alice localhost mongooseimctl check_account bob localhost mongooseimctl check_account carol localhost mongooseimctl check_account dan localhost Now you can list all registered users in your host: mongooseimctl registered_users host Example: mongooseimctl registered_users localhost If you want delete users in your host: mongooseimctl unregister user host Example: mongooseimctl unregister dan localhost","title":"Registering (creating) users"},{"location":"user-guide/Getting-started/#populate-the-contact-lists-rosters","text":"Fo a given user ( localuser and localserver ), add a contact ( user and server ): mongooseimctl add_rosteritem localuser localserver user server nick group subs Examples: mongooseimctl add_rosteritem alice localhost bob localhost bob friends both mongooseimctl add_rosteritem bob localhost alice localhost alice friends both Note: The subs parameter is the \"subscription\" to a user's presence. Possible values are: none , from , to , or both . A subscription in both direction means each user will receive each other's presence. Verify the contact list: mongooseimctl get_roster user host Examples: mongooseimctl get_roster alice localhost mongooseimctl get_roster bob localhost mongooseimctl get_roster carol localhost","title":"Populate the contact lists (rosters)"},{"location":"user-guide/Getting-started/#basic-mongooseim-configuration","text":"You can edit the mongooseim.cfg file: /etc/mongooseim/mongooseim.cfg Warning: We recommend you do not touch the advanced settings at this stage. For each change, edit the configuration file using the right Linux/Unix user. Save (and optionally backup, archive, or version) the configuration file and restart the MongooseIM server.","title":"Basic MongooseIM configuration"},{"location":"user-guide/Getting-started/#logging","text":"Change your own loglevel in the configuration file: % {loglevel, 3}. {loglevel, 4}. Save and exit your editor, restart MongooseIM and check your loglevel from the command line: mongooseimctl get_loglevel Read the ejabberd.log file: /var/log/mongooseim/ejabberd.log You can use commands such cat , more or less , even head or tail . In order to see live logs: tail -f /var/log/mongooseim/ejabberd.log Type Ctrl+C to exit.","title":"Logging"},{"location":"user-guide/Getting-started/#muc-multi-user-chat-for-groupchats","text":"Enable MUC, or Multi-User Chat, for groupchats/channels in the mongooseim.cfg file: {mod_muc, [{host, \"muc.@HOST@\"}, {access, muc}, {access_create, muc_create} ]}, Verify with: mongooseimctl print_flat_config | grep muc {[h,<<\"localhost\">>,module,mod_muc_commands],'FLAT'}. {[h,<<\"localhost\">>,module,mod_muc_light_commands],'FLAT'}. {[h,<<\"localhost\">>,module,mod_muc],'FLAT'}. {[h,<<\"localhost\">>,module_opt,mod_muc,host],\"muc.@HOST@\"}. {[h,<<\"localhost\">>,module_opt,mod_muc,access],muc}. {[h,<<\"localhost\">>,module_opt,mod_muc,access_create],muc_create}.","title":"MUC (Multi-User Chat) for groupchats"},{"location":"user-guide/Getting-started/#roster-versioning","text":"For faster contact list downloads at each client/app (re)connection, edit the configuration file: {mod_roster, [ {versioning, true}, {store_current_id, true} ]}, Verify with: mongooseimctl print_flat_config | grep roster [{service_admin_extra,[{submods,[node,accounts,sessions,vcard,gdpr,roster, {[h,<<\"localhost\">>,module,mod_roster],'FLAT'}. {[h,<<\"localhost\">>,module_opt,mod_roster,versioning],true}. {[h,<<\"localhost\">>,module_opt,mod_roster,store_current_id],true}.","title":"Roster versioning"},{"location":"user-guide/Getting-started/#review-configuration","text":"Read and double-check your configuration in a different way, after starting MongooseIM: mongooseimctl print_flat_config If MongooseIM does not start because the configuration file is broken in some way: mongooseimctl live","title":"Review configuration"},{"location":"user-guide/Getting-started/#using-an-xmppjabber-clientapp","text":"The following steps use the registered users on the MongooseIM server, done above. Users that are registered on your server can now add their accounts in a chat application like Gajim (specifying either the server\u2019s IP address or domain name), and start chatting!","title":"Using an XMPP/Jabber client/app"},{"location":"user-guide/Getting-started/#connect-gajim","text":"Gajim is available on Ubuntu, CentOS & Windows. Warning: Gajim has an obsolete UX. However, it is still well maintained, and has a console that is extremely useful for debugging and testing/validation purposes at the XMPP protocol level. Launch Gajim. Ignore the window with Plugin updates. Go to Edit -> Accounts. Click Add in the left part of the window and select I already have an account I want to use , click Forward Enter the user , domain and password for the accounts registered previously on the command line Click Forward and then Finish Ignore the TLS/SSL error/warning and continue Close the Account window. Add your three created users: alice , bob , and carol . Check what users are currently connected: mongooseimctl connected_users_info","title":"Connect Gajim"},{"location":"user-guide/Getting-started/#chat-with-another-person","text":"Use alice 's account to send messages directly to bob and use bob 's account to reply directly to alice . From the MongooseIM command line: mongooseimctl send_message_chat from to body Examples: mongooseimctl send_message_chat carol@localhost alice@localhost hello mongooseimctl send_message_chat carol@localhost bob@localhost hi","title":"Chat with another person"},{"location":"user-guide/Getting-started/#group-chats","text":"Use alice 's account to create a groupchat channel on your muc.localhost service, and configure it by making it persistent. Invite bob and carol . From bob 's' and carol 's accounts, accept the invitation and join the channel groupchat. All three users exchange messages.","title":"Group chats"},{"location":"user-guide/Getting-started/#contact-lists","text":"Use carol 's account to add alice and bob to her contact list. Use alice 's and bob 's accounts accept those additions. Verify on the MongooseIM server: mongooseimctl get_roster user host Examples: mongooseimctl get_roster alice localhost mongooseimctl get_roster bob localhost mongooseimctl get_roster carol localhost","title":"Contact lists"},{"location":"user-guide/Getting-started/#profile-vcard","text":"Edit alice 's profile (vCard) in Gajim: Modify Account... , then Profile , just set her Name to Alice . Verify on the MongooseIM server: mongooseimctl get_vcard alice localhost FN","title":"Profile (vCard)"},{"location":"user-guide/Getting-started/#summary","text":"Now you have the minimum knowledge: you know how to deploy MongooseIM, configure some basic features, check/verify a few useful items, validate it both on the client and server side, and utilize a few good practices.","title":"Summary"},{"location":"user-guide/Getting-started/#summary-command-line","text":"You know mongooseimctl , with commands such as: start , restart , stop , status , live , foreground get_loglevel register_identified , check_account , registered_users , unregister add_rosteritem , get_roster print_flat_config You can even run mongooseimctl without arguments for a list of available commands.","title":"Summary: command line"},{"location":"user-guide/Getting-started/#summary-files","text":"You know basic entries in files: /etc/mongooseim/mongooseim.cfg /var/log/mongooseim/ejabberd.log","title":"Summary: files"},{"location":"user-guide/Getting-started/#summary-clientapp","text":"In an app, you know how to: connect chat with another user create/join groupchats manage contact lists (roster) edit profile (vCard)","title":"Summary: client/app"},{"location":"user-guide/Getting-started/#go-further","text":"For the next steps, we now encourage you to: Deploy it as a single node, on a publicly accessible server, with a real routable domain name with its certificate Add an RDBMS for persistent data, and LDAP for user directory Enable message history with MAM (Message Archive Management) Enable file exchange with HTTP file upload, with an S3-compatible object storage server Use a mobile app for users to chat","title":"Go further"},{"location":"user-guide/How-to-build/","text":"How to build MongooseIM Instructions provided in this page are verified for: CentOS 7 Ubuntu 16.04 LTS (Xenial) Ubuntu 18.04 LTS (Bionic) macOS 10.14 (Mojave) For any other OS versions, the instructions should still work, however, some steps or file paths may be different. Requirements To compile MongooseIM you need: Make CentOS: make Ubuntu: make Mac: Xcode Command Line Tools C and C++ compiler CentOS: gcc , gcc-c++ Ubuntu: gcc , g++ Mac: Xcode Command Line Tools Erlang/OTP 21.2 or higher; Versions 20.0-21.1 work as well but they are deprecated. The next MIM release won't support them. CentOS: erlang Ubuntu: erlang Mac (Homebrew): erlang Alternative for CentOS and Ubuntu: esl-erlang from Erlang Solutions website Alternative for all OS: kerl OpenSSL 0.9.8 or higher, for STARTTLS, SASL and SSL encryption CentOS: openssl-devel Ubuntu: libssl-dev Mac (Homebrew): openssl ODBC library CentOS: unixODBC-devel Ubuntu: unixodbc-dev Mac (Homebrew): unixodbc Zlib 1.2.3 or higher CentOS: zlib-devel Ubuntu: zlib1g-dev Mac: built-in Preparing macOS environment Step 1 Install Homebrew to manage packages on your Mac. You may use a different package manager but you'll need to figure out the package names and file paths on your own. Step 2 Install Xcode Command Line Tools. $ xcode-select --install # install compilation tools Step 3 Install dependencies with Brew. $ brew install erlang openssl unixodbc Step 4 Add OpenSSL paths to the compiler and linker environment variables: $ export LDFLAGS=\"-L/usr/local/Cellar/openssl/[installed version]/lib/ -undefined dynamic_lookup $LDFLAGS\" $ export CFLAGS=\"-I/usr/local/Cellar/openssl/[installed version]/include/ $CFLAGS\" Please remember to replace [installed version] with the one that is present in your file system. 1.0.2s was the most recent one when this guide was written. Now, please proceed to the \"Building\" section. Preparing CentOS environment Please install the required dependencies: $ sudo yum install git make zlib-devel unixODBC-devel gcc gcc-c++ erlang Now, please proceed to the \"Building\" section. Preparing Ubuntu environment Please install the required dependencies: $ sudo apt install git make zlib1g-dev unixodbc-dev gcc g++ erlang Now, please proceed to the \"Building\" section. Building To compile MongooseIM, navigate to the main repo directory (referenced as $REPO in this guide) and execute: $ make [rel] rel is optional as it is the default target. This will download all dependencies, compile everything and build a prod release. If a more advanced release is required (with only specific DB support, e.g. mysql or pgsql) or you want to set the prefix or user for the installation script please refer to the release configuration page in our documentation. The make rel commands will generate a self-contained OTP system structure in the project's _build/prod/rel/mongooseim subdirectory. The contents of that directory are as follows: bin - startup/administration scripts, etc - configuration files, lib - MongooseIM binary, header and runtime files, var - spool directory, log - log file directory, releases - release files directory. Running MongooseIM To run MongooseIM from the project tree after compiling it, change to $REPO/_build/prod/rel/mongooseim . There you can use the mongooseim command line administration script to start and stop MongooseIM. For example, this command will start the server: $ bin/mongooseim start You can also run the server in interactive mode (drop into an Erlang shell): $ bin/mongooseim live There's also a tool called mongooseimctl to perform some operations on a running instance, e.g.: $ bin/mongooseimctl status MongooseIM node mongooseim@localhost: operating system pid: 3105 Erlang VM status: started (of: starting | started | stopping) boot script status: started version: 3.4.0-7-gaec944c92 (as mongooseim) uptime: 0 days 00:00:12 distribution protocol: inet_tcp logs: log/ejabberd.log Building the testing target and running tests For testing purposes there's a different make target available: $ make devrel which will generate releases mim1 , mim2 , mim3 , fed1 , reg1 in $REPO/_build/ and prepare them for testing and generating coverage reports. In order to learn how to execute tests, please consult Testing MongooseIM page","title":"How to Build MongooseIM from source code"},{"location":"user-guide/How-to-build/#how-to-build-mongooseim","text":"Instructions provided in this page are verified for: CentOS 7 Ubuntu 16.04 LTS (Xenial) Ubuntu 18.04 LTS (Bionic) macOS 10.14 (Mojave) For any other OS versions, the instructions should still work, however, some steps or file paths may be different.","title":"How to build MongooseIM"},{"location":"user-guide/How-to-build/#requirements","text":"To compile MongooseIM you need: Make CentOS: make Ubuntu: make Mac: Xcode Command Line Tools C and C++ compiler CentOS: gcc , gcc-c++ Ubuntu: gcc , g++ Mac: Xcode Command Line Tools Erlang/OTP 21.2 or higher; Versions 20.0-21.1 work as well but they are deprecated. The next MIM release won't support them. CentOS: erlang Ubuntu: erlang Mac (Homebrew): erlang Alternative for CentOS and Ubuntu: esl-erlang from Erlang Solutions website Alternative for all OS: kerl OpenSSL 0.9.8 or higher, for STARTTLS, SASL and SSL encryption CentOS: openssl-devel Ubuntu: libssl-dev Mac (Homebrew): openssl ODBC library CentOS: unixODBC-devel Ubuntu: unixodbc-dev Mac (Homebrew): unixodbc Zlib 1.2.3 or higher CentOS: zlib-devel Ubuntu: zlib1g-dev Mac: built-in","title":"Requirements"},{"location":"user-guide/How-to-build/#preparing-macos-environment","text":"","title":"Preparing macOS environment"},{"location":"user-guide/How-to-build/#step-1","text":"Install Homebrew to manage packages on your Mac. You may use a different package manager but you'll need to figure out the package names and file paths on your own.","title":"Step 1"},{"location":"user-guide/How-to-build/#step-2","text":"Install Xcode Command Line Tools. $ xcode-select --install # install compilation tools","title":"Step 2"},{"location":"user-guide/How-to-build/#step-3","text":"Install dependencies with Brew. $ brew install erlang openssl unixodbc","title":"Step 3"},{"location":"user-guide/How-to-build/#step-4","text":"Add OpenSSL paths to the compiler and linker environment variables: $ export LDFLAGS=\"-L/usr/local/Cellar/openssl/[installed version]/lib/ -undefined dynamic_lookup $LDFLAGS\" $ export CFLAGS=\"-I/usr/local/Cellar/openssl/[installed version]/include/ $CFLAGS\" Please remember to replace [installed version] with the one that is present in your file system. 1.0.2s was the most recent one when this guide was written. Now, please proceed to the \"Building\" section.","title":"Step 4"},{"location":"user-guide/How-to-build/#preparing-centos-environment","text":"Please install the required dependencies: $ sudo yum install git make zlib-devel unixODBC-devel gcc gcc-c++ erlang Now, please proceed to the \"Building\" section.","title":"Preparing CentOS environment"},{"location":"user-guide/How-to-build/#preparing-ubuntu-environment","text":"Please install the required dependencies: $ sudo apt install git make zlib1g-dev unixodbc-dev gcc g++ erlang Now, please proceed to the \"Building\" section.","title":"Preparing Ubuntu environment"},{"location":"user-guide/How-to-build/#building","text":"To compile MongooseIM, navigate to the main repo directory (referenced as $REPO in this guide) and execute: $ make [rel] rel is optional as it is the default target. This will download all dependencies, compile everything and build a prod release. If a more advanced release is required (with only specific DB support, e.g. mysql or pgsql) or you want to set the prefix or user for the installation script please refer to the release configuration page in our documentation. The make rel commands will generate a self-contained OTP system structure in the project's _build/prod/rel/mongooseim subdirectory. The contents of that directory are as follows: bin - startup/administration scripts, etc - configuration files, lib - MongooseIM binary, header and runtime files, var - spool directory, log - log file directory, releases - release files directory.","title":"Building"},{"location":"user-guide/How-to-build/#running-mongooseim","text":"To run MongooseIM from the project tree after compiling it, change to $REPO/_build/prod/rel/mongooseim . There you can use the mongooseim command line administration script to start and stop MongooseIM. For example, this command will start the server: $ bin/mongooseim start You can also run the server in interactive mode (drop into an Erlang shell): $ bin/mongooseim live There's also a tool called mongooseimctl to perform some operations on a running instance, e.g.: $ bin/mongooseimctl status MongooseIM node mongooseim@localhost: operating system pid: 3105 Erlang VM status: started (of: starting | started | stopping) boot script status: started version: 3.4.0-7-gaec944c92 (as mongooseim) uptime: 0 days 00:00:12 distribution protocol: inet_tcp logs: log/ejabberd.log","title":"Running MongooseIM"},{"location":"user-guide/How-to-build/#building-the-testing-target-and-running-tests","text":"For testing purposes there's a different make target available: $ make devrel which will generate releases mim1 , mim2 , mim3 , fed1 , reg1 in $REPO/_build/ and prepare them for testing and generating coverage reports. In order to learn how to execute tests, please consult Testing MongooseIM page","title":"Building the testing target and running tests"},{"location":"user-guide/ICE_tutorial/","text":"How to set up MongooseICE (ICE/TURN/STUN server) Introduction Who is this document for? This tutorial presents our TURN/STUN server in action. You get to see how to set up and configure MongooseICE and examine a system utilising its many talents. Are you in need of an application requiring NAT traversal? Want to see how a TURN and STUN server would handle it? Or maybe you just like to tinker with interesting technologies and experience setting them up first hand? If that's the case, this tutorial is for you. What is the end result of this tutorial? At the end of the tutorial you will have a working environment with two peers, one sending a live video to another. The peer-to-peer communication will not be obstructed by any NATs that may occur in the background. The live video stream is only an example here - there are many possible use cases for peer-to-peer communication with NAT traversal. We chose to build an example application that shows video streaming, because it's vivid, catchy and fun. What do I need to begin? Before you begin you have to prepare an environment for setting up the components used in this tutorial. Here's a list of things you'll need: * One Android phone (or at least an Android emulator). The video player in this tutorial is available only as an Android application. * RaspberryPi or any other device that is able to run Elixir code . Oh, and also has ffmpeg installed. We are going to use use RaspberryPi 3, to give this tutorial a hint of IoT. * At least one machine with a public IPv4 address. It is necessary, because both MongooseIM and MongooseICE servers need to be accessible by all devices that are used in this demo system. You could use a private, local IP address, but then you would need to ensure that your phone and the RaspberryPi are behind some kind of a NAT relative to this IP address. Note: the demo will probably work without the NAT, but then there is no point in setting up a TURN server. We are going to use 2 VPS (Virtual Private Server) that are located somewhere far far away, both having public IPv4 address. Let's say MongooseICE is bound to 1.1.1.1 , and MongooseIM to 2.2.2.2 . General architecture of the environment built with this tutorial This is the architecture of the system we are building: As we know by now, MongooseIM is bound to 2.2.2.2 / myxmpp.com and MongooseICE to 1.1.1.1 . We also have a RaspberryPi that is connected to a private network (so is behind some NAT) and an Android phone that is connected to an LTE network and also is behind the carrier's NAT. ICE notes The end result of this tutorial not only uses MongooseICE and MongooseIM servers but also uses custom version of Mangosta-Android and [DemoStreamerICE]. Both projects are custom modified and custom made respectively in order to showcase the video streaming using the data relay capabilities provided by MongooseICE . The streaming itself, along with the signalling protocol, were prepared only for the case of this demo and are not a part of the platform . Those components exist only to visualize what can be achieved with MongooseICE and what can be built on top of it. Setting up MongooseIM (signalling) The ICE is nothing without signalling. The signalling protocol itself can be designed specifically for the application that is being deployed or can be implemented based on some standards, e.g. Jingle . Here, we chose to implement the simplest signalling possible, i.e. sending relay addresses via XMPP messages. No matter if we decide to go with this approach or with Jingle , we can use the MongooseIM XMPP server as a transport layer for the signalling. In order to enable signalling we need an instance of MongooseIM running with the simplest configuration, since the only thing we need from it is to provide us with means to communicate between two peers. Configuration You can find MongooseIM installation instructions on this page . Once you have cloned the repository and compiled the project, you need to modify the mongooseim.cfg config file (you can find this file at $REPO/_build/prod/rel/mongooseim/etc/mongooseim.cfg , where $REPO is a top-level directory of the cloned repo). You can use this configuration file and modify the relevant part: %%%% ICE DEMO %%%% {hosts, [\"localhost\", \"myxmpp.com\"] }. This sets the virtual hostname of the XMPP server, so that you can register users in this domain. After that, you can start MongooseIM with $REPO/_build/prod/rel/mongooseim/bin/mongooseimctl start Users After we finish setting up MongooseIM , we need to register some users. For this demo we need two users: movie@myxmpp.com and phone@myxmpp.com , for RaspberryPi and the Android phone respectively. In order to do that, type: $REPO/_build/prod/rel/mongooseim/bin/mongooseimctl register_identified phone myxmpp.com xmpp_password $REPO/_build/prod/rel/mongooseim/bin/mongooseimctl register_identified movie myxmpp.com xmpp_password on the machine that has MongooseIM installed. As you can see here, we have created those two users, both with the password xmpp_password for simplicity. Setting up MongooseICE (TURN/STUN server) Now, since MongooseIM handles the signalling, we need the TURN relay and the STUN server to send peer-to-peer data. For that we are going to use the star of this tutorial - MongooseICE . How to get and configure The whole documentation that describes all options and deployment methods, can be found on the project's github page . Let's get to it! (this command assumes that we are on the server for MongooseICE and that it has Docker installed): docker run -it --net=host -e \"MONGOOSEICE_UDP_RELAY_IP=1.1.1.1\" -e \"MONGOOSEICE_STUN_SECRET=secret\" -e \"MONGOOSEICE_UDP_REALM=myrelay\" mongooseim/mongooseice:0.4.0 This command starts the MongooseICE server in the Docker container, attaching its virtual network interface to the network interface of the host machine the Docker deamon is running on. There are three important configuration options we have to set via environment variables: MONGOOSEICE_UDP_RELAY_IP - This is the IP address that MongooseICE provides data relay on. This should be set to public IPv4 address. MONGOOSEICE_STUN_SECRET - This is a secret password that TURN clients need to provide to connect to this server. MONGOOSEICE_UDP_REALM - This is just a name for your TURN relay. And that's it! MongooseICE is now ready to roll! Setting up Mangosta-Android How to get and install The source code of the video-stream-demo-enabled Mangosta-Android can be found on the ice_demo_kt branch. If you want to tinker with it and compile it yourself, you can do that. All you need is Android Studio 2.3+ . The compilation is pretty straightforward, so I'm not going to explain it here. If you are interested in how it works, most of the code is in the inaka.com.mangosta.videostream package. If you don't want to compile this application from source, you can just install this .apk on your phone and that's it. How to configure Right after you start Mangosta-Android for the first time, you will need to login to your XMPP server. In order to do that, just enter the JID you have created for the phone ( phone@myxmpp.com ), the password ( xmpp_password ) and the server address ( 2.2.2.2 or myxmpp.com if you've set up the domain to actually point to this IP address), and then confirm by clicking \"Enter\". After we log in, we can start setting up the connection to the MongooseICE server we set up before. The process is shown on the screenshots below. On the \" Configure ICE \" screen we have to set 5 fields up: TURN server address - IPv4 address of our MongooseICE TURN Server port - since we did not set the port while configuring MongooseICE it uses a default one - 3478 TURN Realm - Realm name we have set via MONGOOSEICE_UDP_REALM variable. In our case it's \" myrelay \". TURN username - Current version of MongooseICE ignores this, so you may leave it as is. TURN password - The password that we have set via MONGOOSEICE_STUN_SECRET variable. In our case it's \" secret \" And that would be all. Now you can click \" TEST CONNECTION \" to, well..., test the connection. If everything works, you can \" SAVE \" the settings. Now your Mangosta-Android is ready to play streamed video, but we still need the source... Setting up RaspberryPi Let's configure the video source now. In our case it will be a RaspberryPi with Elixir and ffmpeg installed running our ICE demo application . The software For this demo we provide a simple XMPP client that also is able to send live video stream using ffmpeg whenever other peer asks for it via XMPP. This client is written in Elixir , so we can run it from source quite easily. How to get and configure You can get the client's sources here . For now we only need to run it, so let's get to it (on our RaspberryPi): git clone https://github.com/esl/ice_demo.git cd ice_demo mix deps.get iex -S mix After a while we should get into Elixir shell. In order to enable the streamer, we need to start it, providing some configuration options (in the Elixir shell): opts = [ jid: \"movie@myxmpp.com\", password: \"xmpp_password\", host: \"myxmpp.com\", turn_addr: \"1.1.1.1:3784\" turn_username: \"username\", turn_secret: \"secret\", video_file: \"/home/pi/sintel.h264\" ] ICEDemo.start_movie(opts) The first 3 options are all about connecting to the XMPP server - we use \" movie@myxmpp.com \" user that we created earlier. Next 3 options are about connecting to the MongooseICE server. Those are similar to ones we set in Mangosta-Android . The last one points to the video file that will be streamed on request. This file has to be raw, H.264-encoded, video-only file. If you are not sure how to get one, you can just use this one (pre-rendered Sintel, OpenBlender project ). With this configuration, our RaspberryPi is ready to stream! The end result Playing the video Now we finally can get out phone and start streaming the video! In order to do that, we have to click the \" New video stream \" button as shown on the screenshots below, enter the JID of the RaspberryPi and confirm with the \" Stream! \" button. Hopefully, now you can see the video on your own mobile device.","title":"How to Set up MongooseICE"},{"location":"user-guide/ICE_tutorial/#how-to-set-up-mongooseice-iceturnstun-server","text":"","title":"How to set up MongooseICE (ICE/TURN/STUN server)"},{"location":"user-guide/ICE_tutorial/#introduction","text":"","title":"Introduction"},{"location":"user-guide/ICE_tutorial/#who-is-this-document-for","text":"This tutorial presents our TURN/STUN server in action. You get to see how to set up and configure MongooseICE and examine a system utilising its many talents. Are you in need of an application requiring NAT traversal? Want to see how a TURN and STUN server would handle it? Or maybe you just like to tinker with interesting technologies and experience setting them up first hand? If that's the case, this tutorial is for you.","title":"Who is this document for?"},{"location":"user-guide/ICE_tutorial/#what-is-the-end-result-of-this-tutorial","text":"At the end of the tutorial you will have a working environment with two peers, one sending a live video to another. The peer-to-peer communication will not be obstructed by any NATs that may occur in the background. The live video stream is only an example here - there are many possible use cases for peer-to-peer communication with NAT traversal. We chose to build an example application that shows video streaming, because it's vivid, catchy and fun.","title":"What is the end result of this tutorial?"},{"location":"user-guide/ICE_tutorial/#what-do-i-need-to-begin","text":"Before you begin you have to prepare an environment for setting up the components used in this tutorial. Here's a list of things you'll need: * One Android phone (or at least an Android emulator). The video player in this tutorial is available only as an Android application. * RaspberryPi or any other device that is able to run Elixir code . Oh, and also has ffmpeg installed. We are going to use use RaspberryPi 3, to give this tutorial a hint of IoT. * At least one machine with a public IPv4 address. It is necessary, because both MongooseIM and MongooseICE servers need to be accessible by all devices that are used in this demo system. You could use a private, local IP address, but then you would need to ensure that your phone and the RaspberryPi are behind some kind of a NAT relative to this IP address. Note: the demo will probably work without the NAT, but then there is no point in setting up a TURN server. We are going to use 2 VPS (Virtual Private Server) that are located somewhere far far away, both having public IPv4 address. Let's say MongooseICE is bound to 1.1.1.1 , and MongooseIM to 2.2.2.2 .","title":"What do I need to begin?"},{"location":"user-guide/ICE_tutorial/#general-architecture-of-the-environment-built-with-this-tutorial","text":"This is the architecture of the system we are building: As we know by now, MongooseIM is bound to 2.2.2.2 / myxmpp.com and MongooseICE to 1.1.1.1 . We also have a RaspberryPi that is connected to a private network (so is behind some NAT) and an Android phone that is connected to an LTE network and also is behind the carrier's NAT.","title":"General architecture of the environment built with this tutorial"},{"location":"user-guide/ICE_tutorial/#ice-notes","text":"The end result of this tutorial not only uses MongooseICE and MongooseIM servers but also uses custom version of Mangosta-Android and [DemoStreamerICE]. Both projects are custom modified and custom made respectively in order to showcase the video streaming using the data relay capabilities provided by MongooseICE . The streaming itself, along with the signalling protocol, were prepared only for the case of this demo and are not a part of the platform . Those components exist only to visualize what can be achieved with MongooseICE and what can be built on top of it.","title":"ICE notes"},{"location":"user-guide/ICE_tutorial/#setting-up-mongooseim-signalling","text":"The ICE is nothing without signalling. The signalling protocol itself can be designed specifically for the application that is being deployed or can be implemented based on some standards, e.g. Jingle . Here, we chose to implement the simplest signalling possible, i.e. sending relay addresses via XMPP messages. No matter if we decide to go with this approach or with Jingle , we can use the MongooseIM XMPP server as a transport layer for the signalling. In order to enable signalling we need an instance of MongooseIM running with the simplest configuration, since the only thing we need from it is to provide us with means to communicate between two peers.","title":"Setting up MongooseIM (signalling)"},{"location":"user-guide/ICE_tutorial/#configuration","text":"You can find MongooseIM installation instructions on this page . Once you have cloned the repository and compiled the project, you need to modify the mongooseim.cfg config file (you can find this file at $REPO/_build/prod/rel/mongooseim/etc/mongooseim.cfg , where $REPO is a top-level directory of the cloned repo). You can use this configuration file and modify the relevant part: %%%% ICE DEMO %%%% {hosts, [\"localhost\", \"myxmpp.com\"] }. This sets the virtual hostname of the XMPP server, so that you can register users in this domain. After that, you can start MongooseIM with $REPO/_build/prod/rel/mongooseim/bin/mongooseimctl start","title":"Configuration"},{"location":"user-guide/ICE_tutorial/#users","text":"After we finish setting up MongooseIM , we need to register some users. For this demo we need two users: movie@myxmpp.com and phone@myxmpp.com , for RaspberryPi and the Android phone respectively. In order to do that, type: $REPO/_build/prod/rel/mongooseim/bin/mongooseimctl register_identified phone myxmpp.com xmpp_password $REPO/_build/prod/rel/mongooseim/bin/mongooseimctl register_identified movie myxmpp.com xmpp_password on the machine that has MongooseIM installed. As you can see here, we have created those two users, both with the password xmpp_password for simplicity.","title":"Users"},{"location":"user-guide/ICE_tutorial/#setting-up-mongooseice-turnstun-server","text":"Now, since MongooseIM handles the signalling, we need the TURN relay and the STUN server to send peer-to-peer data. For that we are going to use the star of this tutorial - MongooseICE .","title":"Setting up MongooseICE (TURN/STUN server)"},{"location":"user-guide/ICE_tutorial/#how-to-get-and-configure","text":"The whole documentation that describes all options and deployment methods, can be found on the project's github page . Let's get to it! (this command assumes that we are on the server for MongooseICE and that it has Docker installed): docker run -it --net=host -e \"MONGOOSEICE_UDP_RELAY_IP=1.1.1.1\" -e \"MONGOOSEICE_STUN_SECRET=secret\" -e \"MONGOOSEICE_UDP_REALM=myrelay\" mongooseim/mongooseice:0.4.0 This command starts the MongooseICE server in the Docker container, attaching its virtual network interface to the network interface of the host machine the Docker deamon is running on. There are three important configuration options we have to set via environment variables: MONGOOSEICE_UDP_RELAY_IP - This is the IP address that MongooseICE provides data relay on. This should be set to public IPv4 address. MONGOOSEICE_STUN_SECRET - This is a secret password that TURN clients need to provide to connect to this server. MONGOOSEICE_UDP_REALM - This is just a name for your TURN relay. And that's it! MongooseICE is now ready to roll!","title":"How to get and configure"},{"location":"user-guide/ICE_tutorial/#setting-up-mangosta-android","text":"","title":"Setting up Mangosta-Android"},{"location":"user-guide/ICE_tutorial/#how-to-get-and-install","text":"The source code of the video-stream-demo-enabled Mangosta-Android can be found on the ice_demo_kt branch. If you want to tinker with it and compile it yourself, you can do that. All you need is Android Studio 2.3+ . The compilation is pretty straightforward, so I'm not going to explain it here. If you are interested in how it works, most of the code is in the inaka.com.mangosta.videostream package. If you don't want to compile this application from source, you can just install this .apk on your phone and that's it.","title":"How to get and install"},{"location":"user-guide/ICE_tutorial/#how-to-configure","text":"Right after you start Mangosta-Android for the first time, you will need to login to your XMPP server. In order to do that, just enter the JID you have created for the phone ( phone@myxmpp.com ), the password ( xmpp_password ) and the server address ( 2.2.2.2 or myxmpp.com if you've set up the domain to actually point to this IP address), and then confirm by clicking \"Enter\". After we log in, we can start setting up the connection to the MongooseICE server we set up before. The process is shown on the screenshots below. On the \" Configure ICE \" screen we have to set 5 fields up: TURN server address - IPv4 address of our MongooseICE TURN Server port - since we did not set the port while configuring MongooseICE it uses a default one - 3478 TURN Realm - Realm name we have set via MONGOOSEICE_UDP_REALM variable. In our case it's \" myrelay \". TURN username - Current version of MongooseICE ignores this, so you may leave it as is. TURN password - The password that we have set via MONGOOSEICE_STUN_SECRET variable. In our case it's \" secret \" And that would be all. Now you can click \" TEST CONNECTION \" to, well..., test the connection. If everything works, you can \" SAVE \" the settings. Now your Mangosta-Android is ready to play streamed video, but we still need the source...","title":"How to configure"},{"location":"user-guide/ICE_tutorial/#setting-up-raspberrypi","text":"Let's configure the video source now. In our case it will be a RaspberryPi with Elixir and ffmpeg installed running our ICE demo application .","title":"Setting up RaspberryPi"},{"location":"user-guide/ICE_tutorial/#the-software","text":"For this demo we provide a simple XMPP client that also is able to send live video stream using ffmpeg whenever other peer asks for it via XMPP. This client is written in Elixir , so we can run it from source quite easily.","title":"The software"},{"location":"user-guide/ICE_tutorial/#how-to-get-and-configure_1","text":"You can get the client's sources here . For now we only need to run it, so let's get to it (on our RaspberryPi): git clone https://github.com/esl/ice_demo.git cd ice_demo mix deps.get iex -S mix After a while we should get into Elixir shell. In order to enable the streamer, we need to start it, providing some configuration options (in the Elixir shell): opts = [ jid: \"movie@myxmpp.com\", password: \"xmpp_password\", host: \"myxmpp.com\", turn_addr: \"1.1.1.1:3784\" turn_username: \"username\", turn_secret: \"secret\", video_file: \"/home/pi/sintel.h264\" ] ICEDemo.start_movie(opts) The first 3 options are all about connecting to the XMPP server - we use \" movie@myxmpp.com \" user that we created earlier. Next 3 options are about connecting to the MongooseICE server. Those are similar to ones we set in Mangosta-Android . The last one points to the video file that will be streamed on request. This file has to be raw, H.264-encoded, video-only file. If you are not sure how to get one, you can just use this one (pre-rendered Sintel, OpenBlender project ). With this configuration, our RaspberryPi is ready to stream!","title":"How to get and configure"},{"location":"user-guide/ICE_tutorial/#the-end-result","text":"","title":"The end result"},{"location":"user-guide/ICE_tutorial/#playing-the-video","text":"Now we finally can get out phone and start streaming the video! In order to do that, we have to click the \" New video stream \" button as shown on the screenshots below, enter the JID of the RaspberryPi and confirm with the \" Stream! \" button. Hopefully, now you can see the video on your own mobile device.","title":"Playing the video"},{"location":"user-guide/Jingle-SIP-setup/","text":"Jingle/SIP setup proof of concept This tutorial will show you how to configure MongooseIM, Routr (a SIP server) and client applications to demonstrate how the Jingle/SIP integration works. Prerequisites We are going to use the following open source software: MongooseIM - https://github.com/esl/MongooseIM see How-to-build for details on building. It's important to remember to run the configuration script with with-jingle-sip flag set: tools/configure with-jingle-sip . Without this, third party dependencies required by the Jingle/SIP translator will not be included in the release. Routr (SIP server) - https://routr.io I recommend downloading binaries for your system from https://routr.io/docs/getting-started-installation.html Jitsi (XMPP and SIP client application) - https://desktop.jitsi.org Otalk - web based XMPP client - https://github.com/otalk/otalk-im-client Folow the instructions on otalk-im-client#installing to run it We will use 2 users xmpp.user@xmpp.example and sip.user@sip.example . Configuring Routr First the domain sip.example needs to be added to domains served by Routr. To do it, paste the following content to config/domains.yml in the directory where Routr was: - apiVersion: v1beta1 kind: Domain metadata: name: SIP domain spec: context: domainUri: sip.example Then the sip.user@sip.example needs to be added to config/agents.yml like below: - apiVersion: v1beta1 kind: Agent metadata: name: SIP User spec: credentials: username: 'sip.user' secret: '1234' domains: [sip.example] Now Routr can be started with ./routr If all goes well we'll see the following output: [INFO ] Starting Routr [INFO ] Listening on 10.152.1.27:5060 [udp] [INFO ] Listening on 10.152.1.27:5060 [tcp] [INFO ] Starting Location service [INFO ] Starting Registry service [INFO ] Starting Restful service (port: 4567, apiPath: '/api/v1beta1') It is important to remember the IP address as it'll be used in next point. A side note In Routr's logs you may see messages like [WARN ] Unable to register with Gateway -> sip.provider.net. (Verify your network status) or [ERROR] java.lang.RuntimeException: javax.sip.header.TooManyHopsException: has already reached 0! They can be ignored for the purpose of the tutorial. Configuring /etc/hosts In my case the IP reported by Routr was 10.152.1.27 . Now we need to use this to update /etc/hosts file like below: 10.152.1.27 sip.example xmpp.example Configuring MongooseIM At this point I assume that MongooseIM was built with make rel , that it is running and the current working directory is _build/prod/rel/mongooseim . Similar to Routr, MongooseIM also needs to know which hosts to server. Please replace the default host defined in etc/mongooseim.cfg ; the line: {hosts, [\"localhost\"] }. should be changed to: {hosts, [\"xmpp.example\", \"sip.example\"] }. Now we need to enable mod_jingle_sip , please add the following line in modules list (somewhere around line 740 in the same file) {mod_jingle_sip, [{proxy_host, \"sip.example\"}]}, More details on MongooseIM configuration you can find in Basic Configuration and in Modules configuration Now we are registering both users in MongooseIM by calling the following commands: bin/mongooseimctl register_identified xmpp.user xmpp.example test_pass bin/mongooseimctl register_identified sip.user sip.example test_pass Yes, we need to have the sip.user@sip.example registered in MongooseIM. This is needed because a Jingle call can be initiated by a regular XMPP client only when the app knows the other user's full JID. The easiest way to achieve that is to exchange presence information between these 2 users. This can happen automatically if 2 xmpp users have each other in the roster. The roster can be set by us with the following commands: bin/mongooseimctl add_rosteritem sip.user sip.example xmpp.user xmpp.example xmpp.user none both bin/mongooseimctl add_rosteritem xmpp.user xmpp.example sip.user sip.example sip.user none both Adding users to Jitsi Now the sip.user@sip.example has to be added to Jitsi app. When the app is opened for the first time it will display a window to configure the user. Later users can be configured from the Preferences page. Adding a SIP user In order to add a user who connects to the SIP server we need to choose the SIP protocol from the available networks in Jitsi. In the SIP id field we put sip.user@sip.example and in the Password field we put 1234 as in the agents.yml file. Now we need to switch to Advanced options and go to the Connection tab. Here we need to unselect the Configure proxy automatically and put the IP of our Routr server, port number 5060 and TCP as the preferred transport. Adding an XMPP user Now we have to add sip.user@sip.example to Jitsi's XMPP network in order to connect this user to MongooseIM over XMPP. It's very similar to adding a user to Jitsi's SIP network, the only difference is the password, for the XMPP conection it's test_pass as set when registering the user in MongooseIM. Here we also need to go to the Advanced window and the Connection tab in order to put the IP addres (the same as before) in the Connect Server field. Remember to check the Override server default options box. To connect sip.user@sip.exmple to MongooseIM over XMPP is to cheat Jingle a bit, so that the client app for user sip.xmpp@xmpp.example can start the Jingle call. When Jitsi connects this user, it will likely display a warning about the server's certificate. This is because by default MongooseIM is configured with a freshly generated, self-signed certificate. We can click Continue anyway button in order to proceed. Adding user to Otalk Please follow the instructiond on https://github.com/otalk/otalk-im-client#installing in order to compile and run the app. If all goes well, you should see the following message printed in the console: demo.stanza.io running at: http://localhost:8000 This means that the app is hosted on http://localhost:8000 . At this point I also recommend opening https://localhost:5285/ws-xmpp in the same browser. This endpoint works correctly only for WebSocket connections but most probably you will be prompted about the certificate. This is again due to the self-signed certificate. We need to add an exception for this certificate in order to successfully connect from Otalk. Now let's open http://localhost:8000 where the Otalk app is hosted. In the Log in section put xmpp.user@xmpp.example in the JID field and test_pass in the Password filed. The default WebSocket endpoint in the WebSocket or BOSH URL field needs to be changed to: wss://localhost:5285/ws-xmpp Mind the wss protocol, Otalk will not connect the user over WebSockets if for example https is put in the field. Now we can hit the Go! button and the xmpp.user@xmpp.example will connect to MongooseIM. Making a call On the left side we can see that the user already has sip.user@sip.example in the roster and there should be a green dot indicating that the user is online. When we click on the contact, the Call button should appear allowing us to initiate the call. In Jitsi, the following window should pop up: Behind the scene the following SIP request was send from MongooseIM to Routr. INVITE sip:sip.user@sip.example:5060 SIP/2.0 Via: SIP/2.0/TCP localhost:5600;rport;branch=z9hG4bK1HMB3o-3mbahM From: xmpp.user <sip:xmpp.user@xmpp.example>;tag=aVEBue To: sip.user <sip:sip.user@sip.example> Call-ID: ae602f16-d57d-4452-b83e-36e54bb6d325 CSeq: 159913767 INVITE Max-Forwards: 70 Content-Length: 2243 Contact: <sip:xmpp.user@localhost:5600;ob;transport=tcp>;+sip.instance=\"<urn:uuid:f45950f1-70cd-229d-6c2b-8c85903ce14e>\" Content-Type: application/sdp Supported: outbound,100rel,path Allow: PRACK,INVITE,ACK,CANCEL,BYE,OPTIONS,INFO,UPDATE,SUBSCRIBE,NOTIFY,REFER,MESSAGE v=0 o=- 1531401304 1531401304 IN IP4 127.0.0.1 s=nksip c=IN IP4 127.0.0.1 t=0 0 a=group:BUNDLE sdparta_0 sdparta_1 m=audio 1436 UDP/TLS/RTP/SAVPF 109 9 0 8 101 a=sendrecv a=mid:sdparta_0 a=setup:actpass a=fingerprint:sha-256 44:84:41:8F:B7:A3:B7:37:BA:00:26:5E:B1:D6:AB:D0:56:56:CF:53:F2:05:DB:99:DE:D4:1C:63:A4:68:58:EA a=ice-pwd:49ad0f02b4f5181c9af3c4006575e071 a=ice-ufrag:a3cc96e2 a=rtcp-mux a=extmap:3 urn:ietf:params:rtp-hdrext:sdes:mid a=extmap:2/recvonly urn:ietf:params:rtp-hdrext:csrc-audio-level a=extmap:1 urn:ietf:params:rtp-hdrext:ssrc-audio-level a=rtpmap:109 opus/48000/2 a=fmtp:109 useinbandfec=1;stereo=1;maxplaybackrate=48000 a=rtpmap:9 G722/8000 a=rtpmap:0 PCMU/8000 a=rtpmap:8 PCMA/8000 a=rtpmap:101 telephone-event/8000 a=fmtp:101 0-15 a=ssrc:1698222108 cname:{ce7fa171-069e-db4f-ba41-cfa4455c1033} a=ssrc:1698222108 msid:{788b64bb-c4fc-b644-89b0-89f69c78f8b0} {2ba61f91-abca-3e48-84b7-85b57e8fdfb5} m=video 1031 UDP/TLS/RTP/SAVPF 120 121 126 97 a=sendrecv a=mid:sdparta_1 a=setup:actpass a=fingerprint:sha-256 44:84:41:8F:B7:A3:B7:37:BA:00:26:5E:B1:D6:AB:D0:56:56:CF:53:F2:05:DB:99:DE:D4:1C:63:A4:68:58:EA a=ice-pwd:49ad0f02b4f5181c9af3c4006575e071 a=ice-ufrag:a3cc96e2 a=rtcp-mux a=extmap:5 urn:ietf:params:rtp-hdrext:toffset a=extmap:4 http://www.webrtc.org/experiments/rtp-hdrext/abs-send-time a=extmap:3 urn:ietf:params:rtp-hdrext:sdes:mid a=rtpmap:120 VP8/90000 a=fmtp:120 max-fr=60;max-fs=12288 a=rtcp-fb:120 goog-remb a=rtcp-fb:120 ccm fir a=rtcp-fb:120 nack pli a=rtcp-fb:120 nack a=rtpmap:121 VP9/90000 a=fmtp:121 max-fr=60;max-fs=12288 a=rtcp-fb:121 goog-remb a=rtcp-fb:121 ccm fir a=rtcp-fb:121 nack pli a=rtcp-fb:121 nack a=rtpmap:126 H264/90000 a=fmtp:126 packetization-mode=1;level-asymmetry-allowed=1;profile-level-id=42e01f a=rtcp-fb:126 goog-remb a=rtcp-fb:126 ccm fir a=rtcp-fb:126 nack pli a=rtcp-fb:126 nack a=rtpmap:97 H264/90000 a=fmtp:97 level-asymmetry-allowed=1;profile-level-id=42e01f a=rtcp-fb:97 goog-remb a=rtcp-fb:97 ccm fir a=rtcp-fb:97 nack pli a=rtcp-fb:97 nack a=ssrc:823938224 cname:{ce7fa171-069e-db4f-ba41-cfa4455c1033} a=ssrc:823938224 msid:{788b64bb-c4fc-b644-89b0-89f69c78f8b0} {a7f87c8d-6002-fd4c-badb-13383c759e48} And Routr sent the Ringing response code to MongooseIM as soon as the Jitsi app displayed the incoming call window: SIP/2.0 180 Ringing CSeq: 159913767 INVITE Call-ID: ae602f16-d57d-4452-b83e-36e54bb6d325 From: \"xmpp.user\" <sip:xmpp.user@xmpp.example>;tag=aVEBue To: \"sip.user\" <sip:sip.user@sip.example>;tag=9b4c72a3 Via: SIP/2.0/TCP localhost:5600;rport=54071;branch=z9hG4bK1HMB3o-3mbahM;received=10.152.1.27 Contact: \"sip.user\" <sip:sip.user@10.152.1.27:53697;transport=tcp;registering_acc=sip_example> User-Agent: Jitsi2.10.5550Mac OS X Content-Length: 0 Summary The example above showcases how you can use Jingle/SIP switch with the available open source software. Sonetel, who are this feature's sponsor, operate on a slightly different use case and utilize more of the functionality with their proprietary software. Current implementation makes following assumptions: The peer-to-peer stream is always encrypted. This means that MongooseIM expects element <fingerprint> as described in XEP-0320 to be in the content description. Not every open source XMPP client supporting Jingle supports this encryption. MongooseIM expects that the 200 OK response contains at least one ICE candidate to set the peer-to-peer connection up. This makes the current implementation a bit limited, but on the other hand the basic integration between XMPP and SIP world is already there. Based on the current state it can be improved and extended if needed.","title":"How to Set up Jingle/SIP"},{"location":"user-guide/Jingle-SIP-setup/#jinglesip-setup-proof-of-concept","text":"This tutorial will show you how to configure MongooseIM, Routr (a SIP server) and client applications to demonstrate how the Jingle/SIP integration works.","title":"Jingle/SIP setup proof of concept"},{"location":"user-guide/Jingle-SIP-setup/#prerequisites","text":"We are going to use the following open source software: MongooseIM - https://github.com/esl/MongooseIM see How-to-build for details on building. It's important to remember to run the configuration script with with-jingle-sip flag set: tools/configure with-jingle-sip . Without this, third party dependencies required by the Jingle/SIP translator will not be included in the release. Routr (SIP server) - https://routr.io I recommend downloading binaries for your system from https://routr.io/docs/getting-started-installation.html Jitsi (XMPP and SIP client application) - https://desktop.jitsi.org Otalk - web based XMPP client - https://github.com/otalk/otalk-im-client Folow the instructions on otalk-im-client#installing to run it We will use 2 users xmpp.user@xmpp.example and sip.user@sip.example .","title":"Prerequisites"},{"location":"user-guide/Jingle-SIP-setup/#configuring-routr","text":"First the domain sip.example needs to be added to domains served by Routr. To do it, paste the following content to config/domains.yml in the directory where Routr was: - apiVersion: v1beta1 kind: Domain metadata: name: SIP domain spec: context: domainUri: sip.example Then the sip.user@sip.example needs to be added to config/agents.yml like below: - apiVersion: v1beta1 kind: Agent metadata: name: SIP User spec: credentials: username: 'sip.user' secret: '1234' domains: [sip.example] Now Routr can be started with ./routr If all goes well we'll see the following output: [INFO ] Starting Routr [INFO ] Listening on 10.152.1.27:5060 [udp] [INFO ] Listening on 10.152.1.27:5060 [tcp] [INFO ] Starting Location service [INFO ] Starting Registry service [INFO ] Starting Restful service (port: 4567, apiPath: '/api/v1beta1') It is important to remember the IP address as it'll be used in next point.","title":"Configuring Routr"},{"location":"user-guide/Jingle-SIP-setup/#a-side-note","text":"In Routr's logs you may see messages like [WARN ] Unable to register with Gateway -> sip.provider.net. (Verify your network status) or [ERROR] java.lang.RuntimeException: javax.sip.header.TooManyHopsException: has already reached 0! They can be ignored for the purpose of the tutorial.","title":"A side note"},{"location":"user-guide/Jingle-SIP-setup/#configuring-etchosts","text":"In my case the IP reported by Routr was 10.152.1.27 . Now we need to use this to update /etc/hosts file like below: 10.152.1.27 sip.example xmpp.example","title":"Configuring /etc/hosts"},{"location":"user-guide/Jingle-SIP-setup/#configuring-mongooseim","text":"At this point I assume that MongooseIM was built with make rel , that it is running and the current working directory is _build/prod/rel/mongooseim . Similar to Routr, MongooseIM also needs to know which hosts to server. Please replace the default host defined in etc/mongooseim.cfg ; the line: {hosts, [\"localhost\"] }. should be changed to: {hosts, [\"xmpp.example\", \"sip.example\"] }. Now we need to enable mod_jingle_sip , please add the following line in modules list (somewhere around line 740 in the same file) {mod_jingle_sip, [{proxy_host, \"sip.example\"}]}, More details on MongooseIM configuration you can find in Basic Configuration and in Modules configuration Now we are registering both users in MongooseIM by calling the following commands: bin/mongooseimctl register_identified xmpp.user xmpp.example test_pass bin/mongooseimctl register_identified sip.user sip.example test_pass Yes, we need to have the sip.user@sip.example registered in MongooseIM. This is needed because a Jingle call can be initiated by a regular XMPP client only when the app knows the other user's full JID. The easiest way to achieve that is to exchange presence information between these 2 users. This can happen automatically if 2 xmpp users have each other in the roster. The roster can be set by us with the following commands: bin/mongooseimctl add_rosteritem sip.user sip.example xmpp.user xmpp.example xmpp.user none both bin/mongooseimctl add_rosteritem xmpp.user xmpp.example sip.user sip.example sip.user none both","title":"Configuring MongooseIM"},{"location":"user-guide/Jingle-SIP-setup/#adding-users-to-jitsi","text":"Now the sip.user@sip.example has to be added to Jitsi app. When the app is opened for the first time it will display a window to configure the user. Later users can be configured from the Preferences page.","title":"Adding users to Jitsi"},{"location":"user-guide/Jingle-SIP-setup/#adding-a-sip-user","text":"In order to add a user who connects to the SIP server we need to choose the SIP protocol from the available networks in Jitsi. In the SIP id field we put sip.user@sip.example and in the Password field we put 1234 as in the agents.yml file. Now we need to switch to Advanced options and go to the Connection tab. Here we need to unselect the Configure proxy automatically and put the IP of our Routr server, port number 5060 and TCP as the preferred transport.","title":"Adding a SIP user"},{"location":"user-guide/Jingle-SIP-setup/#adding-an-xmpp-user","text":"Now we have to add sip.user@sip.example to Jitsi's XMPP network in order to connect this user to MongooseIM over XMPP. It's very similar to adding a user to Jitsi's SIP network, the only difference is the password, for the XMPP conection it's test_pass as set when registering the user in MongooseIM. Here we also need to go to the Advanced window and the Connection tab in order to put the IP addres (the same as before) in the Connect Server field. Remember to check the Override server default options box. To connect sip.user@sip.exmple to MongooseIM over XMPP is to cheat Jingle a bit, so that the client app for user sip.xmpp@xmpp.example can start the Jingle call. When Jitsi connects this user, it will likely display a warning about the server's certificate. This is because by default MongooseIM is configured with a freshly generated, self-signed certificate. We can click Continue anyway button in order to proceed.","title":"Adding an XMPP user"},{"location":"user-guide/Jingle-SIP-setup/#adding-user-to-otalk","text":"Please follow the instructiond on https://github.com/otalk/otalk-im-client#installing in order to compile and run the app. If all goes well, you should see the following message printed in the console: demo.stanza.io running at: http://localhost:8000 This means that the app is hosted on http://localhost:8000 . At this point I also recommend opening https://localhost:5285/ws-xmpp in the same browser. This endpoint works correctly only for WebSocket connections but most probably you will be prompted about the certificate. This is again due to the self-signed certificate. We need to add an exception for this certificate in order to successfully connect from Otalk. Now let's open http://localhost:8000 where the Otalk app is hosted. In the Log in section put xmpp.user@xmpp.example in the JID field and test_pass in the Password filed. The default WebSocket endpoint in the WebSocket or BOSH URL field needs to be changed to: wss://localhost:5285/ws-xmpp Mind the wss protocol, Otalk will not connect the user over WebSockets if for example https is put in the field. Now we can hit the Go! button and the xmpp.user@xmpp.example will connect to MongooseIM.","title":"Adding user to Otalk"},{"location":"user-guide/Jingle-SIP-setup/#making-a-call","text":"On the left side we can see that the user already has sip.user@sip.example in the roster and there should be a green dot indicating that the user is online. When we click on the contact, the Call button should appear allowing us to initiate the call. In Jitsi, the following window should pop up: Behind the scene the following SIP request was send from MongooseIM to Routr. INVITE sip:sip.user@sip.example:5060 SIP/2.0 Via: SIP/2.0/TCP localhost:5600;rport;branch=z9hG4bK1HMB3o-3mbahM From: xmpp.user <sip:xmpp.user@xmpp.example>;tag=aVEBue To: sip.user <sip:sip.user@sip.example> Call-ID: ae602f16-d57d-4452-b83e-36e54bb6d325 CSeq: 159913767 INVITE Max-Forwards: 70 Content-Length: 2243 Contact: <sip:xmpp.user@localhost:5600;ob;transport=tcp>;+sip.instance=\"<urn:uuid:f45950f1-70cd-229d-6c2b-8c85903ce14e>\" Content-Type: application/sdp Supported: outbound,100rel,path Allow: PRACK,INVITE,ACK,CANCEL,BYE,OPTIONS,INFO,UPDATE,SUBSCRIBE,NOTIFY,REFER,MESSAGE v=0 o=- 1531401304 1531401304 IN IP4 127.0.0.1 s=nksip c=IN IP4 127.0.0.1 t=0 0 a=group:BUNDLE sdparta_0 sdparta_1 m=audio 1436 UDP/TLS/RTP/SAVPF 109 9 0 8 101 a=sendrecv a=mid:sdparta_0 a=setup:actpass a=fingerprint:sha-256 44:84:41:8F:B7:A3:B7:37:BA:00:26:5E:B1:D6:AB:D0:56:56:CF:53:F2:05:DB:99:DE:D4:1C:63:A4:68:58:EA a=ice-pwd:49ad0f02b4f5181c9af3c4006575e071 a=ice-ufrag:a3cc96e2 a=rtcp-mux a=extmap:3 urn:ietf:params:rtp-hdrext:sdes:mid a=extmap:2/recvonly urn:ietf:params:rtp-hdrext:csrc-audio-level a=extmap:1 urn:ietf:params:rtp-hdrext:ssrc-audio-level a=rtpmap:109 opus/48000/2 a=fmtp:109 useinbandfec=1;stereo=1;maxplaybackrate=48000 a=rtpmap:9 G722/8000 a=rtpmap:0 PCMU/8000 a=rtpmap:8 PCMA/8000 a=rtpmap:101 telephone-event/8000 a=fmtp:101 0-15 a=ssrc:1698222108 cname:{ce7fa171-069e-db4f-ba41-cfa4455c1033} a=ssrc:1698222108 msid:{788b64bb-c4fc-b644-89b0-89f69c78f8b0} {2ba61f91-abca-3e48-84b7-85b57e8fdfb5} m=video 1031 UDP/TLS/RTP/SAVPF 120 121 126 97 a=sendrecv a=mid:sdparta_1 a=setup:actpass a=fingerprint:sha-256 44:84:41:8F:B7:A3:B7:37:BA:00:26:5E:B1:D6:AB:D0:56:56:CF:53:F2:05:DB:99:DE:D4:1C:63:A4:68:58:EA a=ice-pwd:49ad0f02b4f5181c9af3c4006575e071 a=ice-ufrag:a3cc96e2 a=rtcp-mux a=extmap:5 urn:ietf:params:rtp-hdrext:toffset a=extmap:4 http://www.webrtc.org/experiments/rtp-hdrext/abs-send-time a=extmap:3 urn:ietf:params:rtp-hdrext:sdes:mid a=rtpmap:120 VP8/90000 a=fmtp:120 max-fr=60;max-fs=12288 a=rtcp-fb:120 goog-remb a=rtcp-fb:120 ccm fir a=rtcp-fb:120 nack pli a=rtcp-fb:120 nack a=rtpmap:121 VP9/90000 a=fmtp:121 max-fr=60;max-fs=12288 a=rtcp-fb:121 goog-remb a=rtcp-fb:121 ccm fir a=rtcp-fb:121 nack pli a=rtcp-fb:121 nack a=rtpmap:126 H264/90000 a=fmtp:126 packetization-mode=1;level-asymmetry-allowed=1;profile-level-id=42e01f a=rtcp-fb:126 goog-remb a=rtcp-fb:126 ccm fir a=rtcp-fb:126 nack pli a=rtcp-fb:126 nack a=rtpmap:97 H264/90000 a=fmtp:97 level-asymmetry-allowed=1;profile-level-id=42e01f a=rtcp-fb:97 goog-remb a=rtcp-fb:97 ccm fir a=rtcp-fb:97 nack pli a=rtcp-fb:97 nack a=ssrc:823938224 cname:{ce7fa171-069e-db4f-ba41-cfa4455c1033} a=ssrc:823938224 msid:{788b64bb-c4fc-b644-89b0-89f69c78f8b0} {a7f87c8d-6002-fd4c-badb-13383c759e48} And Routr sent the Ringing response code to MongooseIM as soon as the Jitsi app displayed the incoming call window: SIP/2.0 180 Ringing CSeq: 159913767 INVITE Call-ID: ae602f16-d57d-4452-b83e-36e54bb6d325 From: \"xmpp.user\" <sip:xmpp.user@xmpp.example>;tag=aVEBue To: \"sip.user\" <sip:sip.user@sip.example>;tag=9b4c72a3 Via: SIP/2.0/TCP localhost:5600;rport=54071;branch=z9hG4bK1HMB3o-3mbahM;received=10.152.1.27 Contact: \"sip.user\" <sip:sip.user@10.152.1.27:53697;transport=tcp;registering_acc=sip_example> User-Agent: Jitsi2.10.5550Mac OS X Content-Length: 0","title":"Making a call"},{"location":"user-guide/Jingle-SIP-setup/#summary","text":"The example above showcases how you can use Jingle/SIP switch with the available open source software. Sonetel, who are this feature's sponsor, operate on a slightly different use case and utilize more of the functionality with their proprietary software. Current implementation makes following assumptions: The peer-to-peer stream is always encrypted. This means that MongooseIM expects element <fingerprint> as described in XEP-0320 to be in the content description. Not every open source XMPP client supporting Jingle supports this encryption. MongooseIM expects that the 200 OK response contains at least one ICE candidate to set the peer-to-peer connection up. This makes the current implementation a bit limited, but on the other hand the basic integration between XMPP and SIP world is already there. Based on the current state it can be improved and extended if needed.","title":"Summary"},{"location":"user-guide/MongooseIM-High-level-Architecture/","text":"Inside MongooseIM Modules At its core MongooseIM is a huge message router you can customise to fit your system's needs. You can choose and enable behaviours and functionalities by configuring any of the available modules. A wide range of options includes authentication, privacy, storage, backend integration and mobile optimisations. See ' Extension Modules ' for a full list. Modules can be configured and started either for all virutal hosts served by the instance or with individual configuration for only some of them. Modules may include dependencies on services and on other modules. If a module depends on other modules, required modules are started automatically with configuration provided by the dependent module. If a module requires certain services which are not started, the module refuses to start. Services Services provide certain functionalities not specific to virtual hosts but rather applied to the whole instance or to modules started for various hosts. They are configured globally and launched on startup, before modules, so that dependencies are satisfied. A service can require other services to be operational; required services are started automatically. The required service must also be present in the server's configuration file. They were introduced in MongooseIM 2.2; modules which are not host-specific are gradually being refactored as services. Databases MongooseIM manages two sets of data: transient for session data management, and persistent for archive and configurations. Please refer to ' Database Backends ' doc for more configuration information. Transient databases In the MongooseIM architecture each MongooseIM node host has an accompanying Mnesia node. Redis on the other hand forms a separate cluster and does not utilise MongooseIM nodes. There is no need to set up any backups for transient data since it naturally rebuilds as clients reconnect massively. Persistant databases Both RDBMS/SQL (MySQL/PostgreSQL) and NOSQL (Riak KV) databases are supported. Backups should be regular, and tested. LDAP directory LDAP will also run on a separate cluster. Backups should be regular, and tested. Outside MongooseIM: ecosystem in a datacenter Frontend Native clients on platforms such as Android, iOS, Windows, Linux, macOS, will preferrably use a plain XMPP over TCP connections. Since web clients cannot use TCP connections, they will preferrably use XMPP over websockets, or the now less relevant XMPP over BOSH (using long-lived HTTP connections, more and more used as fallback). Any client could use the client REST API, which is using HTTP request/responses. All these client connections will hit a frontend load balancer before reaching the MongooseIM cluster. Backend MongooseIM supports bilateral communication with other backend services in the datacenter infrastructure. MongooseIM REST API is available for control/management of MongooseIM's operations as well as the functional aspects. An HTTP notification enables forwarding of the events to any other external HTTP service. Management and monitoring WombatOAM enables the monitoring and management of MongooseIM clusters, as well as Riak KV, RabbitMQ, and any other Erlang and Elixir based system. MongooseICE (STUN/TURN) Contact us. MongoosePush (APNS, GCM) Available on: MongoosePush MongooseIM in a worldwide, multi-datacenter configuration The MongooseIM platform enables a service to scale worlwide, with proximity servers across continents and datacenters. It leverages the use of the open standard S2S (server-to-server) protocol. Contact us.","title":"High-level Architecture"},{"location":"user-guide/MongooseIM-High-level-Architecture/#inside-mongooseim","text":"","title":"Inside MongooseIM"},{"location":"user-guide/MongooseIM-High-level-Architecture/#modules","text":"At its core MongooseIM is a huge message router you can customise to fit your system's needs. You can choose and enable behaviours and functionalities by configuring any of the available modules. A wide range of options includes authentication, privacy, storage, backend integration and mobile optimisations. See ' Extension Modules ' for a full list. Modules can be configured and started either for all virutal hosts served by the instance or with individual configuration for only some of them. Modules may include dependencies on services and on other modules. If a module depends on other modules, required modules are started automatically with configuration provided by the dependent module. If a module requires certain services which are not started, the module refuses to start.","title":"Modules"},{"location":"user-guide/MongooseIM-High-level-Architecture/#services","text":"Services provide certain functionalities not specific to virtual hosts but rather applied to the whole instance or to modules started for various hosts. They are configured globally and launched on startup, before modules, so that dependencies are satisfied. A service can require other services to be operational; required services are started automatically. The required service must also be present in the server's configuration file. They were introduced in MongooseIM 2.2; modules which are not host-specific are gradually being refactored as services.","title":"Services"},{"location":"user-guide/MongooseIM-High-level-Architecture/#databases","text":"MongooseIM manages two sets of data: transient for session data management, and persistent for archive and configurations. Please refer to ' Database Backends ' doc for more configuration information.","title":"Databases"},{"location":"user-guide/MongooseIM-High-level-Architecture/#transient-databases","text":"In the MongooseIM architecture each MongooseIM node host has an accompanying Mnesia node. Redis on the other hand forms a separate cluster and does not utilise MongooseIM nodes. There is no need to set up any backups for transient data since it naturally rebuilds as clients reconnect massively.","title":"Transient databases"},{"location":"user-guide/MongooseIM-High-level-Architecture/#persistant-databases","text":"Both RDBMS/SQL (MySQL/PostgreSQL) and NOSQL (Riak KV) databases are supported. Backups should be regular, and tested.","title":"Persistant databases"},{"location":"user-guide/MongooseIM-High-level-Architecture/#ldap-directory","text":"LDAP will also run on a separate cluster. Backups should be regular, and tested.","title":"LDAP directory"},{"location":"user-guide/MongooseIM-High-level-Architecture/#outside-mongooseim-ecosystem-in-a-datacenter","text":"","title":"Outside MongooseIM: ecosystem in a datacenter"},{"location":"user-guide/MongooseIM-High-level-Architecture/#frontend","text":"Native clients on platforms such as Android, iOS, Windows, Linux, macOS, will preferrably use a plain XMPP over TCP connections. Since web clients cannot use TCP connections, they will preferrably use XMPP over websockets, or the now less relevant XMPP over BOSH (using long-lived HTTP connections, more and more used as fallback). Any client could use the client REST API, which is using HTTP request/responses. All these client connections will hit a frontend load balancer before reaching the MongooseIM cluster.","title":"Frontend"},{"location":"user-guide/MongooseIM-High-level-Architecture/#backend","text":"MongooseIM supports bilateral communication with other backend services in the datacenter infrastructure. MongooseIM REST API is available for control/management of MongooseIM's operations as well as the functional aspects. An HTTP notification enables forwarding of the events to any other external HTTP service.","title":"Backend"},{"location":"user-guide/MongooseIM-High-level-Architecture/#management-and-monitoring","text":"WombatOAM enables the monitoring and management of MongooseIM clusters, as well as Riak KV, RabbitMQ, and any other Erlang and Elixir based system.","title":"Management and monitoring"},{"location":"user-guide/MongooseIM-High-level-Architecture/#mongooseice-stunturn","text":"Contact us.","title":"MongooseICE (STUN/TURN)"},{"location":"user-guide/MongooseIM-High-level-Architecture/#mongoosepush-apns-gcm","text":"Available on: MongoosePush","title":"MongoosePush (APNS, GCM)"},{"location":"user-guide/MongooseIM-High-level-Architecture/#mongooseim-in-a-worldwide-multi-datacenter-configuration","text":"The MongooseIM platform enables a service to scale worlwide, with proximity servers across continents and datacenters. It leverages the use of the open standard S2S (server-to-server) protocol. Contact us.","title":"MongooseIM in a worldwide, multi-datacenter configuration"},{"location":"user-guide/Push-notifications/","text":"How to set up Push Notifications with MongoosePush MongooseIM server supports push notifications using FCM ( F irebase C loud M essaging) and APNS ( A pple P ush N otification S ervice) providers. Server side push notification support is fully compliant with XEP-0357 Push Notifications , which defines several components that need to work together in order to provide clients with working push notifications. The following list shows those components as defined in XEP-0357 and MongooseIM components that correspond to those entities: XMPP Server in MongooseIM is enabled by module mod_event_pusher_push App Server in MongooseIM is enabled by adding a push node type to mod_pubsub 's configuration XMPP Push Service is implemented as a MongoosePush application All these entities have to be enabled and properly configured in order to use push notifications. So let's get to it, shall we? Overall component architecture The components that make push notifications possible in MongooseIM add up to the following architecture: The diagram lists three domains in total - two for MongooseIM and one for MongoosePush . Note that this separation is not required, all three components can be on the same host with the same domain. Configuring MongooseIM components Firstly, let's configure all the required MongooseIM components, step by step. mod_event_pusher_push a.k.a. ' XMPP Server ' The first component that we need to configure in MongooseIM is the mod_event_pusher_push module. This module communicates with XMPP clients directly in order to enable/disable notifications on per-client basis. The mod_event_pusher_push module is very easy to enable - just paste the following to your MongooseIM configuration file: {mod_event_pusher, [ {backends, [ {push, [{wpool, [{workers, 100}]}]} ]} ]}. And that's basically it. You have just enabled the push notification support with 100 asynchronous workers that will handle all push notification related work. You can also control the format of the \"sender\" of the push notification (which ultimately becomes the title of push notification) and filter which messages will trigger the notification. In that case you need to create a plugin module that implements the mod_event_pusher_push_plugin behaviour and enable this plugin as specified in the mod_event_pusher_push documentation. mod_pubsub with mod_push_service_mongoosepush a.k.a. ' App Server ' The next component to configure consist of two modules: mod_pubsub with a push node type enabled that will act as a sink for push notifications generated by mod_event_pusher_push mod_push_service_mongoosepush - a connector to MongoosePush application mod_pubsub 's push node According to the XEP-0357 Push Notifications , all notifications generated via the module we have just enabled (i.e. mod_event_pusher_push ) have to be send to a push enabled publish-subscribe node. In order to allow clients to allocate such a node, we need to enable it in our mod_pubsub on the MongooseIM server that will communicate with the XMPP Push Service . The minimal mod_pubsub 's configuration looks as follows: {mod_pubsub, [ {plugins, [<<\"push\">>]} ]}. Such configuration will enable the mod_pubsub with only one node type available: push . Please note that if you want use mod_pubsub as a 'normal' publish-subscribe service, you just need to append the <<\"push\">> node type to the plugins list. Also, it's important to note, that the first node type on the plugins list, will be the default one (allocated when the client does not provide a node type in the node create stanza). mod_push_service_mongoosepush This module acts as a bridge between mod_pubsub that receives notifications from mod_event_pusher_push and passes them to MongoosePush , which sends them to FCM and/or APNS . To enable this first you need to define the pool of HTTPS connections to MongoosePush: {outgoing_pools, [{http, global, mongoose_push_http, [{strategy, available_worker}], [{server, \"https://localhost:8443\"}]} ] }. Please note that more than one pool may exist in the outgoing_pools list. Then add mod_push_service_mongoosepush to the modules section in the config file: {modules, [ (...) {mod_push_service_mongoosepush, [ {pool_name, mongoose_push_http}, {api_version, \"v2\"}]}, (...) First, we create the HTTP pool for communicating with MongoosePush . Here, we assume that MongoosePush will be available on the localhost on port 8443 which is the default one. Next we enable mod_push_service_mongoosepush . First option is the name of the HTTP pool to use and the second one is the version of MongoosePush 's API (currently only \" v2 \" is supported). And that's it, we've just completed the entire MongooseIM configuration. All we need to do now is to set up MongoosePush . Starting MongoosePush The easiest way to start MongoosePush is using its docker image . But before you can set MongoosePush up, you need a FCM application token and/or an APNS application certificate. You can get the FCM token here and the easiest way of getting an APNS application certificate is by running this script (please note that you need the certificate in pem format). After you get the FCM application token and/or the APNS application certificate, you can prepare to start MongoosePush . Firstly, prepare the following files structure: priv/ ssl/ rest_cert.pem - The REST endpoint certificate rest_key.pem - private key for the REST endpoint certificate apns/ prod_cert.pem - Production APNS app certificate prod_key.pem - Production APNS app certificate's private key dev_cert.pem - Development APNS app certificate dev_key.pem - Development APNS app certificate's private key If your FCM app token is MY_FCM_SECRET_TOKEN and you have the priv directory with all ceriticates in the current directory, start MongoosePush with the following command: docker run -v `pwd`/priv:/opt/app/priv \\ -e PUSH_FCM_APP_KEY=\"MY_FCM_SECRET_TOKEN\" \\ -e PUSH_HTTPS_CERTFILE=\"/opt/app/priv/ssl/rest_cert.pem\" \\ -e PUSH_HTTPS_KEYFILE=\"/opt/app/priv/ssl/rest_key.pem\" \\ -it --rm mongooseim/mongoose-push:latest If you don't want to use either APNS or FCM , you simply need to pass PUSH_APNS_ENABLED=0 or PUSH_FCM_ENABLED=0 respectively as additional env variables in your docker run command. For more advanced options and configuration please refer to \"Quick start / Configuring\" in MongoosePush 's README.md . When your MongoosePush docker is up and running, Push Notifications can be used in your MongooseIM instance. Using push notifications on client side There are just a few things the XMPP client application needs to receive the push notifications. See the diagram to examine the process described in this section along with the example notification flow: Registering with a Push Service provider Firstly, the client application has to get a device-specific token from the Push Service Provider (FCM or APNS). This process is different, depending on the platform, so please consult your Push Service Provider's manual to see how to get this token. For example, here you can learn about setting up FCM on Android platform and here you can learn about setting up APNS on iOS platform. After this step, your application shall be able to receive FCM or APNS token - it will be required in the next step of this tutorial. Setting up an XMPP pubsub node Please note this first step is specific to the app-server your client application uses. In case of MongooseIM, you just need to allocate (create) a special PubSub node that will act as a gateway for all notifications sent by the XMPP chat server. Without any further ado, let's configure the PubSub 's push node. In this example mypubsub.com is a domain of the MongooseIM server that has mod_pubsub enabled with the push node support. The client sends the following stanza to the server: <iq type='set' to='pubsub.mypubsub.com' id='create1'> <pubsub xmlns='http://jabber.org/protocol/pubsub'> <create node='punsub_node_for_my_private_iphone' type='push'/> <configure> <x xmlns='jabber:x:data' type='submit'> <field var='FORM_TYPE' type='hidden'> <value>http://jabber.org/protocol/pubsub#node_config</value> </field> <field var='pubsub#access_model'> <value>whitelist</value> </field> <field var='pubsub#publish_model'> <value>publishers</value> </field> </x> </configure> </pubsub> </iq> The pubsub.mypubsub.com will be used as a gateway for all notifications and will pass them through to the APNS and/or FCM. The most important and only distinction from the standard node creation is the type='push' part of the create element. This denotes that you need a node that will handle your push notifications. Here we create a node called punsub_node_for_my_private_iphone . This node should be unique to the device and you may reuse nodes already created this way. It is also recommended and important from security perspective to configure the node with: access_model set to whitelist so only affiliated users can access the node. publish_model set to publishers so only users with publisher or publisher_only role can publish notifications. After this step, you need to have the pubsub host (here pubsub.mypubsub.com ) and the node name (here: punsub_node_for_my_private_iphone ). Enabling push notifications The next and the last step is to enable push notifications on the server that handles your messages (and has mod_event_pusher_push enabled). Let's assume this server**** is available under the mychat.com domain. To enable push notifications in the simplest configuration, just send the following stanza: <iq type='set' id='x43'> <enable xmlns='urn:xmpp:push:0' jid='pubsub.mypubsub.com' node='punsub_node_for_my_private_iphone'> <x xmlns='jabber:x:data' type='submit'> <field var='FORM_TYPE'><value>http://jabber.org/protocol/pubsub#publish-options</value></field> <field var='service'><value>apns</value></field> <field var='device_id'><value>your_pns_device_token</value></field> <field var='silent'><value>false</value></field> <field var='topic'><value>some_apns_topic</value></field> </x> </enable> </iq> We have now enabled push notifications to be send to the pubsub.mypubsub.com to the node punsub_node_for_my_private_iphone created in previous paragraph. In publish-options we have passed the service name that we are using ( apns or fcm ) and the device token (here: your_pns_device_token ) that you received from you push notification service provider (as described in Registering with Push Service provider ). Those two options are the only ones required, but there are some others that are optional: mode - which may be either prod or dev (default to prod ). Decides which connection pool type on MongoosePush shall be used. This may be used when APNS on MongoosePush is configured to work with both production and development certificate. click_action - action to perform when notification is clicked on the device. activity on Android and category on iOS . Please refer to your platform / push notification service provider for more info. topic - currently only used with APNS . the value is passed to APNS as topic header. For more information please refer to APNS documentation. silent - if set to true , all notifications will be \"silent\". This means that only data payload will be send to push notifications provider with no notification. The data payload will contain all notification fields as defined in XEP-0357 . Disabling push notifications Disabling push notifications is very simple. Just send the following stanza to your XMPP chat server: <iq type='set' id='x44'> <disable xmlns='urn:xmpp:push:0' jid='pubsub.mypubsub.com' node='punsub_node_for_my_private_iphone'/> </iq> You may skip the node='punsub_node_for_my_private_iphone' to globally disable push notifications on all nodes that are registered from your JID . This may be used to disbale push notifications on all your devices.","title":"How to Set up MongoosePush"},{"location":"user-guide/Push-notifications/#how-to-set-up-push-notifications-with-mongoosepush","text":"MongooseIM server supports push notifications using FCM ( F irebase C loud M essaging) and APNS ( A pple P ush N otification S ervice) providers. Server side push notification support is fully compliant with XEP-0357 Push Notifications , which defines several components that need to work together in order to provide clients with working push notifications. The following list shows those components as defined in XEP-0357 and MongooseIM components that correspond to those entities: XMPP Server in MongooseIM is enabled by module mod_event_pusher_push App Server in MongooseIM is enabled by adding a push node type to mod_pubsub 's configuration XMPP Push Service is implemented as a MongoosePush application All these entities have to be enabled and properly configured in order to use push notifications. So let's get to it, shall we?","title":"How to set up Push Notifications with MongoosePush"},{"location":"user-guide/Push-notifications/#overall-component-architecture","text":"The components that make push notifications possible in MongooseIM add up to the following architecture: The diagram lists three domains in total - two for MongooseIM and one for MongoosePush . Note that this separation is not required, all three components can be on the same host with the same domain.","title":"Overall component architecture"},{"location":"user-guide/Push-notifications/#configuring-mongooseim-components","text":"Firstly, let's configure all the required MongooseIM components, step by step.","title":"Configuring MongooseIM components"},{"location":"user-guide/Push-notifications/#mod_event_pusher_push-aka-xmpp-server","text":"The first component that we need to configure in MongooseIM is the mod_event_pusher_push module. This module communicates with XMPP clients directly in order to enable/disable notifications on per-client basis. The mod_event_pusher_push module is very easy to enable - just paste the following to your MongooseIM configuration file: {mod_event_pusher, [ {backends, [ {push, [{wpool, [{workers, 100}]}]} ]} ]}. And that's basically it. You have just enabled the push notification support with 100 asynchronous workers that will handle all push notification related work. You can also control the format of the \"sender\" of the push notification (which ultimately becomes the title of push notification) and filter which messages will trigger the notification. In that case you need to create a plugin module that implements the mod_event_pusher_push_plugin behaviour and enable this plugin as specified in the mod_event_pusher_push documentation.","title":"mod_event_pusher_push a.k.a. 'XMPP Server'"},{"location":"user-guide/Push-notifications/#mod_pubsub-with-mod_push_service_mongoosepush-aka-app-server","text":"The next component to configure consist of two modules: mod_pubsub with a push node type enabled that will act as a sink for push notifications generated by mod_event_pusher_push mod_push_service_mongoosepush - a connector to MongoosePush application","title":"mod_pubsub with mod_push_service_mongoosepush a.k.a. 'App Server'"},{"location":"user-guide/Push-notifications/#mod_pubsubs-push-node","text":"According to the XEP-0357 Push Notifications , all notifications generated via the module we have just enabled (i.e. mod_event_pusher_push ) have to be send to a push enabled publish-subscribe node. In order to allow clients to allocate such a node, we need to enable it in our mod_pubsub on the MongooseIM server that will communicate with the XMPP Push Service . The minimal mod_pubsub 's configuration looks as follows: {mod_pubsub, [ {plugins, [<<\"push\">>]} ]}. Such configuration will enable the mod_pubsub with only one node type available: push . Please note that if you want use mod_pubsub as a 'normal' publish-subscribe service, you just need to append the <<\"push\">> node type to the plugins list. Also, it's important to note, that the first node type on the plugins list, will be the default one (allocated when the client does not provide a node type in the node create stanza).","title":"mod_pubsub's push node"},{"location":"user-guide/Push-notifications/#mod_push_service_mongoosepush","text":"This module acts as a bridge between mod_pubsub that receives notifications from mod_event_pusher_push and passes them to MongoosePush , which sends them to FCM and/or APNS . To enable this first you need to define the pool of HTTPS connections to MongoosePush: {outgoing_pools, [{http, global, mongoose_push_http, [{strategy, available_worker}], [{server, \"https://localhost:8443\"}]} ] }. Please note that more than one pool may exist in the outgoing_pools list. Then add mod_push_service_mongoosepush to the modules section in the config file: {modules, [ (...) {mod_push_service_mongoosepush, [ {pool_name, mongoose_push_http}, {api_version, \"v2\"}]}, (...) First, we create the HTTP pool for communicating with MongoosePush . Here, we assume that MongoosePush will be available on the localhost on port 8443 which is the default one. Next we enable mod_push_service_mongoosepush . First option is the name of the HTTP pool to use and the second one is the version of MongoosePush 's API (currently only \" v2 \" is supported). And that's it, we've just completed the entire MongooseIM configuration. All we need to do now is to set up MongoosePush .","title":"mod_push_service_mongoosepush"},{"location":"user-guide/Push-notifications/#starting-mongoosepush","text":"The easiest way to start MongoosePush is using its docker image . But before you can set MongoosePush up, you need a FCM application token and/or an APNS application certificate. You can get the FCM token here and the easiest way of getting an APNS application certificate is by running this script (please note that you need the certificate in pem format). After you get the FCM application token and/or the APNS application certificate, you can prepare to start MongoosePush . Firstly, prepare the following files structure: priv/ ssl/ rest_cert.pem - The REST endpoint certificate rest_key.pem - private key for the REST endpoint certificate apns/ prod_cert.pem - Production APNS app certificate prod_key.pem - Production APNS app certificate's private key dev_cert.pem - Development APNS app certificate dev_key.pem - Development APNS app certificate's private key If your FCM app token is MY_FCM_SECRET_TOKEN and you have the priv directory with all ceriticates in the current directory, start MongoosePush with the following command: docker run -v `pwd`/priv:/opt/app/priv \\ -e PUSH_FCM_APP_KEY=\"MY_FCM_SECRET_TOKEN\" \\ -e PUSH_HTTPS_CERTFILE=\"/opt/app/priv/ssl/rest_cert.pem\" \\ -e PUSH_HTTPS_KEYFILE=\"/opt/app/priv/ssl/rest_key.pem\" \\ -it --rm mongooseim/mongoose-push:latest If you don't want to use either APNS or FCM , you simply need to pass PUSH_APNS_ENABLED=0 or PUSH_FCM_ENABLED=0 respectively as additional env variables in your docker run command. For more advanced options and configuration please refer to \"Quick start / Configuring\" in MongoosePush 's README.md . When your MongoosePush docker is up and running, Push Notifications can be used in your MongooseIM instance.","title":"Starting MongoosePush"},{"location":"user-guide/Push-notifications/#using-push-notifications-on-client-side","text":"There are just a few things the XMPP client application needs to receive the push notifications. See the diagram to examine the process described in this section along with the example notification flow:","title":"Using push notifications on client side"},{"location":"user-guide/Push-notifications/#registering-with-a-push-service-provider","text":"Firstly, the client application has to get a device-specific token from the Push Service Provider (FCM or APNS). This process is different, depending on the platform, so please consult your Push Service Provider's manual to see how to get this token. For example, here you can learn about setting up FCM on Android platform and here you can learn about setting up APNS on iOS platform. After this step, your application shall be able to receive FCM or APNS token - it will be required in the next step of this tutorial.","title":"Registering with a Push Service provider"},{"location":"user-guide/Push-notifications/#setting-up-an-xmpp-pubsub-node","text":"Please note this first step is specific to the app-server your client application uses. In case of MongooseIM, you just need to allocate (create) a special PubSub node that will act as a gateway for all notifications sent by the XMPP chat server. Without any further ado, let's configure the PubSub 's push node. In this example mypubsub.com is a domain of the MongooseIM server that has mod_pubsub enabled with the push node support. The client sends the following stanza to the server: <iq type='set' to='pubsub.mypubsub.com' id='create1'> <pubsub xmlns='http://jabber.org/protocol/pubsub'> <create node='punsub_node_for_my_private_iphone' type='push'/> <configure> <x xmlns='jabber:x:data' type='submit'> <field var='FORM_TYPE' type='hidden'> <value>http://jabber.org/protocol/pubsub#node_config</value> </field> <field var='pubsub#access_model'> <value>whitelist</value> </field> <field var='pubsub#publish_model'> <value>publishers</value> </field> </x> </configure> </pubsub> </iq> The pubsub.mypubsub.com will be used as a gateway for all notifications and will pass them through to the APNS and/or FCM. The most important and only distinction from the standard node creation is the type='push' part of the create element. This denotes that you need a node that will handle your push notifications. Here we create a node called punsub_node_for_my_private_iphone . This node should be unique to the device and you may reuse nodes already created this way. It is also recommended and important from security perspective to configure the node with: access_model set to whitelist so only affiliated users can access the node. publish_model set to publishers so only users with publisher or publisher_only role can publish notifications. After this step, you need to have the pubsub host (here pubsub.mypubsub.com ) and the node name (here: punsub_node_for_my_private_iphone ).","title":"Setting up an XMPP pubsub node"},{"location":"user-guide/Push-notifications/#enabling-push-notifications","text":"The next and the last step is to enable push notifications on the server that handles your messages (and has mod_event_pusher_push enabled). Let's assume this server**** is available under the mychat.com domain. To enable push notifications in the simplest configuration, just send the following stanza: <iq type='set' id='x43'> <enable xmlns='urn:xmpp:push:0' jid='pubsub.mypubsub.com' node='punsub_node_for_my_private_iphone'> <x xmlns='jabber:x:data' type='submit'> <field var='FORM_TYPE'><value>http://jabber.org/protocol/pubsub#publish-options</value></field> <field var='service'><value>apns</value></field> <field var='device_id'><value>your_pns_device_token</value></field> <field var='silent'><value>false</value></field> <field var='topic'><value>some_apns_topic</value></field> </x> </enable> </iq> We have now enabled push notifications to be send to the pubsub.mypubsub.com to the node punsub_node_for_my_private_iphone created in previous paragraph. In publish-options we have passed the service name that we are using ( apns or fcm ) and the device token (here: your_pns_device_token ) that you received from you push notification service provider (as described in Registering with Push Service provider ). Those two options are the only ones required, but there are some others that are optional: mode - which may be either prod or dev (default to prod ). Decides which connection pool type on MongoosePush shall be used. This may be used when APNS on MongoosePush is configured to work with both production and development certificate. click_action - action to perform when notification is clicked on the device. activity on Android and category on iOS . Please refer to your platform / push notification service provider for more info. topic - currently only used with APNS . the value is passed to APNS as topic header. For more information please refer to APNS documentation. silent - if set to true , all notifications will be \"silent\". This means that only data payload will be send to push notifications provider with no notification. The data payload will contain all notification fields as defined in XEP-0357 .","title":"Enabling push notifications"},{"location":"user-guide/Push-notifications/#disabling-push-notifications","text":"Disabling push notifications is very simple. Just send the following stanza to your XMPP chat server: <iq type='set' id='x44'> <disable xmlns='urn:xmpp:push:0' jid='pubsub.mypubsub.com' node='punsub_node_for_my_private_iphone'/> </iq> You may skip the node='punsub_node_for_my_private_iphone' to globally disable push notifications on all nodes that are registered from your JID . This may be used to disbale push notifications on all your devices.","title":"Disabling push notifications"},{"location":"user-guide/iOS_tutorial/","text":"Build a complete iOS messaging app using XMPPFramework Read our blog posts: * Build a complete iOS messaging app using XMPPFramework - Tutorial Part 1 * Build a complete iOS messaging app using XMPPFramework - Part 2 YAXT??! Yet another XMPP tutorial? Well, this is going to be another tutorial, but I\u2019m going to try to make it a little bit different. This is an XMPP tutorial from an iOS developer\u2019s perspective. I\u2019ll try to answer all the questions I had when I started working in this area. This journey is going to go from no XMPP knowldege at all to having a fully functional instant messaging iOS appusing this cool protocol. We are going to be using the super awesome (yet overwhelming at the beginning\u2026) XMPPFramework library, and the idea is also to also mix in some iOS concepts that you are going to need for your app. What\u2019s XMPP? From Wikipedia : Extensible Messaging and Presence Protocol (XMPP) is a communications protocol for message-oriented middleware based on XML. This basically means XMPP is a protocol for exchanging stuff. What kind of stuff? Messages and presences. We all know what messages are, but what about presences? A presence is just a way of sharing a \u201cstatus\u201d, that\u2019s it. You can be \u2018online\u2019, 'offline\u2019, 'having lunch\u2019, or whatever you want. Also there\u2019s another important word: Extensible meaning it can grow. It started as an instant messaging protocol and it has grown into multiple fields for example IoT (Internet of Things). And last, but not least: every piece of information we are going to exchange under this protocol is going to be XML. I can heard you complaining but\u2026 Come on, it\u2019s not that bad! Why do we need XMPP? Why not just REST? Well what other options do we have? On the one hand, a custom solution means building everything from scratch, that takes time. On the other hand, we have XMPP, a super tested technology broadly used by millions of people every day, so we can say that\u2019s an advantage over a custom approach. Everytime I talk about XMPP, someone asks me 'Why not just REST?\u2019. Well, there is a misconception here. REST is not a protocol, it\u2019s just a way of architecting a networked application; it\u2019s just a standarized way of doing something (that I love btw). So let\u2019s change the question to something that makes more sense: \u201cWhy not just build a custom REST chat application?\u201d. The first thing that comes to my mind is what I already explained in the previous paragraph, but there is something else. How do I know when someone has sent me a message? For XMPP this is trivial: we have an open connection all the time so, as soon as a message arrives to the server, it will send us the message. We have a full-duplex. On the other hand, the only solution with REST is polling. We will need to ask the server for new messages from time to time to see if there is something new for us. That sucks. So, we will have to add a mechanism that allows us to receive the messages as soon as they are created, like SSE or WebSockets. There is one more XMPP advantage over a custom REST chat application. REST uses HTTP, an application level protocol that is built on top of a transport level protocol: TCP. So everytime you want to use your REST solution, you will need HTTP, a protocol that is not always available everywhere (maybe you need to embed this in a cheap piece of hardware?). Besides, we have XMPP built on top of TCP that\u2019s going to be always available. What\u2019s the basic stuff I need to know to get started? Well, you know a lot already but let\u2019s make a list. Lists are always good: XMPP is built on top of TCP. It keeps an open connection all the time. Client/Server architecture. Messages always go through a server. Everything we send and receive is going to be XML and it\u2019s called Stanza. We have three different types of stanzas: iq, message and presence. Every individual on the XMPP network is univocally identified by a JID (Jabber ID). All the stanzas are cointained in a Stream. Let\u2019s imagine the Stream as a white canvas where you and the server write the stanzas. Stream, iq, message and presence are the core of XMPP. You can find everything perfectly detailed in RFC6120 XMPP can be extended to accomplish different stuff. Each extension is called XEP (XMPP Extension Protocol). What\u2019s a JID? Jabber ID (JID) is how we univocally identify each individual in XMPP. It is the address to where we are going to send our stanzas. This is how a JID looks like: localpart : This is your username. domainpart : Server name where the localpart resides. resourcepart : This is optional, and it identifies a particular client for the user. For example: I can be logged in with andres@erlang-solutions.com on my iPhone, on my Android and on my mac at the same time\u2026 So all these will be the same localpart + domainpart but different resourcepart I\u2019m sure you have already noticed how similar the JID looks to a standard email address. This is because you can connect multiple servers together and the messages are rooted to the right user in the right server, just as email works. Pretty cool, right? Sometimes you will see we have a JID with just the domain part. Why?! Because it\u2019s also possible to send stanzas to a service instead of a user. A service? What\u2019s a service?! Services are different pieces of an XMPP server that offer you some special functionality, but don\u2019t worry about this right now, just remember: you can have JIDs without a localpart. What\u2019s a Stanza? Stanza is the name of the XML pieces that we are going to be sending and receiving. The defined stanzas are: <message/> , <presence/> and <iq/> . <message/> This is a basic <message/> stanza. Everytime you want to send a message to someone (a JID), you will have to send this stanza: <message from='andres@erlang-solutions.com/iphone' to='juana@erlang-solutions.com' type='chat'> <body>Hey there!</body> </message> ``` ### `<iq/>` It stands for Info/Query. It\u2019s a query-action mechanism, you send an `iq` and you will get a response to that query. You can pair the `iq-query` with the `iq-response` using the stanza id. For example, we send an `iq` to the server to do something (don\u2019t pay attention to what we want to do\u2026 you just need to know there is an `iq` stanza and how the mechanism works): ```xml <iq to='erlang-solutions.com' type='get' id='1'> <query xmlns='http://jabber.org/protocol/disco#items'/> </iq> And we get back another iq with the same id with the result of the previous query: <iq from='erlang-solutions.com' to='ramabit@erlang-solutions.com/Andress-MacBook-Air' id='1' type='result'> <query xmlns='http://jabber.org/protocol/disco#items'> <item jid='muc.erlang-solutions.com'/> <item jid='muclight.erlang-solutions.com'/> <item jid='pubsub.erlang-solutions.com'/> </query> </iq> <presence/> Used to exchange presence information, as you could have imagined. Usually presences are sent from the client to the server and broadcasted by it. The most basic, yet valid presence, to indicate to the server that a user is avaiable is: <presence/> After a sucessfull connection, you are not going to receive any <message/> until you make yourself available sending the previous presence. If you want to make yourself unavailable, you just have to send: <presence type=\"unavailable\"></presence> If we want to make the presences more useful, we can send something like this: <presence> <status>On vacation</status> </presence> What\u2019s a Stream? Before answering this, let\u2019s refresh our mind. What\u2019s a Unix socket? From Wikipedia: A socket is a special file used for inter-process communication. These allows communication between two processes. So a socket is a file that can be written by two processes (in the same computer or in different computers in the same network). So the client is going to write to this file and server too. Ok, but how is a socket related to a Stream? Well, we are going to be connected to a server using a socket, therefore we are going to have a 'shared file\u2019 between the client and the server. This shared file is a white canvas where we are going to start writting our XML stanzas. The first thing we are going to write to this file is an opening <stream> tag! And there you go\u2026 that\u2019s our stream. Perfect, I understand what a stream is, but I still don\u2019t understand how to send a message to the server. Well, the only thing we need to do to send a message is writting a stanza in our shared file. But what happens when the server wants to send me a message? Simple: it will write the message in the 'shared file\u2019. Are we ok so far? I\u2019m sure at this point you have questions like: \u201cWhat?! An active TCP connection open all the time? I\u2019m used to REST! How am I going to do that?!\u201d Easy, you don\u2019t have to care about that any more! That\u2019s why we are going to use the library, and it will take care of that. \u201cYou said nothing about how to connect to the server!\u201d Believe me, you don\u2019t have to care about this either. If we start adding all this info, we are going to get crazy. Trust me, I\u2019ve been there. \u201cWhat about encrypted messages? We need security! How are we going to handle this?\u201d Again, you don\u2019t have to care about this at this point. Baby steps! You just need to be able to answer: \u201cWhat\u2019s XMPP?\u201d, \u201cHow do you send a message?\u201d, \u201cHow do you change your status in XMPP?\u201d, \u201cHow do you ask something to the server?\u201d, \u201cWhat\u2019s a Stream?\u201d. If you can answer all that, you are WAY better than me when I started. First steps: installing the XMPPFramework library Let\u2019s create a brand new Xcode project and install the library. In this tutorial we are going to be using Swift 3 . The easiest way to integrate XMPPFramework to the project is using CocoaPods . Let\u2019s create our Podfile using the pod init command in the folder where our .xcodeproj lives. There are thousands of forks but the maintained one is the original: robbiehanson/XMPPFramework . So let\u2019s add the pod to our Podfile and remember to uncomment the use_frameworks! . use_frameworks! target 'CrazyMessages' do pod 'XMPPFramework', :git=> 'git@github.com:robbiehanson/XMPPFramework.git', :branch => 'master' end Then pod install and CocoaPods is going to do its magic and create a .xcworkspace with the library integrated. Now we just need to import XMPPFramework in the files we want to use the library and that\u2019s it. Starting to build our Instant Messaging app The most important thing in an XMPP application is the stream, that\u2019s where we are going to \u201cwrite\u201d our stanzas, so we need an object that is going to hold it. We are going to create an XMPPController class with an XMPPStream : import Foundation import XMPPFramework class XMPPController: NSObject { var xmppStream: XMPPStream init() { self.xmppStream = XMPPStream() } } We are dealing with a highly asynchronous library here. For every action we are going to have a response some time in the future. To handle this XMPPFramework defines the XMPPStreamDelegate . So implementing that delegate is going to help us answer lots of different questions like: \u201cHow do I know when XMPP has successfully connected?\u201d, \u201cHow do I know if I\u2019m correctly authenticated?\u201d, \u201cHow do I know if I received a message?\u201d. XMPPStreamDelegate is your friend! So we have our XMPPController and our XMPPStream , what do we need to do now? Configure our stream with the hostName , port and ourJID . To provide all this info to the controller we are going to make some changes to the init to be able to receive all these parameters: enum XMPPControllerError: Error { case wrongUserJID } class XMPPController: NSObject { var xmppStream: XMPPStream let hostName: String let userJID: XMPPJID let hostPort: UInt16 let password: String init(hostName: String, userJIDString: String, hostPort: UInt16 = 5222, password: String) throws { guard let userJID = XMPPJID(string: userJIDString) else { throw XMPPControllerError.wrongUserJID } self.hostName = hostName self.userJID = userJID self.hostPort = hostPort self.password = password // Stream Configuration self.xmppStream = XMPPStream() self.xmppStream.hostName = hostName self.xmppStream.hostPort = hostPort self.xmppStream.startTLSPolicy = XMPPStreamStartTLSPolicy.allowed self.xmppStream.myJID = userJID super.init() self.xmppStream.addDelegate(self, delegateQueue: DispatchQueue.main) } } Our next step is going to actually connect to a server and authenticate using our userJID and password , so we are adding a connect method to our XMPPController . func connect() { if !self.xmppStream.isDisconnected() { return } try! self.xmppStream.connect(withTimeout: XMPPStreamTimeoutNone) } But how do we know we have successfully connected to the server? As I said earlier, we need to check for a suitable delegate method from XMPPStreamDelegate . After we connect to the server we need to authenticate so we are going to do the following: extension XMPPController: XMPPStreamDelegate { func xmppStreamDidConnect(_ stream: XMPPStream!) { print(\"Stream: Connected\") try! stream.authenticate(withPassword: self.password) } func xmppStreamDidAuthenticate(_ sender: XMPPStream!) { self.xmppStream.send(XMPPPresence()) print(\"Stream: Authenticated\") } } We need to test this. Let\u2019s just create an instance of XMPPController in the AppDelegate to test how it works: try! self.xmppController = XMPPController(hostName: \"host.com\", userJIDString: \"user@host.com\", password: \"password\") self.xmppController.connect() If everything goes fine we should see two messages in the logs but of course that\u2019s not happening, we missed something. We never told to our xmppStream who was the delegate object! We need to add the following line after the super.init() self.xmppStream.addDelegate(self, delegateQueue: DispatchQueue.main) If we run the app again: Stream: Connected Stream: Authenticated Success! We have our own XMPPController with a fully functional and authenticated stream! Something that may catch your attention is how we are setting our delegate, we are not doing: self.xmppStream.delegate = self Why not? Because we can \u201cbroadcast\u201d the events to multiple delegates, we can have 10 different objects implementing those methods. Also we can tell what\u2019s the thread where we want to receive that call, in the previous example we want it in the main thread. Getting a Log In Our app is super ugly, let\u2019s put on some makeup! We have nothing but an XMPPController and a hardcoded call in the AppDelegate . I\u2019m going to create a ViewController that is going to be presented modally as soon as the app starts, that ViewController will have the neccesary fields/info to log in to the server. I\u2019m going to create a LogInViewControllerDelegate that is going to tell to our ViewController that the Log in button was pressed and that\u2019s it. In that delegate implementation we are going to create our XMPPController , add the ViewControlleras delegate of the XMPPStream and connect! extension ViewController: LogInViewControllerDelegate { func didTouchLogIn(sender: LogInViewController, userJID: String, userPassword: String, server: String) { self.logInViewController = sender do { try self.xmppController = XMPPController(hostName: server, userJIDString: userJID, password: userPassword) self.xmppController.xmppStream.addDelegate(self, delegateQueue: DispatchQueue.main) self.xmppController.connect() } catch { sender.showErrorMessage(message: \"Something went wrong\") } } } Why are we adding ViewController as a delegate of XMPPStream if our XMPPController alreay has that delegate implemented? Because we need to know if this connection and authentication was successfull or notin our ViewController so we are able to dismiss the LogInViewController or show an error message if something failed. This is why being able to add multiple delegates is so useful. So as I said I\u2019m going to make ViewController to comform to the XMPPStreamDelegate : extension ViewController: XMPPStreamDelegate { func xmppStreamDidAuthenticate(_ sender: XMPPStream!) { self.logInViewController?.dismiss(animated: true, completion: nil) } func xmppStream(_ sender: XMPPStream!, didNotAuthenticate error: DDXMLElement!) { self.logInViewController?.showErrorMessage(message: \"Wrong password or username\") } } And that\u2019s it! Our app can log in to our server as I\u2019m showing here: Logging! We\u2019ve been talking a lot about XMPP, stanzas and streams\u2026 but is there a way I can see the stream? Yes SR! XMPPFramework got us covered! XMPPFramework ships with CocoaLumberJack , a pretty well known logging framework. We just need to configure it, set the logging level we want and that\u2019s it. Logs are going to start showing up! Configuring CocoaLumberjack This is a really simple task, you just need to add to your func application(application: UIApplication, didFinishLaunchingWithOptions ... method the following line (remember to import CocoaLumberjack ): DDLog.add(DDTTYLogger.sharedInstance(), with: DDLogLevel.all) I\u2019m not going to paste here all the connection process log because it makes no sense to try to understand what\u2019s going on at this stage of our learning. But I think showing what some stanzas look like is a good idea. To do this I\u2019m going to be sending messages from Adium . I\u2019m going to send this <message/> : <message to=\"test.user@erlang-solutions.com\"> <body>This is a message sent from Adium!</body> </message> Let\u2019s see how it looks like when it reaches our app: <message xmlns=\"jabber:client\" from=\"iamadium@erlang-solutions.com/MacBook-Air\" to=\"test.user@erlang-solutions.com\"> <body>This is a message sent from Adium!</body> </message> Let\u2019s send a <presence/> from Adium: <presence> <status>On vacation</status> </presence> We are receiving: <presence xmlns=\"jabber:client\" from=\"iamadium@erlang-solutions.com/MacBook-Air\" to=\"test.user@erlang-solutions.com\"> <status>On vacation</status> </presence> No doubts at all right? We send something and we receive it on the other end! That\u2019s it! Test Time! I want to be sure that you are understanding and following everything and not just copy and pasting from a tutorial (as I usually do \ud83d\ude4a). So if you are able to answer these questions you are on a good track! Why am I sending a presence after successfully authenticating? What happens if I don\u2019t send it? What happens if I write a wrong server URL in the Log In form? How do I fix this problem if there is a problem\u2026 How do I detect if suddenly the stream is disconnected from the server? (maybe a network outage?) How do I detect if the user/password was wrong? If you need help leave a message!","title":"How to Build an iOS messaging app"},{"location":"user-guide/iOS_tutorial/#build-a-complete-ios-messaging-app-using-xmppframework","text":"Read our blog posts: * Build a complete iOS messaging app using XMPPFramework - Tutorial Part 1 * Build a complete iOS messaging app using XMPPFramework - Part 2","title":"Build a complete iOS messaging app using XMPPFramework"},{"location":"user-guide/iOS_tutorial/#yaxt-yet-another-xmpp-tutorial","text":"Well, this is going to be another tutorial, but I\u2019m going to try to make it a little bit different. This is an XMPP tutorial from an iOS developer\u2019s perspective. I\u2019ll try to answer all the questions I had when I started working in this area. This journey is going to go from no XMPP knowldege at all to having a fully functional instant messaging iOS appusing this cool protocol. We are going to be using the super awesome (yet overwhelming at the beginning\u2026) XMPPFramework library, and the idea is also to also mix in some iOS concepts that you are going to need for your app.","title":"YAXT??! Yet another XMPP tutorial?"},{"location":"user-guide/iOS_tutorial/#whats-xmpp","text":"From Wikipedia : Extensible Messaging and Presence Protocol (XMPP) is a communications protocol for message-oriented middleware based on XML. This basically means XMPP is a protocol for exchanging stuff. What kind of stuff? Messages and presences. We all know what messages are, but what about presences? A presence is just a way of sharing a \u201cstatus\u201d, that\u2019s it. You can be \u2018online\u2019, 'offline\u2019, 'having lunch\u2019, or whatever you want. Also there\u2019s another important word: Extensible meaning it can grow. It started as an instant messaging protocol and it has grown into multiple fields for example IoT (Internet of Things). And last, but not least: every piece of information we are going to exchange under this protocol is going to be XML. I can heard you complaining but\u2026 Come on, it\u2019s not that bad!","title":"What\u2019s XMPP?"},{"location":"user-guide/iOS_tutorial/#why-do-we-need-xmpp-why-not-just-rest","text":"Well what other options do we have? On the one hand, a custom solution means building everything from scratch, that takes time. On the other hand, we have XMPP, a super tested technology broadly used by millions of people every day, so we can say that\u2019s an advantage over a custom approach. Everytime I talk about XMPP, someone asks me 'Why not just REST?\u2019. Well, there is a misconception here. REST is not a protocol, it\u2019s just a way of architecting a networked application; it\u2019s just a standarized way of doing something (that I love btw). So let\u2019s change the question to something that makes more sense: \u201cWhy not just build a custom REST chat application?\u201d. The first thing that comes to my mind is what I already explained in the previous paragraph, but there is something else. How do I know when someone has sent me a message? For XMPP this is trivial: we have an open connection all the time so, as soon as a message arrives to the server, it will send us the message. We have a full-duplex. On the other hand, the only solution with REST is polling. We will need to ask the server for new messages from time to time to see if there is something new for us. That sucks. So, we will have to add a mechanism that allows us to receive the messages as soon as they are created, like SSE or WebSockets. There is one more XMPP advantage over a custom REST chat application. REST uses HTTP, an application level protocol that is built on top of a transport level protocol: TCP. So everytime you want to use your REST solution, you will need HTTP, a protocol that is not always available everywhere (maybe you need to embed this in a cheap piece of hardware?). Besides, we have XMPP built on top of TCP that\u2019s going to be always available.","title":"Why do we need XMPP? Why not just REST?"},{"location":"user-guide/iOS_tutorial/#whats-the-basic-stuff-i-need-to-know-to-get-started","text":"Well, you know a lot already but let\u2019s make a list. Lists are always good: XMPP is built on top of TCP. It keeps an open connection all the time. Client/Server architecture. Messages always go through a server. Everything we send and receive is going to be XML and it\u2019s called Stanza. We have three different types of stanzas: iq, message and presence. Every individual on the XMPP network is univocally identified by a JID (Jabber ID). All the stanzas are cointained in a Stream. Let\u2019s imagine the Stream as a white canvas where you and the server write the stanzas. Stream, iq, message and presence are the core of XMPP. You can find everything perfectly detailed in RFC6120 XMPP can be extended to accomplish different stuff. Each extension is called XEP (XMPP Extension Protocol).","title":"What\u2019s the basic stuff I need to know to get started?"},{"location":"user-guide/iOS_tutorial/#whats-a-jid","text":"Jabber ID (JID) is how we univocally identify each individual in XMPP. It is the address to where we are going to send our stanzas. This is how a JID looks like: localpart : This is your username. domainpart : Server name where the localpart resides. resourcepart : This is optional, and it identifies a particular client for the user. For example: I can be logged in with andres@erlang-solutions.com on my iPhone, on my Android and on my mac at the same time\u2026 So all these will be the same localpart + domainpart but different resourcepart I\u2019m sure you have already noticed how similar the JID looks to a standard email address. This is because you can connect multiple servers together and the messages are rooted to the right user in the right server, just as email works. Pretty cool, right? Sometimes you will see we have a JID with just the domain part. Why?! Because it\u2019s also possible to send stanzas to a service instead of a user. A service? What\u2019s a service?! Services are different pieces of an XMPP server that offer you some special functionality, but don\u2019t worry about this right now, just remember: you can have JIDs without a localpart.","title":"What\u2019s a JID?"},{"location":"user-guide/iOS_tutorial/#whats-a-stanza","text":"Stanza is the name of the XML pieces that we are going to be sending and receiving. The defined stanzas are: <message/> , <presence/> and <iq/> .","title":"What\u2019s a Stanza?"},{"location":"user-guide/iOS_tutorial/#message","text":"This is a basic <message/> stanza. Everytime you want to send a message to someone (a JID), you will have to send this stanza: <message from='andres@erlang-solutions.com/iphone' to='juana@erlang-solutions.com' type='chat'> <body>Hey there!</body> </message> ``` ### `<iq/>` It stands for Info/Query. It\u2019s a query-action mechanism, you send an `iq` and you will get a response to that query. You can pair the `iq-query` with the `iq-response` using the stanza id. For example, we send an `iq` to the server to do something (don\u2019t pay attention to what we want to do\u2026 you just need to know there is an `iq` stanza and how the mechanism works): ```xml <iq to='erlang-solutions.com' type='get' id='1'> <query xmlns='http://jabber.org/protocol/disco#items'/> </iq> And we get back another iq with the same id with the result of the previous query: <iq from='erlang-solutions.com' to='ramabit@erlang-solutions.com/Andress-MacBook-Air' id='1' type='result'> <query xmlns='http://jabber.org/protocol/disco#items'> <item jid='muc.erlang-solutions.com'/> <item jid='muclight.erlang-solutions.com'/> <item jid='pubsub.erlang-solutions.com'/> </query> </iq>","title":"&lt;message/&gt;"},{"location":"user-guide/iOS_tutorial/#presence","text":"Used to exchange presence information, as you could have imagined. Usually presences are sent from the client to the server and broadcasted by it. The most basic, yet valid presence, to indicate to the server that a user is avaiable is: <presence/> After a sucessfull connection, you are not going to receive any <message/> until you make yourself available sending the previous presence. If you want to make yourself unavailable, you just have to send: <presence type=\"unavailable\"></presence> If we want to make the presences more useful, we can send something like this: <presence> <status>On vacation</status> </presence>","title":"&lt;presence/&gt;"},{"location":"user-guide/iOS_tutorial/#whats-a-stream","text":"Before answering this, let\u2019s refresh our mind. What\u2019s a Unix socket? From Wikipedia: A socket is a special file used for inter-process communication. These allows communication between two processes. So a socket is a file that can be written by two processes (in the same computer or in different computers in the same network). So the client is going to write to this file and server too. Ok, but how is a socket related to a Stream? Well, we are going to be connected to a server using a socket, therefore we are going to have a 'shared file\u2019 between the client and the server. This shared file is a white canvas where we are going to start writting our XML stanzas. The first thing we are going to write to this file is an opening <stream> tag! And there you go\u2026 that\u2019s our stream. Perfect, I understand what a stream is, but I still don\u2019t understand how to send a message to the server. Well, the only thing we need to do to send a message is writting a stanza in our shared file. But what happens when the server wants to send me a message? Simple: it will write the message in the 'shared file\u2019.","title":"What\u2019s a Stream?"},{"location":"user-guide/iOS_tutorial/#are-we-ok-so-far","text":"I\u2019m sure at this point you have questions like: \u201cWhat?! An active TCP connection open all the time? I\u2019m used to REST! How am I going to do that?!\u201d Easy, you don\u2019t have to care about that any more! That\u2019s why we are going to use the library, and it will take care of that. \u201cYou said nothing about how to connect to the server!\u201d Believe me, you don\u2019t have to care about this either. If we start adding all this info, we are going to get crazy. Trust me, I\u2019ve been there. \u201cWhat about encrypted messages? We need security! How are we going to handle this?\u201d Again, you don\u2019t have to care about this at this point. Baby steps! You just need to be able to answer: \u201cWhat\u2019s XMPP?\u201d, \u201cHow do you send a message?\u201d, \u201cHow do you change your status in XMPP?\u201d, \u201cHow do you ask something to the server?\u201d, \u201cWhat\u2019s a Stream?\u201d. If you can answer all that, you are WAY better than me when I started.","title":"Are we ok so far?"},{"location":"user-guide/iOS_tutorial/#first-steps-installing-the-xmppframework-library","text":"Let\u2019s create a brand new Xcode project and install the library. In this tutorial we are going to be using Swift 3 . The easiest way to integrate XMPPFramework to the project is using CocoaPods . Let\u2019s create our Podfile using the pod init command in the folder where our .xcodeproj lives. There are thousands of forks but the maintained one is the original: robbiehanson/XMPPFramework . So let\u2019s add the pod to our Podfile and remember to uncomment the use_frameworks! . use_frameworks! target 'CrazyMessages' do pod 'XMPPFramework', :git=> 'git@github.com:robbiehanson/XMPPFramework.git', :branch => 'master' end Then pod install and CocoaPods is going to do its magic and create a .xcworkspace with the library integrated. Now we just need to import XMPPFramework in the files we want to use the library and that\u2019s it.","title":"First steps: installing the XMPPFramework library"},{"location":"user-guide/iOS_tutorial/#starting-to-build-our-instant-messaging-app","text":"The most important thing in an XMPP application is the stream, that\u2019s where we are going to \u201cwrite\u201d our stanzas, so we need an object that is going to hold it. We are going to create an XMPPController class with an XMPPStream : import Foundation import XMPPFramework class XMPPController: NSObject { var xmppStream: XMPPStream init() { self.xmppStream = XMPPStream() } } We are dealing with a highly asynchronous library here. For every action we are going to have a response some time in the future. To handle this XMPPFramework defines the XMPPStreamDelegate . So implementing that delegate is going to help us answer lots of different questions like: \u201cHow do I know when XMPP has successfully connected?\u201d, \u201cHow do I know if I\u2019m correctly authenticated?\u201d, \u201cHow do I know if I received a message?\u201d. XMPPStreamDelegate is your friend! So we have our XMPPController and our XMPPStream , what do we need to do now? Configure our stream with the hostName , port and ourJID . To provide all this info to the controller we are going to make some changes to the init to be able to receive all these parameters: enum XMPPControllerError: Error { case wrongUserJID } class XMPPController: NSObject { var xmppStream: XMPPStream let hostName: String let userJID: XMPPJID let hostPort: UInt16 let password: String init(hostName: String, userJIDString: String, hostPort: UInt16 = 5222, password: String) throws { guard let userJID = XMPPJID(string: userJIDString) else { throw XMPPControllerError.wrongUserJID } self.hostName = hostName self.userJID = userJID self.hostPort = hostPort self.password = password // Stream Configuration self.xmppStream = XMPPStream() self.xmppStream.hostName = hostName self.xmppStream.hostPort = hostPort self.xmppStream.startTLSPolicy = XMPPStreamStartTLSPolicy.allowed self.xmppStream.myJID = userJID super.init() self.xmppStream.addDelegate(self, delegateQueue: DispatchQueue.main) } } Our next step is going to actually connect to a server and authenticate using our userJID and password , so we are adding a connect method to our XMPPController . func connect() { if !self.xmppStream.isDisconnected() { return } try! self.xmppStream.connect(withTimeout: XMPPStreamTimeoutNone) } But how do we know we have successfully connected to the server? As I said earlier, we need to check for a suitable delegate method from XMPPStreamDelegate . After we connect to the server we need to authenticate so we are going to do the following: extension XMPPController: XMPPStreamDelegate { func xmppStreamDidConnect(_ stream: XMPPStream!) { print(\"Stream: Connected\") try! stream.authenticate(withPassword: self.password) } func xmppStreamDidAuthenticate(_ sender: XMPPStream!) { self.xmppStream.send(XMPPPresence()) print(\"Stream: Authenticated\") } } We need to test this. Let\u2019s just create an instance of XMPPController in the AppDelegate to test how it works: try! self.xmppController = XMPPController(hostName: \"host.com\", userJIDString: \"user@host.com\", password: \"password\") self.xmppController.connect() If everything goes fine we should see two messages in the logs but of course that\u2019s not happening, we missed something. We never told to our xmppStream who was the delegate object! We need to add the following line after the super.init() self.xmppStream.addDelegate(self, delegateQueue: DispatchQueue.main) If we run the app again: Stream: Connected Stream: Authenticated Success! We have our own XMPPController with a fully functional and authenticated stream! Something that may catch your attention is how we are setting our delegate, we are not doing: self.xmppStream.delegate = self Why not? Because we can \u201cbroadcast\u201d the events to multiple delegates, we can have 10 different objects implementing those methods. Also we can tell what\u2019s the thread where we want to receive that call, in the previous example we want it in the main thread.","title":"Starting to build our Instant Messaging app"},{"location":"user-guide/iOS_tutorial/#getting-a-log-in","text":"Our app is super ugly, let\u2019s put on some makeup! We have nothing but an XMPPController and a hardcoded call in the AppDelegate . I\u2019m going to create a ViewController that is going to be presented modally as soon as the app starts, that ViewController will have the neccesary fields/info to log in to the server. I\u2019m going to create a LogInViewControllerDelegate that is going to tell to our ViewController that the Log in button was pressed and that\u2019s it. In that delegate implementation we are going to create our XMPPController , add the ViewControlleras delegate of the XMPPStream and connect! extension ViewController: LogInViewControllerDelegate { func didTouchLogIn(sender: LogInViewController, userJID: String, userPassword: String, server: String) { self.logInViewController = sender do { try self.xmppController = XMPPController(hostName: server, userJIDString: userJID, password: userPassword) self.xmppController.xmppStream.addDelegate(self, delegateQueue: DispatchQueue.main) self.xmppController.connect() } catch { sender.showErrorMessage(message: \"Something went wrong\") } } } Why are we adding ViewController as a delegate of XMPPStream if our XMPPController alreay has that delegate implemented? Because we need to know if this connection and authentication was successfull or notin our ViewController so we are able to dismiss the LogInViewController or show an error message if something failed. This is why being able to add multiple delegates is so useful. So as I said I\u2019m going to make ViewController to comform to the XMPPStreamDelegate : extension ViewController: XMPPStreamDelegate { func xmppStreamDidAuthenticate(_ sender: XMPPStream!) { self.logInViewController?.dismiss(animated: true, completion: nil) } func xmppStream(_ sender: XMPPStream!, didNotAuthenticate error: DDXMLElement!) { self.logInViewController?.showErrorMessage(message: \"Wrong password or username\") } } And that\u2019s it! Our app can log in to our server as I\u2019m showing here:","title":"Getting a Log In"},{"location":"user-guide/iOS_tutorial/#logging","text":"We\u2019ve been talking a lot about XMPP, stanzas and streams\u2026 but is there a way I can see the stream? Yes SR! XMPPFramework got us covered! XMPPFramework ships with CocoaLumberJack , a pretty well known logging framework. We just need to configure it, set the logging level we want and that\u2019s it. Logs are going to start showing up!","title":"Logging!"},{"location":"user-guide/iOS_tutorial/#configuring-cocoalumberjack","text":"This is a really simple task, you just need to add to your func application(application: UIApplication, didFinishLaunchingWithOptions ... method the following line (remember to import CocoaLumberjack ): DDLog.add(DDTTYLogger.sharedInstance(), with: DDLogLevel.all) I\u2019m not going to paste here all the connection process log because it makes no sense to try to understand what\u2019s going on at this stage of our learning. But I think showing what some stanzas look like is a good idea. To do this I\u2019m going to be sending messages from Adium . I\u2019m going to send this <message/> : <message to=\"test.user@erlang-solutions.com\"> <body>This is a message sent from Adium!</body> </message> Let\u2019s see how it looks like when it reaches our app: <message xmlns=\"jabber:client\" from=\"iamadium@erlang-solutions.com/MacBook-Air\" to=\"test.user@erlang-solutions.com\"> <body>This is a message sent from Adium!</body> </message> Let\u2019s send a <presence/> from Adium: <presence> <status>On vacation</status> </presence> We are receiving: <presence xmlns=\"jabber:client\" from=\"iamadium@erlang-solutions.com/MacBook-Air\" to=\"test.user@erlang-solutions.com\"> <status>On vacation</status> </presence> No doubts at all right? We send something and we receive it on the other end! That\u2019s it!","title":"Configuring CocoaLumberjack"},{"location":"user-guide/iOS_tutorial/#test-time","text":"I want to be sure that you are understanding and following everything and not just copy and pasting from a tutorial (as I usually do \ud83d\ude4a). So if you are able to answer these questions you are on a good track! Why am I sending a presence after successfully authenticating? What happens if I don\u2019t send it? What happens if I write a wrong server URL in the Log In form? How do I fix this problem if there is a problem\u2026 How do I detect if suddenly the stream is disconnected from the server? (maybe a network outage?) How do I detect if the user/password was wrong? If you need help leave a message!","title":"Test Time!"},{"location":"user-guide/release_config/","text":"Advanced release configuration It's now possible to install MongooseIM from source in two modes: system - it's used internally to generate Linux packages (.deb, .rpm) user - which is the default mode and used for testing on travis and in development You can also build OS specific packages by using the tools in [MongooseIM repo root]/tools/pkg - refer to README.md therein. Configure script The tools/configure script can be used to specify which 3rd party dependencies should be included in the final release or to set the installation prefix and installation mode. More details can found in the tool's help. The help is printed when the script is run without any parameters tools/configure : configure: OPTIONS Specifies which 3rd party deps will be included in the release. Writes configure.out file as output - this file can be sourced with: . configure.out Writes rel/configure.vars.config which can be used as Reltool input. 3rd party apps: with-none include no 3rd party drivers with-all include all drivers with-mysql include mysql driver with-odbc include an ODBC driver (requires unixodbc to compile) with-pgsql include pgsql driver with-redis include redis driver with-riak include riak driver Options: prefix Installation PREFIX directory. Default: /usr/local system Install files into $PREFIX/{bin, etc, ...} instead of a completely self contained release. Default: no user System user to run the server as. Default: This script is also accessible via the make configure target. Example If mysql and redis are the only drivers that should be included in the release, run the following command before make rel : $ ./tools/configure with-mysql with-redis You only need to run the ./tools/configure command once (unless changing the release's config is needed to include some other dependencies). System install To manually test the installation run tools/test-install.sh . This script is intended for careful inspection by a human user, not for automation. Results should be similar to those described below. On Mac: ./tools/configure with-all user=erszcz prefix=/tmp/mim-sandbox-system system=yes cat configure.out rel/configure.vars.config RUNNER_GROUP=staff make install Overriding RUNNER_GROUP on a Mac is necessary, as users by default don't have private groups of the same name as their usernames. Generated build configs: $ cat configure.out rel/configure.vars.config export MONGOOSEIM_CONFIGURED=\"yes\" export APPS=\"mysql eodbc epgsql eredis riakc nksip cqerl tirerl erlcloud\" export PREFIX=\"/tmp/mim-sandbox-system\" export RELTOOL_VARS=\"rel/configure.vars.config\" export SYSTEM=\"yes\" export RUNNER_USER=\"erszcz\" export BIN_DIR=\"$PREFIX/usr/bin\" export ETC_DIR=\"$PREFIX/etc/mongooseim\" export LIB_DIR=\"$PREFIX/usr/lib/mongooseim\" export LOG_DIR=\"$PREFIX/var/log/mongooseim\" export MDB_DIR=\"$PREFIX/var/lib/mongooseim\" export LOCK_DIR=\"$PREFIX/var/lock/mongooseim\" {mongooseim_runner_user, \"erszcz\"}. {mongooseim_script_dir, \"/tmp/mim-sandbox-system/usr/lib/mongooseim/bin\"}. {mongooseim_etc_dir, \"/tmp/mim-sandbox-system/etc/mongooseim\"}. {mongooseim_log_dir, \"/tmp/mim-sandbox-system/var/log/mongooseim\"}. {mongooseim_mdb_dir, \"/tmp/mim-sandbox-system/var/lib/mongooseim\"}. {mongooseim_mdb_dir_toggle, []}. {mongooseim_lock_dir, \"/tmp/mim-sandbox-system/var/lock/mongooseim\"}. Installed tree: $ tree mim-sandbox-system/ -L 3 mim-sandbox-system/ \u251c\u2500\u2500 etc \u2502 \u2514\u2500\u2500 mongooseim \u2502 \u251c\u2500\u2500 app.config \u2502 \u251c\u2500\u2500 mongooseim.cfg \u2502 \u2514\u2500\u2500 vm.args \u251c\u2500\u2500 usr \u2502 \u251c\u2500\u2500 bin \u2502 \u2502 \u2514\u2500\u2500 mongooseimctl \u2502 \u2514\u2500\u2500 lib \u2502 \u2514\u2500\u2500 mongooseim \u2514\u2500\u2500 var \u251c\u2500\u2500 lib \u2502 \u2514\u2500\u2500 mongooseim \u251c\u2500\u2500 lock \u2502 \u2514\u2500\u2500 mongooseim \u2514\u2500\u2500 log \u2514\u2500\u2500 mongooseim 13 directories, 4 files Files which change after starting and stopping such an installation: var/lib/mongooseim/DECISION_TAB.LOG var/lib/mongooseim/LATEST.LOG var/lib/mongooseim/last_activity.DCD var/lib/mongooseim/muc_registered.DCD var/lib/mongooseim/muc_room.DCD var/lib/mongooseim/offline_msg.DAT var/lib/mongooseim/passwd.DCD var/lib/mongooseim/privacy.DCD var/lib/mongooseim/private_storage.DAT var/lib/mongooseim/roster.DCD var/lib/mongooseim/roster_version.DCD var/lib/mongooseim/schema.DAT var/lib/mongooseim/vcard.DAT var/lib/mongooseim/vcard_search.DCD var/log/mongooseim/crash.log var/log/mongooseim/ejabberd.log var/log/mongooseim/erlang.log.1 var/log/mongooseim/run_erl.log Caveats Running make install will blindly overwrite any configs it encounters on its way. Mnesia database and log files are preserved only due to the fact that they're not build process artifacts.","title":"Release/Installation configuration"},{"location":"user-guide/release_config/#advanced-release-configuration","text":"It's now possible to install MongooseIM from source in two modes: system - it's used internally to generate Linux packages (.deb, .rpm) user - which is the default mode and used for testing on travis and in development You can also build OS specific packages by using the tools in [MongooseIM repo root]/tools/pkg - refer to README.md therein.","title":"Advanced release configuration"},{"location":"user-guide/release_config/#configure-script","text":"The tools/configure script can be used to specify which 3rd party dependencies should be included in the final release or to set the installation prefix and installation mode. More details can found in the tool's help. The help is printed when the script is run without any parameters tools/configure : configure: OPTIONS Specifies which 3rd party deps will be included in the release. Writes configure.out file as output - this file can be sourced with: . configure.out Writes rel/configure.vars.config which can be used as Reltool input. 3rd party apps: with-none include no 3rd party drivers with-all include all drivers with-mysql include mysql driver with-odbc include an ODBC driver (requires unixodbc to compile) with-pgsql include pgsql driver with-redis include redis driver with-riak include riak driver Options: prefix Installation PREFIX directory. Default: /usr/local system Install files into $PREFIX/{bin, etc, ...} instead of a completely self contained release. Default: no user System user to run the server as. Default: This script is also accessible via the make configure target.","title":"Configure script"},{"location":"user-guide/release_config/#example","text":"If mysql and redis are the only drivers that should be included in the release, run the following command before make rel : $ ./tools/configure with-mysql with-redis You only need to run the ./tools/configure command once (unless changing the release's config is needed to include some other dependencies).","title":"Example"},{"location":"user-guide/release_config/#system-install","text":"To manually test the installation run tools/test-install.sh . This script is intended for careful inspection by a human user, not for automation. Results should be similar to those described below. On Mac: ./tools/configure with-all user=erszcz prefix=/tmp/mim-sandbox-system system=yes cat configure.out rel/configure.vars.config RUNNER_GROUP=staff make install Overriding RUNNER_GROUP on a Mac is necessary, as users by default don't have private groups of the same name as their usernames. Generated build configs: $ cat configure.out rel/configure.vars.config export MONGOOSEIM_CONFIGURED=\"yes\" export APPS=\"mysql eodbc epgsql eredis riakc nksip cqerl tirerl erlcloud\" export PREFIX=\"/tmp/mim-sandbox-system\" export RELTOOL_VARS=\"rel/configure.vars.config\" export SYSTEM=\"yes\" export RUNNER_USER=\"erszcz\" export BIN_DIR=\"$PREFIX/usr/bin\" export ETC_DIR=\"$PREFIX/etc/mongooseim\" export LIB_DIR=\"$PREFIX/usr/lib/mongooseim\" export LOG_DIR=\"$PREFIX/var/log/mongooseim\" export MDB_DIR=\"$PREFIX/var/lib/mongooseim\" export LOCK_DIR=\"$PREFIX/var/lock/mongooseim\" {mongooseim_runner_user, \"erszcz\"}. {mongooseim_script_dir, \"/tmp/mim-sandbox-system/usr/lib/mongooseim/bin\"}. {mongooseim_etc_dir, \"/tmp/mim-sandbox-system/etc/mongooseim\"}. {mongooseim_log_dir, \"/tmp/mim-sandbox-system/var/log/mongooseim\"}. {mongooseim_mdb_dir, \"/tmp/mim-sandbox-system/var/lib/mongooseim\"}. {mongooseim_mdb_dir_toggle, []}. {mongooseim_lock_dir, \"/tmp/mim-sandbox-system/var/lock/mongooseim\"}. Installed tree: $ tree mim-sandbox-system/ -L 3 mim-sandbox-system/ \u251c\u2500\u2500 etc \u2502 \u2514\u2500\u2500 mongooseim \u2502 \u251c\u2500\u2500 app.config \u2502 \u251c\u2500\u2500 mongooseim.cfg \u2502 \u2514\u2500\u2500 vm.args \u251c\u2500\u2500 usr \u2502 \u251c\u2500\u2500 bin \u2502 \u2502 \u2514\u2500\u2500 mongooseimctl \u2502 \u2514\u2500\u2500 lib \u2502 \u2514\u2500\u2500 mongooseim \u2514\u2500\u2500 var \u251c\u2500\u2500 lib \u2502 \u2514\u2500\u2500 mongooseim \u251c\u2500\u2500 lock \u2502 \u2514\u2500\u2500 mongooseim \u2514\u2500\u2500 log \u2514\u2500\u2500 mongooseim 13 directories, 4 files Files which change after starting and stopping such an installation: var/lib/mongooseim/DECISION_TAB.LOG var/lib/mongooseim/LATEST.LOG var/lib/mongooseim/last_activity.DCD var/lib/mongooseim/muc_registered.DCD var/lib/mongooseim/muc_room.DCD var/lib/mongooseim/offline_msg.DAT var/lib/mongooseim/passwd.DCD var/lib/mongooseim/privacy.DCD var/lib/mongooseim/private_storage.DAT var/lib/mongooseim/roster.DCD var/lib/mongooseim/roster_version.DCD var/lib/mongooseim/schema.DAT var/lib/mongooseim/vcard.DAT var/lib/mongooseim/vcard_search.DCD var/log/mongooseim/crash.log var/log/mongooseim/ejabberd.log var/log/mongooseim/erlang.log.1 var/log/mongooseim/run_erl.log","title":"System install"},{"location":"user-guide/release_config/#caveats","text":"Running make install will blindly overwrite any configs it encounters on its way. Mnesia database and log files are preserved only due to the fact that they're not build process artifacts.","title":"Caveats"}]}